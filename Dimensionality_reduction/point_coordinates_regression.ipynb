{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Triangulation import *\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from  Neural_network import *\n",
    "\n",
    "%matplotlib qt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_set_nb_of_points(point_coordinates):\n",
    "    set_of_numbers=set()\n",
    "    for index,_ in enumerate(point_coordinates):\n",
    "        set_of_numbers.add(len(point_coordinates[index][0]))\n",
    "    return set_of_numbers\n",
    "\n",
    "\n",
    "def get_indices_nb_of_points(set_of_numbers,number_of_points,point_coordinates):\n",
    "    indices=[]\n",
    "    if number_of_points not in set_of_numbers:\n",
    "        return \"No such number of points for sample\"\n",
    "    else:\n",
    "        for index,_ in enumerate(point_coordinates):\n",
    "            if len(point_coordinates[index][0])==number_of_points:\n",
    "                indices.append(index)\n",
    "        return indices\n",
    "    \n",
    "def get_polygons_nb_of_points(indices):\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "polygons=load_dataset('12_polygons.pkl')\n",
    "polygons=[i for i in polygons for j in range(10)]\n",
    "polygons_reshaped=[]\n",
    "for polygon in polygons:\n",
    "    polygons_reshaped.append(polygon.reshape(2,12))\n",
    "\n",
    "polygons_reshaped=np.array(polygons_reshaped)\n",
    "#polygons_reshaped=polygons_reshaped.reshape(60000,24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_coordinates=load_dataset('12_point_coordinates')\n",
    "number_of_insertion_points=load_dataset('12_nb_of_points.pkl')\n",
    "centers_of_mass=load_dataset('12_centers_of_mass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_of_points=get_set_nb_of_points(point_coordinates)        \n",
    "indices=get_indices_nb_of_points(set_of_points,1,point_coordinates)\n",
    "indices=np.asarray(indices)\n",
    "number_of_insertion_points=np.array(number_of_insertion_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "polygons_reshaped.resize(len(point_coordinates),2*12)\n",
    "\n",
    "polygons_reshaped=np.hstack([polygons_reshaped[indices],number_of_insertion_points[indices,1].reshape(len(indices),1) ])\n",
    "#polygons_reshaped=polygons_reshaped[indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_coordinates=[ point_coordinates[i][0] for i in indices]\n",
    "point_coordinates=np.array(point_coordinates)\n",
    "#barycenters,point_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(polygons_reshaped),len(indices)\n",
    "#point_coordinates.shape\n",
    "#centers_of_mass=centers_of_mass.reshape(60000,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_of_test_data=int(len(polygons_reshaped)*0.2)\n",
    "nb_of_training_data=int(len(polygons_reshaped)-nb_of_test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tensor=torch.from_numpy(polygons_reshaped[:nb_of_training_data]).type(torch.FloatTensor)\n",
    "x_tensor_test=torch.from_numpy(polygons_reshaped[nb_of_training_data:]).type(torch.FloatTensor)\n",
    "x_variable,x_variable_test=Variable(x_tensor),Variable(x_tensor_test)\n",
    "\n",
    "y_tensor=torch.from_numpy(point_coordinates[:nb_of_training_data]).type(torch.FloatTensor)\n",
    "y_tensor_test=torch.from_numpy(point_coordinates[nb_of_training_data:]).type(torch.FloatTensor)\n",
    "y_variable,y_variable_test=Variable(y_tensor),Variable(y_tensor_test)\n",
    "\n",
    "\n",
    "\n",
    "shuffle=torch.randperm(x_variable.shape[0])\n",
    "x_variable = x_variable[shuffle]\n",
    "y_variable=y_variable[shuffle]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data length: 174978\n"
     ]
    }
   ],
   "source": [
    "my_net=Net(2*12+1,1*2,nb_of_hidden_layers=3, nb_of_hidden_nodes=40,batch_normalization=True)\n",
    "print(\"Training data length:\",x_variable.size()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(my_net.parameters(), lr=1e-3,weight_decay=0)\n",
    "#optimizer = torch.optim.SGD(my_net.parameters(), lr=1e-5,weight_decay=.5,momentum=0.9)\n",
    "max_distance=0.6108970818704328\n",
    "loss_func =torch.nn.MSELoss(size_average=False) \n",
    "#loss_func=myLossfunction()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda activated\n"
     ]
    }
   ],
   "source": [
    "if  torch.cuda.is_available():\n",
    "    loss_func.cuda()\n",
    "    x_variable , y_variable=x_variable.cuda(), y_variable.cuda()\n",
    "    x_variable_test,y_variable_test= Variable(x_tensor_test.cuda(),volatile=True),Variable(y_tensor_test.cuda(),volatile=True)\n",
    "    print(\"cuda activated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Training Loss: 0.39317632520231116 Test Loss: 0.17085867758292567\n",
      "Epoch: 10 Training Loss: 0.14491973633828253 Test Loss: 0.12781880175709812\n",
      "Epoch: 20 Training Loss: 0.11138427603220119 Test Loss: 0.10534570857217561\n",
      "Epoch: 30 Training Loss: 0.10730795442855673 Test Loss: 0.10512591280375594\n",
      "Epoch: 40 Training Loss: 0.10602773768345164 Test Loss: 0.1050891108816352\n",
      "Epoch: 50 Training Loss: 0.1053702833802678 Test Loss: 0.10508067222433362\n",
      "Epoch: 60 Training Loss: 0.10495881982306347 Test Loss: 0.10506405164136796\n",
      "Epoch: 70 Training Loss: 0.10467170783612798 Test Loss: 0.10507635243547686\n",
      "Epoch: 80 Training Loss: 0.10446492402794923 Test Loss: 0.10508016992330377\n",
      "Epoch: 90 Training Loss: 0.10430646660758781 Test Loss: 0.10508041549269614\n",
      "Epoch: 100 Training Loss: 0.10418070861051104 Test Loss: 0.10508390927541492\n",
      "Epoch: 110 Training Loss: 0.10407956308257324 Test Loss: 0.10508714632649621\n",
      "Epoch: 120 Training Loss: 0.10399854285253003 Test Loss: 0.1050882737132521\n",
      "Epoch: 130 Training Loss: 0.10393084460975094 Test Loss: 0.10508945691123354\n",
      "Epoch: 140 Training Loss: 0.10387309181368515 Test Loss: 0.10509094148983289\n",
      "Epoch: 150 Training Loss: 0.10382248835389306 Test Loss: 0.10509161122453936\n",
      "Epoch: 160 Training Loss: 0.10377831985485318 Test Loss: 0.10509270512455994\n",
      "Epoch: 170 Training Loss: 0.10373970450928116 Test Loss: 0.10509283907150123\n",
      "Epoch: 180 Training Loss: 0.1037051298502526 Test Loss: 0.10509358694192346\n",
      "Epoch: 190 Training Loss: 0.10367363593566048 Test Loss: 0.10509379902458052\n",
      "Epoch: 200 Training Loss: 0.10364515021174091 Test Loss: 0.10509426783887504\n",
      "Epoch: 210 Training Loss: 0.10361862343944667 Test Loss: 0.10509399994499245\n",
      "Epoch: 220 Training Loss: 0.1035945914004189 Test Loss: 0.1050918009827062\n",
      "Epoch: 230 Training Loss: 0.10357237878654744 Test Loss: 0.1050912205459606\n",
      "Epoch: 240 Training Loss: 0.10355177909865812 Test Loss: 0.10509257117761865\n",
      "Epoch: 250 Training Loss: 0.10353311045710033 Test Loss: 0.10509351996845281\n",
      "Epoch: 260 Training Loss: 0.10351551337882477 Test Loss: 0.10509296185619742\n",
      "Epoch: 270 Training Loss: 0.10349864183818823 Test Loss: 0.10509375437560008\n",
      "Epoch: 280 Training Loss: 0.10348262419954223 Test Loss: 0.10509339718375663\n",
      "Epoch: 290 Training Loss: 0.1034675274355919 Test Loss: 0.10509357577967836\n",
      "Epoch: 300 Training Loss: 0.10345314504716308 Test Loss: 0.10509322975008001\n",
      "Epoch: 310 Training Loss: 0.10343900822531975 Test Loss: 0.1050956184705331\n",
      "Epoch: 320 Training Loss: 0.1034251671995908 Test Loss: 0.10509372088886476\n",
      "Epoch: 330 Training Loss: 0.1034113484980969 Test Loss: 0.10509807416445684\n",
      "Epoch: 340 Training Loss: 0.10339829440165335 Test Loss: 0.10509459154398318\n",
      "Epoch: 350 Training Loss: 0.1033854747096778 Test Loss: 0.10509594217564124\n",
      "Epoch: 360 Training Loss: 0.10337287826005269 Test Loss: 0.10509443527255166\n",
      "Epoch: 370 Training Loss: 0.10336063899818834 Test Loss: 0.10509464735520871\n",
      "Epoch: 380 Training Loss: 0.1033482546287962 Test Loss: 0.10509484827562066\n",
      "Epoch: 390 Training Loss: 0.10333622744716478 Test Loss: 0.10509637750320044\n",
      "Epoch: 400 Training Loss: 0.10332457977752918 Test Loss: 0.10509639982769066\n",
      "Epoch: 410 Training Loss: 0.10331354602435734 Test Loss: 0.10509509384501303\n",
      "Epoch: 420 Training Loss: 0.1033028192294174 Test Loss: 0.105096745857289\n",
      "Epoch: 430 Training Loss: 0.10329207011024243 Test Loss: 0.1050967346950439\n",
      "Epoch: 440 Training Loss: 0.10328157771977048 Test Loss: 0.10509766116138784\n",
      "Epoch: 450 Training Loss: 0.10327105184294597 Test Loss: 0.10509629936748469\n",
      "Epoch: 460 Training Loss: 0.10326057619565031 Test Loss: 0.10509709188688734\n",
      "Epoch: 470 Training Loss: 0.10325016194000103 Test Loss: 0.10509796254200576\n",
      "Epoch: 480 Training Loss: 0.10323999325093726 Test Loss: 0.10509817462466281\n",
      "Epoch: 490 Training Loss: 0.10323015942539919 Test Loss: 0.10509820811139814\n",
      "Epoch: 500 Training Loss: 0.10322049861268273 Test Loss: 0.10509734861852482\n",
      "Epoch: 510 Training Loss: 0.10321079315149619 Test Loss: 0.10509757186342698\n",
      "Epoch: 520 Training Loss: 0.10320100955548697 Test Loss: 0.10509856530324159\n",
      "Epoch: 530 Training Loss: 0.1031911757299489 Test Loss: 0.10509877738589864\n",
      "Epoch: 540 Training Loss: 0.10318126935064693 Test Loss: 0.10509733745627972\n",
      "Epoch: 550 Training Loss: 0.10317153040310782 Test Loss: 0.10509735978076994\n",
      "Epoch: 560 Training Loss: 0.10316183052298003 Test Loss: 0.10509752721444655\n",
      "Epoch: 570 Training Loss: 0.10315233156096766 Test Loss: 0.10509624355625914\n",
      "Epoch: 580 Training Loss: 0.10314306142236453 Test Loss: 0.10509555149706246\n",
      "Epoch: 590 Training Loss: 0.10313383035117273 Test Loss: 0.10509577474196462\n",
      "Epoch: 600 Training Loss: 0.10312472764433243 Test Loss: 0.10509500454705217\n",
      "Epoch: 610 Training Loss: 0.10311545750572929 Test Loss: 0.10509864343895735\n",
      "Epoch: 620 Training Loss: 0.10310621527241996 Test Loss: 0.1050984425185454\n",
      "Epoch: 630 Training Loss: 0.10309712930875596 Test Loss: 0.10509794021751555\n",
      "Epoch: 640 Training Loss: 0.10308802660191567 Test Loss: 0.10509792905527043\n",
      "Epoch: 650 Training Loss: 0.10307868949060739 Test Loss: 0.10509846484303562\n",
      "Epoch: 660 Training Loss: 0.10306934679824035 Test Loss: 0.10509783975730957\n",
      "Epoch: 670 Training Loss: 0.10306026641563511 Test Loss: 0.10509831973384921\n",
      "Epoch: 680 Training Loss: 0.10305128091102882 Test Loss: 0.10509894481957525\n",
      "Epoch: 690 Training Loss: 0.10304225075795242 Test Loss: 0.10510028428898821\n",
      "Epoch: 700 Training Loss: 0.10303317037534719 Test Loss: 0.10510134470227346\n",
      "Epoch: 710 Training Loss: 0.1030236881565111 Test Loss: 0.10510639003706222\n",
      "Epoch: 720 Training Loss: 0.10301420593767502 Test Loss: 0.10510419107477596\n",
      "Epoch: 730 Training Loss: 0.10300467907036885 Test Loss: 0.10509953641856598\n",
      "Epoch: 740 Training Loss: 0.10299504058188744 Test Loss: 0.10509983779918389\n",
      "Epoch: 750 Training Loss: 0.10298547464716994 Test Loss: 0.1051022488441272\n",
      "Epoch: 760 Training Loss: 0.10297602591468642 Test Loss: 0.10510092053695935\n",
      "Epoch: 770 Training Loss: 0.10296657718220291 Test Loss: 0.10509722583382863\n",
      "Epoch: 780 Training Loss: 0.10295675451878236 Test Loss: 0.10510022847776267\n",
      "Epoch: 790 Training Loss: 0.10294684813948039 Test Loss: 0.10509988244816432\n",
      "Epoch: 800 Training Loss: 0.10293693617911966 Test Loss: 0.10510059683185123\n",
      "Epoch: 810 Training Loss: 0.10292744837922482 Test Loss: 0.10510344320435373\n",
      "Epoch: 820 Training Loss: 0.10291794941721245 Test Loss: 0.10510314182373583\n",
      "Epoch: 830 Training Loss: 0.10290807094320428 Test Loss: 0.10510009453082136\n",
      "Epoch: 840 Training Loss: 0.10289801387531576 Test Loss: 0.10510144516247942\n",
      "Epoch: 850 Training Loss: 0.10288769449766542 Test Loss: 0.10510026196449798\n",
      "Epoch: 860 Training Loss: 0.1028772858230749 Test Loss: 0.10509975966346813\n",
      "Epoch: 870 Training Loss: 0.10286638601531335 Test Loss: 0.10510069729205719\n",
      "Epoch: 880 Training Loss: 0.102855458302258 Test Loss: 0.10510241627780381\n",
      "Epoch: 890 Training Loss: 0.10284437990061608 Test Loss: 0.10510188049003863\n",
      "Epoch: 900 Training Loss: 0.10283311174297625 Test Loss: 0.10510355482680482\n",
      "Epoch: 910 Training Loss: 0.10282192730121786 Test Loss: 0.10510503940540417\n",
      "Epoch: 920 Training Loss: 0.10281088796698727 Test Loss: 0.10510415758804065\n",
      "Epoch: 930 Training Loss: 0.10279985979487422 Test Loss: 0.1051028292808728\n",
      "Epoch: 940 Training Loss: 0.10278865302888078 Test Loss: 0.10510555286867913\n",
      "Epoch: 950 Training Loss: 0.10277747416818114 Test Loss: 0.10510675839115079\n",
      "Epoch: 960 Training Loss: 0.10276611113254237 Test Loss: 0.10510505056764928\n",
      "Epoch: 970 Training Loss: 0.10275462531361085 Test Loss: 0.10510483848499223\n",
      "Epoch: 980 Training Loss: 0.10274338506126485 Test Loss: 0.10510683652686655\n",
      "Epoch: 990 Training Loss: 0.10273158670304267 Test Loss: 0.10510835459220122\n",
      "Epoch: 1000 Training Loss: 0.10271959300776383 Test Loss: 0.10510092053695935\n",
      "Epoch: 1010 Training Loss: 0.10270785604118804 Test Loss: 0.1051113014249097\n",
      "Epoch: 1020 Training Loss: 0.10269629766849261 Test Loss: 0.10511414779741221\n",
      "Epoch: 1030 Training Loss: 0.1026848676601487 Test Loss: 0.10510301903903964\n",
      "Epoch: 1040 Training Loss: 0.10267304139663272 Test Loss: 0.105109470816712\n",
      "Epoch: 1050 Training Loss: 0.10266125420052806 Test Loss: 0.10509748256546612\n",
      "Epoch: 1060 Training Loss: 0.10264972931418521 Test Loss: 0.10510899084017236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1070 Training Loss: 0.10263838302172273 Test Loss: 0.10511232835145963\n",
      "Epoch: 1080 Training Loss: 0.10262715951255301 Test Loss: 0.10511414779741221\n",
      "Epoch: 1090 Training Loss: 0.10261576299056167 Test Loss: 0.1051097498728397\n",
      "Epoch: 1100 Training Loss: 0.10260493015550526 Test Loss: 0.105114125472922\n",
      "Epoch: 1110 Training Loss: 0.10259386291598087 Test Loss: 0.10510909130037834\n",
      "Epoch: 1120 Training Loss: 0.10258247197504829 Test Loss: 0.10511366782087257\n",
      "Epoch: 1130 Training Loss: 0.10257077407588383 Test Loss: 0.10511226137798899\n",
      "Epoch: 1140 Training Loss: 0.10255897571766165 Test Loss: 0.10510584308705194\n",
      "Epoch: 1150 Training Loss: 0.10254750664190641 Test Loss: 0.10510993963100654\n",
      "Epoch: 1160 Training Loss: 0.10253664032049743 Test Loss: 0.10511433755557906\n",
      "Epoch: 1170 Training Loss: 0.10252620374061311 Test Loss: 0.10510491662070798\n",
      "Epoch: 1180 Training Loss: 0.10251594575460915 Test Loss: 0.1051064904972682\n",
      "Epoch: 1190 Training Loss: 0.10250614541542365 Test Loss: 0.10510924757180985\n",
      "Epoch: 1200 Training Loss: 0.10249665761552881 Test Loss: 0.10510492778295309\n",
      "Epoch: 1210 Training Loss: 0.10248718655881026 Test Loss: 0.10509960339203663\n",
      "Epoch: 1220 Training Loss: 0.10247798339291225 Test Loss: 0.10511000660447718\n",
      "Epoch: 1230 Training Loss: 0.10246919322536262 Test Loss: 0.1051089015422115\n",
      "Epoch: 1240 Training Loss: 0.1024597444928791 Test Loss: 0.1051041017768151\n",
      "Epoch: 1250 Training Loss: 0.10245045761109968 Test Loss: 0.10510026196449798\n",
      "Epoch: 1260 Training Loss: 0.10244102004073369 Test Loss: 0.10509945828285022\n",
      "Epoch: 1270 Training Loss: 0.1024318894285996 Test Loss: 0.10511179256369445\n",
      "Epoch: 1280 Training Loss: 0.10242241279082227 Test Loss: 0.10509916806447742\n",
      "Epoch: 1290 Training Loss: 0.1024130310310439 Test Loss: 0.10511352271168617\n",
      "Epoch: 1300 Training Loss: 0.10240338696150374 Test Loss: 0.10511268554330308\n",
      "Epoch: 1310 Training Loss: 0.10239379312149241 Test Loss: 0.10510010569306648\n",
      "Epoch: 1320 Training Loss: 0.10238397045807188 Test Loss: 0.10509846484303562\n",
      "Epoch: 1330 Training Loss: 0.10237393013335962 Test Loss: 0.10509904527978123\n",
      "Epoch: 1340 Training Loss: 0.10236382283594224 Test Loss: 0.10508447854991541\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-0ea4af3e8d5b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_variable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmy_net\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_variable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnarrow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m                 \u001b[1;31m# input x and predict based on x\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_variable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnarrow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m     \u001b[1;31m# must be (1. nn output, 2. target), the target label is NOT one-hotted\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[1;31m#loss=loss_func.apply(out, y_variable.narrow(0,b,batch_size).resize(batch_size,2))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 357\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    358\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    377\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m         \u001b[0m_assert_no_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 379\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize_average\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    380\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[1;34m(input, target, size_average, reduce)\u001b[0m\n\u001b[0;32m   1280\u001b[0m     \"\"\"\n\u001b[0;32m   1281\u001b[0m     return _pointwise_loss(lambda a, b: (a - b) ** 2, torch._C._nn.mse_loss,\n\u001b[1;32m-> 1282\u001b[1;33m                            input, target, size_average, reduce)\n\u001b[0m\u001b[0;32m   1283\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36m_pointwise_loss\u001b[1;34m(lambd, lambd_optimized, input, target, size_average, reduce)\u001b[0m\n\u001b[0;32m   1246\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1247\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1248\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlambd_optimized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1249\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size=int(x_variable.size()[0]/2 )\n",
    "nb_of_epochs=13000\n",
    "my_net.cuda()\n",
    "\n",
    "# Train the network #\n",
    "my_net.train()\n",
    "for t in range(nb_of_epochs):\n",
    "    sum_loss=0\n",
    "    for b in range(0,x_variable.size(0),batch_size):\n",
    "        out = my_net(x_variable.narrow(0,b,batch_size))                 # input x and predict based on x\n",
    "        loss = loss_func(out, y_variable.narrow(0,b,batch_size))     # must be (1. nn output, 2. target), the target label is NOT one-hotted\n",
    "        #loss=loss_func.apply(out, y_variable.narrow(0,b,batch_size).resize(batch_size,2))\n",
    "\n",
    "        sum_loss+=loss.data[0]\n",
    "        optimizer.zero_grad()   # clear gradients for next train\n",
    "        loss.backward()         # backpropagation, compute gradients\n",
    "        #print(t,loss.data[0])\n",
    "        optimizer.step()        # apply gradients\n",
    "    if t%10==0:\n",
    "        my_net.eval()\n",
    "        test_loss=loss_func(my_net(x_variable_test),y_variable_test).data[0]\n",
    "        my_net.train()\n",
    "        print(\"Epoch:\",t,\"Training Loss:\",sum_loss/(x_variable.size(0)),\"Test Loss:\",test_loss/x_variable_test.size(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "contour1=np.delete(polygons_reshaped[311],24)\n",
    "\n",
    "contour1=polygons[10].reshape(12,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 0.00646368949978321 -0.1199108451461814 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "nb_of_inserted_points,inserted_point_coordinates=get_extrapoints_target_length(contour1,.9)\n",
    "inserted_point_coordinates=np.array(inserted_point_coordinates)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1946bb8b668>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_contour(contour1)\n",
    "plt.scatter(inserted_point_coordinates[:,0],inserted_point_coordinates[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (bn_input): BatchNorm1d(25, eps=1e-05, momentum=0.5, affine=True)\n",
       "  (fc0): Linear(in_features=25, out_features=40, bias=True)\n",
       "  (bn0): BatchNorm1d(40, eps=1e-05, momentum=0.5, affine=True)\n",
       "  (predict): Linear(in_features=40, out_features=2, bias=True)\n",
       "  (fc1): Linear(in_features=40, out_features=40, bias=True)\n",
       "  (bn1): BatchNorm1d(40, eps=1e-05, momentum=0.5, affine=True)\n",
       ")"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_net.eval()\n",
    "#torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=my_net(x_variable).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_inserted_points=predictions.data.numpy()[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_inserted_points=predicted_inserted_points.reshape(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(predicted_inserted_points[:,0],predicted_inserted_points[:,1],label='Predicted points')\n",
    "plt.scatter(inserted_point_coordinates[:,0],inserted_point_coordinates[:,1],label='Original points')\n",
    "#plt.scatter(polygons_reshaped[3112][0::2].sum()/12,polygons_reshaped[312][1::2].sum()/12,label='Original points')\n",
    "plot_contour(contour1)\n",
    "plt.legend()\n",
    "original_points=point_coordinates.reshape(218722,2)\n",
    "#plt.scatter(original_points[:,0],original_points[:,1],label='Original points')\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "plt.scatter(centers_of_mass[10][0],centers_of_mass[10][1],label='Original points'\n",
    "           )\n",
    "plot_contour(polygons[2])\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "from scipy.spatial import ConvexHull\n",
    "points=centers_of_mass\n",
    "hull=ConvexHull(points)\n",
    "hull2=ConvexHull(original_points)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#plt.plot(points[:,0], points[:,1], 'o')\n",
    "for simplex in hull.simplices:\n",
    "    plt.plot(points[simplex, 0], points[simplex, 1], 'k-')\n",
    "for simplex in hull2.simplices:\n",
    "    plt.plot(original_points[simplex, 0], original_points[simplex, 1], 'k-')\n",
    "\n",
    "    \n",
    "    \n",
    "convex_points=centers_of_mass[hull.vertices]\n",
    "convex_points2=original_points[hull2.vertices]\n",
    "\n",
    "distances=np.empty([convex_points.shape[0],convex_points.shape[0]])    \n",
    "distances2=np.empty([convex_points2.shape[0],convex_points2.shape[0]])    \n",
    "\n",
    "    \n",
    "for i,point_i in enumerate(convex_points):\n",
    "    for j,point_j in enumerate(convex_points):\n",
    "        distances[i][j]=np.linalg.norm(point_i-point_j)\n",
    "for i,point_i in enumerate(convex_points2):\n",
    "    for j,point_j in enumerate(convex_points2):\n",
    "        distances2[i][j]=np.linalg.norm(point_i-point_j)\n",
    "        \n",
    "def max_element(A):\n",
    "    r, (c, l) = max(map(lambda t: (t[0], max(enumerate(t[1]), key=lambda v: v[1])), enumerate(A)), key=lambda v: v[1][1])\n",
    "    return (l, r, c)\n",
    "\n",
    "print(max_element(distances))\n",
    "print(max_element(distances2))\n",
    "\n",
    "maximum_distance_points=convex_points[[0,11]]\n",
    "maximum_distance_points2=convex_points2[[3,11]]\n",
    "\n",
    "plt.plot(maximum_distance_points[:,0],maximum_distance_points[:,1])\n",
    "plt.plot(maximum_distance_points2[:,0],maximum_distance_points2[:,1])\n",
    "1.8508252250365/0.6108970818704328"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "distances=[np.linalg.norm(i-j) for i in centers_of_mass for j in predicted_inserted_points]\n",
    "distances=np.array(distances)\n",
    "100*distances.sum()/(x_variable.size(0) *max_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_variable,x_variable_test=x_variable.resize(x_variable.size()[0],1,25),Variable(x_tensor_test.view(x_variable_test.size()[0],1,25),volatile=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using convolution network\n",
    "# O: output dimension\n",
    "# I: Input dimensiion\n",
    "# S: Stride\n",
    "# P: padding\n",
    "# w: kernel size\n",
    "# O=(I-w-2*P)/S+1\n",
    "\n",
    "\n",
    "class Conv_net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Conv_net,self).__init__()\n",
    "        self.conv1=nn.Conv1d(1,140,kernel_size=3,stride=2)\n",
    "        self.conv2=nn.Conv1d(140,280,kernel_size=2,stride=1)\n",
    "\n",
    "        self.bn1=nn.BatchNorm1d(num_features=280*10)\n",
    "        self.fc1=nn.Linear(280*10,12)\n",
    "        \n",
    "        self.bn2=nn.BatchNorm1d(num_features=12)\n",
    "        self.fc2=nn.Linear(12,12)\n",
    "        \n",
    "        self.bn3=nn.BatchNorm1d(num_features=12)\n",
    "        self.fc3=nn.Linear(12,12)\n",
    "        \n",
    "        \n",
    "        self.bn4=nn.BatchNorm1d(num_features=12)\n",
    "        self.fc4=nn.Linear(12,2)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=self.conv1(x)\n",
    "\n",
    "        x=F.relu(x)\n",
    "        #x=self.conv2(x)\n",
    "\n",
    "        x=F.relu(F.max_pool1d(self.conv2(x),kernel_size=2,stride=1))\n",
    "        x=F.relu(self.fc1(self.bn1(x.view(-1,280*10))))\n",
    "        x=F.relu(self.fc2(self.bn2(x)))\n",
    "        x=F.relu(self.fc3(self.bn3(x)))\n",
    "\n",
    "        x=self.fc4(self.bn4(x))\n",
    "\n",
    "        return x\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "my_conv_net=Conv_net()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(my_conv_net.parameters(), lr=1e-3,weight_decay=0)\n",
    "\n",
    "#optimizer = torch.optim.SGD(my_net.parameters(), lr=1e-5,weight_decay=.5,momentum=0.9)\n",
    "\n",
    "#loss_func = torch.nn.MSELoss(size_average=False) \n",
    "#loss_func=torch.nn.SmoothL1Loss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda activated\n"
     ]
    }
   ],
   "source": [
    "if  torch.cuda.is_available():\n",
    "    loss_func.cuda()\n",
    "    my_conv_net.cuda()\n",
    "    x_variable , y_variable,x_variable_test,y_variable_test= x_variable.cuda(), y_variable.cuda(),x_variable_test.cuda(),y_variable_test.cuda()\n",
    "    print(\"cuda activated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Training Loss: 0.1868208081705718 Test Loss: 0.11212024256183706\n",
      "Epoch: 10 Training Loss: 0.10370551250159395 Test Loss: 0.10662627481768928\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size=int(x_variable.size()[0]/18 )\n",
    "nb_of_epochs=13000\n",
    "# Train the network #\n",
    "my_conv_net.train()\n",
    "for t in range(nb_of_epochs):\n",
    "    sum_loss=0\n",
    "    for b in range(0,x_variable.size(0),batch_size):\n",
    "        out = my_conv_net(x_variable.narrow(0,b,batch_size))                 # input x and predict based on x\n",
    "        loss = loss_func(out, y_variable.narrow(0,b,batch_size))     # must be (1. nn output, 2. target), the target label is NOT one-hotted\n",
    "        #loss=loss_func.apply(out, y_variable.narrow(0,b,batch_size))\n",
    "        #loss=torch.sqrt((out[0]-y_variable.narrow(0,b,batch_size)[0]).pow(2)+(out[1]-y_variable.narrow(0,b,batch_size)[1]).pow(2)) \n",
    "        sum_loss+=loss.data[0]\n",
    "        optimizer.zero_grad()   # clear gradients for next train\n",
    "        loss.backward()         # backpropagation, compute gradients\n",
    "        #print(t,loss.data[0])\n",
    "        optimizer.step()        # apply gradients\n",
    "    if t%10==0:\n",
    "        my_conv_net.eval()\n",
    "        test_loss=loss_func(my_conv_net(x_variable_test),y_variable_test).data[0]\n",
    "        my_conv_net.train()\n",
    "        print(\"Epoch:\",t,\"Training Loss:\",sum_loss/x_variable.size(0),\"Test Loss:\",test_loss/x_variable_test.size(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_variable=x_variable.cpu()\n",
    "my_conv_net=my_conv_net.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 1 extra points\n",
      "13 -0.1925145994756827 -0.0867447465103373 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1f958d13940>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "contour1=np.delete(polygons_reshaped[15],24)\n",
    "contour1=contour1.reshape(12,2)\n",
    "nb_of_inserted_points,inserted_point_coordinates=get_extrapoints_target_length(contour1,.4\n",
    "                                                                              )\n",
    "inserted_point_coordinates=np.array(inserted_point_coordinates)\n",
    "my_conv_net.eval()\n",
    "predictions=my_conv_net(x_variable).cpu()\n",
    "predicted_inserted_points=predictions.data.numpy()[15]\n",
    "predicted_inserted_points=predicted_inserted_points.reshape(1,2)\n",
    "plt.scatter(predicted_inserted_points[:,0],predicted_inserted_points[:,1],label='Predicted points')\n",
    "plt.scatter(inserted_point_coordinates[:,0],inserted_point_coordinates[:,1],label='Original points')\n",
    "\n",
    "plot_contour(contour1)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.09719837, -0.23911646]], dtype=float32)"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_inserted_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_tensor=torch.FloatTensor([2.2,1.2])\n",
    "a_tensor=torch.FloatTensor([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_variable=Variable(d_tensor)\n",
    "\n",
    "a_variable=Variable(a_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_variable.requires_grad=False\n",
    "a_variable.requires_grad=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 1.4422\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 750,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fun=torch.sqrt((a_variable[0]-d_variable[0]).pow(2)+(a_variable[1]-d_variable[1]).pow(2))\n",
    "fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [],
   "source": [
    "fun.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "-0.8321\n",
       " 0.5547\n",
       "[torch.FloatTensor of size 2]"
      ]
     },
     "execution_count": 693,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_variable.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0\n",
       " 0\n",
       "[torch.FloatTensor of size 2]"
      ]
     },
     "execution_count": 694,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_variable.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd.function import Function\n",
    "from math import pow\n",
    "\n",
    "class myLossfunction(Function):\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(self,output,target):\n",
    "        self.save_for_backward(output,target) \n",
    "\n",
    "                        \n",
    "       # output=output.view(int(output.size()[0]/2),2)\n",
    "\n",
    "        #target=target.view(int(target.size()[0]/2),2)\n",
    "        distance=torch.nn.PairwiseDistance()\n",
    "        result=distance(output,target)\n",
    "\n",
    "        result=torch.FloatTensor(result)\n",
    "        #self.save_for_backward(result)\n",
    "\n",
    "\n",
    "        return  result \n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(self,grad_output1):\n",
    "        input1,target=self.saved_variables\n",
    "        \n",
    "        print(input1)\n",
    "        #distance=torch.nn.PairwiseDistance()(input1.view(int(input1.size()[0]/2),2),target.view(int(target.size()[0]/2),2))\n",
    "        distance=torch.nn.PairwiseDistance()(input1,target)\n",
    "\n",
    "        grad_output1=(input1-target)/distance\n",
    "\n",
    "        \n",
    "        return grad_output1,None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.2042\n",
       " 0.4508\n",
       " 0.6575\n",
       "   ⋮    \n",
       " 0.3220\n",
       " 0.1622\n",
       " 1.0774\n",
       "[torch.FloatTensor of size 9721x1]"
      ]
     },
     "execution_count": 813,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myloss=myLossfunction().apply(out,y_variable.narrow(0,b,batch_size).resize(batch_size,2))\n",
    "myloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "-2.3953e-01 -1.6375e-01\n",
      "-1.9727e-01 -3.8089e-01\n",
      "-4.1456e-01 -9.3787e-02\n",
      "           ⋮            \n",
      "-7.2860e-02 -6.4023e-02\n",
      "-1.8527e-01 -2.7595e-01\n",
      "-2.6488e-01 -8.1565e-01\n",
      "[torch.FloatTensor of size 9721x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "myloss.backward(torch.Tensor([1, 1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "-0.8320  0.5547\n",
       "[torch.FloatTensor of size 1x2]"
      ]
     },
     "execution_count": 754,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_variable.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "backward() missing 2 required positional arguments: 'self' and 'grad_output1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-634-fd86ffc8917c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmyLossfunction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: backward() missing 2 required positional arguments: 'self' and 'grad_output1'"
     ]
    }
   ],
   "source": [
    "myLossfunction.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0\n",
       " 0\n",
       "[torch.FloatTensor of size 2]"
      ]
     },
     "execution_count": 635,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_variable.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flush all variables in GPU\n",
    "del my_conv_net,my_net,x_variable_test,x_variable,y_variable,y_variable_test,loss_func\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2dust=torch.nn.PairwiseDistance(p=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 1.4422\n",
       " 2.2472\n",
       "[torch.FloatTensor of size 2x1]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2dust(a_variable.resize(2,2),d_variable.resize(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.09185446,  0.06111541]],\n",
       "\n",
       "       [[ 0.09185446,  0.06111541]],\n",
       "\n",
       "       [[ 0.09185446,  0.06111541]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.29833109, -0.19828089]],\n",
       "\n",
       "       [[ 0.29833109, -0.19828089]],\n",
       "\n",
       "       [[ 0.29833109, -0.19828089]]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "point_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "(  0   ,.,.) = \n",
       "  5.4394e-01 -1.2854e-01  1.2081e+00  ...   8.7166e-01 -3.9516e-01  4.0000e-01\n",
       "\n",
       "(  1   ,.,.) = \n",
       "  8.0653e-01 -7.0666e-02  7.9998e-01  ...   1.0453e+00 -4.1684e-01  4.0000e-01\n",
       "\n",
       "(  2   ,.,.) = \n",
       "  5.0649e-01  6.8832e-02  9.6722e-01  ...   8.5345e-01 -5.3134e-01  3.0000e-01\n",
       "  ...  \n",
       "\n",
       "(174975,.,.) = \n",
       "  1.1163e+00 -3.1378e-02  7.0993e-01  ...   7.3510e-01 -6.3782e-01  5.0000e-01\n",
       "\n",
       "(174976,.,.) = \n",
       "  7.6960e-01 -4.1094e-02  7.8531e-01  ...   9.1110e-01 -3.1011e-01  9.0000e-01\n",
       "\n",
       "(174977,.,.) = \n",
       "  1.2754e+00 -3.7225e-01  7.9667e-01  ...   5.6758e-01 -2.6036e-01  5.0000e-01\n",
       "[torch.FloatTensor of size 174978x1x25]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Should I order the interior points ?\n",
    "\n",
    "For each interior point calculate distance with points of the polygon\n",
    "\n",
    "find which ti which point it is closer and sort it according to the index.\n",
    "\n",
    "If multiple points are closer to the same point of the contour then take into\n",
    "\n",
    "account the distance to the point.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "invalid argument 2: size '[4860 x 2]' is invalid for input with 19442 elements at C:\\Anaconda2\\conda-bld\\pytorch_1519501749874\\work\\torch\\lib\\TH\\THStorage.c:41",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-768-8090ffc56ab5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0moutput_reshaped\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: invalid argument 2: size '[4860 x 2]' is invalid for input with 19442 elements at C:\\Anaconda2\\conda-bld\\pytorch_1519501749874\\work\\torch\\lib\\TH\\THStorage.c:41"
     ]
    }
   ],
   "source": [
    " output_reshaped=out.view(int(out.size()[0]/2),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       " -1.4947e-01 -2.7472e-01\n",
       " -1.9165e-01 -2.2482e-01\n",
       " -1.3642e-01 -3.2461e-01\n",
       "            ⋮            \n",
       " -3.8810e-02 -2.6062e-01\n",
       " -1.4880e-01 -2.9060e-01\n",
       " -1.3283e-01 -3.1349e-01\n",
       " [torch.FloatTensor of size 9721x2], Variable containing:\n",
       " -0.2311  0.0403\n",
       "  0.1704 -0.1201\n",
       "  0.2371 -0.1810\n",
       "        ⋮        \n",
       " -0.0681  0.2579\n",
       " -0.1204 -0.1273\n",
       " -0.0528  0.2407\n",
       " [torch.FloatTensor of size 9721x2])"
      ]
     },
     "execution_count": 790,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out,y_variable.narrow(0,b,batch_size).resize(batch_size,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       " (  0   ,.,.) = \n",
       "  -0.2311  0.0403\n",
       " \n",
       " (  1   ,.,.) = \n",
       "   0.1704 -0.1201\n",
       " \n",
       " (  2   ,.,.) = \n",
       "   0.2371 -0.1810\n",
       "   ...  \n",
       " \n",
       " (174975,.,.) = \n",
       "  -0.1804  0.0393\n",
       " \n",
       " (174976,.,.) = \n",
       "   0.2417  0.0188\n",
       " \n",
       " (174977,.,.) = \n",
       "   0.2496 -0.1190\n",
       " [torch.FloatTensor of size 174978x1x2], Variable containing:\n",
       " -1.4947e-01 -2.7472e-01\n",
       " -1.9165e-01 -2.2482e-01\n",
       " -1.3642e-01 -3.2461e-01\n",
       "            ⋮            \n",
       " -3.8810e-02 -2.6062e-01\n",
       " -1.4880e-01 -2.9060e-01\n",
       " -1.3283e-01 -3.1349e-01\n",
       " [torch.FloatTensor of size 9721x2])"
      ]
     },
     "execution_count": 789,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_variable,out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0177044392397268e-16"
      ]
     },
     "execution_count": 839,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polygons[0][:,0].sum()/12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-826-db58e474dc7f>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-826-db58e474dc7f>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    for polygon\u001b[0m\n\u001b[1;37m                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def get_barycenters(polygons):\n",
    "    \n",
    "    for polygon "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 864,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.72589751,  0.84207899,  0.71337615,  0.16721335, -0.53593486,\n",
       "       -1.19396456, -0.99666214, -0.86514855, -0.06646145,  0.05744332,\n",
       "        0.52287723,  0.62928501])"
      ]
     },
     "execution_count": 864,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polygons_reshaped[0][0::2].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 865,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.17159901,  0.40510667,  0.63783057,  0.58156785,  0.85478697,\n",
       "        0.50564378,  0.37817729, -0.73118862, -0.53079973, -1.1159677 ,\n",
       "       -0.86178872, -0.29496737])"
      ]
     },
     "execution_count": 865,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polygons_reshaped[0][1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.72589751,  0.17159901,  0.84207899, ..., -0.86178872,\n",
       "         0.62928501, -0.29496737],\n",
       "       [ 0.72589751,  0.17159901,  0.84207899, ..., -0.86178872,\n",
       "         0.62928501, -0.29496737],\n",
       "       [ 0.72589751,  0.17159901,  0.84207899, ..., -0.86178872,\n",
       "         0.62928501, -0.29496737],\n",
       "       ...,\n",
       "       [ 0.94168403, -0.21109   ,  0.66819129, ..., -0.98049631,\n",
       "         0.94108807, -0.3414368 ],\n",
       "       [ 0.94168403, -0.21109   ,  0.66819129, ..., -0.98049631,\n",
       "         0.94108807, -0.3414368 ],\n",
       "       [ 0.94168403, -0.21109   ,  0.66819129, ..., -0.98049631,\n",
       "         0.94108807, -0.3414368 ]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polygons_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "barycenters=[np.array([i[0::2].sum()/12,i[1::2].sum()/12]) for i in polygons_reshaped]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "barycenters=np.array(barycenters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "218722"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(point_coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(218722, 24)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polygons_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_coordinates=point_coordinates.reshape(len(point_coordinates),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "polygons_with_points=np.hstack([polygons_reshaped,point_coordinates])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "polygons_with_points=polygons_with_points.reshape(len(polygons_with_points),13,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.72589751,  0.17159901],\n",
       "        [ 0.84207899,  0.40510667],\n",
       "        [ 0.71337615,  0.63783057],\n",
       "        ...,\n",
       "        [ 0.52287723, -0.86178872],\n",
       "        [ 0.62928501, -0.29496737],\n",
       "        [ 0.09185446,  0.06111541]],\n",
       "\n",
       "       [[ 0.72589751,  0.17159901],\n",
       "        [ 0.84207899,  0.40510667],\n",
       "        [ 0.71337615,  0.63783057],\n",
       "        ...,\n",
       "        [ 0.52287723, -0.86178872],\n",
       "        [ 0.62928501, -0.29496737],\n",
       "        [ 0.09185446,  0.06111541]],\n",
       "\n",
       "       [[ 0.72589751,  0.17159901],\n",
       "        [ 0.84207899,  0.40510667],\n",
       "        [ 0.71337615,  0.63783057],\n",
       "        ...,\n",
       "        [ 0.52287723, -0.86178872],\n",
       "        [ 0.62928501, -0.29496737],\n",
       "        [ 0.09185446,  0.06111541]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.94168403, -0.21109   ],\n",
       "        [ 0.66819129,  0.35508194],\n",
       "        [ 0.41427257,  0.62051448],\n",
       "        ...,\n",
       "        [ 0.46430839, -0.98049631],\n",
       "        [ 0.94108807, -0.3414368 ],\n",
       "        [ 0.29833109, -0.19828089]],\n",
       "\n",
       "       [[ 0.94168403, -0.21109   ],\n",
       "        [ 0.66819129,  0.35508194],\n",
       "        [ 0.41427257,  0.62051448],\n",
       "        ...,\n",
       "        [ 0.46430839, -0.98049631],\n",
       "        [ 0.94108807, -0.3414368 ],\n",
       "        [ 0.29833109, -0.19828089]],\n",
       "\n",
       "       [[ 0.94168403, -0.21109   ],\n",
       "        [ 0.66819129,  0.35508194],\n",
       "        [ 0.41427257,  0.62051448],\n",
       "        ...,\n",
       "        [ 0.46430839, -0.98049631],\n",
       "        [ 0.94108807, -0.3414368 ],\n",
       "        [ 0.29833109, -0.19828089]]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polygons_with_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'numpy.ndarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-cd78c0aa7e0b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpolygons_with_points_unique\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpolygons_with_points\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'numpy.ndarray'"
     ]
    }
   ],
   "source": [
    "polygons_with_points_unique=list(set(polygons_with_points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 2, 12)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers_of_mass=np.array(centers_of_mass)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 2)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centers_of_mass.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "(  0  ,.,.) = \n",
       "  1.0804e+00  3.6440e-01  6.1404e-01  ...   4.9729e-01 -1.0542e+00  8.4189e-01\n",
       " -1.1037e+00 -1.0409e-01 -5.6104e-01  ...  -1.1438e+00  7.8898e-01 -5.4535e-01\n",
       "\n",
       "(  1  ,.,.) = \n",
       "  8.2030e-01 -9.6631e-02  1.1965e+00  ...   7.3245e-01 -1.1246e+00  6.5850e-01\n",
       " -9.8128e-01 -1.1748e-01 -4.0551e-01  ...  -7.3543e-01  5.2845e-01 -3.5533e-01\n",
       "\n",
       "(  2  ,.,.) = \n",
       "  8.8570e-01 -9.5701e-02  1.2094e+00  ...   5.8753e-01 -7.4392e-01  6.8171e-01\n",
       " -1.2722e+00 -1.4492e-01 -1.0465e+00  ...  -5.5213e-01  6.8863e-01 -5.0008e-01\n",
       " ...  \n",
       "\n",
       "(47997,.,.) = \n",
       "  1.0355e+00 -1.4388e-01  8.2466e-01  ...   7.1425e-01 -8.3453e-01  3.6346e-01\n",
       " -7.5888e-01  6.7694e-02 -8.8216e-01  ...  -1.0865e+00  3.7439e-01 -3.2188e-01\n",
       "\n",
       "(47998,.,.) = \n",
       "  6.8633e-01  5.9241e-02  9.9623e-01  ...   1.1396e+00 -7.3713e-01  8.0244e-02\n",
       " -8.3097e-01 -2.3101e-01 -8.2566e-01  ...  -7.4034e-01  6.7384e-01 -5.5374e-01\n",
       "\n",
       "(47999,.,.) = \n",
       "  8.7795e-01  6.0293e-02  8.4823e-01  ...   7.8716e-01 -7.3494e-01  3.3091e-01\n",
       " -1.1220e+00  3.2642e-01 -9.8364e-01  ...  -7.1744e-01  1.1813e+00 -3.0074e-01\n",
       "[torch.cuda.FloatTensor of size 48000x2x12 (GPU 0)]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "contour3=apply_procrustes(generate_contour(12))\n",
    "plot_contour(contour3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 -0.1397529684620565 -0.03668817911622362 0\n",
      "14 -0.5556838673885416 0.006489134426013973 0\n",
      "13 -0.1506273310219623 -0.02890481750650344 0\n",
      "14 -0.5584024580285181 0.008434974828444014 0\n",
      "13 -0.1355795824036162 -0.0391512743253334 0\n",
      "14 -0.5546405208739316 0.005873360623736529 0\n",
      "13 -0.1606318248853285 -0.1507826396315696 0\n",
      "13 -0.1029359385443222 -0.01988941712108101 0\n",
      "14 -0.546479609909108 0.01068882492479963 0\n",
      "13 -0.1469844471794247 -0.05733317507392088 0\n",
      "14 0.7059926839926042 0.1405732385547066 0\n",
      "15 -0.5574917370678837 0.001327885436589659 0\n",
      "13 -0.06406265062238639 -0.0485721250445643 0\n",
      "13 -0.1236015407066197 -0.04107046060343363 0\n",
      "14 -0.5516460104496824 0.00539356405421147 0\n",
      "13 -0.14404267783239 -0.03219865149111428 0\n",
      "14 -0.556756294731125 0.00761151633229131 0\n",
      "13 -0.1415910047281703 -0.02934662034552328 0\n",
      "14 -0.5561433764550701 0.008324524118689058 0\n",
      "13 -0.1393203257012531 -0.04295809812348142 0\n",
      "14 -0.5555757066983406 0.004921654674199518 0\n",
      "13 -0.05551841490555372 -0.04630404540602545 0\n",
      "13 -0.1152941486290197 -0.03570669163350242 0\n",
      "14 -0.5495691624302824 0.006734506296694273 0\n",
      "13 -0.1481990857572459 -0.04522022789034128 0\n",
      "14 0.6966692085386884 0.2002444115280739 0\n",
      "15 -0.5577953967123389 0.00435612223248456 0\n",
      "13 -0.07055101030846371 -0.06536714467005897 0\n",
      "14 0.7254559917690627 0.1782028488186872 0\n",
      "13 0.668636742504867 0.1730424300096725 0\n",
      "14 -0.3420547800645272 -0.1011080068174328 0\n",
      "13 -0.2207103626209955 -0.1180203033517528 0\n",
      "14 -0.5759232159282763 -0.01384389663286831 0\n",
      "13 -0.05923516989966464 -0.05308195828137971 0\n",
      "13 -0.1290742129902545 -0.01990870138843091 0\n",
      "14 -0.5530141785205911 0.01068400385796215 0\n",
      "13 -0.06150263613039254 -0.02419357870215745 0\n",
      "13 -0.1118374092753558 -0.02796508085981035 0\n",
      "14 -0.5487049775918664 0.008669908990117291 0\n",
      "13 -0.06851715015816352 -0.03510044619353291 0\n",
      "13 -0.05297605435286387 -0.03865576811700715 0\n",
      "13 -0.3399600547589283 -0.09338459917915261 0\n",
      "13 -0.1467402633727014 -0.02403623576471525 0\n",
      "14 -0.5574306911162028 0.00965212026389106 0\n",
      "13 -0.06130916081936404 -0.03530915509763472 0\n",
      "13 -0.131623347546258 -0.01892871825386482 0\n",
      "14 -0.5536514621595919 0.01092899964160368 0\n",
      "13 -0.1358796847893088 -0.02270373409710344 0\n",
      "14 -0.5547155464703547 0.009985245680794019 0\n",
      "13 -0.1267787163622686 -0.01536690253090524 0\n",
      "14 -0.5524403043635946 0.01181945357234357 0\n",
      "13 -0.131539460607141 -0.0267662067652194 0\n",
      "14 -0.5536304904248127 0.008969627513765028 0\n",
      "13 -0.1365378918460694 -0.04084007827572396 0\n",
      "14 -0.5548800982345449 0.005451159636138889 0\n",
      "13 -0.3301168705830743 -0.08407409346101147 0\n",
      "13 -0.05559670217067636 -0.03394052144826785 0\n",
      "13 -0.04427075026552559 -0.01020100824648889 0\n",
      "13 -0.05258371292902656 -0.07324115685308397 0\n",
      "14 0.7498154331000679 0.1680858372150571 0\n",
      "13 -0.327337823060125 -0.08280235421318367 0\n",
      "13 -0.2280980501718821 -0.12173847705694 0\n",
      "14 -0.577770137815998 -0.01477344005916512 0\n",
      "13 -0.1474131678571638 -0.04244606622435481 0\n",
      "14 -0.5575989172373185 0.005049662648981176 0\n",
      "13 -0.03956674944986851 -0.02710795433156328 0\n",
      "13 -0.0668955770514985 -0.04266069365978505 0\n",
      "13 -0.132949276301365 -0.0122946015815628 0\n",
      "14 -0.5539829443483685 0.01258752880967917 0\n",
      "13 -0.1403216370137341 -0.047837722399509 0\n",
      "14 -0.555826034526461 0.003701748605192623 0\n",
      "13 -0.07562338668806432 -0.05991482889543128 0\n",
      "14 0.7265490209758726 0.1622457298735304 0\n",
      "13 -0.1468261710666018 -0.03980637410123573 0\n",
      "14 -0.5574521680396779 0.005709585679760947 0\n",
      "13 -0.2197673007388687 -0.09477857564662642 0\n",
      "14 -0.5756874504577447 -0.008033464706586727 0\n",
      "13 -0.140856607160155 -0.1568805282005062 0\n",
      "13 -0.05612086084599307 -0.02274351477224481 0\n",
      "13 -0.1306790362512654 -0.02395026286339837 0\n",
      "14 -0.5534153843358438 0.009673613489220287 0\n",
      "13 -0.1466484840583014 -0.03078314879845298 0\n",
      "14 -0.5574077462876028 0.007965392005456633 0\n",
      "13 0.6781525585907586 0.1781686756011178 0\n",
      "14 -0.3398428873609275 -0.1112426127964096 0\n",
      "13 -0.1286765556329334 -0.03834700299175541 0\n",
      "14 -0.5529147641812608 0.006074428457131026 0\n",
      "13 -0.1425208477071837 -0.1480949726841848 0\n",
      "13 -0.2295247198802254 -0.122490114835207 0\n",
      "14 -0.5781268052430838 -0.01496134950373186 0\n",
      "15 0.6657881575066984 0.2005219709940744 0\n",
      "13 -0.1401382249124987 -0.04438696191526676 0\n",
      "14 -0.5557801815011522 0.004564438726253188 0\n",
      "13 -0.3331606528800971 -0.07990415180608197 0\n",
      "13 -0.1526067429149884 -0.04102509893687514 0\n",
      "14 0.6797516074813463 0.2115398151852108 0\n",
      "15 -0.5588973110017745 0.005404904470851093 0\n",
      "13 -0.1366886318782331 -0.01417230109403478 0\n",
      "14 -0.5549177832425858 0.01211810393156118 0\n",
      "13 -0.05981068413271194 -0.04720046188510983 0\n",
      "13 -0.2125650283954261 -0.1049708062633488 0\n",
      "14 -0.573886882371884 -0.01058152236076733 0\n",
      "13 -0.1500018396124621 -0.03656289705671551 0\n",
      "14 -0.5582460851761431 0.006520454940891001 0\n",
      "13 -0.1289985351318677 -0.02400084491377941 0\n",
      "14 -0.5529952590559945 0.009660967976625027 0\n",
      "13 -0.1394876835303045 -0.03746581650992508 0\n",
      "14 -0.5556175461556037 0.006294725077588608 0\n",
      "13 -0.118664770504445 -0.0127507651422367 0\n",
      "14 -0.5504118178991387 0.0124734879195107 0\n",
      "13 -0.1341437017418671 -0.01698123672938327 0\n",
      "14 -0.5542815507084941 0.01141587002272406 0\n",
      "13 -0.1478384116236053 -0.05920448952487276 0\n",
      "14 0.6838935371480942 0.1919000591336481 0\n",
      "15 -0.5577052281789288 0.0008600568238516897 0\n",
      "13 -0.1413124189310576 -0.03188163586906931 0\n",
      "14 -0.5560737300057919 0.007690770237802545 0\n",
      "13 -0.2242051176715144 -0.08375400982115525 0\n",
      "14 -0.5767969046909061 -0.005277323250218933 0\n",
      "13 -0.1515301104572981 -0.05879096046795171 0\n",
      "14 0.689944160006159 0.1719409864438256 0\n",
      "15 -0.558628152887352 0.0009634390880819514 0\n",
      "13 -0.1614356047742784 -0.1424951007962882 0\n",
      "13 -0.1524243529220074 -0.1699834645643355 0\n",
      "14 0.7252994759466482 0.2092065714876347 0\n",
      "13 -0.03151777023174163 -0.05092264937644676 0\n",
      "13 -0.189640727251055 -0.02570138845168707 0\n",
      "13 -0.07358253211827795 -0.06678878014543131 0\n",
      "14 0.7294955491776982 0.1763605516738522 0\n",
      "13 -0.1232421838936155 -0.01819063288795197 0\n",
      "14 -0.5515561712464313 0.01111352098308189 0\n",
      "13 -0.1408574837019793 -0.1242156432237974 0\n",
      "13 -0.1480153563676902 -0.1428787241247025 0\n",
      "13 -0.03666884231416678 -0.03799211108395292 0\n",
      "13 -0.2247757957830015 -0.1238216139338256 0\n",
      "14 -0.5769395742187778 -0.01529422427838652 0\n",
      "13 -0.2167594209378544 -0.1056574500741192 0\n",
      "14 -0.5749354805074911 -0.01075318331345993 0\n",
      "13 -0.1249749877229445 -0.03861279751962351 0\n",
      "14 -0.5519893722037637 0.006007979825164002 0\n",
      "13 -0.06750263578351787 -0.03580310179476102 0\n",
      "13 -0.1345067389077143 -0.1404675268215443 0\n",
      "13 -0.1264632831340571 -0.04099417656393815 0\n",
      "14 -0.5523614460565417 0.005412635064085342 0\n",
      "13 -0.1464945834086179 -0.05695040544565277 0\n",
      "14 0.6905684970705867 0.187069267302955 0\n",
      "15 -0.557369271125182 0.001423577843656685 0\n",
      "13 -0.1487693391512562 -0.1419271050077581 0\n",
      "13 -0.1234861307451766 -0.02284691760734195 0\n",
      "14 -0.5516171579593217 0.009949449803234391 0\n",
      "13 0.6848397681433996 0.1766069557976743 0\n",
      "14 -0.1742528694427543 -0.1793763288269057 0\n",
      "13 -0.1317130355441832 -0.01877169288191783 0\n",
      "14 -0.5536738841590733 0.01096825598459042 0\n",
      "13 -0.2259633919170091 -0.119115970462218 0\n",
      "14 -0.5772364732522796 -0.01411781341048462 0\n",
      "13 -0.04801941787163085 -0.05048921835696252 0\n",
      "13 -0.1305435506635666 -0.02483942972507727 0\n",
      "14 -0.5533815129389191 0.009451321773800561 0\n",
      "13 -0.05310040463287966 -0.04999466596033805 0\n",
      "13 -0.1270756280915445 -0.03395358713439253 0\n",
      "14 -0.5525145322959136 0.007172782421471739 0\n",
      "13 -0.1428323311334145 -0.1547412602474058 0\n",
      "13 -0.1336810424955752 -0.0412095563716969 0\n",
      "14 -0.5541658858969213 0.005358790112145654 0\n",
      "13 -0.2177818512972035 -0.09961526651157587 0\n",
      "14 -0.5751910880973283 -0.00924263742282409 0\n",
      "13 -0.1450776076669155 -0.1407926389674559 0\n",
      "13 -0.1309676650605889 -0.02008444381223736 0\n",
      "14 -0.5534875415381747 0.01064006825201053 0\n",
      "13 -0.2172699141104487 -0.1033083044113232 0\n",
      "14 -0.5750631038006396 -0.01016589689776093 0\n",
      "13 -0.07739642030705787 -0.04701983303141259 0\n",
      "14 0.7058805647781584 0.1897875196112926 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1bd48fd9630>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inserted_points=[]\n",
    "nb_of_sampling=100\n",
    "contour=contour3.copy()\n",
    "plot_contour(contour3)\n",
    "\n",
    "for i in range(0,nb_of_sampling):\n",
    "    contour[0]=np.random.normal(contour3[0],0.08)\n",
    "    contour[11]=np.random.normal(contour3[11],0.08)\n",
    "\n",
    "    nb_of_points,point_coords=get_extrapoints_target_length(contour,0.2)\n",
    "    inserted_points.append(point_coords)\n",
    "    plt.scatter(contour[0][0],contour[0][1])\n",
    "    plt.scatter(contour[11][0],contour[11][1])\n",
    "\n",
    "\n",
    "inserted_points=[i for i in inserted_points if len(i)==1]\n",
    "inserted_points=np.array(inserted_points)\n",
    "inserted_points=inserted_points.reshape(len(inserted_points),2)\n",
    "\n",
    "plt.scatter(inserted_points[:,0],inserted_points[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

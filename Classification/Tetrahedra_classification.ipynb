{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import triplot\n",
    "from math import sqrt\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection, Line3DCollection\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly\n",
    "from enum import IntEnum\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as Func\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "\n",
    "from IPython.core.debugger import Tracer\n",
    "from math import pi,cos,sin\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [],
   "source": [
    "minDihedralAngleThreshold = 30.0\n",
    "maxDihedralAngleThreshold = 180.0-40.0\n",
    "minSolidAngleThreshold = 30.0\n",
    "maxSolidAngleThreshold = 180.0-40.0\n",
    "\n",
    "class shapeType(IntEnum):\n",
    "    ROUND=0\n",
    "    NEEDLE=1\n",
    "   # WEDGE=2\n",
    "   # SPINDLE=3\n",
    "   # SLIVER=4\n",
    "   # CAP=5\n",
    "        \n",
    "\n",
    "def tri_normal(tetra_point_0,tetra_point_1,tetra_point_2):\n",
    "    A=tetra_point_1-tetra_point_0\n",
    "    B=tetra_point_2-tetra_point_0\n",
    "    vector=np.cross(A,B)\n",
    "    norm=np.linalg.norm(vector)\n",
    "    return vector/norm\n",
    "        \n",
    "\n",
    "def face_normals(tetra):\n",
    "    tripermutations=[[1,3,2,0],\n",
    "                     [0,2,3,1],\n",
    "                     [0,3,1,2],\n",
    "                     [0,1,2,3]]\n",
    "    normals=np.empty([4,3])\n",
    "    for i in range(4):\n",
    "        normals[i]=tri_normal(tetra[tripermutations[i][0]]\n",
    "                             ,tetra[tripermutations[i][1]],\n",
    "                              tetra[tripermutations[i][2]])\n",
    "    return normals\n",
    "    \n",
    "    \n",
    "def solid_angle(v1,v2,v3):\n",
    "    matrix=np.array([[v1[0],v1[1],v1[2]],\n",
    "                   [v2[0],v2[1],v2[2]],\n",
    "                 [v3[0],v3[1],v3[2]]])\n",
    "    det=np.linalg.det(matrix)\n",
    "    v1_norm,v2_norm,v3_norm=np.linalg.norm(v1),np.linalg.norm(v2),np.linalg.norm(v3)\n",
    "    div=v1_norm*v2_norm*v3_norm+np.dot(v1,v2)*v3_norm+np.dot(v1,v3)*v2_norm+np.dot(v2,v3)*v1_norm\n",
    "    angle=np.absolute(np.arctan2(det,div))\n",
    "    angle*=2\n",
    "    return angle\n",
    "    \n",
    "    \n",
    "def solid_angles(tetra):\n",
    "    angles=np.empty([4,1])\n",
    "    for i in range(4):\n",
    "        a=tetra[(i+1)%4]-tetra[i]\n",
    "        b=tetra[(i+2)%4]-tetra[i]\n",
    "        c=tetra[(i+3)%4]-tetra[i]\n",
    "        angles[i]=solid_angle(a,b,c)\n",
    "    return angles*180/pi\n",
    "\n",
    "def dihedral_angles(tetra):\n",
    "    normals=face_normals(tetra)\n",
    "    angles=np.empty([6,1])\n",
    "    counter=0\n",
    "    for i in range(3):\n",
    "        for j in range(i+1,4):\n",
    "            angles[counter]=pi-np.arccos(np.dot(normals[i],normals[j]))\n",
    "            counter+=1\n",
    "    return angles*180/pi\n",
    "\n",
    "\n",
    "def shape_type(tetra):\n",
    "    \n",
    "    solidAngles,dihedralAngles=solid_angles(tetra),dihedral_angles(tetra)\n",
    "    maxSolidangle,minSolidAngle=np.max(solidAngles),np.min(solidAngles)\n",
    "    maxDihedralangle,minDihedralangle=np.max(dihedralAngles),np.min(dihedralAngles)\n",
    "    \n",
    "    smallDihedralAngle=minDihedralangle<minDihedralAngleThreshold\n",
    "    largeDihedralAngle=maxDihedralangle>maxDihedralAngleThreshold\n",
    "    smallSolidAngle=minSolidAngle<minSolidAngleThreshold\n",
    "    largeSolidAngle=maxSolidangle>maxSolidAngleThreshold\n",
    "    shape=shapeType.ROUND\n",
    "    \n",
    "    if not smallDihedralAngle and not largeDihedralAngle:\n",
    "        if smallSolidAngle: shape=shapeType.NEEDLE\n",
    "        else:shape=shapeType.ROUND\n",
    "   \n",
    "    elif smallDihedralAngle and not largeDihedralAngle:\n",
    "        shape=shapeType.WEDGE\n",
    "    \n",
    "    elif not smallDihedralAngle and largeDihedralAngle and not largeSolidAngle and smallSolidAngle:\n",
    "        shape=shapeType.SPINDLE\n",
    "    \n",
    "    elif smallDihedralAngle and largeDihedralAngle and not largeSolidAngle and smallSolidAngle:\n",
    "        shape=shapeType.SLIVER\n",
    "    elif smallDihedralAngle and largeDihedralAngle and  largeSolidAngle and smallSolidAngle:\n",
    "        shape=shapeType.CAP\n",
    "    \n",
    "    return shape.name,shape.value\n",
    "    \n",
    "\n",
    "# returns tetrahedron of efdge length 1    \n",
    "def regular_tet():\n",
    "    tetrahedron=np.array([[0.57735026918962573,0,0],\n",
    "                        [-0.28867513459481275, -0.5,0],\n",
    "                        [-0.28867513459481314, 0.49999999999999983,0],\n",
    "                        [0,0, 0.81649658092772603]])\n",
    "    return tetrahedron\n",
    "\n",
    "# returns tetrahedron of efdge length sqrt(2)  \n",
    "def squared_regular_tet():\n",
    "    tetrahedron=np.array([ [1,-1/sqrt(3),-1/sqrt(6)]\n",
    "                                , [-1,-1/sqrt(3),-1/sqrt(6)] \n",
    "                               , [0,2/sqrt(3),-1/sqrt(6)] \n",
    "                                   , [0,0,3/sqrt(6)] ])\n",
    "    return tetrahedron\n",
    "\n",
    "\n",
    "\n",
    "def get_barycenter(number,pos):\n",
    "    barycenter=np.zeros([1,3])\n",
    "    for i in range(number):\n",
    "        barycenter+=pos[i]\n",
    "    return barycenter/number\n",
    "\n",
    "def get_cap_tet(shapefactor):\n",
    "    tet=regular_tet()\n",
    "    \n",
    "    triBarycenter=get_barycenter(3,tet)\n",
    "    dir2triBarycenter=np.empty([3,3])\n",
    "    \n",
    "    for i in range(3):\n",
    "        dir2triBarycenter[i]=triBarycenter-tet[i]\n",
    "        length2triBarycenter=np.linalg.norm(dir2triBarycenter[i])\n",
    "        dir2triBarycenter[i]/=np.linalg.norm(dir2triBarycenter[i])\n",
    "    \n",
    "    dir2triBarycenter_opp=triBarycenter-tet[3]\n",
    "    length2triBarycenter_opp=np.linalg.norm(dir2triBarycenter_opp)\n",
    "    dir2triBarycenter_opp/=np.linalg.norm(dir2triBarycenter_opp)\n",
    "    \n",
    "    dx=shapefactor*length2triBarycenter_opp\n",
    "    factor=dir2triBarycenter_opp*dx\n",
    "    for i in range(3):\n",
    "        tet[3][i]+=factor[0][i]\n",
    "    return tet\n",
    "    \n",
    "def get_needle_tet(shapefactor):\n",
    "    tet=regular_tet()\n",
    "    \n",
    "    tetBarycenter=get_barycenter(4,tet)\n",
    "    dir2tetBarycenter=np.empty([4,3])\n",
    "    length2tetBarycenter=np.empty([4,1])\n",
    "\n",
    "    for i in range(4):\n",
    "        dir2tetBarycenter[i]=tetBarycenter-tet[i]\n",
    "        length2tetBarycenter[i]=np.linalg.norm(dir2tetBarycenter[i])\n",
    "        dir2tetBarycenter[i]/=np.linalg.norm(dir2tetBarycenter[i])\n",
    "   \n",
    "    triBarycenter=get_barycenter(3,tet)\n",
    "    dir2triBarycenter=np.empty([3,3])\n",
    "    length2triBarycenter=np.empty([3,1])\n",
    "    for i in range(3):\n",
    "        dir2triBarycenter[i]=triBarycenter-tet[i]\n",
    "        length2triBarycenter[i]=np.linalg.norm(dir2triBarycenter[i])\n",
    "        dir2triBarycenter[i]/=np.linalg.norm(dir2triBarycenter[i])\n",
    "     \n",
    "    # COME BACK L \n",
    "    dx=shapefactor*np.linalg.norm(triBarycenter-tet[3])\n",
    "    for i in range(3):\n",
    "        tet[i]=tet[i]+dir2triBarycenter[i]*dx\n",
    "    return tet\n",
    "\n",
    "\n",
    "\n",
    "def get_wedge_tet(shapefactor):\n",
    "    tet=regular_tet()\n",
    "    \n",
    "    segBarycenter=np.empty([2,3])\n",
    "    segBarycenter[0]=get_barycenter(2,tet)\n",
    "    segBarycenter[1]=get_barycenter(2,tet[2:])\n",
    "    \n",
    "    dir2SegBaryCenter=np.empty([2,2,3])\n",
    "    length2SegBaryCenter=np.empty([2,3])\n",
    "    \n",
    "    for i in range(2):\n",
    "        dir2SegBaryCenter[0][i]=segBarycenter[0]-tet[i]\n",
    "        length2SegBaryCenter[0]=np.linalg.norm(dir2SegBaryCenter[0][i])\n",
    "        dir2SegBaryCenter[0][i]/=np.linalg.norm(dir2SegBaryCenter[0][i])\n",
    "        \n",
    "        dir2SegBaryCenter[1][i]=segBarycenter[0]-tet[i+2]\n",
    "        length2SegBaryCenter[1]=np.linalg.norm(dir2SegBaryCenter[1][i])\n",
    "        dir2SegBaryCenter[0][i]/=np.linalg.norm(dir2SegBaryCenter[1][i])\n",
    "        \n",
    "    dx=shapefactor*length2SegBaryCenter[0]\n",
    "    for i in range(2):\n",
    "        tet[i]+=dir2SegBaryCenter[0][i]*dx\n",
    "    for i in range(2):\n",
    "        tet[i+2]+=dir2SegBaryCenter[1][i]*dx\n",
    "    return tet\n",
    "\n",
    "\n",
    "\n",
    "def get_spindle_tet(shapefactor):\n",
    "    tet=regular_tet()\n",
    "    \n",
    "    segBarycenter=np.empty([2,3])\n",
    "    segBarycenter[0]=get_barycenter(2,tet)\n",
    "    segBarycenter[1]=get_barycenter(2,tet[2:])\n",
    "    \n",
    "    dir2SegBaryCenter=np.empty([2,2,3])\n",
    "    length2SegBaryCenter=np.empty([2,3])\n",
    "    \n",
    "    for i in range(2):\n",
    "        dir2SegBaryCenter[0][i]=segBarycenter[0]-tet[i]\n",
    "        length2SegBaryCenter[0]=np.linalg.norm(dir2SegBaryCenter[0][i])\n",
    "        dir2SegBaryCenter[0][i]/=np.linalg.norm(dir2SegBaryCenter[0][i])\n",
    "        \n",
    "        dir2SegBaryCenter[1][i]=segBarycenter[0]-tet[i+2]\n",
    "        length2SegBaryCenter[1]=np.linalg.norm(dir2SegBaryCenter[1][i])\n",
    "        dir2SegBaryCenter[0][i]/=np.linalg.norm(dir2SegBaryCenter[1][i])\n",
    "        \n",
    "    seg2segBaryCenter=(segBarycenter[0]+segBarycenter[1])/2\n",
    "    dirseg2segBaryCenter=np.empty([2,3])\n",
    "    for i in range(2):\n",
    "        dirseg2segBaryCenter[i]=seg2segBaryCenter-segBarycenter[i]\n",
    "        lengthSeg2SegBaryCenter=np.linalg.norm(dirseg2segBaryCenter[i])\n",
    "        dirseg2segBaryCenter[i]/=np.linalg.norm(dirseg2segBaryCenter[i])\n",
    "    \n",
    "    dx=shapefactor*length2SegBaryCenter[0]\n",
    "    for j in range(2):\n",
    "        tet[j]+=dir2SegBaryCenter[0][j]*dx\n",
    "    \n",
    "    dh=shapefactor*lengthSeg2SegBaryCenter\n",
    "    for j in range(2):\n",
    "        tet[j]+=dirseg2segBaryCenter[0]*dh\n",
    "    \n",
    "    for j in range(2):\n",
    "        tet[j+2]+=dirseg2segBaryCenter[1]*dh\n",
    "    \n",
    "    return tet\n",
    "\n",
    "\n",
    "\n",
    "def get_sliver_tet(shapefactor):\n",
    "    tet=regular_tet()\n",
    "    \n",
    "    segBarycenter=np.empty([2,3])\n",
    "    segBarycenter[0]=get_barycenter(2,tet)\n",
    "    segBarycenter[1]=get_barycenter(2,tet[2:])\n",
    "    \n",
    "    dir2SegBaryCenter=np.empty([2,2,3])\n",
    "    length2SegBaryCenter=np.empty([2,3])\n",
    "    \n",
    "    for i in range(2):\n",
    "        dir2SegBaryCenter[0][i]=segBarycenter[0]-tet[i]\n",
    "        length2SegBaryCenter[0]=np.linalg.norm(dir2SegBaryCenter[0][i])\n",
    "        dir2SegBaryCenter[0][i]/=np.linalg.norm(dir2SegBaryCenter[0][i])\n",
    "        \n",
    "        dir2SegBaryCenter[1][i]=segBarycenter[0]-tet[i+2]\n",
    "        length2SegBaryCenter[1]=np.linalg.norm(dir2SegBaryCenter[1][i])\n",
    "        dir2SegBaryCenter[0][i]/=np.linalg.norm(dir2SegBaryCenter[1][i])\n",
    "        \n",
    "    seg2segBaryCenter=(segBarycenter[0]+segBarycenter[1])/2\n",
    "    dirseg2segBaryCenter=np.empty([2,3])\n",
    "    for i in range(2):\n",
    "        dirseg2segBaryCenter[i]=seg2segBaryCenter-segBarycenter[i]\n",
    "        lengthSeg2SegBaryCenter=np.linalg.norm(dirseg2segBaryCenter[i])\n",
    "        dirseg2segBaryCenter[i]/=np.linalg.norm(dirseg2segBaryCenter[i])\n",
    "    \n",
    "   \n",
    "    dh=shapefactor*lengthSeg2SegBaryCenter\n",
    "    for j in range(2):\n",
    "        tet[j]+=dirseg2segBaryCenter[0]*dh\n",
    "    \n",
    "    for j in range(2):\n",
    "        tet[j+2]+=dirseg2segBaryCenter[1]*dh\n",
    "    \n",
    "    return tet\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def rot_x(theta):\n",
    "    return np.array([[1,0,0],     \n",
    "                     [0,cos(theta),-sin(theta)],\n",
    "                      [0,sin(theta),cos(theta)] ])\n",
    "def rot_y(theta):\n",
    "    return np.array([[cos(theta),0,sin(theta)],     \n",
    "                             [0,1,0],\n",
    "                      [-sin(theta),0,cos(theta)] ])\n",
    "\n",
    "def rot_z(theta):\n",
    "    return np.array([[cos(theta),-sin(theta),0],     \n",
    "                     [sin(theta),cos(theta),0],\n",
    "                      [0,0,1] ])\n",
    "\n",
    "\n",
    "def rotate(angle_x,angle_y,angle_z):\n",
    "    return rot_z(angle_z).dot(rot_y(angle_y)).dot(rot_x(angle_x))\n",
    "\n",
    "def get_eigenvalues(tetrahedra):\n",
    "    \"\"\"\n",
    "    Computes and returns the deformation gradient\n",
    "    matrix as well as its eigenvalues\n",
    "    \"\"\"\n",
    "    \n",
    "    # Reference regular tetrahdra #\n",
    "\n",
    "    ref_tetrahedra =regular_tet()\n",
    "    #plt.triplot(ref_triangle[:,0],ref_triangle[:,1],linewidth=7.0)\n",
    "\n",
    "    # Material coordinates\n",
    "    dX=np.array([      \n",
    "       [ref_tetrahedra[1][0]-ref_tetrahedra[0][0] , ref_tetrahedra[2][0]-ref_tetrahedra[0][0],ref_tetrahedra[3][0]-ref_tetrahedra[0][0]] ,   \n",
    "       [ref_tetrahedra[1][1]-ref_tetrahedra[0][1] , ref_tetrahedra[2][1]-ref_tetrahedra[0][1],ref_tetrahedra[3][1]-ref_tetrahedra[0][1]],\n",
    "       [ref_tetrahedra[1][2]-ref_tetrahedra[0][2] , ref_tetrahedra[2][2]-ref_tetrahedra[0][2],ref_tetrahedra[3][2]-ref_tetrahedra[0][2]] ,       ])\n",
    "    \n",
    "# Material coordinates\n",
    "    dx=np.array([      \n",
    "       [tetrahedra[1][0]-tetrahedra[0][0] , tetrahedra[2][0]-tetrahedra[0][0],tetrahedra[3][0]-tetrahedra[0][0]] ,   \n",
    "       [tetrahedra[1][1]-tetrahedra[0][1] , tetrahedra[2][1]-tetrahedra[0][1],tetrahedra[3][1]-tetrahedra[0][1]],\n",
    "       [tetrahedra[1][2]-tetrahedra[0][2] , tetrahedra[2][2]-tetrahedra[0][2],tetrahedra[3][2]-tetrahedra[0][2]] ,       ])\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "   # The deformation matrix is F=dx*DX^(-1)\n",
    "\n",
    "    inv_dX=np.linalg.inv(dX)\n",
    "    F=np.dot(dx,np.linalg.inv(dX))\n",
    "    #print(\"Determinant of the deformation gradient is: {0}\".format(np.linalg.det(F)))\n",
    "\n",
    "\n",
    "    # The goal is to find and appropriate diagonalization \n",
    "    # of F=U*F'*V.T. To properly diagonalize it we first \n",
    "    # consider A=F.T*F. Then by definition (symmetric matrix)\n",
    "    # the diagonalizarion of A will give always real and non \n",
    "    # nonegative singular valures. We have, A=(VF'U.T)(UF'V.T)\n",
    "    # =VF^2V.T\n",
    "    \n",
    "    A=F.T.dot(F)\n",
    "    \n",
    "    # Perform an SVD to A we get:\n",
    "    \n",
    "    u,s,V_tranpose=np.linalg.svd(A)\n",
    "    V=V_tranpose.T\n",
    "    #s,V=np.linalg.eig(A)\n",
    "    #print(\"Determinant of eigenvectors V of FF.T is:{0}\".format(np.linalg.det(V)))\n",
    "    \n",
    "    # The entries of F' are the square roots of s\n",
    "    F_diag=np.sqrt(s)\n",
    "    np.sort(F_diag)\n",
    "    F_diag=np.diag(F_diag)\n",
    "    \n",
    "    \n",
    "    # We compute  U=F*V*(F_diag)^-1\n",
    "    \n",
    "    F_diag_inverse=np.linalg.inv(F_diag)\n",
    "    U=F.dot(V).dot(F_diag_inverse)\n",
    "    \n",
    "    # Checking if indeed F=UF'V.T\n",
    "    #print(np.allclose(F,U.dot(F_diag).dot(V.T)))\n",
    "    #print(np.linalg.det(U))\n",
    "    \n",
    "    # Calculate rotation matrix and calculate rotation angle(z-axis) (Source: http://nghiaho.com/?page_id=846)\n",
    "    R=np.dot(V,U.T)\n",
    "    \n",
    "    # Checking for reflection case\n",
    "    if np.linalg.det(R)<0:\n",
    "        V[1,:]*=-1\n",
    "        R=np.dot(V,U.T)\n",
    "    \n",
    "    rotation_angle_x=180/pi*np.arctan2(R[2,1],R[2,2]) #x->(-pi,pi)\n",
    "    rotation_angle_y=180/pi*np.arctan2(-R[2,0],sqrt(np.power(R[2,1],2)+np.power(R[2,2],2))) #y->(-pi/,pi/2)\n",
    "    rotation_angle_z=180/pi*np.arctan2(R[1,0],R[0,0]) #z->(-pi/,pi)\n",
    "\n",
    "    \n",
    "    \n",
    "    # now extract the sign of the singular values of F \n",
    "    # by sign(u_i*v_i)*F_diag\n",
    "    signs=[-1 if np.sign(U[:,i].dot(V[:,i]))<0 else 1 for i in range(A.shape[1])]\n",
    "    eig=[signs[i]*F_diag[i][i] for i in range(A.shape[1])]\n",
    "    factor=1\n",
    "\n",
    "    for i in range(A.shape[1]):\n",
    "        factor*=np.power(F_diag[i,i],1/3)\n",
    "\n",
    "    # To make the eigenvalues scale invariant multiply them with\n",
    "    # 1/P(l_i)\n",
    "    for i in range(len(eig)):\n",
    "        eig= np.multiply(eig,1/(factor)**(1/3) if factor!=0 else 0)\n",
    "\n",
    "            \n",
    "    #print(\" Eigenvalues of F are : {0}\".format(eig))  \n",
    "   \n",
    "     # Treat change of sign due to rotation\n",
    "    \n",
    "    ###if  90 < rotation_angle_x <= 180 or -180 <= rotation_angle_x <= -90:\n",
    "    ###    eig[0]*=-1\n",
    "    ###    eig[2]*=-1\n",
    "    ###if  90 < rotation_angle_z <= 180 or -180 <= rotation_angle_z <= -90:\n",
    "    ###        eig[1]*=-1\n",
    "    ###        eig[2]*=-1\n",
    "    ###elif  90 < rotation_angle_z <= 180 or -180 <= rotation_angle_z <= -90:\n",
    "    ###        eig[0]*=-1\n",
    "    ###        eig[1]*=-1\n",
    "    \n",
    "    return eig,F,U,[rotation_angle_x,rotation_angle_y,rotation_angle_z]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "CAP",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-544-e212df8734af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mdh2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdihedral_angles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msliver_tet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0msa2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msolid_angles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msliver_tet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshape_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcap_tet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[1;31m#dh,sa,dh2,sa2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mrotating_tetrahedron\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrotate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpi\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpi\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mregular_tetrahedron\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-542-aef2db638f3e>\u001b[0m in \u001b[0;36mshape_type\u001b[0;34m(tetra)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshapeType\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSLIVER\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0msmallDihedralAngle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlargeDihedralAngle\u001b[0m \u001b[1;32mand\u001b[0m  \u001b[0mlargeSolidAngle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0msmallSolidAngle\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshapeType\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCAP\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Users\\papagian\\AppData\\Local\\Continuum\\Anaconda3\\lib\\enum.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(cls, name)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_member_map_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: CAP"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "regular_tetrahedron=regular_tet()\n",
    "normal=face_normals(regular_tetrahedron)\n",
    "\n",
    "barycenter=get_barycenter(4,regular_tetrahedron)\n",
    "barycenter\n",
    "cap_tet=get_cap_tet(1)\n",
    "needle_tet=get_needle_tet(0.9)\n",
    "wedge_tet=get_wedge_tet(0.8)\n",
    "spindle_tet=get_spindle_tet(4)\n",
    "sliver_tet=get_sliver_tet(1)\n",
    "dh=dihedral_angles(spindle_tet)\n",
    "sa=solid_angles(spindle_tet)\n",
    "dh2=dihedral_angles(sliver_tet)\n",
    "sa2=solid_angles(sliver_tet)\n",
    "shape,value=shape_type(cap_tet)\n",
    "#dh,sa,dh2,sa2\n",
    "rotating_tetrahedron=np.dot(rotate(pi/3,0,pi/2),regular_tetrahedron.T).T\n",
    "eig,F,U,rotation_angle=get_eigenvalues(rotating_tetrahedron)\n",
    "print(eig,rotation_angle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segBarycenter=np.empty([2,3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_coords_x,plot_coords_y,plot_coords_z=zip(*rotating_tetrahedron)\n",
    "plot_coords_x2,plot_coords_y2,plot_coords_z2=zip(*regular_tetrahedron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mesh=go.Mesh3d(x=plot_coords_x,y=plot_coords_y,z=plot_coords_z,color='blue',opacity=2)\n",
    "#mesh2=go.Mesh3d(x=plot_coords_x2,y=plot_coords_y2,z=plot_coords_z2,color='red',opacity=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotly.offline.init_notebook_mode(connected=True)\n",
    "#plotly.offline.plot([mesh,mesh2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " ...]"
      ]
     },
     "execution_count": 545,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# building the train data \n",
    "nb_of_samples=4000\n",
    "step=(1.0-0.9)/nb_of_samples\n",
    "eigen_values=np.empty([2*nb_of_samples,3])\n",
    "type_values=[]\n",
    "type_names=[]\n",
    "\n",
    "#for f in [get_needle_tet,get_sliver_tet,get_wedge_tet,get_cap_tet,get_spindle_tet]:\n",
    "for f in [get_needle_tet]:\n",
    "    count=0\n",
    "    for i in range(nb_of_samples):\n",
    "        tet=f(0.9+i*step)\n",
    "        eig,_,_,_=get_eigenvalues(tet)\n",
    "        eigen_values[i+count*nb_of_samples]=eig\n",
    "        shape,value=shape_type(tet)\n",
    "        type_values.append(value)\n",
    "    \n",
    "        type_names.append(shape)\n",
    "    count+=1\n",
    "    \n",
    "for i in range(nb_of_samples):\n",
    "    tet=get_sliver_tet(0.1+i*step) #mainly done to produce round samples(close to regular)\n",
    "    eigen_values[i+(count)*nb_of_samples]=eig\n",
    "    shape,value=shape_type(tet)\n",
    "    type_values.append(value)\n",
    "    type_names.append(shape)\n",
    "type_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.37745348, -0.64855078, -0.64855078],\n",
       "       [ 2.37724808, -0.6485788 , -0.6485788 ],\n",
       "       [ 2.37704273, -0.64860681, -0.64860681],\n",
       "       ..., \n",
       "       [ 1.79973476, -0.74541092, -0.74541092],\n",
       "       [ 1.79973476, -0.74541092, -0.74541092],\n",
       "       [ 1.79973476, -0.74541092, -0.74541092]])"
      ]
     },
     "execution_count": 546,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigen_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 547,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# building the test data #\n",
    "nb_of_test_samples=800\n",
    "step=(1.0-0.9)/nb_of_samples\n",
    "eigen_values_test=np.empty([2*nb_of_test_samples,3])\n",
    "type_values_test=[]\n",
    "type_names_test=[]\n",
    "\n",
    "#for f in [get_needle_tet,get_sliver_tet,get_wedge_tet,get_cap_tet,get_spindle_tet]:\n",
    "for f in [get_needle_tet]:\n",
    "\n",
    "    count=0\n",
    "    for i in range(nb_of_test_samples):\n",
    "        tet=f(0.9+i*step)\n",
    "        eig,_,_,_=get_eigenvalues(tet)\n",
    "        eigen_values_test[i+count*nb_of_test_samples]=eig\n",
    "        shape,value=shape_type(tet)\n",
    "        type_values_test.append(value)\n",
    "    \n",
    "        type_names_test.append(shape)\n",
    "    count+=1\n",
    "    \n",
    "for i in range(nb_of_test_samples):\n",
    "    tet=get_sliver_tet(0.0001+i*step) #mainly done to produce round samples(close to regular)\n",
    "    eigen_values_test[i+(count)*nb_of_test_samples]=eig\n",
    "    shape,value=shape_type(tet)\n",
    "    type_values_test.append(value)\n",
    "    type_names_test.append(shape)\n",
    "type_values_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "#manage the training data\n",
    "\n",
    "X_train=eigen_values\n",
    "Y_train=np.array(type_values).reshape(2*nb_of_samples) # 6 refers to the number of categories\n",
    "\n",
    "X_test=eigen_values_test\n",
    "Y_test=np.array(type_values_test).reshape(2*nb_of_test_samples) # 6 refers to the number of categories\n",
    "\n",
    "\n",
    "for i in range(2*(nb_of_samples)):\n",
    "    for j in range(2):\n",
    "        if np.isinf(X_train[i][j]):\n",
    "            X_train[i][j]=0\n",
    "            \n",
    "for i in range(2*(nb_of_test_samples)):\n",
    "    for j in range(2):\n",
    "        if np.isinf(X_test[i][j]):\n",
    "            X_test[i][j]=0\n",
    "# Convert to pytorch tennsors\n",
    "\n",
    "x_tensor=torch.from_numpy(X_train).type(torch.FloatTensor)\n",
    "x_tensor[x_tensor == float(\"Inf\")] = 0\n",
    "x_tensor[x_tensor == float(\"-Inf\")] = 0\n",
    "\n",
    "x_test_tensor=torch.from_numpy(X_train).type(torch.FloatTensor)\n",
    "x_test_tensor[x_test_tensor == float(\"Inf\")] = 0\n",
    "x_test_tensor[x_test_tensor == float(\"-Inf\")] = 0\n",
    "\n",
    "\n",
    "\n",
    "y_tensor=torch.from_numpy(Y_train).type(torch.LongTensor)\n",
    "y_test_tensor=torch.from_numpy(Y_test).type(torch.LongTensor)\n",
    "# Convert to pytorch variables\n",
    "x_variable=Variable(x_tensor,requires_grad=False)\n",
    "y_variable=Variable(y_tensor,requires_grad=False)\n",
    "\n",
    "\n",
    "\n",
    "x_test_variable=Variable(x_test_tensor,requires_grad=False)\n",
    "y_test_variable=Variable(y_test_tensor,requires_grad=False)\n",
    "\n",
    "# Normalize data\n",
    "mu,std=x_variable.mean(0),x_variable.std(0)\n",
    "mu_test,std_test=x_test_variable.mean(0),x_test_variable.std(0)\n",
    "\n",
    "\n",
    "x_variable.sub_(mu).div_(std)\n",
    "x_test_variable.sub_(mu).div_(std)\n",
    "y_variable,x_variable\n",
    "\n",
    "\n",
    "shuffle=torch.randperm(x_variable.shape[0])\n",
    "x_variable = x_variable[shuffle]\n",
    "y_variable=y_variable[shuffle]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, n_feature, n_hidden, n_output):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(n_feature, n_hidden)   # hidden layer\n",
    "        self.fc1_bn=torch.nn.BatchNorm1d(n_hidden)\n",
    "\n",
    "        self.fc2 = torch.nn.Linear(n_hidden, n_hidden)   # output layer\n",
    "        self.fc2_bn=torch.nn.BatchNorm1d(n_hidden)\n",
    "        \n",
    "        self.fc3 = torch.nn.Linear(n_hidden, n_hidden)   # output layer\n",
    "        self.fc3_bn=torch.nn.BatchNorm1d(n_hidden)\n",
    "        \n",
    "        self.fc4 = torch.nn.Linear(n_hidden, n_hidden)   # output layer\n",
    "        self.fc4_bn=torch.nn.BatchNorm1d(n_hidden)\n",
    "        \n",
    "        self.fc5 = torch.nn.Linear(n_hidden, n_hidden)   # output layer\n",
    "        self.fc5_bn=torch.nn.BatchNorm1d(n_hidden)\n",
    "        \n",
    "        self.fc6 = torch.nn.Linear(n_hidden, n_output)   # output layer\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = Func.relu(self.fc1(x))      # activation function for hidden layer\n",
    "        x=self.fc2_bn(x)\n",
    "\n",
    "        x = Func.relu(self.fc2(x))\n",
    "        x=self.fc2_bn(x)\n",
    "        x =Func.relu(self.fc3(x))\n",
    "        x=self.fc3_bn(x)\n",
    "        x = Func.relu(self.fc4(x))\n",
    "        x=self.fc2_bn(x)\n",
    "        x =Func.relu(self.fc5(x))\n",
    "        x=self.fc3_bn(x)\n",
    "        x =Func.relu(self.fc6(x))\n",
    "\n",
    "        return x\n",
    "        #return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=3, out_features=100)\n",
      "  (fc1_bn): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (fc2): Linear(in_features=100, out_features=100)\n",
      "  (fc2_bn): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (fc3): Linear(in_features=100, out_features=100)\n",
      "  (fc3_bn): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (fc4): Linear(in_features=100, out_features=100)\n",
      "  (fc4_bn): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (fc5): Linear(in_features=100, out_features=100)\n",
      "  (fc5_bn): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (fc6): Linear(in_features=100, out_features=2)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Set architeture #\n",
    "net = Net(n_feature=3, n_hidden=100, n_output=2)     # define the network\n",
    "print(net)  # net architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer=torch.optim.Adam(net.parameters(),lr=0.00001)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-7)\n",
    "#optimizer = torch.optim.SGD(net.parameters(), lr=1e-3,momentum=0.9)\n",
    "loss_func = torch.nn.CrossEntropyLoss()  # the target label is NOT an one-hotted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Loss: 55.88132095336914  acc_train_error 50.0%  acc_test_error 50.0%\n",
      "Epoch: 1 Loss: 55.74956130981445  acc_train_error 50.0%  acc_test_error 50.0%\n",
      "Epoch: 2 Loss: 55.62139129638672  acc_train_error 50.0%  acc_test_error 50.0%\n",
      "Epoch: 3 Loss: 55.5003776550293  acc_train_error 50.0%  acc_test_error 50.0%\n",
      "Epoch: 4 Loss: 55.38279342651367  acc_train_error 50.0%  acc_test_error 50.0%\n",
      "Epoch: 5 Loss: 55.26974868774414  acc_train_error 50.0%  acc_test_error 50.0%\n",
      "Epoch: 6 Loss: 55.16136932373047  acc_train_error 50.0%  acc_test_error 50.0%\n",
      "Epoch: 7 Loss: 55.05427169799805  acc_train_error 50.0%  acc_test_error 50.0%\n",
      "Epoch: 8 Loss: 54.95062255859375  acc_train_error 50.0%  acc_test_error 50.0%\n",
      "Epoch: 9 Loss: 54.85337829589844  acc_train_error 50.0%  acc_test_error 50.0%\n",
      "Epoch: 10 Loss: 54.76095199584961  acc_train_error 50.0%  acc_test_error 50.0%\n",
      "Epoch: 11 Loss: 54.66729736328125  acc_train_error 50.0%  acc_test_error 50.0%\n",
      "Epoch: 12 Loss: 54.57306671142578  acc_train_error 50.0%  acc_test_error 50.0%\n",
      "Epoch: 13 Loss: 54.4769401550293  acc_train_error 50.0%  acc_test_error 50.0%\n",
      "Epoch: 14 Loss: 54.38376235961914  acc_train_error 50.0%  acc_test_error 50.0%\n",
      "Epoch: 15 Loss: 54.28767776489258  acc_train_error 50.0%  acc_test_error 50.0%\n",
      "Epoch: 16 Loss: 54.19025421142578  acc_train_error 50.0%  acc_test_error 50.0%\n",
      "Epoch: 17 Loss: 54.08859634399414  acc_train_error 50.0%  acc_test_error 50.0%\n",
      "Epoch: 18 Loss: 53.983699798583984  acc_train_error 50.0%  acc_test_error 50.0%\n",
      "Epoch: 19 Loss: 53.87592697143555  acc_train_error 50.0%  acc_test_error 50.0%\n",
      "Epoch: 20 Loss: 53.7681770324707  acc_train_error 50.0%  acc_test_error 50.0%\n",
      "Epoch: 21 Loss: 53.66246032714844  acc_train_error 50.0%  acc_test_error 50.0%\n",
      "Epoch: 22 Loss: 53.5465087890625  acc_train_error 50.0%  acc_test_error 50.0%\n",
      "Epoch: 23 Loss: 53.42013931274414  acc_train_error 50.0%  acc_test_error 50.0%\n",
      "Epoch: 24 Loss: 53.28945541381836  acc_train_error 50.0%  acc_test_error 50.0%\n",
      "Epoch: 25 Loss: 53.15703201293945  acc_train_error 50.0%  acc_test_error 50.0%\n",
      "Epoch: 26 Loss: 53.015750885009766  acc_train_error 50.0%  acc_test_error 50.0%\n",
      "Epoch: 27 Loss: 52.875614166259766  acc_train_error 50.0%  acc_test_error 50.0%\n",
      "Epoch: 28 Loss: 52.7363395690918  acc_train_error 50.0%  acc_test_error 50.0%\n",
      "Epoch: 29 Loss: 52.60008239746094  acc_train_error 50.0%  acc_test_error 50.0%\n",
      "Epoch: 30 Loss: 52.462745666503906  acc_train_error 50.0%  acc_test_error 50.0%\n",
      "Epoch: 31 Loss: 52.327701568603516  acc_train_error 50.0%  acc_test_error 50.0%\n",
      "Epoch: 32 Loss: 52.19397735595703  acc_train_error 50.0%  acc_test_error 50.0%\n",
      "Epoch: 33 Loss: 52.05957794189453  acc_train_error 50.0%  acc_test_error 50.0%\n",
      "Epoch: 34 Loss: 51.927520751953125  acc_train_error 50.0%  acc_test_error 50.0%\n",
      "Epoch: 35 Loss: 51.79711151123047  acc_train_error 50.0%  acc_test_error 50.0%\n",
      "Epoch: 36 Loss: 51.66645050048828  acc_train_error 50.0%  acc_test_error 50.0%\n",
      "Epoch: 37 Loss: 51.53548049926758  acc_train_error 50.0%  acc_test_error 50.0%\n",
      "Epoch: 38 Loss: 51.40640640258789  acc_train_error 50.0%  acc_test_error 50.0%\n",
      "Epoch: 39 Loss: 51.2790641784668  acc_train_error 50.0%  acc_test_error 50.0%\n",
      "Epoch: 40 Loss: 51.15275573730469  acc_train_error 50.0%  acc_test_error 50.0%\n",
      "Epoch: 41 Loss: 51.026676177978516  acc_train_error 50.0%  acc_test_error 50.0%\n",
      "Epoch: 42 Loss: 50.9000358581543  acc_train_error 50.0%  acc_test_error 50.0%\n",
      "Epoch: 43 Loss: 50.77480697631836  acc_train_error 50.0%  acc_test_error 50.0%\n",
      "Epoch: 44 Loss: 50.651161193847656  acc_train_error 50.0%  acc_test_error 50.0%\n",
      "Epoch: 45 Loss: 50.52821350097656  acc_train_error 50.0%  acc_test_error 50.0%\n",
      "Epoch: 46 Loss: 50.406551361083984  acc_train_error 50.0%  acc_test_error 50.0%\n",
      "Epoch: 47 Loss: 50.28514862060547  acc_train_error 50.0%  acc_test_error 50.0%\n",
      "Epoch: 48 Loss: 50.16535949707031  acc_train_error 49.9875%  acc_test_error 50.0%\n",
      "Epoch: 49 Loss: 50.048030853271484  acc_train_error 49.8875%  acc_test_error 50.0%\n",
      "Epoch: 50 Loss: 49.93214797973633  acc_train_error 49.775%  acc_test_error 50.0%\n",
      "Epoch: 51 Loss: 49.817073822021484  acc_train_error 49.675%  acc_test_error 50.0%\n",
      "Epoch: 52 Loss: 49.70343017578125  acc_train_error 49.5625%  acc_test_error 50.0%\n",
      "Epoch: 53 Loss: 49.5920524597168  acc_train_error 49.4%  acc_test_error 50.0%\n",
      "Epoch: 54 Loss: 49.48138427734375  acc_train_error 49.175%  acc_test_error 50.0%\n",
      "Epoch: 55 Loss: 49.371917724609375  acc_train_error 49.075%  acc_test_error 50.0%\n",
      "Epoch: 56 Loss: 49.26317596435547  acc_train_error 49.0%  acc_test_error 50.0%\n",
      "Epoch: 57 Loss: 49.15458297729492  acc_train_error 48.9375%  acc_test_error 50.0%\n",
      "Epoch: 58 Loss: 49.047386169433594  acc_train_error 48.8875%  acc_test_error 50.0%\n",
      "Epoch: 59 Loss: 48.94196701049805  acc_train_error 48.85%  acc_test_error 50.0%\n",
      "Epoch: 60 Loss: 48.8385124206543  acc_train_error 48.7875%  acc_test_error 50.0%\n",
      "Epoch: 61 Loss: 48.737613677978516  acc_train_error 48.7625%  acc_test_error 50.0%\n",
      "Epoch: 62 Loss: 48.63838195800781  acc_train_error 48.7125%  acc_test_error 50.0%\n",
      "Epoch: 63 Loss: 48.54054641723633  acc_train_error 48.675%  acc_test_error 50.0%\n",
      "Epoch: 64 Loss: 48.44377899169922  acc_train_error 48.625%  acc_test_error 50.0%\n",
      "Epoch: 65 Loss: 48.347591400146484  acc_train_error 48.575%  acc_test_error 50.0%\n",
      "Epoch: 66 Loss: 48.25210189819336  acc_train_error 48.4375%  acc_test_error 50.0%\n",
      "Epoch: 67 Loss: 48.156524658203125  acc_train_error 48.1625%  acc_test_error 50.0%\n",
      "Epoch: 68 Loss: 48.06150436401367  acc_train_error 48.05%  acc_test_error 50.0%\n",
      "Epoch: 69 Loss: 47.967498779296875  acc_train_error 47.95%  acc_test_error 50.0%\n",
      "Epoch: 70 Loss: 47.874176025390625  acc_train_error 47.85%  acc_test_error 50.0%\n",
      "Epoch: 71 Loss: 47.78163528442383  acc_train_error 47.6375%  acc_test_error 50.0%\n",
      "Epoch: 72 Loss: 47.690406799316406  acc_train_error 47.3375%  acc_test_error 50.0%\n",
      "Epoch: 73 Loss: 47.60032653808594  acc_train_error 46.875%  acc_test_error 50.0%\n",
      "Epoch: 74 Loss: 47.511474609375  acc_train_error 46.7875%  acc_test_error 50.0%\n",
      "Epoch: 75 Loss: 47.42409133911133  acc_train_error 46.7375%  acc_test_error 50.0%\n",
      "Epoch: 76 Loss: 47.33739471435547  acc_train_error 46.6625%  acc_test_error 50.0%\n",
      "Epoch: 77 Loss: 47.25122833251953  acc_train_error 46.6125%  acc_test_error 50.0%\n",
      "Epoch: 78 Loss: 47.16572952270508  acc_train_error 46.575%  acc_test_error 50.0%\n",
      "Epoch: 79 Loss: 47.08091354370117  acc_train_error 46.525%  acc_test_error 50.0%\n",
      "Epoch: 80 Loss: 46.99650955200195  acc_train_error 46.475%  acc_test_error 50.0%\n",
      "Epoch: 81 Loss: 46.913028717041016  acc_train_error 46.425%  acc_test_error 50.0%\n",
      "Epoch: 82 Loss: 46.82999038696289  acc_train_error 46.375%  acc_test_error 50.0%\n",
      "Epoch: 83 Loss: 46.74732208251953  acc_train_error 46.325%  acc_test_error 50.0%\n",
      "Epoch: 84 Loss: 46.66485595703125  acc_train_error 46.3125%  acc_test_error 50.0%\n",
      "Epoch: 85 Loss: 46.58332443237305  acc_train_error 46.275%  acc_test_error 50.0%\n",
      "Epoch: 86 Loss: 46.50271987915039  acc_train_error 46.2375%  acc_test_error 50.0%\n",
      "Epoch: 87 Loss: 46.42253875732422  acc_train_error 46.1875%  acc_test_error 50.0%\n",
      "Epoch: 88 Loss: 46.342830657958984  acc_train_error 46.0875%  acc_test_error 50.0%\n",
      "Epoch: 89 Loss: 46.263267517089844  acc_train_error 46.0%  acc_test_error 50.0%\n",
      "Epoch: 90 Loss: 46.18376541137695  acc_train_error 45.9875%  acc_test_error 50.0%\n",
      "Epoch: 91 Loss: 46.104549407958984  acc_train_error 45.9375%  acc_test_error 50.0%\n",
      "Epoch: 92 Loss: 46.02546691894531  acc_train_error 45.8875%  acc_test_error 50.0%\n",
      "Epoch: 93 Loss: 45.9462890625  acc_train_error 45.85%  acc_test_error 50.0%\n",
      "Epoch: 94 Loss: 45.867462158203125  acc_train_error 45.8%  acc_test_error 50.0%\n",
      "Epoch: 95 Loss: 45.78915023803711  acc_train_error 45.7625%  acc_test_error 50.0%\n",
      "Epoch: 96 Loss: 45.7114143371582  acc_train_error 45.725%  acc_test_error 50.0%\n",
      "Epoch: 97 Loss: 45.63420486450195  acc_train_error 45.7125%  acc_test_error 50.0%\n",
      "Epoch: 98 Loss: 45.55717849731445  acc_train_error 45.7%  acc_test_error 50.0%\n",
      "Epoch: 99 Loss: 45.480411529541016  acc_train_error 45.7%  acc_test_error 50.0%\n",
      "Epoch: 100 Loss: 45.404029846191406  acc_train_error 45.7%  acc_test_error 50.0%\n",
      "Epoch: 101 Loss: 45.327510833740234  acc_train_error 45.7%  acc_test_error 50.0%\n",
      "Epoch: 102 Loss: 45.25080108642578  acc_train_error 45.6875%  acc_test_error 50.0%\n",
      "Epoch: 103 Loss: 45.17424392700195  acc_train_error 45.675%  acc_test_error 50.0%\n",
      "Epoch: 104 Loss: 45.09785842895508  acc_train_error 45.675%  acc_test_error 50.0%\n",
      "Epoch: 105 Loss: 45.02175521850586  acc_train_error 45.6625%  acc_test_error 50.0%\n",
      "Epoch: 106 Loss: 44.94611740112305  acc_train_error 45.6625%  acc_test_error 50.0%\n",
      "Epoch: 107 Loss: 44.87076950073242  acc_train_error 45.6625%  acc_test_error 50.0%\n",
      "Epoch: 108 Loss: 44.795562744140625  acc_train_error 45.6625%  acc_test_error 50.0%\n",
      "Epoch: 109 Loss: 44.720672607421875  acc_train_error 45.6625%  acc_test_error 50.0%\n",
      "Epoch: 110 Loss: 44.646175384521484  acc_train_error 45.6625%  acc_test_error 50.0%\n",
      "Epoch: 111 Loss: 44.57196807861328  acc_train_error 45.6625%  acc_test_error 50.0%\n",
      "Epoch: 112 Loss: 44.49807357788086  acc_train_error 45.65%  acc_test_error 50.0%\n",
      "Epoch: 113 Loss: 44.42436981201172  acc_train_error 45.65%  acc_test_error 50.0%\n",
      "Epoch: 114 Loss: 44.350738525390625  acc_train_error 45.65%  acc_test_error 50.0%\n",
      "Epoch: 115 Loss: 44.277366638183594  acc_train_error 45.6375%  acc_test_error 50.0%\n",
      "Epoch: 116 Loss: 44.204322814941406  acc_train_error 45.6375%  acc_test_error 50.0%\n",
      "Epoch: 117 Loss: 44.13177490234375  acc_train_error 45.6375%  acc_test_error 50.0%\n",
      "Epoch: 118 Loss: 44.05958557128906  acc_train_error 45.6375%  acc_test_error 50.0%\n",
      "Epoch: 119 Loss: 43.98786926269531  acc_train_error 45.6375%  acc_test_error 50.0%\n",
      "Epoch: 120 Loss: 43.916690826416016  acc_train_error 45.6375%  acc_test_error 50.0%\n",
      "Epoch: 121 Loss: 43.84607696533203  acc_train_error 45.6375%  acc_test_error 50.0%\n",
      "Epoch: 122 Loss: 43.775691986083984  acc_train_error 45.625%  acc_test_error 50.0%\n",
      "Epoch: 123 Loss: 43.705753326416016  acc_train_error 45.625%  acc_test_error 50.0%\n",
      "Epoch: 124 Loss: 43.63614273071289  acc_train_error 45.625%  acc_test_error 50.0%\n",
      "Epoch: 125 Loss: 43.56669998168945  acc_train_error 45.625%  acc_test_error 50.0%\n",
      "Epoch: 126 Loss: 43.49740219116211  acc_train_error 45.6125%  acc_test_error 50.0%\n",
      "Epoch: 127 Loss: 43.428306579589844  acc_train_error 45.6125%  acc_test_error 50.0%\n",
      "Epoch: 128 Loss: 43.35969543457031  acc_train_error 45.6%  acc_test_error 50.0%\n",
      "Epoch: 129 Loss: 43.29172134399414  acc_train_error 45.55%  acc_test_error 50.0%\n",
      "Epoch: 130 Loss: 43.22395324707031  acc_train_error 45.5125%  acc_test_error 50.0%\n",
      "Epoch: 131 Loss: 43.15663528442383  acc_train_error 45.45%  acc_test_error 50.0%\n",
      "Epoch: 132 Loss: 43.08937072753906  acc_train_error 45.4%  acc_test_error 50.0%\n",
      "Epoch: 133 Loss: 43.02183532714844  acc_train_error 45.3875%  acc_test_error 50.0%\n",
      "Epoch: 134 Loss: 42.954769134521484  acc_train_error 45.375%  acc_test_error 50.0%\n",
      "Epoch: 135 Loss: 42.88813781738281  acc_train_error 45.3625%  acc_test_error 50.0%\n",
      "Epoch: 136 Loss: 42.82196807861328  acc_train_error 45.35%  acc_test_error 50.0%\n",
      "Epoch: 137 Loss: 42.75625991821289  acc_train_error 45.3375%  acc_test_error 50.0%\n",
      "Epoch: 138 Loss: 42.691097259521484  acc_train_error 45.325%  acc_test_error 50.0%\n",
      "Epoch: 139 Loss: 42.626277923583984  acc_train_error 45.3125%  acc_test_error 50.0%\n",
      "Epoch: 140 Loss: 42.561824798583984  acc_train_error 45.3125%  acc_test_error 50.0%\n",
      "Epoch: 141 Loss: 42.49778366088867  acc_train_error 45.3%  acc_test_error 50.0%\n",
      "Epoch: 142 Loss: 42.434059143066406  acc_train_error 45.2875%  acc_test_error 50.0%\n",
      "Epoch: 143 Loss: 42.37078857421875  acc_train_error 45.275%  acc_test_error 50.0%\n",
      "Epoch: 144 Loss: 42.30781936645508  acc_train_error 45.275%  acc_test_error 50.0%\n",
      "Epoch: 145 Loss: 42.24530792236328  acc_train_error 45.2625%  acc_test_error 50.0%\n",
      "Epoch: 146 Loss: 42.183101654052734  acc_train_error 45.25%  acc_test_error 50.0%\n",
      "Epoch: 147 Loss: 42.12130355834961  acc_train_error 45.2375%  acc_test_error 50.0%\n",
      "Epoch: 148 Loss: 42.0598258972168  acc_train_error 45.25%  acc_test_error 50.0%\n",
      "Epoch: 149 Loss: 41.998722076416016  acc_train_error 45.2375%  acc_test_error 50.0%\n",
      "Epoch: 150 Loss: 41.9379768371582  acc_train_error 45.225%  acc_test_error 50.0%\n",
      "Epoch: 151 Loss: 41.87749099731445  acc_train_error 45.225%  acc_test_error 50.0%\n",
      "Epoch: 152 Loss: 41.817474365234375  acc_train_error 45.2125%  acc_test_error 50.0%\n",
      "Epoch: 153 Loss: 41.75773239135742  acc_train_error 45.2%  acc_test_error 50.0%\n",
      "Epoch: 154 Loss: 41.69820785522461  acc_train_error 45.2125%  acc_test_error 50.0%\n",
      "Epoch: 155 Loss: 41.63902282714844  acc_train_error 45.2%  acc_test_error 50.0%\n",
      "Epoch: 156 Loss: 41.580223083496094  acc_train_error 45.1875%  acc_test_error 50.0%\n",
      "Epoch: 157 Loss: 41.5216178894043  acc_train_error 45.175%  acc_test_error 50.0%\n",
      "Epoch: 158 Loss: 41.46329116821289  acc_train_error 45.175%  acc_test_error 50.0%\n",
      "Epoch: 159 Loss: 41.40516662597656  acc_train_error 45.1625%  acc_test_error 50.0%\n",
      "Epoch: 160 Loss: 41.34723663330078  acc_train_error 45.15%  acc_test_error 50.0%\n",
      "Epoch: 161 Loss: 41.28950881958008  acc_train_error 45.15%  acc_test_error 50.0%\n",
      "Epoch: 162 Loss: 41.2320442199707  acc_train_error 45.15%  acc_test_error 50.0%\n",
      "Epoch: 163 Loss: 41.17485427856445  acc_train_error 45.1375%  acc_test_error 50.0%\n",
      "Epoch: 164 Loss: 41.117862701416016  acc_train_error 45.125%  acc_test_error 50.0%\n",
      "Epoch: 165 Loss: 41.06101989746094  acc_train_error 45.125%  acc_test_error 50.0%\n",
      "Epoch: 166 Loss: 41.00431823730469  acc_train_error 45.1125%  acc_test_error 50.0%\n",
      "Epoch: 167 Loss: 40.947959899902344  acc_train_error 45.1125%  acc_test_error 50.0%\n",
      "Epoch: 168 Loss: 40.891883850097656  acc_train_error 45.1%  acc_test_error 50.0%\n",
      "Epoch: 169 Loss: 40.83600997924805  acc_train_error 45.1%  acc_test_error 50.0%\n",
      "Epoch: 170 Loss: 40.7802734375  acc_train_error 45.0875%  acc_test_error 50.0%\n",
      "Epoch: 171 Loss: 40.724708557128906  acc_train_error 45.075%  acc_test_error 50.0%\n",
      "Epoch: 172 Loss: 40.66930389404297  acc_train_error 45.075%  acc_test_error 50.0%\n",
      "Epoch: 173 Loss: 40.614131927490234  acc_train_error 45.0625%  acc_test_error 50.0%\n",
      "Epoch: 174 Loss: 40.559181213378906  acc_train_error 45.0625%  acc_test_error 50.0%\n",
      "Epoch: 175 Loss: 40.504329681396484  acc_train_error 45.05%  acc_test_error 50.0%\n",
      "Epoch: 176 Loss: 40.449588775634766  acc_train_error 45.05%  acc_test_error 50.0%\n",
      "Epoch: 177 Loss: 40.394996643066406  acc_train_error 45.0375%  acc_test_error 50.0%\n",
      "Epoch: 178 Loss: 40.340579986572266  acc_train_error 45.05%  acc_test_error 50.0%\n",
      "Epoch: 179 Loss: 40.28641891479492  acc_train_error 45.05%  acc_test_error 50.0%\n",
      "Epoch: 180 Loss: 40.232486724853516  acc_train_error 45.0375%  acc_test_error 50.0%\n",
      "Epoch: 181 Loss: 40.17876052856445  acc_train_error 45.0375%  acc_test_error 50.0%\n",
      "Epoch: 182 Loss: 40.12518310546875  acc_train_error 45.025%  acc_test_error 50.0%\n",
      "Epoch: 183 Loss: 40.07177734375  acc_train_error 45.0375%  acc_test_error 50.0%\n",
      "Epoch: 184 Loss: 40.01847457885742  acc_train_error 45.025%  acc_test_error 50.0%\n",
      "Epoch: 185 Loss: 39.96528625488281  acc_train_error 45.025%  acc_test_error 50.0%\n",
      "Epoch: 186 Loss: 39.91215896606445  acc_train_error 45.0125%  acc_test_error 50.0%\n",
      "Epoch: 187 Loss: 39.85913848876953  acc_train_error 45.0125%  acc_test_error 50.0%\n",
      "Epoch: 188 Loss: 39.806190490722656  acc_train_error 45.0%  acc_test_error 50.0%\n",
      "Epoch: 189 Loss: 39.753231048583984  acc_train_error 45.0125%  acc_test_error 50.0%\n",
      "Epoch: 190 Loss: 39.700233459472656  acc_train_error 45.0%  acc_test_error 50.0%\n",
      "Epoch: 191 Loss: 39.647186279296875  acc_train_error 45.0%  acc_test_error 50.0%\n",
      "Epoch: 192 Loss: 39.59421157836914  acc_train_error 45.0%  acc_test_error 50.0%\n",
      "Epoch: 193 Loss: 39.54135513305664  acc_train_error 44.9875%  acc_test_error 50.0%\n",
      "Epoch: 194 Loss: 39.48862075805664  acc_train_error 44.9875%  acc_test_error 50.0%\n",
      "Epoch: 195 Loss: 39.43588638305664  acc_train_error 44.975%  acc_test_error 50.0%\n",
      "Epoch: 196 Loss: 39.383140563964844  acc_train_error 44.9875%  acc_test_error 50.0%\n",
      "Epoch: 197 Loss: 39.330318450927734  acc_train_error 44.975%  acc_test_error 50.0%\n",
      "Epoch: 198 Loss: 39.27745056152344  acc_train_error 44.9625%  acc_test_error 50.0%\n",
      "Epoch: 199 Loss: 39.22461700439453  acc_train_error 44.9625%  acc_test_error 50.0%\n",
      "Epoch: 200 Loss: 39.17190170288086  acc_train_error 44.95%  acc_test_error 50.0%\n",
      "Epoch: 201 Loss: 39.1192626953125  acc_train_error 44.95%  acc_test_error 50.0%\n",
      "Epoch: 202 Loss: 39.066593170166016  acc_train_error 44.95%  acc_test_error 50.0%\n",
      "Epoch: 203 Loss: 39.013858795166016  acc_train_error 44.95%  acc_test_error 50.0%\n",
      "Epoch: 204 Loss: 38.9609489440918  acc_train_error 44.9375%  acc_test_error 50.0%\n",
      "Epoch: 205 Loss: 38.908103942871094  acc_train_error 44.9375%  acc_test_error 50.0%\n",
      "Epoch: 206 Loss: 38.85541915893555  acc_train_error 44.925%  acc_test_error 50.0%\n",
      "Epoch: 207 Loss: 38.80263137817383  acc_train_error 44.925%  acc_test_error 50.0%\n",
      "Epoch: 208 Loss: 38.7497444152832  acc_train_error 44.9125%  acc_test_error 50.0%\n",
      "Epoch: 209 Loss: 38.696876525878906  acc_train_error 44.9125%  acc_test_error 50.0%\n",
      "Epoch: 210 Loss: 38.64405059814453  acc_train_error 44.9125%  acc_test_error 50.0%\n",
      "Epoch: 211 Loss: 38.59109878540039  acc_train_error 44.9%  acc_test_error 50.0%\n",
      "Epoch: 212 Loss: 38.53816604614258  acc_train_error 44.9%  acc_test_error 50.0%\n",
      "Epoch: 213 Loss: 38.48508834838867  acc_train_error 44.8875%  acc_test_error 50.0%\n",
      "Epoch: 214 Loss: 38.43171691894531  acc_train_error 44.875%  acc_test_error 50.0%\n",
      "Epoch: 215 Loss: 38.37815856933594  acc_train_error 44.875%  acc_test_error 50.0%\n",
      "Epoch: 216 Loss: 38.32461929321289  acc_train_error 44.8625%  acc_test_error 50.0%\n",
      "Epoch: 217 Loss: 38.27113723754883  acc_train_error 44.8625%  acc_test_error 50.0%\n",
      "Epoch: 218 Loss: 38.217655181884766  acc_train_error 44.8625%  acc_test_error 50.0%\n",
      "Epoch: 219 Loss: 38.164085388183594  acc_train_error 44.85%  acc_test_error 50.0%\n",
      "Epoch: 220 Loss: 38.11016845703125  acc_train_error 44.85%  acc_test_error 50.0%\n",
      "Epoch: 221 Loss: 38.05600357055664  acc_train_error 44.8375%  acc_test_error 50.0%\n",
      "Epoch: 222 Loss: 38.00163650512695  acc_train_error 44.8375%  acc_test_error 50.0%\n",
      "Epoch: 223 Loss: 37.94701385498047  acc_train_error 44.825%  acc_test_error 50.0%\n",
      "Epoch: 224 Loss: 37.8924446105957  acc_train_error 44.8125%  acc_test_error 50.0%\n",
      "Epoch: 225 Loss: 37.838138580322266  acc_train_error 44.825%  acc_test_error 50.0%\n",
      "Epoch: 226 Loss: 37.78399658203125  acc_train_error 44.8125%  acc_test_error 50.0%\n",
      "Epoch: 227 Loss: 37.729637145996094  acc_train_error 44.8125%  acc_test_error 50.0%\n",
      "Epoch: 228 Loss: 37.67491912841797  acc_train_error 44.8%  acc_test_error 50.0%\n",
      "Epoch: 229 Loss: 37.61990737915039  acc_train_error 44.7875%  acc_test_error 50.0%\n",
      "Epoch: 230 Loss: 37.564876556396484  acc_train_error 44.8%  acc_test_error 50.0%\n",
      "Epoch: 231 Loss: 37.5100212097168  acc_train_error 44.7875%  acc_test_error 50.0%\n",
      "Epoch: 232 Loss: 37.455352783203125  acc_train_error 44.7875%  acc_test_error 50.0%\n",
      "Epoch: 233 Loss: 37.40085983276367  acc_train_error 44.775%  acc_test_error 50.0%\n",
      "Epoch: 234 Loss: 37.346153259277344  acc_train_error 44.7625%  acc_test_error 50.0%\n",
      "Epoch: 235 Loss: 37.291324615478516  acc_train_error 44.7625%  acc_test_error 50.0%\n",
      "Epoch: 236 Loss: 37.23604202270508  acc_train_error 44.75%  acc_test_error 50.0%\n",
      "Epoch: 237 Loss: 37.18051528930664  acc_train_error 44.7625%  acc_test_error 50.0%\n",
      "Epoch: 238 Loss: 37.12457275390625  acc_train_error 44.75%  acc_test_error 50.0%\n",
      "Epoch: 239 Loss: 37.06824493408203  acc_train_error 44.75%  acc_test_error 50.0%\n",
      "Epoch: 240 Loss: 37.01169204711914  acc_train_error 44.7375%  acc_test_error 50.0%\n",
      "Epoch: 241 Loss: 36.95492172241211  acc_train_error 44.725%  acc_test_error 50.0%\n",
      "Epoch: 242 Loss: 36.89841842651367  acc_train_error 44.725%  acc_test_error 50.0%\n",
      "Epoch: 243 Loss: 36.841976165771484  acc_train_error 44.7125%  acc_test_error 50.0%\n",
      "Epoch: 244 Loss: 36.78538513183594  acc_train_error 44.725%  acc_test_error 50.0%\n",
      "Epoch: 245 Loss: 36.728580474853516  acc_train_error 44.7125%  acc_test_error 50.0%\n",
      "Epoch: 246 Loss: 36.671756744384766  acc_train_error 44.7%  acc_test_error 50.0%\n",
      "Epoch: 247 Loss: 36.614341735839844  acc_train_error 44.6875%  acc_test_error 50.0%\n",
      "Epoch: 248 Loss: 36.55683135986328  acc_train_error 44.7%  acc_test_error 50.0%\n",
      "Epoch: 249 Loss: 36.49932098388672  acc_train_error 44.675%  acc_test_error 50.0%\n",
      "Epoch: 250 Loss: 36.44144058227539  acc_train_error 44.6625%  acc_test_error 50.0%\n",
      "Epoch: 251 Loss: 36.38307189941406  acc_train_error 44.65%  acc_test_error 50.0%\n",
      "Epoch: 252 Loss: 36.32482147216797  acc_train_error 44.6375%  acc_test_error 50.0%\n",
      "Epoch: 253 Loss: 36.26654052734375  acc_train_error 44.625%  acc_test_error 50.0%\n",
      "Epoch: 254 Loss: 36.208194732666016  acc_train_error 44.6125%  acc_test_error 50.0%\n",
      "Epoch: 255 Loss: 36.14966583251953  acc_train_error 44.6%  acc_test_error 50.0%\n",
      "Epoch: 256 Loss: 36.09105682373047  acc_train_error 44.575%  acc_test_error 50.0%\n",
      "Epoch: 257 Loss: 36.032562255859375  acc_train_error 44.5625%  acc_test_error 50.0%\n",
      "Epoch: 258 Loss: 35.97385787963867  acc_train_error 44.55%  acc_test_error 50.0%\n",
      "Epoch: 259 Loss: 35.915199279785156  acc_train_error 44.5375%  acc_test_error 50.0%\n",
      "Epoch: 260 Loss: 35.85658645629883  acc_train_error 44.525%  acc_test_error 50.0%\n",
      "Epoch: 261 Loss: 35.797855377197266  acc_train_error 44.5125%  acc_test_error 50.0%\n",
      "Epoch: 262 Loss: 35.738624572753906  acc_train_error 44.5%  acc_test_error 50.0%\n",
      "Epoch: 263 Loss: 35.67902755737305  acc_train_error 44.475%  acc_test_error 50.0%\n",
      "Epoch: 264 Loss: 35.61927795410156  acc_train_error 44.4625%  acc_test_error 50.0%\n",
      "Epoch: 265 Loss: 35.55983352661133  acc_train_error 44.45%  acc_test_error 50.0%\n",
      "Epoch: 266 Loss: 35.50057601928711  acc_train_error 44.45%  acc_test_error 50.0%\n",
      "Epoch: 267 Loss: 35.44147491455078  acc_train_error 44.45%  acc_test_error 50.0%\n",
      "Epoch: 268 Loss: 35.38249206542969  acc_train_error 44.45%  acc_test_error 50.0%\n",
      "Epoch: 269 Loss: 35.32344055175781  acc_train_error 44.4375%  acc_test_error 50.0%\n",
      "Epoch: 270 Loss: 35.264339447021484  acc_train_error 44.4375%  acc_test_error 50.0%\n",
      "Epoch: 271 Loss: 35.205196380615234  acc_train_error 44.425%  acc_test_error 50.0%\n",
      "Epoch: 272 Loss: 35.146480560302734  acc_train_error 44.4375%  acc_test_error 50.0%\n",
      "Epoch: 273 Loss: 35.0882568359375  acc_train_error 44.425%  acc_test_error 50.0%\n",
      "Epoch: 274 Loss: 35.03040313720703  acc_train_error 44.4125%  acc_test_error 50.0%\n",
      "Epoch: 275 Loss: 34.97279739379883  acc_train_error 44.3875%  acc_test_error 50.0%\n",
      "Epoch: 276 Loss: 34.91530990600586  acc_train_error 44.375%  acc_test_error 50.0%\n",
      "Epoch: 277 Loss: 34.85801696777344  acc_train_error 44.3625%  acc_test_error 50.0%\n",
      "Epoch: 278 Loss: 34.800724029541016  acc_train_error 44.3375%  acc_test_error 50.0%\n",
      "Epoch: 279 Loss: 34.74281692504883  acc_train_error 44.3125%  acc_test_error 50.0%\n",
      "Epoch: 280 Loss: 34.684608459472656  acc_train_error 44.3%  acc_test_error 50.0%\n",
      "Epoch: 281 Loss: 34.62628936767578  acc_train_error 44.2875%  acc_test_error 50.0%\n",
      "Epoch: 282 Loss: 34.56829071044922  acc_train_error 44.275%  acc_test_error 50.0%\n",
      "Epoch: 283 Loss: 34.51066207885742  acc_train_error 44.2625%  acc_test_error 50.0%\n",
      "Epoch: 284 Loss: 34.453392028808594  acc_train_error 44.25%  acc_test_error 50.0%\n",
      "Epoch: 285 Loss: 34.39653015136719  acc_train_error 44.2375%  acc_test_error 50.0%\n",
      "Epoch: 286 Loss: 34.33986282348633  acc_train_error 44.2125%  acc_test_error 50.0%\n",
      "Epoch: 287 Loss: 34.28343200683594  acc_train_error 44.2%  acc_test_error 50.0%\n",
      "Epoch: 288 Loss: 34.22722625732422  acc_train_error 44.2%  acc_test_error 50.0%\n",
      "Epoch: 289 Loss: 34.17143249511719  acc_train_error 44.1875%  acc_test_error 50.0%\n",
      "Epoch: 290 Loss: 34.11613082885742  acc_train_error 44.175%  acc_test_error 50.0%\n",
      "Epoch: 291 Loss: 34.06119918823242  acc_train_error 44.1625%  acc_test_error 50.0%\n",
      "Epoch: 292 Loss: 34.006690979003906  acc_train_error 44.1625%  acc_test_error 50.0%\n",
      "Epoch: 293 Loss: 33.95262908935547  acc_train_error 44.15%  acc_test_error 50.0%\n",
      "Epoch: 294 Loss: 33.898948669433594  acc_train_error 44.15%  acc_test_error 50.0%\n",
      "Epoch: 295 Loss: 33.84565734863281  acc_train_error 44.15%  acc_test_error 50.0%\n",
      "Epoch: 296 Loss: 33.79275894165039  acc_train_error 44.15%  acc_test_error 50.0%\n",
      "Epoch: 297 Loss: 33.74037170410156  acc_train_error 44.15%  acc_test_error 50.0%\n",
      "Epoch: 298 Loss: 33.68848419189453  acc_train_error 44.1375%  acc_test_error 50.0%\n",
      "Epoch: 299 Loss: 33.63715744018555  acc_train_error 44.1375%  acc_test_error 50.0%\n",
      "Epoch: 300 Loss: 33.58644104003906  acc_train_error 44.1375%  acc_test_error 50.0%\n",
      "Epoch: 301 Loss: 33.53617477416992  acc_train_error 44.1375%  acc_test_error 50.0%\n",
      "Epoch: 302 Loss: 33.486289978027344  acc_train_error 44.125%  acc_test_error 50.0%\n",
      "Epoch: 303 Loss: 33.43677520751953  acc_train_error 44.125%  acc_test_error 50.0%\n",
      "Epoch: 304 Loss: 33.387596130371094  acc_train_error 44.125%  acc_test_error 50.0%\n",
      "Epoch: 305 Loss: 33.33867263793945  acc_train_error 44.125%  acc_test_error 50.0%\n",
      "Epoch: 306 Loss: 33.29021072387695  acc_train_error 44.125%  acc_test_error 50.0%\n",
      "Epoch: 307 Loss: 33.242271423339844  acc_train_error 44.125%  acc_test_error 50.0%\n",
      "Epoch: 308 Loss: 33.194740295410156  acc_train_error 44.1125%  acc_test_error 50.0%\n",
      "Epoch: 309 Loss: 33.147552490234375  acc_train_error 44.1125%  acc_test_error 50.0%\n",
      "Epoch: 310 Loss: 33.10065460205078  acc_train_error 44.125%  acc_test_error 50.0%\n",
      "Epoch: 311 Loss: 33.054073333740234  acc_train_error 44.1125%  acc_test_error 50.0%\n",
      "Epoch: 312 Loss: 33.007904052734375  acc_train_error 44.1125%  acc_test_error 50.0%\n",
      "Epoch: 313 Loss: 32.962318420410156  acc_train_error 44.1125%  acc_test_error 50.0%\n",
      "Epoch: 314 Loss: 32.917152404785156  acc_train_error 44.1125%  acc_test_error 50.0%\n",
      "Epoch: 315 Loss: 32.87223815917969  acc_train_error 44.1%  acc_test_error 50.0%\n",
      "Epoch: 316 Loss: 32.82764434814453  acc_train_error 44.1125%  acc_test_error 50.0%\n",
      "Epoch: 317 Loss: 32.78318405151367  acc_train_error 44.1125%  acc_test_error 50.0%\n",
      "Epoch: 318 Loss: 32.73903274536133  acc_train_error 44.1%  acc_test_error 50.0%\n",
      "Epoch: 319 Loss: 32.69518280029297  acc_train_error 44.1125%  acc_test_error 50.0%\n",
      "Epoch: 320 Loss: 32.65149688720703  acc_train_error 44.1%  acc_test_error 50.0%\n",
      "Epoch: 321 Loss: 32.608089447021484  acc_train_error 44.1%  acc_test_error 50.0%\n",
      "Epoch: 322 Loss: 32.56476974487305  acc_train_error 44.0875%  acc_test_error 50.0%\n",
      "Epoch: 323 Loss: 32.52153015136719  acc_train_error 44.1%  acc_test_error 50.0%\n",
      "Epoch: 324 Loss: 32.47832489013672  acc_train_error 44.1%  acc_test_error 50.0%\n",
      "Epoch: 325 Loss: 32.43515396118164  acc_train_error 44.0875%  acc_test_error 50.0%\n",
      "Epoch: 326 Loss: 32.392086029052734  acc_train_error 44.0875%  acc_test_error 50.0%\n",
      "Epoch: 327 Loss: 32.3491325378418  acc_train_error 44.0875%  acc_test_error 50.0%\n",
      "Epoch: 328 Loss: 32.30648422241211  acc_train_error 44.0875%  acc_test_error 50.0%\n",
      "Epoch: 329 Loss: 32.26389694213867  acc_train_error 44.0875%  acc_test_error 50.0%\n",
      "Epoch: 330 Loss: 32.22118377685547  acc_train_error 44.0875%  acc_test_error 50.0%\n",
      "Epoch: 331 Loss: 32.17845153808594  acc_train_error 44.0875%  acc_test_error 50.0%\n",
      "Epoch: 332 Loss: 32.13605499267578  acc_train_error 44.0875%  acc_test_error 50.0%\n",
      "Epoch: 333 Loss: 32.09366226196289  acc_train_error 44.075%  acc_test_error 50.0%\n",
      "Epoch: 334 Loss: 32.05132293701172  acc_train_error 44.075%  acc_test_error 50.0%\n",
      "Epoch: 335 Loss: 32.00933837890625  acc_train_error 44.075%  acc_test_error 50.0%\n",
      "Epoch: 336 Loss: 31.96744728088379  acc_train_error 44.075%  acc_test_error 50.0%\n",
      "Epoch: 337 Loss: 31.92566680908203  acc_train_error 44.075%  acc_test_error 50.0%\n",
      "Epoch: 338 Loss: 31.884092330932617  acc_train_error 44.075%  acc_test_error 50.0%\n",
      "Epoch: 339 Loss: 31.842580795288086  acc_train_error 44.075%  acc_test_error 50.0%\n",
      "Epoch: 340 Loss: 31.801250457763672  acc_train_error 44.075%  acc_test_error 50.0%\n",
      "Epoch: 341 Loss: 31.76012420654297  acc_train_error 44.075%  acc_test_error 50.0%\n",
      "Epoch: 342 Loss: 31.719310760498047  acc_train_error 44.075%  acc_test_error 50.0%\n",
      "Epoch: 343 Loss: 31.678621292114258  acc_train_error 44.075%  acc_test_error 50.0%\n",
      "Epoch: 344 Loss: 31.6381778717041  acc_train_error 44.075%  acc_test_error 50.0%\n",
      "Epoch: 345 Loss: 31.597932815551758  acc_train_error 44.075%  acc_test_error 50.0%\n",
      "Epoch: 346 Loss: 31.557804107666016  acc_train_error 44.075%  acc_test_error 50.0%\n",
      "Epoch: 347 Loss: 31.5178165435791  acc_train_error 44.075%  acc_test_error 50.0%\n",
      "Epoch: 348 Loss: 31.47795867919922  acc_train_error 44.075%  acc_test_error 50.0%\n",
      "Epoch: 349 Loss: 31.438201904296875  acc_train_error 44.075%  acc_test_error 50.0%\n",
      "Epoch: 350 Loss: 31.398605346679688  acc_train_error 44.075%  acc_test_error 50.0%\n",
      "Epoch: 351 Loss: 31.35923194885254  acc_train_error 44.075%  acc_test_error 50.0%\n",
      "Epoch: 352 Loss: 31.32006072998047  acc_train_error 44.0875%  acc_test_error 50.0%\n",
      "Epoch: 353 Loss: 31.281055450439453  acc_train_error 44.0875%  acc_test_error 50.0%\n",
      "Epoch: 354 Loss: 31.242116928100586  acc_train_error 44.075%  acc_test_error 50.0%\n",
      "Epoch: 355 Loss: 31.20332145690918  acc_train_error 44.075%  acc_test_error 50.0%\n",
      "Epoch: 356 Loss: 31.164669036865234  acc_train_error 44.075%  acc_test_error 50.0%\n",
      "Epoch: 357 Loss: 31.12621307373047  acc_train_error 44.075%  acc_test_error 50.0%\n",
      "Epoch: 358 Loss: 31.08794403076172  acc_train_error 44.075%  acc_test_error 50.0%\n",
      "Epoch: 359 Loss: 31.049806594848633  acc_train_error 44.075%  acc_test_error 50.0%\n",
      "Epoch: 360 Loss: 31.011655807495117  acc_train_error 44.0875%  acc_test_error 50.0%\n",
      "Epoch: 361 Loss: 30.973403930664062  acc_train_error 44.0875%  acc_test_error 50.0%\n",
      "Epoch: 362 Loss: 30.935192108154297  acc_train_error 44.075%  acc_test_error 50.0%\n",
      "Epoch: 363 Loss: 30.897050857543945  acc_train_error 44.075%  acc_test_error 50.0%\n",
      "Epoch: 364 Loss: 30.858905792236328  acc_train_error 44.075%  acc_test_error 50.0%\n",
      "Epoch: 365 Loss: 30.820878982543945  acc_train_error 44.0875%  acc_test_error 50.0%\n",
      "Epoch: 366 Loss: 30.78289794921875  acc_train_error 44.0875%  acc_test_error 50.0%\n",
      "Epoch: 367 Loss: 30.744892120361328  acc_train_error 44.0875%  acc_test_error 50.0%\n",
      "Epoch: 368 Loss: 30.706722259521484  acc_train_error 44.075%  acc_test_error 50.0%\n",
      "Epoch: 369 Loss: 30.66849136352539  acc_train_error 44.0875%  acc_test_error 50.0%\n",
      "Epoch: 370 Loss: 30.630165100097656  acc_train_error 44.0875%  acc_test_error 50.0%\n",
      "Epoch: 371 Loss: 30.591936111450195  acc_train_error 44.0875%  acc_test_error 50.0%\n",
      "Epoch: 372 Loss: 30.55379295349121  acc_train_error 44.075%  acc_test_error 50.0%\n",
      "Epoch: 373 Loss: 30.51563835144043  acc_train_error 44.075%  acc_test_error 50.0%\n",
      "Epoch: 374 Loss: 30.477441787719727  acc_train_error 44.0875%  acc_test_error 50.0%\n",
      "Epoch: 375 Loss: 30.439199447631836  acc_train_error 44.0875%  acc_test_error 50.0%\n",
      "Epoch: 376 Loss: 30.40093421936035  acc_train_error 44.075%  acc_test_error 50.0%\n",
      "Epoch: 377 Loss: 30.362565994262695  acc_train_error 44.075%  acc_test_error 50.0%\n",
      "Epoch: 378 Loss: 30.324209213256836  acc_train_error 44.0875%  acc_test_error 50.0%\n",
      "Epoch: 379 Loss: 30.285842895507812  acc_train_error 44.0875%  acc_test_error 50.0%\n",
      "Epoch: 380 Loss: 30.24746322631836  acc_train_error 44.075%  acc_test_error 50.0%\n",
      "Epoch: 381 Loss: 30.208921432495117  acc_train_error 44.075%  acc_test_error 50.0%\n",
      "Epoch: 382 Loss: 30.17032814025879  acc_train_error 44.075%  acc_test_error 50.0%\n",
      "Epoch: 383 Loss: 30.131654739379883  acc_train_error 44.0875%  acc_test_error 50.0%\n",
      "Epoch: 384 Loss: 30.09295654296875  acc_train_error 44.0875%  acc_test_error 50.0%\n",
      "Epoch: 385 Loss: 30.054128646850586  acc_train_error 44.075%  acc_test_error 50.0%\n",
      "Epoch: 386 Loss: 30.01502227783203  acc_train_error 44.075%  acc_test_error 50.0%\n",
      "Epoch: 387 Loss: 29.975723266601562  acc_train_error 44.075%  acc_test_error 50.0%\n",
      "Epoch: 388 Loss: 29.936189651489258  acc_train_error 44.075%  acc_test_error 50.0%\n",
      "Epoch: 389 Loss: 29.89644432067871  acc_train_error 44.0875%  acc_test_error 50.0%\n",
      "Epoch: 390 Loss: 29.85651206970215  acc_train_error 44.0875%  acc_test_error 50.0%\n",
      "Epoch: 391 Loss: 29.81638526916504  acc_train_error 44.0875%  acc_test_error 50.0%\n",
      "Epoch: 392 Loss: 29.776168823242188  acc_train_error 44.075%  acc_test_error 50.0%\n",
      "Epoch: 393 Loss: 29.735809326171875  acc_train_error 44.0875%  acc_test_error 50.0%\n",
      "Epoch: 394 Loss: 29.695287704467773  acc_train_error 44.0875%  acc_test_error 50.0%\n",
      "Epoch: 395 Loss: 29.654645919799805  acc_train_error 44.0875%  acc_test_error 50.0%\n",
      "Epoch: 396 Loss: 29.613832473754883  acc_train_error 44.0875%  acc_test_error 50.0%\n",
      "Epoch: 397 Loss: 29.572811126708984  acc_train_error 44.0875%  acc_test_error 50.0%\n",
      "Epoch: 398 Loss: 29.53165054321289  acc_train_error 44.1%  acc_test_error 50.0%\n",
      "Epoch: 399 Loss: 29.49044418334961  acc_train_error 44.1%  acc_test_error 50.0%\n",
      "Epoch: 400 Loss: 29.449138641357422  acc_train_error 44.1%  acc_test_error 50.0%\n",
      "Epoch: 401 Loss: 29.407670974731445  acc_train_error 44.1%  acc_test_error 50.0%\n",
      "Epoch: 402 Loss: 29.366113662719727  acc_train_error 44.1%  acc_test_error 50.0%\n",
      "Epoch: 403 Loss: 29.324617385864258  acc_train_error 44.125%  acc_test_error 50.0%\n",
      "Epoch: 404 Loss: 29.283153533935547  acc_train_error 44.125%  acc_test_error 50.0%\n",
      "Epoch: 405 Loss: 29.24162483215332  acc_train_error 44.125%  acc_test_error 50.0%\n",
      "Epoch: 406 Loss: 29.19999885559082  acc_train_error 44.125%  acc_test_error 50.0%\n",
      "Epoch: 407 Loss: 29.158313751220703  acc_train_error 44.1375%  acc_test_error 50.0%\n",
      "Epoch: 408 Loss: 29.116622924804688  acc_train_error 44.1375%  acc_test_error 50.0%\n",
      "Epoch: 409 Loss: 29.07506561279297  acc_train_error 44.1375%  acc_test_error 50.0%\n",
      "Epoch: 410 Loss: 29.033714294433594  acc_train_error 44.1375%  acc_test_error 50.0%\n",
      "Epoch: 411 Loss: 28.9925479888916  acc_train_error 44.15%  acc_test_error 50.0%\n",
      "Epoch: 412 Loss: 28.951688766479492  acc_train_error 44.15%  acc_test_error 50.0%\n",
      "Epoch: 413 Loss: 28.911226272583008  acc_train_error 44.1625%  acc_test_error 50.0%\n",
      "Epoch: 414 Loss: 28.871095657348633  acc_train_error 44.175%  acc_test_error 50.0%\n",
      "Epoch: 415 Loss: 28.831289291381836  acc_train_error 44.175%  acc_test_error 50.0%\n",
      "Epoch: 416 Loss: 28.79182243347168  acc_train_error 44.175%  acc_test_error 50.0%\n",
      "Epoch: 417 Loss: 28.752647399902344  acc_train_error 44.175%  acc_test_error 50.0%\n",
      "Epoch: 418 Loss: 28.713863372802734  acc_train_error 44.175%  acc_test_error 50.0%\n",
      "Epoch: 419 Loss: 28.67544174194336  acc_train_error 44.1875%  acc_test_error 50.0%\n",
      "Epoch: 420 Loss: 28.63750457763672  acc_train_error 44.1875%  acc_test_error 50.0%\n",
      "Epoch: 421 Loss: 28.60005760192871  acc_train_error 44.1875%  acc_test_error 50.0%\n",
      "Epoch: 422 Loss: 28.563121795654297  acc_train_error 44.2%  acc_test_error 50.0%\n",
      "Epoch: 423 Loss: 28.526674270629883  acc_train_error 44.2%  acc_test_error 50.0%\n",
      "Epoch: 424 Loss: 28.490747451782227  acc_train_error 44.2125%  acc_test_error 50.0%\n",
      "Epoch: 425 Loss: 28.455368041992188  acc_train_error 44.2125%  acc_test_error 50.0%\n",
      "Epoch: 426 Loss: 28.42055892944336  acc_train_error 44.2125%  acc_test_error 50.0%\n",
      "Epoch: 427 Loss: 28.38625144958496  acc_train_error 44.2125%  acc_test_error 50.0%\n",
      "Epoch: 428 Loss: 28.352413177490234  acc_train_error 44.225%  acc_test_error 50.0%\n",
      "Epoch: 429 Loss: 28.31907081604004  acc_train_error 44.225%  acc_test_error 50.0%\n",
      "Epoch: 430 Loss: 28.286212921142578  acc_train_error 44.225%  acc_test_error 50.0%\n",
      "Epoch: 431 Loss: 28.253721237182617  acc_train_error 44.225%  acc_test_error 50.0%\n",
      "Epoch: 432 Loss: 28.22167205810547  acc_train_error 44.2375%  acc_test_error 50.0%\n",
      "Epoch: 433 Loss: 28.190053939819336  acc_train_error 44.2375%  acc_test_error 50.0%\n",
      "Epoch: 434 Loss: 28.158845901489258  acc_train_error 44.2375%  acc_test_error 50.0%\n",
      "Epoch: 435 Loss: 28.127988815307617  acc_train_error 44.2375%  acc_test_error 50.0%\n",
      "Epoch: 436 Loss: 28.097429275512695  acc_train_error 44.25%  acc_test_error 50.0%\n",
      "Epoch: 437 Loss: 28.067214965820312  acc_train_error 44.25%  acc_test_error 50.0%\n",
      "Epoch: 438 Loss: 28.03729820251465  acc_train_error 44.25%  acc_test_error 50.0%\n",
      "Epoch: 439 Loss: 28.00754165649414  acc_train_error 44.25%  acc_test_error 50.0%\n",
      "Epoch: 440 Loss: 27.97801971435547  acc_train_error 44.25%  acc_test_error 50.0%\n",
      "Epoch: 441 Loss: 27.94881820678711  acc_train_error 44.25%  acc_test_error 50.0%\n",
      "Epoch: 442 Loss: 27.91988754272461  acc_train_error 44.25%  acc_test_error 50.0%\n",
      "Epoch: 443 Loss: 27.89118194580078  acc_train_error 44.25%  acc_test_error 50.0%\n",
      "Epoch: 444 Loss: 27.86268424987793  acc_train_error 44.2625%  acc_test_error 50.0%\n",
      "Epoch: 445 Loss: 27.834430694580078  acc_train_error 44.2625%  acc_test_error 50.0%\n",
      "Epoch: 446 Loss: 27.806438446044922  acc_train_error 44.2625%  acc_test_error 50.0%\n",
      "Epoch: 447 Loss: 27.77865982055664  acc_train_error 44.25%  acc_test_error 50.0%\n",
      "Epoch: 448 Loss: 27.75113868713379  acc_train_error 44.2625%  acc_test_error 50.0%\n",
      "Epoch: 449 Loss: 27.7237606048584  acc_train_error 44.2625%  acc_test_error 50.0%\n",
      "Epoch: 450 Loss: 27.696510314941406  acc_train_error 44.2625%  acc_test_error 50.0%\n",
      "Epoch: 451 Loss: 27.669403076171875  acc_train_error 44.2625%  acc_test_error 50.0%\n",
      "Epoch: 452 Loss: 27.642492294311523  acc_train_error 44.2625%  acc_test_error 50.0%\n",
      "Epoch: 453 Loss: 27.6157283782959  acc_train_error 44.25%  acc_test_error 50.0%\n",
      "Epoch: 454 Loss: 27.589073181152344  acc_train_error 44.2625%  acc_test_error 50.0%\n",
      "Epoch: 455 Loss: 27.562528610229492  acc_train_error 44.2625%  acc_test_error 50.0%\n",
      "Epoch: 456 Loss: 27.536083221435547  acc_train_error 44.2625%  acc_test_error 50.0%\n",
      "Epoch: 457 Loss: 27.509796142578125  acc_train_error 44.2625%  acc_test_error 50.0%\n",
      "Epoch: 458 Loss: 27.48369789123535  acc_train_error 44.25%  acc_test_error 50.0%\n",
      "Epoch: 459 Loss: 27.457653045654297  acc_train_error 44.25%  acc_test_error 50.0%\n",
      "Epoch: 460 Loss: 27.431724548339844  acc_train_error 44.2625%  acc_test_error 50.0%\n",
      "Epoch: 461 Loss: 27.405942916870117  acc_train_error 44.2625%  acc_test_error 50.0%\n",
      "Epoch: 462 Loss: 27.380260467529297  acc_train_error 44.25%  acc_test_error 50.0%\n",
      "Epoch: 463 Loss: 27.35467529296875  acc_train_error 44.25%  acc_test_error 50.0%\n",
      "Epoch: 464 Loss: 27.329191207885742  acc_train_error 44.25%  acc_test_error 50.0%\n",
      "Epoch: 465 Loss: 27.303804397583008  acc_train_error 44.25%  acc_test_error 50.0%\n",
      "Epoch: 466 Loss: 27.278526306152344  acc_train_error 44.25%  acc_test_error 50.0%\n",
      "Epoch: 467 Loss: 27.253252029418945  acc_train_error 44.2375%  acc_test_error 50.0%\n",
      "Epoch: 468 Loss: 27.227991104125977  acc_train_error 44.2375%  acc_test_error 50.0%\n",
      "Epoch: 469 Loss: 27.202781677246094  acc_train_error 44.2375%  acc_test_error 50.0%\n",
      "Epoch: 470 Loss: 27.177602767944336  acc_train_error 44.2375%  acc_test_error 50.0%\n",
      "Epoch: 471 Loss: 27.152477264404297  acc_train_error 44.225%  acc_test_error 50.0%\n",
      "Epoch: 472 Loss: 27.127429962158203  acc_train_error 44.225%  acc_test_error 50.0%\n",
      "Epoch: 473 Loss: 27.102468490600586  acc_train_error 44.225%  acc_test_error 50.0%\n",
      "Epoch: 474 Loss: 27.077463150024414  acc_train_error 44.2125%  acc_test_error 50.0%\n",
      "Epoch: 475 Loss: 27.052486419677734  acc_train_error 44.2125%  acc_test_error 50.0%\n",
      "Epoch: 476 Loss: 27.027631759643555  acc_train_error 44.2125%  acc_test_error 50.0%\n",
      "Epoch: 477 Loss: 27.002859115600586  acc_train_error 44.2125%  acc_test_error 50.0%\n",
      "Epoch: 478 Loss: 26.978073120117188  acc_train_error 44.2%  acc_test_error 50.0%\n",
      "Epoch: 479 Loss: 26.953245162963867  acc_train_error 44.2%  acc_test_error 50.0%\n",
      "Epoch: 480 Loss: 26.928415298461914  acc_train_error 44.2%  acc_test_error 50.0%\n",
      "Epoch: 481 Loss: 26.9036808013916  acc_train_error 44.2%  acc_test_error 50.0%\n",
      "Epoch: 482 Loss: 26.879032135009766  acc_train_error 44.1875%  acc_test_error 50.0%\n",
      "Epoch: 483 Loss: 26.854434967041016  acc_train_error 44.1875%  acc_test_error 50.0%\n",
      "Epoch: 484 Loss: 26.8298397064209  acc_train_error 44.1875%  acc_test_error 50.0%\n",
      "Epoch: 485 Loss: 26.805212020874023  acc_train_error 44.1875%  acc_test_error 50.0%\n",
      "Epoch: 486 Loss: 26.780672073364258  acc_train_error 44.1875%  acc_test_error 50.0%\n",
      "Epoch: 487 Loss: 26.756275177001953  acc_train_error 44.175%  acc_test_error 50.0%\n",
      "Epoch: 488 Loss: 26.731966018676758  acc_train_error 44.175%  acc_test_error 50.0%\n",
      "Epoch: 489 Loss: 26.707660675048828  acc_train_error 44.175%  acc_test_error 50.0%\n",
      "Epoch: 490 Loss: 26.683332443237305  acc_train_error 44.175%  acc_test_error 50.0%\n",
      "Epoch: 491 Loss: 26.659069061279297  acc_train_error 44.1625%  acc_test_error 50.0%\n",
      "Epoch: 492 Loss: 26.634904861450195  acc_train_error 44.1625%  acc_test_error 50.0%\n",
      "Epoch: 493 Loss: 26.61081314086914  acc_train_error 44.1625%  acc_test_error 50.0%\n",
      "Epoch: 494 Loss: 26.586793899536133  acc_train_error 44.1625%  acc_test_error 50.0%\n",
      "Epoch: 495 Loss: 26.56287956237793  acc_train_error 44.1625%  acc_test_error 50.0%\n",
      "Epoch: 496 Loss: 26.539079666137695  acc_train_error 44.15%  acc_test_error 50.0%\n",
      "Epoch: 497 Loss: 26.515390396118164  acc_train_error 44.15%  acc_test_error 50.0%\n",
      "Epoch: 498 Loss: 26.491775512695312  acc_train_error 44.15%  acc_test_error 50.0%\n",
      "Epoch: 499 Loss: 26.468162536621094  acc_train_error 44.15%  acc_test_error 50.0%\n",
      "Epoch: 500 Loss: 26.44449806213379  acc_train_error 44.15%  acc_test_error 50.0%\n",
      "Epoch: 501 Loss: 26.420827865600586  acc_train_error 44.15%  acc_test_error 50.0%\n",
      "Epoch: 502 Loss: 26.39726448059082  acc_train_error 44.15%  acc_test_error 50.0%\n",
      "Epoch: 503 Loss: 26.37375259399414  acc_train_error 44.1375%  acc_test_error 50.0%\n",
      "Epoch: 504 Loss: 26.35040283203125  acc_train_error 44.1375%  acc_test_error 50.0%\n",
      "Epoch: 505 Loss: 26.327199935913086  acc_train_error 44.1375%  acc_test_error 50.0%\n",
      "Epoch: 506 Loss: 26.30413055419922  acc_train_error 44.1375%  acc_test_error 50.0%\n",
      "Epoch: 507 Loss: 26.281139373779297  acc_train_error 44.1375%  acc_test_error 50.0%\n",
      "Epoch: 508 Loss: 26.258302688598633  acc_train_error 44.1375%  acc_test_error 50.0%\n",
      "Epoch: 509 Loss: 26.235576629638672  acc_train_error 44.1375%  acc_test_error 50.0%\n",
      "Epoch: 510 Loss: 26.21291160583496  acc_train_error 44.1375%  acc_test_error 50.0%\n",
      "Epoch: 511 Loss: 26.19032859802246  acc_train_error 44.1375%  acc_test_error 50.0%\n",
      "Epoch: 512 Loss: 26.167865753173828  acc_train_error 44.1375%  acc_test_error 50.0%\n",
      "Epoch: 513 Loss: 26.14546012878418  acc_train_error 44.1375%  acc_test_error 50.0%\n",
      "Epoch: 514 Loss: 26.123123168945312  acc_train_error 44.125%  acc_test_error 50.0%\n",
      "Epoch: 515 Loss: 26.10085678100586  acc_train_error 44.125%  acc_test_error 50.0%\n",
      "Epoch: 516 Loss: 26.07845115661621  acc_train_error 44.125%  acc_test_error 50.0%\n",
      "Epoch: 517 Loss: 26.05595588684082  acc_train_error 44.125%  acc_test_error 50.0%\n",
      "Epoch: 518 Loss: 26.033504486083984  acc_train_error 44.125%  acc_test_error 50.0%\n",
      "Epoch: 519 Loss: 26.011171340942383  acc_train_error 44.1125%  acc_test_error 50.0%\n",
      "Epoch: 520 Loss: 25.988964080810547  acc_train_error 44.1125%  acc_test_error 50.0%\n",
      "Epoch: 521 Loss: 25.966835021972656  acc_train_error 44.1125%  acc_test_error 50.0%\n",
      "Epoch: 522 Loss: 25.944719314575195  acc_train_error 44.1125%  acc_test_error 50.0%\n",
      "Epoch: 523 Loss: 25.922555923461914  acc_train_error 44.125%  acc_test_error 50.0%\n",
      "Epoch: 524 Loss: 25.900529861450195  acc_train_error 44.125%  acc_test_error 50.0%\n",
      "Epoch: 525 Loss: 25.87856674194336  acc_train_error 44.125%  acc_test_error 50.0%\n",
      "Epoch: 526 Loss: 25.85650062561035  acc_train_error 44.125%  acc_test_error 50.0%\n",
      "Epoch: 527 Loss: 25.834474563598633  acc_train_error 44.125%  acc_test_error 50.0%\n",
      "Epoch: 528 Loss: 25.812482833862305  acc_train_error 44.125%  acc_test_error 50.0%\n",
      "Epoch: 529 Loss: 25.79041290283203  acc_train_error 44.125%  acc_test_error 50.0%\n",
      "Epoch: 530 Loss: 25.768327713012695  acc_train_error 44.1125%  acc_test_error 50.0%\n",
      "Epoch: 531 Loss: 25.746309280395508  acc_train_error 44.1125%  acc_test_error 50.0%\n",
      "Epoch: 532 Loss: 25.724397659301758  acc_train_error 44.1125%  acc_test_error 50.0%\n",
      "Epoch: 533 Loss: 25.702543258666992  acc_train_error 44.1125%  acc_test_error 50.0%\n",
      "Epoch: 534 Loss: 25.680803298950195  acc_train_error 44.1125%  acc_test_error 50.0%\n",
      "Epoch: 535 Loss: 25.65914535522461  acc_train_error 44.1125%  acc_test_error 50.0%\n",
      "Epoch: 536 Loss: 25.637489318847656  acc_train_error 44.1125%  acc_test_error 50.0%\n",
      "Epoch: 537 Loss: 25.61583709716797  acc_train_error 44.1125%  acc_test_error 50.0%\n",
      "Epoch: 538 Loss: 25.59417152404785  acc_train_error 44.1%  acc_test_error 50.0%\n",
      "Epoch: 539 Loss: 25.572492599487305  acc_train_error 44.1%  acc_test_error 50.0%\n",
      "Epoch: 540 Loss: 25.550748825073242  acc_train_error 44.1%  acc_test_error 50.0%\n",
      "Epoch: 541 Loss: 25.529010772705078  acc_train_error 44.1%  acc_test_error 50.0%\n",
      "Epoch: 542 Loss: 25.507278442382812  acc_train_error 44.1%  acc_test_error 50.0%\n",
      "Epoch: 543 Loss: 25.485620498657227  acc_train_error 44.0875%  acc_test_error 50.0%\n",
      "Epoch: 544 Loss: 25.463926315307617  acc_train_error 44.075%  acc_test_error 50.0%\n",
      "Epoch: 545 Loss: 25.442209243774414  acc_train_error 44.075%  acc_test_error 50.0%\n",
      "Epoch: 546 Loss: 25.420459747314453  acc_train_error 44.075%  acc_test_error 50.0%\n",
      "Epoch: 547 Loss: 25.398653030395508  acc_train_error 44.075%  acc_test_error 50.0%\n",
      "Epoch: 548 Loss: 25.37680435180664  acc_train_error 44.075%  acc_test_error 50.0%\n",
      "Epoch: 549 Loss: 25.354909896850586  acc_train_error 44.0625%  acc_test_error 50.0%\n",
      "Epoch: 550 Loss: 25.332965850830078  acc_train_error 44.0625%  acc_test_error 50.0%\n",
      "Epoch: 551 Loss: 25.311006546020508  acc_train_error 44.0625%  acc_test_error 50.0%\n",
      "Epoch: 552 Loss: 25.289031982421875  acc_train_error 44.0625%  acc_test_error 50.0%\n",
      "Epoch: 553 Loss: 25.26696014404297  acc_train_error 44.0625%  acc_test_error 50.0%\n",
      "Epoch: 554 Loss: 25.244895935058594  acc_train_error 44.05%  acc_test_error 50.0%\n",
      "Epoch: 555 Loss: 25.222803115844727  acc_train_error 44.05%  acc_test_error 50.0%\n",
      "Epoch: 556 Loss: 25.20064353942871  acc_train_error 44.05%  acc_test_error 50.0%\n",
      "Epoch: 557 Loss: 25.178504943847656  acc_train_error 44.05%  acc_test_error 50.0%\n",
      "Epoch: 558 Loss: 25.156343460083008  acc_train_error 44.05%  acc_test_error 50.0%\n",
      "Epoch: 559 Loss: 25.134170532226562  acc_train_error 44.05%  acc_test_error 50.0%\n",
      "Epoch: 560 Loss: 25.11199378967285  acc_train_error 44.05%  acc_test_error 50.0%\n",
      "Epoch: 561 Loss: 25.089797973632812  acc_train_error 44.0375%  acc_test_error 50.0%\n",
      "Epoch: 562 Loss: 25.067489624023438  acc_train_error 44.0375%  acc_test_error 50.0%\n",
      "Epoch: 563 Loss: 25.045011520385742  acc_train_error 44.0375%  acc_test_error 50.0%\n",
      "Epoch: 564 Loss: 25.022457122802734  acc_train_error 44.0375%  acc_test_error 50.0%\n",
      "Epoch: 565 Loss: 24.999879837036133  acc_train_error 44.025%  acc_test_error 50.0%\n",
      "Epoch: 566 Loss: 24.97732162475586  acc_train_error 44.0375%  acc_test_error 50.0%\n",
      "Epoch: 567 Loss: 24.95476531982422  acc_train_error 44.0375%  acc_test_error 50.0%\n",
      "Epoch: 568 Loss: 24.932144165039062  acc_train_error 44.025%  acc_test_error 50.0%\n",
      "Epoch: 569 Loss: 24.90947151184082  acc_train_error 44.025%  acc_test_error 50.0%\n",
      "Epoch: 570 Loss: 24.886568069458008  acc_train_error 44.025%  acc_test_error 50.0%\n",
      "Epoch: 571 Loss: 24.86341094970703  acc_train_error 44.0375%  acc_test_error 50.0%\n",
      "Epoch: 572 Loss: 24.840042114257812  acc_train_error 44.025%  acc_test_error 50.0%\n",
      "Epoch: 573 Loss: 24.816604614257812  acc_train_error 44.025%  acc_test_error 50.0%\n",
      "Epoch: 574 Loss: 24.793073654174805  acc_train_error 44.025%  acc_test_error 50.0%\n",
      "Epoch: 575 Loss: 24.769487380981445  acc_train_error 44.025%  acc_test_error 50.0%\n",
      "Epoch: 576 Loss: 24.74589729309082  acc_train_error 44.025%  acc_test_error 50.0%\n",
      "Epoch: 577 Loss: 24.722265243530273  acc_train_error 44.0375%  acc_test_error 50.0%\n",
      "Epoch: 578 Loss: 24.698566436767578  acc_train_error 44.025%  acc_test_error 50.0%\n",
      "Epoch: 579 Loss: 24.674758911132812  acc_train_error 44.025%  acc_test_error 50.0%\n",
      "Epoch: 580 Loss: 24.65077781677246  acc_train_error 44.025%  acc_test_error 50.0%\n",
      "Epoch: 581 Loss: 24.626556396484375  acc_train_error 44.025%  acc_test_error 50.0%\n",
      "Epoch: 582 Loss: 24.60231590270996  acc_train_error 44.025%  acc_test_error 50.0%\n",
      "Epoch: 583 Loss: 24.577919006347656  acc_train_error 44.0375%  acc_test_error 50.0%\n",
      "Epoch: 584 Loss: 24.55333709716797  acc_train_error 44.0375%  acc_test_error 50.0%\n",
      "Epoch: 585 Loss: 24.52861213684082  acc_train_error 44.0375%  acc_test_error 50.0%\n",
      "Epoch: 586 Loss: 24.503807067871094  acc_train_error 44.025%  acc_test_error 50.0%\n",
      "Epoch: 587 Loss: 24.478965759277344  acc_train_error 44.0375%  acc_test_error 50.0%\n",
      "Epoch: 588 Loss: 24.454051971435547  acc_train_error 44.0375%  acc_test_error 50.0%\n",
      "Epoch: 589 Loss: 24.429187774658203  acc_train_error 44.0375%  acc_test_error 50.0%\n",
      "Epoch: 590 Loss: 24.404312133789062  acc_train_error 44.0375%  acc_test_error 50.0%\n",
      "Epoch: 591 Loss: 24.379316329956055  acc_train_error 44.0375%  acc_test_error 50.0%\n",
      "Epoch: 592 Loss: 24.354236602783203  acc_train_error 44.05%  acc_test_error 50.0%\n",
      "Epoch: 593 Loss: 24.32903289794922  acc_train_error 44.05%  acc_test_error 50.0%\n",
      "Epoch: 594 Loss: 24.3038330078125  acc_train_error 44.05%  acc_test_error 50.0%\n",
      "Epoch: 595 Loss: 24.278518676757812  acc_train_error 44.05%  acc_test_error 50.0%\n",
      "Epoch: 596 Loss: 24.253116607666016  acc_train_error 44.0625%  acc_test_error 50.0%\n",
      "Epoch: 597 Loss: 24.22759437561035  acc_train_error 44.0625%  acc_test_error 50.0%\n",
      "Epoch: 598 Loss: 24.20184898376465  acc_train_error 44.0625%  acc_test_error 50.0%\n",
      "Epoch: 599 Loss: 24.17597770690918  acc_train_error 44.0625%  acc_test_error 50.0%\n",
      "Epoch: 600 Loss: 24.149980545043945  acc_train_error 44.075%  acc_test_error 50.0%\n",
      "Epoch: 601 Loss: 24.12381362915039  acc_train_error 44.075%  acc_test_error 50.0%\n",
      "Epoch: 602 Loss: 24.097476959228516  acc_train_error 44.0875%  acc_test_error 50.0%\n",
      "Epoch: 603 Loss: 24.07103157043457  acc_train_error 44.0875%  acc_test_error 50.0%\n",
      "Epoch: 604 Loss: 24.044464111328125  acc_train_error 44.1%  acc_test_error 50.0%\n",
      "Epoch: 605 Loss: 24.017799377441406  acc_train_error 44.1%  acc_test_error 50.0%\n",
      "Epoch: 606 Loss: 23.991016387939453  acc_train_error 44.1%  acc_test_error 50.0%\n",
      "Epoch: 607 Loss: 23.964115142822266  acc_train_error 44.1%  acc_test_error 50.0%\n",
      "Epoch: 608 Loss: 23.937145233154297  acc_train_error 44.1%  acc_test_error 50.0%\n",
      "Epoch: 609 Loss: 23.91007423400879  acc_train_error 44.125%  acc_test_error 50.0%\n",
      "Epoch: 610 Loss: 23.88286590576172  acc_train_error 44.125%  acc_test_error 50.0%\n",
      "Epoch: 611 Loss: 23.85525131225586  acc_train_error 44.125%  acc_test_error 50.0%\n",
      "Epoch: 612 Loss: 23.82745933532715  acc_train_error 44.1375%  acc_test_error 50.0%\n",
      "Epoch: 613 Loss: 23.799514770507812  acc_train_error 44.1375%  acc_test_error 50.0%\n",
      "Epoch: 614 Loss: 23.771425247192383  acc_train_error 44.15%  acc_test_error 50.0%\n",
      "Epoch: 615 Loss: 23.743303298950195  acc_train_error 44.15%  acc_test_error 50.0%\n",
      "Epoch: 616 Loss: 23.715166091918945  acc_train_error 44.15%  acc_test_error 50.0%\n",
      "Epoch: 617 Loss: 23.686948776245117  acc_train_error 44.1625%  acc_test_error 50.0%\n",
      "Epoch: 618 Loss: 23.65865135192871  acc_train_error 44.175%  acc_test_error 50.0%\n",
      "Epoch: 619 Loss: 23.63033676147461  acc_train_error 44.1875%  acc_test_error 50.0%\n",
      "Epoch: 620 Loss: 23.602022171020508  acc_train_error 44.1875%  acc_test_error 50.0%\n",
      "Epoch: 621 Loss: 23.5737361907959  acc_train_error 44.2%  acc_test_error 50.0%\n",
      "Epoch: 622 Loss: 23.545482635498047  acc_train_error 44.2%  acc_test_error 50.0%\n",
      "Epoch: 623 Loss: 23.517261505126953  acc_train_error 44.2%  acc_test_error 50.0%\n",
      "Epoch: 624 Loss: 23.489152908325195  acc_train_error 44.2125%  acc_test_error 50.0%\n",
      "Epoch: 625 Loss: 23.46119499206543  acc_train_error 44.225%  acc_test_error 50.0%\n",
      "Epoch: 626 Loss: 23.433368682861328  acc_train_error 44.2375%  acc_test_error 50.0%\n",
      "Epoch: 627 Loss: 23.405696868896484  acc_train_error 44.25%  acc_test_error 50.0%\n",
      "Epoch: 628 Loss: 23.378124237060547  acc_train_error 44.25%  acc_test_error 50.0%\n",
      "Epoch: 629 Loss: 23.350706100463867  acc_train_error 44.2625%  acc_test_error 50.0%\n",
      "Epoch: 630 Loss: 23.323558807373047  acc_train_error 44.2625%  acc_test_error 50.0%\n",
      "Epoch: 631 Loss: 23.296546936035156  acc_train_error 44.275%  acc_test_error 50.0%\n",
      "Epoch: 632 Loss: 23.269620895385742  acc_train_error 44.2875%  acc_test_error 50.0%\n",
      "Epoch: 633 Loss: 23.242782592773438  acc_train_error 44.3%  acc_test_error 50.0%\n",
      "Epoch: 634 Loss: 23.215917587280273  acc_train_error 44.3125%  acc_test_error 50.0%\n",
      "Epoch: 635 Loss: 23.189144134521484  acc_train_error 44.325%  acc_test_error 50.0%\n",
      "Epoch: 636 Loss: 23.162559509277344  acc_train_error 44.3375%  acc_test_error 50.0%\n",
      "Epoch: 637 Loss: 23.136091232299805  acc_train_error 44.35%  acc_test_error 50.0%\n",
      "Epoch: 638 Loss: 23.109682083129883  acc_train_error 44.3875%  acc_test_error 50.0%\n",
      "Epoch: 639 Loss: 23.083370208740234  acc_train_error 44.4%  acc_test_error 50.0%\n",
      "Epoch: 640 Loss: 23.057296752929688  acc_train_error 44.425%  acc_test_error 50.0%\n",
      "Epoch: 641 Loss: 23.031448364257812  acc_train_error 44.4375%  acc_test_error 50.0%\n",
      "Epoch: 642 Loss: 23.005775451660156  acc_train_error 44.45%  acc_test_error 50.0%\n",
      "Epoch: 643 Loss: 22.98020362854004  acc_train_error 44.4625%  acc_test_error 50.0%\n",
      "Epoch: 644 Loss: 22.9547061920166  acc_train_error 44.4875%  acc_test_error 50.0%\n",
      "Epoch: 645 Loss: 22.929309844970703  acc_train_error 44.5125%  acc_test_error 50.0%\n",
      "Epoch: 646 Loss: 22.904205322265625  acc_train_error 44.5375%  acc_test_error 50.0%\n",
      "Epoch: 647 Loss: 22.87925148010254  acc_train_error 44.5625%  acc_test_error 50.0%\n",
      "Epoch: 648 Loss: 22.854398727416992  acc_train_error 44.5875%  acc_test_error 50.0%\n",
      "Epoch: 649 Loss: 22.829734802246094  acc_train_error 44.6125%  acc_test_error 50.0%\n",
      "Epoch: 650 Loss: 22.80512046813965  acc_train_error 44.65%  acc_test_error 50.0%\n",
      "Epoch: 651 Loss: 22.78071403503418  acc_train_error 44.675%  acc_test_error 50.0%\n",
      "Epoch: 652 Loss: 22.756357192993164  acc_train_error 44.725%  acc_test_error 50.0%\n",
      "Epoch: 653 Loss: 22.732030868530273  acc_train_error 44.75%  acc_test_error 50.0%\n",
      "Epoch: 654 Loss: 22.707908630371094  acc_train_error 44.775%  acc_test_error 50.0%\n",
      "Epoch: 655 Loss: 22.68393325805664  acc_train_error 44.8%  acc_test_error 50.0%\n",
      "Epoch: 656 Loss: 22.6601505279541  acc_train_error 44.8375%  acc_test_error 50.0%\n",
      "Epoch: 657 Loss: 22.636470794677734  acc_train_error 44.8625%  acc_test_error 50.0%\n",
      "Epoch: 658 Loss: 22.612958908081055  acc_train_error 44.9%  acc_test_error 50.0%\n",
      "Epoch: 659 Loss: 22.589651107788086  acc_train_error 44.9375%  acc_test_error 50.0%\n",
      "Epoch: 660 Loss: 22.566402435302734  acc_train_error 44.975%  acc_test_error 50.0%\n",
      "Epoch: 661 Loss: 22.54322624206543  acc_train_error 45.0375%  acc_test_error 50.0%\n",
      "Epoch: 662 Loss: 22.520111083984375  acc_train_error 45.0625%  acc_test_error 50.0%\n",
      "Epoch: 663 Loss: 22.497234344482422  acc_train_error 45.1625%  acc_test_error 50.0%\n",
      "Epoch: 664 Loss: 22.47452163696289  acc_train_error 45.2625%  acc_test_error 50.0%\n",
      "Epoch: 665 Loss: 22.451801300048828  acc_train_error 45.3%  acc_test_error 50.0%\n",
      "Epoch: 666 Loss: 22.429227828979492  acc_train_error 45.3125%  acc_test_error 50.0%\n",
      "Epoch: 667 Loss: 22.406740188598633  acc_train_error 45.3375%  acc_test_error 50.0%\n",
      "Epoch: 668 Loss: 22.38441276550293  acc_train_error 45.3625%  acc_test_error 50.0%\n",
      "Epoch: 669 Loss: 22.362289428710938  acc_train_error 45.375%  acc_test_error 50.0%\n",
      "Epoch: 670 Loss: 22.340253829956055  acc_train_error 45.3875%  acc_test_error 50.0%\n",
      "Epoch: 671 Loss: 22.318262100219727  acc_train_error 45.3875%  acc_test_error 50.0%\n",
      "Epoch: 672 Loss: 22.296123504638672  acc_train_error 45.4%  acc_test_error 50.0%\n",
      "Epoch: 673 Loss: 22.27400016784668  acc_train_error 45.425%  acc_test_error 50.0%\n",
      "Epoch: 674 Loss: 22.251815795898438  acc_train_error 45.4375%  acc_test_error 50.0%\n",
      "Epoch: 675 Loss: 22.22977066040039  acc_train_error 45.4375%  acc_test_error 50.0%\n",
      "Epoch: 676 Loss: 22.207738876342773  acc_train_error 45.45%  acc_test_error 50.0%\n",
      "Epoch: 677 Loss: 22.18576431274414  acc_train_error 45.475%  acc_test_error 50.0%\n",
      "Epoch: 678 Loss: 22.163612365722656  acc_train_error 45.4875%  acc_test_error 50.0%\n",
      "Epoch: 679 Loss: 22.141401290893555  acc_train_error 45.5%  acc_test_error 50.0%\n",
      "Epoch: 680 Loss: 22.11916160583496  acc_train_error 45.5%  acc_test_error 50.0%\n",
      "Epoch: 681 Loss: 22.097135543823242  acc_train_error 45.575%  acc_test_error 50.0%\n",
      "Epoch: 682 Loss: 22.07542610168457  acc_train_error 45.6625%  acc_test_error 50.0%\n",
      "Epoch: 683 Loss: 22.053970336914062  acc_train_error 45.7125%  acc_test_error 50.0%\n",
      "Epoch: 684 Loss: 22.032766342163086  acc_train_error 45.8125%  acc_test_error 50.0%\n",
      "Epoch: 685 Loss: 22.01178550720215  acc_train_error 45.9375%  acc_test_error 50.0%\n",
      "Epoch: 686 Loss: 21.99083137512207  acc_train_error 46.0625%  acc_test_error 50.0%\n",
      "Epoch: 687 Loss: 21.969934463500977  acc_train_error 46.1125%  acc_test_error 50.0%\n",
      "Epoch: 688 Loss: 21.949087142944336  acc_train_error 46.1625%  acc_test_error 50.0%\n",
      "Epoch: 689 Loss: 21.928377151489258  acc_train_error 46.2%  acc_test_error 50.0%\n",
      "Epoch: 690 Loss: 21.907758712768555  acc_train_error 46.275%  acc_test_error 50.0%\n",
      "Epoch: 691 Loss: 21.88723373413086  acc_train_error 46.4125%  acc_test_error 50.0%\n",
      "Epoch: 692 Loss: 21.866682052612305  acc_train_error 46.4875%  acc_test_error 50.0%\n",
      "Epoch: 693 Loss: 21.846309661865234  acc_train_error 46.5%  acc_test_error 50.0%\n",
      "Epoch: 694 Loss: 21.826234817504883  acc_train_error 46.5125%  acc_test_error 50.0%\n",
      "Epoch: 695 Loss: 21.806259155273438  acc_train_error 46.525%  acc_test_error 50.0%\n",
      "Epoch: 696 Loss: 21.786273956298828  acc_train_error 46.5375%  acc_test_error 50.0%\n",
      "Epoch: 697 Loss: 21.766069412231445  acc_train_error 46.5375%  acc_test_error 50.0%\n",
      "Epoch: 698 Loss: 21.745655059814453  acc_train_error 46.55%  acc_test_error 50.0%\n",
      "Epoch: 699 Loss: 21.72506332397461  acc_train_error 46.5625%  acc_test_error 50.0%\n",
      "Epoch: 700 Loss: 21.7042236328125  acc_train_error 46.575%  acc_test_error 50.0%\n",
      "Epoch: 701 Loss: 21.68299674987793  acc_train_error 46.5875%  acc_test_error 50.0%\n",
      "Epoch: 702 Loss: 21.66145896911621  acc_train_error 46.6%  acc_test_error 50.0%\n",
      "Epoch: 703 Loss: 21.64031219482422  acc_train_error 46.6%  acc_test_error 50.0%\n",
      "Epoch: 704 Loss: 21.61945152282715  acc_train_error 46.6125%  acc_test_error 50.0%\n",
      "Epoch: 705 Loss: 21.5986385345459  acc_train_error 46.625%  acc_test_error 50.0%\n",
      "Epoch: 706 Loss: 21.577890396118164  acc_train_error 46.6375%  acc_test_error 50.0%\n",
      "Epoch: 707 Loss: 21.557209014892578  acc_train_error 46.65%  acc_test_error 50.0%\n",
      "Epoch: 708 Loss: 21.5367374420166  acc_train_error 46.6625%  acc_test_error 50.0%\n",
      "Epoch: 709 Loss: 21.5162410736084  acc_train_error 46.6625%  acc_test_error 50.0%\n",
      "Epoch: 710 Loss: 21.495786666870117  acc_train_error 46.675%  acc_test_error 50.0%\n",
      "Epoch: 711 Loss: 21.475475311279297  acc_train_error 46.6875%  acc_test_error 50.0%\n",
      "Epoch: 712 Loss: 21.454936981201172  acc_train_error 46.7%  acc_test_error 50.0%\n",
      "Epoch: 713 Loss: 21.434324264526367  acc_train_error 46.7125%  acc_test_error 50.0%\n",
      "Epoch: 714 Loss: 21.413745880126953  acc_train_error 46.7125%  acc_test_error 50.0%\n",
      "Epoch: 715 Loss: 21.392946243286133  acc_train_error 46.7125%  acc_test_error 50.0%\n",
      "Epoch: 716 Loss: 21.372051239013672  acc_train_error 46.725%  acc_test_error 50.0%\n",
      "Epoch: 717 Loss: 21.35140609741211  acc_train_error 46.7375%  acc_test_error 50.0%\n",
      "Epoch: 718 Loss: 21.330915451049805  acc_train_error 46.7375%  acc_test_error 50.0%\n",
      "Epoch: 719 Loss: 21.310489654541016  acc_train_error 46.7375%  acc_test_error 50.0%\n",
      "Epoch: 720 Loss: 21.28989601135254  acc_train_error 46.75%  acc_test_error 50.0%\n",
      "Epoch: 721 Loss: 21.26936149597168  acc_train_error 46.75%  acc_test_error 50.0%\n",
      "Epoch: 722 Loss: 21.249046325683594  acc_train_error 46.7625%  acc_test_error 50.0%\n",
      "Epoch: 723 Loss: 21.22884178161621  acc_train_error 46.775%  acc_test_error 50.0%\n",
      "Epoch: 724 Loss: 21.20872688293457  acc_train_error 46.775%  acc_test_error 50.0%\n",
      "Epoch: 725 Loss: 21.188823699951172  acc_train_error 46.775%  acc_test_error 50.0%\n",
      "Epoch: 726 Loss: 21.168947219848633  acc_train_error 46.775%  acc_test_error 50.0%\n",
      "Epoch: 727 Loss: 21.148544311523438  acc_train_error 46.7875%  acc_test_error 50.0%\n",
      "Epoch: 728 Loss: 21.12788963317871  acc_train_error 46.7875%  acc_test_error 50.0%\n",
      "Epoch: 729 Loss: 21.107351303100586  acc_train_error 46.8%  acc_test_error 50.0%\n",
      "Epoch: 730 Loss: 21.08692741394043  acc_train_error 46.7875%  acc_test_error 50.0%\n",
      "Epoch: 731 Loss: 21.066457748413086  acc_train_error 46.8%  acc_test_error 50.0%\n",
      "Epoch: 732 Loss: 21.0457706451416  acc_train_error 46.8125%  acc_test_error 50.0%\n",
      "Epoch: 733 Loss: 21.025236129760742  acc_train_error 46.8125%  acc_test_error 50.0%\n",
      "Epoch: 734 Loss: 21.00501823425293  acc_train_error 46.825%  acc_test_error 50.0%\n",
      "Epoch: 735 Loss: 20.984952926635742  acc_train_error 46.8125%  acc_test_error 50.0%\n",
      "Epoch: 736 Loss: 20.965290069580078  acc_train_error 46.825%  acc_test_error 50.0%\n",
      "Epoch: 737 Loss: 20.945894241333008  acc_train_error 46.825%  acc_test_error 50.0%\n",
      "Epoch: 738 Loss: 20.926616668701172  acc_train_error 46.8375%  acc_test_error 50.0%\n",
      "Epoch: 739 Loss: 20.907474517822266  acc_train_error 46.8375%  acc_test_error 50.0%\n",
      "Epoch: 740 Loss: 20.888429641723633  acc_train_error 46.85%  acc_test_error 50.0%\n",
      "Epoch: 741 Loss: 20.86928367614746  acc_train_error 46.8375%  acc_test_error 50.0%\n",
      "Epoch: 742 Loss: 20.85005760192871  acc_train_error 46.85%  acc_test_error 50.0%\n",
      "Epoch: 743 Loss: 20.83055877685547  acc_train_error 46.85%  acc_test_error 50.0%\n",
      "Epoch: 744 Loss: 20.81119728088379  acc_train_error 46.85%  acc_test_error 50.0%\n",
      "Epoch: 745 Loss: 20.791784286499023  acc_train_error 46.8625%  acc_test_error 50.0%\n",
      "Epoch: 746 Loss: 20.772357940673828  acc_train_error 46.8625%  acc_test_error 50.0%\n",
      "Epoch: 747 Loss: 20.75297737121582  acc_train_error 46.8625%  acc_test_error 50.0%\n",
      "Epoch: 748 Loss: 20.733837127685547  acc_train_error 46.8625%  acc_test_error 50.0%\n",
      "Epoch: 749 Loss: 20.71491241455078  acc_train_error 46.875%  acc_test_error 50.0%\n",
      "Epoch: 750 Loss: 20.696109771728516  acc_train_error 46.875%  acc_test_error 50.0%\n",
      "Epoch: 751 Loss: 20.67742919921875  acc_train_error 46.875%  acc_test_error 50.0%\n",
      "Epoch: 752 Loss: 20.65890884399414  acc_train_error 46.8875%  acc_test_error 50.0%\n",
      "Epoch: 753 Loss: 20.640514373779297  acc_train_error 46.8875%  acc_test_error 50.0%\n",
      "Epoch: 754 Loss: 20.622304916381836  acc_train_error 46.875%  acc_test_error 50.0%\n",
      "Epoch: 755 Loss: 20.6042537689209  acc_train_error 46.875%  acc_test_error 50.0%\n",
      "Epoch: 756 Loss: 20.586275100708008  acc_train_error 46.8875%  acc_test_error 50.0%\n",
      "Epoch: 757 Loss: 20.568435668945312  acc_train_error 46.8875%  acc_test_error 50.0%\n",
      "Epoch: 758 Loss: 20.55059814453125  acc_train_error 46.8875%  acc_test_error 50.0%\n",
      "Epoch: 759 Loss: 20.532711029052734  acc_train_error 46.8875%  acc_test_error 50.0%\n",
      "Epoch: 760 Loss: 20.51495933532715  acc_train_error 46.9%  acc_test_error 50.0%\n",
      "Epoch: 761 Loss: 20.497188568115234  acc_train_error 46.9%  acc_test_error 50.0%\n",
      "Epoch: 762 Loss: 20.479328155517578  acc_train_error 46.8875%  acc_test_error 50.0%\n",
      "Epoch: 763 Loss: 20.461563110351562  acc_train_error 46.8875%  acc_test_error 50.0%\n",
      "Epoch: 764 Loss: 20.44390106201172  acc_train_error 46.8875%  acc_test_error 50.0%\n",
      "Epoch: 765 Loss: 20.426319122314453  acc_train_error 46.9%  acc_test_error 50.0%\n",
      "Epoch: 766 Loss: 20.408740997314453  acc_train_error 46.9%  acc_test_error 50.0%\n",
      "Epoch: 767 Loss: 20.391023635864258  acc_train_error 46.9%  acc_test_error 50.0%\n",
      "Epoch: 768 Loss: 20.373313903808594  acc_train_error 46.9%  acc_test_error 50.0%\n",
      "Epoch: 769 Loss: 20.355772018432617  acc_train_error 46.9%  acc_test_error 50.0%\n",
      "Epoch: 770 Loss: 20.33832550048828  acc_train_error 46.9%  acc_test_error 50.0%\n",
      "Epoch: 771 Loss: 20.3210391998291  acc_train_error 46.9%  acc_test_error 50.0%\n",
      "Epoch: 772 Loss: 20.303810119628906  acc_train_error 46.8875%  acc_test_error 50.0%\n",
      "Epoch: 773 Loss: 20.28662872314453  acc_train_error 46.8875%  acc_test_error 50.0%\n",
      "Epoch: 774 Loss: 20.2695255279541  acc_train_error 46.8875%  acc_test_error 50.0%\n",
      "Epoch: 775 Loss: 20.252439498901367  acc_train_error 46.8875%  acc_test_error 50.0%\n",
      "Epoch: 776 Loss: 20.235353469848633  acc_train_error 46.8875%  acc_test_error 50.0%\n",
      "Epoch: 777 Loss: 20.218406677246094  acc_train_error 46.8875%  acc_test_error 50.0%\n",
      "Epoch: 778 Loss: 20.20155906677246  acc_train_error 46.8875%  acc_test_error 50.0%\n",
      "Epoch: 779 Loss: 20.18478775024414  acc_train_error 46.8625%  acc_test_error 50.0%\n",
      "Epoch: 780 Loss: 20.168184280395508  acc_train_error 46.8625%  acc_test_error 50.0%\n",
      "Epoch: 781 Loss: 20.151662826538086  acc_train_error 46.8625%  acc_test_error 50.0%\n",
      "Epoch: 782 Loss: 20.135089874267578  acc_train_error 46.8625%  acc_test_error 50.0%\n",
      "Epoch: 783 Loss: 20.118505477905273  acc_train_error 46.8625%  acc_test_error 50.0%\n",
      "Epoch: 784 Loss: 20.101926803588867  acc_train_error 46.85%  acc_test_error 50.0%\n",
      "Epoch: 785 Loss: 20.08539390563965  acc_train_error 46.85%  acc_test_error 50.0%\n",
      "Epoch: 786 Loss: 20.069019317626953  acc_train_error 46.85%  acc_test_error 50.0%\n",
      "Epoch: 787 Loss: 20.05276870727539  acc_train_error 46.85%  acc_test_error 50.0%\n",
      "Epoch: 788 Loss: 20.036632537841797  acc_train_error 46.85%  acc_test_error 50.0%\n",
      "Epoch: 789 Loss: 20.02057647705078  acc_train_error 46.8375%  acc_test_error 50.0%\n",
      "Epoch: 790 Loss: 20.004602432250977  acc_train_error 46.8375%  acc_test_error 50.0%\n",
      "Epoch: 791 Loss: 19.9886417388916  acc_train_error 46.8375%  acc_test_error 50.0%\n",
      "Epoch: 792 Loss: 19.972665786743164  acc_train_error 46.8375%  acc_test_error 50.0%\n",
      "Epoch: 793 Loss: 19.95676040649414  acc_train_error 46.8375%  acc_test_error 50.0%\n",
      "Epoch: 794 Loss: 19.94086456298828  acc_train_error 46.825%  acc_test_error 50.0%\n",
      "Epoch: 795 Loss: 19.925020217895508  acc_train_error 46.825%  acc_test_error 50.0%\n",
      "Epoch: 796 Loss: 19.909297943115234  acc_train_error 46.825%  acc_test_error 50.0%\n",
      "Epoch: 797 Loss: 19.893524169921875  acc_train_error 46.825%  acc_test_error 50.0%\n",
      "Epoch: 798 Loss: 19.877666473388672  acc_train_error 46.825%  acc_test_error 50.0%\n",
      "Epoch: 799 Loss: 19.86189842224121  acc_train_error 46.8125%  acc_test_error 50.0%\n",
      "Epoch: 800 Loss: 19.846172332763672  acc_train_error 46.8%  acc_test_error 50.0%\n",
      "Epoch: 801 Loss: 19.83049201965332  acc_train_error 46.8%  acc_test_error 50.0%\n",
      "Epoch: 802 Loss: 19.8149356842041  acc_train_error 46.8%  acc_test_error 50.0%\n",
      "Epoch: 803 Loss: 19.79945182800293  acc_train_error 46.8%  acc_test_error 50.0%\n",
      "Epoch: 804 Loss: 19.783971786499023  acc_train_error 46.8%  acc_test_error 50.0%\n",
      "Epoch: 805 Loss: 19.76856803894043  acc_train_error 46.7875%  acc_test_error 50.0%\n",
      "Epoch: 806 Loss: 19.75324249267578  acc_train_error 46.7875%  acc_test_error 50.0%\n",
      "Epoch: 807 Loss: 19.737886428833008  acc_train_error 46.7875%  acc_test_error 50.0%\n",
      "Epoch: 808 Loss: 19.7225341796875  acc_train_error 46.7875%  acc_test_error 50.0%\n",
      "Epoch: 809 Loss: 19.707178115844727  acc_train_error 46.7875%  acc_test_error 50.0%\n",
      "Epoch: 810 Loss: 19.691883087158203  acc_train_error 46.775%  acc_test_error 50.0%\n",
      "Epoch: 811 Loss: 19.67668342590332  acc_train_error 46.775%  acc_test_error 50.0%\n",
      "Epoch: 812 Loss: 19.661582946777344  acc_train_error 46.775%  acc_test_error 50.0%\n",
      "Epoch: 813 Loss: 19.646587371826172  acc_train_error 46.775%  acc_test_error 50.0%\n",
      "Epoch: 814 Loss: 19.63162612915039  acc_train_error 46.775%  acc_test_error 50.0%\n",
      "Epoch: 815 Loss: 19.61664581298828  acc_train_error 46.7625%  acc_test_error 50.0%\n",
      "Epoch: 816 Loss: 19.601665496826172  acc_train_error 46.7625%  acc_test_error 50.0%\n",
      "Epoch: 817 Loss: 19.58673858642578  acc_train_error 46.7625%  acc_test_error 50.0%\n",
      "Epoch: 818 Loss: 19.571857452392578  acc_train_error 46.7625%  acc_test_error 50.0%\n",
      "Epoch: 819 Loss: 19.556915283203125  acc_train_error 46.75%  acc_test_error 50.0%\n",
      "Epoch: 820 Loss: 19.5417423248291  acc_train_error 46.7625%  acc_test_error 50.0%\n",
      "Epoch: 821 Loss: 19.526552200317383  acc_train_error 46.7625%  acc_test_error 50.0%\n",
      "Epoch: 822 Loss: 19.511375427246094  acc_train_error 46.7625%  acc_test_error 50.0%\n",
      "Epoch: 823 Loss: 19.49625015258789  acc_train_error 46.7625%  acc_test_error 50.0%\n",
      "Epoch: 824 Loss: 19.481170654296875  acc_train_error 46.7625%  acc_test_error 50.0%\n",
      "Epoch: 825 Loss: 19.466135025024414  acc_train_error 46.7625%  acc_test_error 50.0%\n",
      "Epoch: 826 Loss: 19.45111846923828  acc_train_error 46.7625%  acc_test_error 50.0%\n",
      "Epoch: 827 Loss: 19.436124801635742  acc_train_error 46.7625%  acc_test_error 50.0%\n",
      "Epoch: 828 Loss: 19.421138763427734  acc_train_error 46.7625%  acc_test_error 50.0%\n",
      "Epoch: 829 Loss: 19.40615463256836  acc_train_error 46.7625%  acc_test_error 50.0%\n",
      "Epoch: 830 Loss: 19.391218185424805  acc_train_error 46.7625%  acc_test_error 50.0%\n",
      "Epoch: 831 Loss: 19.376354217529297  acc_train_error 46.7625%  acc_test_error 50.0%\n",
      "Epoch: 832 Loss: 19.3614501953125  acc_train_error 46.7625%  acc_test_error 50.0%\n",
      "Epoch: 833 Loss: 19.34665298461914  acc_train_error 46.7625%  acc_test_error 50.0%\n",
      "Epoch: 834 Loss: 19.33194351196289  acc_train_error 46.7625%  acc_test_error 50.0%\n",
      "Epoch: 835 Loss: 19.317298889160156  acc_train_error 46.7625%  acc_test_error 50.0%\n",
      "Epoch: 836 Loss: 19.302589416503906  acc_train_error 46.7625%  acc_test_error 50.0%\n",
      "Epoch: 837 Loss: 19.287944793701172  acc_train_error 46.7625%  acc_test_error 50.0%\n",
      "Epoch: 838 Loss: 19.273380279541016  acc_train_error 46.7625%  acc_test_error 50.0%\n",
      "Epoch: 839 Loss: 19.258909225463867  acc_train_error 46.7625%  acc_test_error 50.0%\n",
      "Epoch: 840 Loss: 19.244579315185547  acc_train_error 46.7625%  acc_test_error 50.0%\n",
      "Epoch: 841 Loss: 19.230304718017578  acc_train_error 46.7625%  acc_test_error 50.0%\n",
      "Epoch: 842 Loss: 19.216028213500977  acc_train_error 46.7625%  acc_test_error 50.0%\n",
      "Epoch: 843 Loss: 19.201786041259766  acc_train_error 46.7625%  acc_test_error 50.0%\n",
      "Epoch: 844 Loss: 19.18755340576172  acc_train_error 46.7625%  acc_test_error 50.0%\n",
      "Epoch: 845 Loss: 19.17337989807129  acc_train_error 46.7625%  acc_test_error 50.0%\n",
      "Epoch: 846 Loss: 19.15932846069336  acc_train_error 46.75%  acc_test_error 50.0%\n",
      "Epoch: 847 Loss: 19.145381927490234  acc_train_error 46.75%  acc_test_error 50.0%\n",
      "Epoch: 848 Loss: 19.13144302368164  acc_train_error 46.75%  acc_test_error 50.0%\n",
      "Epoch: 849 Loss: 19.117515563964844  acc_train_error 46.75%  acc_test_error 50.0%\n",
      "Epoch: 850 Loss: 19.10361099243164  acc_train_error 46.75%  acc_test_error 50.0%\n",
      "Epoch: 851 Loss: 19.08970832824707  acc_train_error 46.7375%  acc_test_error 50.0%\n",
      "Epoch: 852 Loss: 19.075740814208984  acc_train_error 46.7375%  acc_test_error 50.0%\n",
      "Epoch: 853 Loss: 19.061748504638672  acc_train_error 46.7375%  acc_test_error 50.0%\n",
      "Epoch: 854 Loss: 19.04783821105957  acc_train_error 46.7375%  acc_test_error 50.0%\n",
      "Epoch: 855 Loss: 19.033971786499023  acc_train_error 46.7375%  acc_test_error 50.0%\n",
      "Epoch: 856 Loss: 19.0201473236084  acc_train_error 46.7375%  acc_test_error 50.0%\n",
      "Epoch: 857 Loss: 19.006338119506836  acc_train_error 46.7375%  acc_test_error 50.0%\n",
      "Epoch: 858 Loss: 18.992610931396484  acc_train_error 46.7375%  acc_test_error 50.0%\n",
      "Epoch: 859 Loss: 18.978940963745117  acc_train_error 46.725%  acc_test_error 50.0%\n",
      "Epoch: 860 Loss: 18.965312957763672  acc_train_error 46.725%  acc_test_error 50.0%\n",
      "Epoch: 861 Loss: 18.951732635498047  acc_train_error 46.725%  acc_test_error 50.0%\n",
      "Epoch: 862 Loss: 18.938217163085938  acc_train_error 46.725%  acc_test_error 50.0%\n",
      "Epoch: 863 Loss: 18.924753189086914  acc_train_error 46.725%  acc_test_error 50.0%\n",
      "Epoch: 864 Loss: 18.911378860473633  acc_train_error 46.7125%  acc_test_error 50.0%\n",
      "Epoch: 865 Loss: 18.898099899291992  acc_train_error 46.7125%  acc_test_error 50.0%\n",
      "Epoch: 866 Loss: 18.88486671447754  acc_train_error 46.7125%  acc_test_error 50.0%\n",
      "Epoch: 867 Loss: 18.871658325195312  acc_train_error 46.7%  acc_test_error 50.0%\n",
      "Epoch: 868 Loss: 18.858455657958984  acc_train_error 46.7%  acc_test_error 50.0%\n",
      "Epoch: 869 Loss: 18.845266342163086  acc_train_error 46.7%  acc_test_error 50.0%\n",
      "Epoch: 870 Loss: 18.832029342651367  acc_train_error 46.7%  acc_test_error 50.0%\n",
      "Epoch: 871 Loss: 18.818832397460938  acc_train_error 46.7%  acc_test_error 50.0%\n",
      "Epoch: 872 Loss: 18.80571174621582  acc_train_error 46.7%  acc_test_error 50.0%\n",
      "Epoch: 873 Loss: 18.79255485534668  acc_train_error 46.6875%  acc_test_error 50.0%\n",
      "Epoch: 874 Loss: 18.7794246673584  acc_train_error 46.6875%  acc_test_error 50.0%\n",
      "Epoch: 875 Loss: 18.766353607177734  acc_train_error 46.6875%  acc_test_error 50.0%\n",
      "Epoch: 876 Loss: 18.753328323364258  acc_train_error 46.6875%  acc_test_error 50.0%\n",
      "Epoch: 877 Loss: 18.740320205688477  acc_train_error 46.675%  acc_test_error 50.0%\n",
      "Epoch: 878 Loss: 18.72736930847168  acc_train_error 46.675%  acc_test_error 50.0%\n",
      "Epoch: 879 Loss: 18.714418411254883  acc_train_error 46.675%  acc_test_error 50.0%\n",
      "Epoch: 880 Loss: 18.70151710510254  acc_train_error 46.6625%  acc_test_error 50.0%\n",
      "Epoch: 881 Loss: 18.68865966796875  acc_train_error 46.6625%  acc_test_error 50.0%\n",
      "Epoch: 882 Loss: 18.675857543945312  acc_train_error 46.65%  acc_test_error 50.0%\n",
      "Epoch: 883 Loss: 18.66303062438965  acc_train_error 46.6375%  acc_test_error 50.0%\n",
      "Epoch: 884 Loss: 18.650238037109375  acc_train_error 46.6375%  acc_test_error 50.0%\n",
      "Epoch: 885 Loss: 18.637470245361328  acc_train_error 46.625%  acc_test_error 50.0%\n",
      "Epoch: 886 Loss: 18.624753952026367  acc_train_error 46.625%  acc_test_error 50.0%\n",
      "Epoch: 887 Loss: 18.61208152770996  acc_train_error 46.625%  acc_test_error 50.0%\n",
      "Epoch: 888 Loss: 18.599390029907227  acc_train_error 46.6125%  acc_test_error 50.0%\n",
      "Epoch: 889 Loss: 18.586605072021484  acc_train_error 46.6125%  acc_test_error 50.0%\n",
      "Epoch: 890 Loss: 18.57379913330078  acc_train_error 46.6125%  acc_test_error 50.0%\n",
      "Epoch: 891 Loss: 18.561050415039062  acc_train_error 46.6%  acc_test_error 50.0%\n",
      "Epoch: 892 Loss: 18.548294067382812  acc_train_error 46.6%  acc_test_error 50.0%\n",
      "Epoch: 893 Loss: 18.53563690185547  acc_train_error 46.6%  acc_test_error 50.0%\n",
      "Epoch: 894 Loss: 18.5230712890625  acc_train_error 46.6%  acc_test_error 50.0%\n",
      "Epoch: 895 Loss: 18.51055145263672  acc_train_error 46.5875%  acc_test_error 50.0%\n",
      "Epoch: 896 Loss: 18.498044967651367  acc_train_error 46.575%  acc_test_error 50.0%\n",
      "Epoch: 897 Loss: 18.485525131225586  acc_train_error 46.575%  acc_test_error 50.0%\n",
      "Epoch: 898 Loss: 18.473064422607422  acc_train_error 46.575%  acc_test_error 50.0%\n",
      "Epoch: 899 Loss: 18.4606990814209  acc_train_error 46.5625%  acc_test_error 50.0%\n",
      "Epoch: 900 Loss: 18.44841194152832  acc_train_error 46.5625%  acc_test_error 50.0%\n",
      "Epoch: 901 Loss: 18.43618392944336  acc_train_error 46.55%  acc_test_error 50.0%\n",
      "Epoch: 902 Loss: 18.423959732055664  acc_train_error 46.55%  acc_test_error 50.0%\n",
      "Epoch: 903 Loss: 18.411752700805664  acc_train_error 46.5375%  acc_test_error 50.0%\n",
      "Epoch: 904 Loss: 18.39956283569336  acc_train_error 46.5375%  acc_test_error 50.0%\n",
      "Epoch: 905 Loss: 18.38744354248047  acc_train_error 46.5375%  acc_test_error 50.0%\n",
      "Epoch: 906 Loss: 18.375370025634766  acc_train_error 46.525%  acc_test_error 50.0%\n",
      "Epoch: 907 Loss: 18.363290786743164  acc_train_error 46.525%  acc_test_error 50.0%\n",
      "Epoch: 908 Loss: 18.351228713989258  acc_train_error 46.5125%  acc_test_error 50.0%\n",
      "Epoch: 909 Loss: 18.339149475097656  acc_train_error 46.5125%  acc_test_error 50.0%\n",
      "Epoch: 910 Loss: 18.327110290527344  acc_train_error 46.5125%  acc_test_error 50.0%\n",
      "Epoch: 911 Loss: 18.315021514892578  acc_train_error 46.5%  acc_test_error 50.0%\n",
      "Epoch: 912 Loss: 18.302906036376953  acc_train_error 46.5%  acc_test_error 50.0%\n",
      "Epoch: 913 Loss: 18.290788650512695  acc_train_error 46.475%  acc_test_error 50.0%\n",
      "Epoch: 914 Loss: 18.278675079345703  acc_train_error 46.475%  acc_test_error 50.0%\n",
      "Epoch: 915 Loss: 18.266536712646484  acc_train_error 46.475%  acc_test_error 50.0%\n",
      "Epoch: 916 Loss: 18.254371643066406  acc_train_error 46.4625%  acc_test_error 50.0%\n",
      "Epoch: 917 Loss: 18.242225646972656  acc_train_error 46.4625%  acc_test_error 50.0%\n",
      "Epoch: 918 Loss: 18.230148315429688  acc_train_error 46.45%  acc_test_error 50.0%\n",
      "Epoch: 919 Loss: 18.218122482299805  acc_train_error 46.45%  acc_test_error 50.0%\n",
      "Epoch: 920 Loss: 18.206130981445312  acc_train_error 46.45%  acc_test_error 50.0%\n",
      "Epoch: 921 Loss: 18.194177627563477  acc_train_error 46.4375%  acc_test_error 50.0%\n",
      "Epoch: 922 Loss: 18.18221092224121  acc_train_error 46.4375%  acc_test_error 50.0%\n",
      "Epoch: 923 Loss: 18.17019271850586  acc_train_error 46.425%  acc_test_error 50.0%\n",
      "Epoch: 924 Loss: 18.158140182495117  acc_train_error 46.425%  acc_test_error 50.0%\n",
      "Epoch: 925 Loss: 18.1461238861084  acc_train_error 46.4125%  acc_test_error 50.0%\n",
      "Epoch: 926 Loss: 18.13408851623535  acc_train_error 46.4125%  acc_test_error 50.0%\n",
      "Epoch: 927 Loss: 18.121978759765625  acc_train_error 46.4125%  acc_test_error 50.0%\n",
      "Epoch: 928 Loss: 18.109865188598633  acc_train_error 46.3875%  acc_test_error 50.0%\n",
      "Epoch: 929 Loss: 18.097768783569336  acc_train_error 46.3875%  acc_test_error 50.0%\n",
      "Epoch: 930 Loss: 18.08576202392578  acc_train_error 46.3875%  acc_test_error 50.0%\n",
      "Epoch: 931 Loss: 18.073657989501953  acc_train_error 46.3875%  acc_test_error 50.0%\n",
      "Epoch: 932 Loss: 18.06159210205078  acc_train_error 46.375%  acc_test_error 50.0%\n",
      "Epoch: 933 Loss: 18.049625396728516  acc_train_error 46.375%  acc_test_error 50.0%\n",
      "Epoch: 934 Loss: 18.03763198852539  acc_train_error 46.375%  acc_test_error 50.0%\n",
      "Epoch: 935 Loss: 18.025707244873047  acc_train_error 46.3625%  acc_test_error 50.0%\n",
      "Epoch: 936 Loss: 18.013824462890625  acc_train_error 46.3625%  acc_test_error 50.0%\n",
      "Epoch: 937 Loss: 18.001955032348633  acc_train_error 46.3625%  acc_test_error 50.0%\n",
      "Epoch: 938 Loss: 17.99009895324707  acc_train_error 46.35%  acc_test_error 50.0%\n",
      "Epoch: 939 Loss: 17.97820472717285  acc_train_error 46.35%  acc_test_error 50.0%\n",
      "Epoch: 940 Loss: 17.966318130493164  acc_train_error 46.35%  acc_test_error 50.0%\n",
      "Epoch: 941 Loss: 17.954391479492188  acc_train_error 46.3375%  acc_test_error 50.0%\n",
      "Epoch: 942 Loss: 17.94256019592285  acc_train_error 46.3375%  acc_test_error 50.0%\n",
      "Epoch: 943 Loss: 17.93074607849121  acc_train_error 46.3375%  acc_test_error 50.0%\n",
      "Epoch: 944 Loss: 17.918941497802734  acc_train_error 46.325%  acc_test_error 50.0%\n",
      "Epoch: 945 Loss: 17.907136917114258  acc_train_error 46.325%  acc_test_error 50.0%\n",
      "Epoch: 946 Loss: 17.895353317260742  acc_train_error 46.325%  acc_test_error 50.0%\n",
      "Epoch: 947 Loss: 17.883634567260742  acc_train_error 46.325%  acc_test_error 50.0%\n",
      "Epoch: 948 Loss: 17.87189483642578  acc_train_error 46.3125%  acc_test_error 50.0%\n",
      "Epoch: 949 Loss: 17.860031127929688  acc_train_error 46.3125%  acc_test_error 50.0%\n",
      "Epoch: 950 Loss: 17.848196029663086  acc_train_error 46.3125%  acc_test_error 50.0%\n",
      "Epoch: 951 Loss: 17.83637809753418  acc_train_error 46.3125%  acc_test_error 50.0%\n",
      "Epoch: 952 Loss: 17.82459259033203  acc_train_error 46.3125%  acc_test_error 50.0%\n",
      "Epoch: 953 Loss: 17.812850952148438  acc_train_error 46.3125%  acc_test_error 50.0%\n",
      "Epoch: 954 Loss: 17.801177978515625  acc_train_error 46.3%  acc_test_error 50.0%\n",
      "Epoch: 955 Loss: 17.789533615112305  acc_train_error 46.3%  acc_test_error 50.0%\n",
      "Epoch: 956 Loss: 17.77790641784668  acc_train_error 46.3%  acc_test_error 50.0%\n",
      "Epoch: 957 Loss: 17.76631736755371  acc_train_error 46.3%  acc_test_error 50.0%\n",
      "Epoch: 958 Loss: 17.75472640991211  acc_train_error 46.2875%  acc_test_error 50.0%\n",
      "Epoch: 959 Loss: 17.74323081970215  acc_train_error 46.275%  acc_test_error 50.0%\n",
      "Epoch: 960 Loss: 17.731760025024414  acc_train_error 46.275%  acc_test_error 50.0%\n",
      "Epoch: 961 Loss: 17.72022247314453  acc_train_error 46.275%  acc_test_error 50.0%\n",
      "Epoch: 962 Loss: 17.70862579345703  acc_train_error 46.2625%  acc_test_error 50.0%\n",
      "Epoch: 963 Loss: 17.6970157623291  acc_train_error 46.2625%  acc_test_error 50.0%\n",
      "Epoch: 964 Loss: 17.68532371520996  acc_train_error 46.2625%  acc_test_error 50.0%\n",
      "Epoch: 965 Loss: 17.673625946044922  acc_train_error 46.2625%  acc_test_error 50.0%\n",
      "Epoch: 966 Loss: 17.6618709564209  acc_train_error 46.2625%  acc_test_error 50.0%\n",
      "Epoch: 967 Loss: 17.650192260742188  acc_train_error 46.25%  acc_test_error 50.0%\n",
      "Epoch: 968 Loss: 17.638587951660156  acc_train_error 46.25%  acc_test_error 50.0%\n",
      "Epoch: 969 Loss: 17.62710952758789  acc_train_error 46.25%  acc_test_error 50.0%\n",
      "Epoch: 970 Loss: 17.615633010864258  acc_train_error 46.25%  acc_test_error 50.0%\n",
      "Epoch: 971 Loss: 17.60420036315918  acc_train_error 46.2375%  acc_test_error 50.0%\n",
      "Epoch: 972 Loss: 17.592741012573242  acc_train_error 46.2375%  acc_test_error 50.0%\n",
      "Epoch: 973 Loss: 17.581096649169922  acc_train_error 46.2375%  acc_test_error 50.0%\n",
      "Epoch: 974 Loss: 17.5693359375  acc_train_error 46.2375%  acc_test_error 50.0%\n",
      "Epoch: 975 Loss: 17.55756187438965  acc_train_error 46.2375%  acc_test_error 50.0%\n",
      "Epoch: 976 Loss: 17.545867919921875  acc_train_error 46.2375%  acc_test_error 50.0%\n",
      "Epoch: 977 Loss: 17.534221649169922  acc_train_error 46.2375%  acc_test_error 50.0%\n",
      "Epoch: 978 Loss: 17.52248191833496  acc_train_error 46.2375%  acc_test_error 50.0%\n",
      "Epoch: 979 Loss: 17.510784149169922  acc_train_error 46.2375%  acc_test_error 50.0%\n",
      "Epoch: 980 Loss: 17.499187469482422  acc_train_error 46.2375%  acc_test_error 50.0%\n",
      "Epoch: 981 Loss: 17.48766326904297  acc_train_error 46.225%  acc_test_error 50.0%\n",
      "Epoch: 982 Loss: 17.476184844970703  acc_train_error 46.225%  acc_test_error 50.0%\n",
      "Epoch: 983 Loss: 17.464534759521484  acc_train_error 46.225%  acc_test_error 50.0%\n",
      "Epoch: 984 Loss: 17.45305061340332  acc_train_error 46.225%  acc_test_error 50.0%\n",
      "Epoch: 985 Loss: 17.441631317138672  acc_train_error 46.2375%  acc_test_error 50.0%\n",
      "Epoch: 986 Loss: 17.430253982543945  acc_train_error 46.2375%  acc_test_error 50.0%\n",
      "Epoch: 987 Loss: 17.418874740600586  acc_train_error 46.225%  acc_test_error 50.0%\n",
      "Epoch: 988 Loss: 17.40755844116211  acc_train_error 46.225%  acc_test_error 50.0%\n",
      "Epoch: 989 Loss: 17.396249771118164  acc_train_error 46.225%  acc_test_error 50.0%\n",
      "Epoch: 990 Loss: 17.384952545166016  acc_train_error 46.2125%  acc_test_error 50.0%\n",
      "Epoch: 991 Loss: 17.373706817626953  acc_train_error 46.2125%  acc_test_error 50.0%\n",
      "Epoch: 992 Loss: 17.362442016601562  acc_train_error 46.2125%  acc_test_error 50.0%\n",
      "Epoch: 993 Loss: 17.35120391845703  acc_train_error 46.2%  acc_test_error 50.0%\n",
      "Epoch: 994 Loss: 17.339963912963867  acc_train_error 46.2%  acc_test_error 50.0%\n",
      "Epoch: 995 Loss: 17.328624725341797  acc_train_error 46.2%  acc_test_error 50.0%\n",
      "Epoch: 996 Loss: 17.317367553710938  acc_train_error 46.1875%  acc_test_error 50.0%\n",
      "Epoch: 997 Loss: 17.306129455566406  acc_train_error 46.1875%  acc_test_error 50.0%\n",
      "Epoch: 998 Loss: 17.294965744018555  acc_train_error 46.175%  acc_test_error 50.0%\n",
      "Epoch: 999 Loss: 17.28386878967285  acc_train_error 46.175%  acc_test_error 50.0%\n",
      "Epoch: 1000 Loss: 17.272640228271484  acc_train_error 46.175%  acc_test_error 50.0%\n",
      "Epoch: 1001 Loss: 17.2614803314209  acc_train_error 46.1625%  acc_test_error 50.0%\n",
      "Epoch: 1002 Loss: 17.250308990478516  acc_train_error 46.15%  acc_test_error 50.0%\n",
      "Epoch: 1003 Loss: 17.239139556884766  acc_train_error 46.15%  acc_test_error 50.0%\n",
      "Epoch: 1004 Loss: 17.227876663208008  acc_train_error 46.1375%  acc_test_error 50.0%\n",
      "Epoch: 1005 Loss: 17.21653938293457  acc_train_error 46.1375%  acc_test_error 50.0%\n",
      "Epoch: 1006 Loss: 17.205249786376953  acc_train_error 46.125%  acc_test_error 50.0%\n",
      "Epoch: 1007 Loss: 17.19386100769043  acc_train_error 46.1125%  acc_test_error 50.0%\n",
      "Epoch: 1008 Loss: 17.182435989379883  acc_train_error 46.1%  acc_test_error 50.0%\n",
      "Epoch: 1009 Loss: 17.170997619628906  acc_train_error 46.1125%  acc_test_error 50.0%\n",
      "Epoch: 1010 Loss: 17.159528732299805  acc_train_error 46.1%  acc_test_error 50.0%\n",
      "Epoch: 1011 Loss: 17.14805793762207  acc_train_error 46.0875%  acc_test_error 50.0%\n",
      "Epoch: 1012 Loss: 17.13656234741211  acc_train_error 46.075%  acc_test_error 50.0%\n",
      "Epoch: 1013 Loss: 17.1251277923584  acc_train_error 46.0625%  acc_test_error 50.0%\n",
      "Epoch: 1014 Loss: 17.113676071166992  acc_train_error 46.05%  acc_test_error 50.0%\n",
      "Epoch: 1015 Loss: 17.102275848388672  acc_train_error 46.0375%  acc_test_error 50.0%\n",
      "Epoch: 1016 Loss: 17.090900421142578  acc_train_error 46.025%  acc_test_error 50.0%\n",
      "Epoch: 1017 Loss: 17.079498291015625  acc_train_error 46.0125%  acc_test_error 50.0%\n",
      "Epoch: 1018 Loss: 17.068161010742188  acc_train_error 45.975%  acc_test_error 50.0%\n",
      "Epoch: 1019 Loss: 17.056764602661133  acc_train_error 45.95%  acc_test_error 50.0%\n",
      "Epoch: 1020 Loss: 17.04541778564453  acc_train_error 45.925%  acc_test_error 50.0%\n",
      "Epoch: 1021 Loss: 17.034074783325195  acc_train_error 45.9%  acc_test_error 50.0%\n",
      "Epoch: 1022 Loss: 17.022741317749023  acc_train_error 45.875%  acc_test_error 50.0%\n",
      "Epoch: 1023 Loss: 17.011178970336914  acc_train_error 45.85%  acc_test_error 50.0%\n",
      "Epoch: 1024 Loss: 16.999656677246094  acc_train_error 45.8375%  acc_test_error 50.0%\n",
      "Epoch: 1025 Loss: 16.988208770751953  acc_train_error 45.8%  acc_test_error 50.0%\n",
      "Epoch: 1026 Loss: 16.9766845703125  acc_train_error 45.7625%  acc_test_error 50.0%\n",
      "Epoch: 1027 Loss: 16.96501922607422  acc_train_error 45.725%  acc_test_error 50.0%\n",
      "Epoch: 1028 Loss: 16.95353889465332  acc_train_error 45.5625%  acc_test_error 50.0%\n",
      "Epoch: 1029 Loss: 16.942108154296875  acc_train_error 45.3375%  acc_test_error 50.0%\n",
      "Epoch: 1030 Loss: 16.930728912353516  acc_train_error 45.2625%  acc_test_error 50.0%\n",
      "Epoch: 1031 Loss: 16.91932487487793  acc_train_error 45.175%  acc_test_error 50.0%\n",
      "Epoch: 1032 Loss: 16.90782356262207  acc_train_error 45.1%  acc_test_error 50.0%\n",
      "Epoch: 1033 Loss: 16.896286010742188  acc_train_error 45.0%  acc_test_error 50.0%\n",
      "Epoch: 1034 Loss: 16.884809494018555  acc_train_error 44.8375%  acc_test_error 50.0%\n",
      "Epoch: 1035 Loss: 16.873367309570312  acc_train_error 44.8%  acc_test_error 50.0%\n",
      "Epoch: 1036 Loss: 16.861989974975586  acc_train_error 44.75%  acc_test_error 50.0%\n",
      "Epoch: 1037 Loss: 16.850706100463867  acc_train_error 44.7125%  acc_test_error 50.0%\n",
      "Epoch: 1038 Loss: 16.83942413330078  acc_train_error 44.6625%  acc_test_error 50.0%\n",
      "Epoch: 1039 Loss: 16.828092575073242  acc_train_error 44.475%  acc_test_error 50.0%\n",
      "Epoch: 1040 Loss: 16.816829681396484  acc_train_error 44.35%  acc_test_error 50.0%\n",
      "Epoch: 1041 Loss: 16.805564880371094  acc_train_error 43.6375%  acc_test_error 50.0%\n",
      "Epoch: 1042 Loss: 16.79433250427246  acc_train_error 43.1875%  acc_test_error 50.0%\n",
      "Epoch: 1043 Loss: 16.783145904541016  acc_train_error 43.025%  acc_test_error 50.0%\n",
      "Epoch: 1044 Loss: 16.771936416625977  acc_train_error 42.8875%  acc_test_error 50.0%\n",
      "Epoch: 1045 Loss: 16.760623931884766  acc_train_error 42.7625%  acc_test_error 50.0%\n",
      "Epoch: 1046 Loss: 16.74897575378418  acc_train_error 42.575%  acc_test_error 50.0%\n",
      "Epoch: 1047 Loss: 16.737321853637695  acc_train_error 42.5125%  acc_test_error 50.0%\n",
      "Epoch: 1048 Loss: 16.72578239440918  acc_train_error 42.45%  acc_test_error 50.0%\n",
      "Epoch: 1049 Loss: 16.714345932006836  acc_train_error 42.4125%  acc_test_error 50.0%\n",
      "Epoch: 1050 Loss: 16.702953338623047  acc_train_error 42.375%  acc_test_error 50.0%\n",
      "Epoch: 1051 Loss: 16.691471099853516  acc_train_error 42.325%  acc_test_error 50.0%\n",
      "Epoch: 1052 Loss: 16.679805755615234  acc_train_error 42.3125%  acc_test_error 50.0%\n",
      "Epoch: 1053 Loss: 16.667930603027344  acc_train_error 42.2875%  acc_test_error 50.0%\n",
      "Epoch: 1054 Loss: 16.65579605102539  acc_train_error 42.2625%  acc_test_error 50.0%\n",
      "Epoch: 1055 Loss: 16.643596649169922  acc_train_error 42.2375%  acc_test_error 50.0%\n",
      "Epoch: 1056 Loss: 16.63159942626953  acc_train_error 42.2125%  acc_test_error 50.0%\n",
      "Epoch: 1057 Loss: 16.619535446166992  acc_train_error 42.2%  acc_test_error 50.0%\n",
      "Epoch: 1058 Loss: 16.607683181762695  acc_train_error 42.175%  acc_test_error 50.0%\n",
      "Epoch: 1059 Loss: 16.595947265625  acc_train_error 42.15%  acc_test_error 50.0%\n",
      "Epoch: 1060 Loss: 16.584312438964844  acc_train_error 42.1375%  acc_test_error 50.0%\n",
      "Epoch: 1061 Loss: 16.572633743286133  acc_train_error 42.1125%  acc_test_error 50.0%\n",
      "Epoch: 1062 Loss: 16.560823440551758  acc_train_error 42.0875%  acc_test_error 50.0%\n",
      "Epoch: 1063 Loss: 16.549100875854492  acc_train_error 42.0625%  acc_test_error 50.0%\n",
      "Epoch: 1064 Loss: 16.53742218017578  acc_train_error 42.05%  acc_test_error 50.0%\n",
      "Epoch: 1065 Loss: 16.525850296020508  acc_train_error 42.0375%  acc_test_error 50.0%\n",
      "Epoch: 1066 Loss: 16.5142879486084  acc_train_error 42.0125%  acc_test_error 50.0%\n",
      "Epoch: 1067 Loss: 16.50264549255371  acc_train_error 41.975%  acc_test_error 50.0%\n",
      "Epoch: 1068 Loss: 16.491121292114258  acc_train_error 41.95%  acc_test_error 50.0%\n",
      "Epoch: 1069 Loss: 16.479644775390625  acc_train_error 41.925%  acc_test_error 50.0%\n",
      "Epoch: 1070 Loss: 16.46817970275879  acc_train_error 41.9%  acc_test_error 50.0%\n",
      "Epoch: 1071 Loss: 16.456829071044922  acc_train_error 41.8875%  acc_test_error 50.0%\n",
      "Epoch: 1072 Loss: 16.445571899414062  acc_train_error 41.8625%  acc_test_error 50.0%\n",
      "Epoch: 1073 Loss: 16.434368133544922  acc_train_error 41.85%  acc_test_error 50.0%\n",
      "Epoch: 1074 Loss: 16.42296600341797  acc_train_error 41.8375%  acc_test_error 50.0%\n",
      "Epoch: 1075 Loss: 16.41147232055664  acc_train_error 41.825%  acc_test_error 50.0%\n",
      "Epoch: 1076 Loss: 16.40003776550293  acc_train_error 41.8125%  acc_test_error 50.0%\n",
      "Epoch: 1077 Loss: 16.38873863220215  acc_train_error 41.8%  acc_test_error 50.0%\n",
      "Epoch: 1078 Loss: 16.377485275268555  acc_train_error 41.7875%  acc_test_error 50.0%\n",
      "Epoch: 1079 Loss: 16.366241455078125  acc_train_error 41.775%  acc_test_error 50.0%\n",
      "Epoch: 1080 Loss: 16.355093002319336  acc_train_error 41.7625%  acc_test_error 50.0%\n",
      "Epoch: 1081 Loss: 16.344038009643555  acc_train_error 41.75%  acc_test_error 50.0%\n",
      "Epoch: 1082 Loss: 16.332881927490234  acc_train_error 41.7375%  acc_test_error 50.0%\n",
      "Epoch: 1083 Loss: 16.321744918823242  acc_train_error 41.725%  acc_test_error 50.0%\n",
      "Epoch: 1084 Loss: 16.310667037963867  acc_train_error 41.7%  acc_test_error 50.0%\n",
      "Epoch: 1085 Loss: 16.299633026123047  acc_train_error 41.6875%  acc_test_error 50.0%\n",
      "Epoch: 1086 Loss: 16.288475036621094  acc_train_error 41.675%  acc_test_error 50.0%\n",
      "Epoch: 1087 Loss: 16.277250289916992  acc_train_error 41.6625%  acc_test_error 50.0%\n",
      "Epoch: 1088 Loss: 16.265907287597656  acc_train_error 41.65%  acc_test_error 50.0%\n",
      "Epoch: 1089 Loss: 16.254323959350586  acc_train_error 41.6375%  acc_test_error 50.0%\n",
      "Epoch: 1090 Loss: 16.2427978515625  acc_train_error 41.625%  acc_test_error 50.0%\n",
      "Epoch: 1091 Loss: 16.23146629333496  acc_train_error 41.6125%  acc_test_error 50.0%\n",
      "Epoch: 1092 Loss: 16.22030258178711  acc_train_error 41.6%  acc_test_error 50.0%\n",
      "Epoch: 1093 Loss: 16.20933723449707  acc_train_error 41.5875%  acc_test_error 50.0%\n",
      "Epoch: 1094 Loss: 16.198427200317383  acc_train_error 41.575%  acc_test_error 50.0%\n",
      "Epoch: 1095 Loss: 16.187509536743164  acc_train_error 41.5625%  acc_test_error 50.0%\n",
      "Epoch: 1096 Loss: 16.176599502563477  acc_train_error 41.55%  acc_test_error 50.0%\n",
      "Epoch: 1097 Loss: 16.165719985961914  acc_train_error 41.5375%  acc_test_error 50.0%\n",
      "Epoch: 1098 Loss: 16.154891967773438  acc_train_error 41.5375%  acc_test_error 50.0%\n",
      "Epoch: 1099 Loss: 16.144140243530273  acc_train_error 41.525%  acc_test_error 50.0%\n",
      "Epoch: 1100 Loss: 16.133434295654297  acc_train_error 41.5125%  acc_test_error 50.0%\n",
      "Epoch: 1101 Loss: 16.122751235961914  acc_train_error 41.5%  acc_test_error 50.0%\n",
      "Epoch: 1102 Loss: 16.11212158203125  acc_train_error 41.4875%  acc_test_error 50.0%\n",
      "Epoch: 1103 Loss: 16.101564407348633  acc_train_error 41.475%  acc_test_error 50.0%\n",
      "Epoch: 1104 Loss: 16.09105682373047  acc_train_error 41.475%  acc_test_error 50.0%\n",
      "Epoch: 1105 Loss: 16.080596923828125  acc_train_error 41.4625%  acc_test_error 50.0%\n",
      "Epoch: 1106 Loss: 16.0701904296875  acc_train_error 41.45%  acc_test_error 50.0%\n",
      "Epoch: 1107 Loss: 16.059783935546875  acc_train_error 41.4375%  acc_test_error 50.0%\n",
      "Epoch: 1108 Loss: 16.04943084716797  acc_train_error 41.425%  acc_test_error 50.0%\n",
      "Epoch: 1109 Loss: 16.03911781311035  acc_train_error 41.4%  acc_test_error 50.0%\n",
      "Epoch: 1110 Loss: 16.028812408447266  acc_train_error 41.3875%  acc_test_error 50.0%\n",
      "Epoch: 1111 Loss: 16.018512725830078  acc_train_error 41.3875%  acc_test_error 50.0%\n",
      "Epoch: 1112 Loss: 16.00822639465332  acc_train_error 41.375%  acc_test_error 50.0%\n",
      "Epoch: 1113 Loss: 15.99786376953125  acc_train_error 41.3625%  acc_test_error 50.0%\n",
      "Epoch: 1114 Loss: 15.987217903137207  acc_train_error 41.35%  acc_test_error 50.0%\n",
      "Epoch: 1115 Loss: 15.976183891296387  acc_train_error 41.3375%  acc_test_error 50.0%\n",
      "Epoch: 1116 Loss: 15.965156555175781  acc_train_error 41.3375%  acc_test_error 50.0%\n",
      "Epoch: 1117 Loss: 15.954131126403809  acc_train_error 41.325%  acc_test_error 50.0%\n",
      "Epoch: 1118 Loss: 15.943161010742188  acc_train_error 41.3125%  acc_test_error 50.0%\n",
      "Epoch: 1119 Loss: 15.932352066040039  acc_train_error 41.3%  acc_test_error 50.0%\n",
      "Epoch: 1120 Loss: 15.92164134979248  acc_train_error 41.2875%  acc_test_error 50.0%\n",
      "Epoch: 1121 Loss: 15.911031723022461  acc_train_error 41.2875%  acc_test_error 50.0%\n",
      "Epoch: 1122 Loss: 15.900497436523438  acc_train_error 41.275%  acc_test_error 50.0%\n",
      "Epoch: 1123 Loss: 15.889904975891113  acc_train_error 41.2625%  acc_test_error 50.0%\n",
      "Epoch: 1124 Loss: 15.879420280456543  acc_train_error 41.25%  acc_test_error 50.0%\n",
      "Epoch: 1125 Loss: 15.869030952453613  acc_train_error 41.25%  acc_test_error 50.0%\n",
      "Epoch: 1126 Loss: 15.85863208770752  acc_train_error 41.2375%  acc_test_error 50.0%\n",
      "Epoch: 1127 Loss: 15.84816837310791  acc_train_error 41.225%  acc_test_error 50.0%\n",
      "Epoch: 1128 Loss: 15.837695121765137  acc_train_error 41.2125%  acc_test_error 50.0%\n",
      "Epoch: 1129 Loss: 15.827010154724121  acc_train_error 41.2125%  acc_test_error 50.0%\n",
      "Epoch: 1130 Loss: 15.816190719604492  acc_train_error 41.2%  acc_test_error 50.0%\n",
      "Epoch: 1131 Loss: 15.805258750915527  acc_train_error 41.1875%  acc_test_error 50.0%\n",
      "Epoch: 1132 Loss: 15.793657302856445  acc_train_error 41.175%  acc_test_error 50.0%\n",
      "Epoch: 1133 Loss: 15.782248497009277  acc_train_error 41.175%  acc_test_error 50.0%\n",
      "Epoch: 1134 Loss: 15.771031379699707  acc_train_error 41.1625%  acc_test_error 50.0%\n",
      "Epoch: 1135 Loss: 15.759242057800293  acc_train_error 41.15%  acc_test_error 50.0%\n",
      "Epoch: 1136 Loss: 15.747003555297852  acc_train_error 41.125%  acc_test_error 50.0%\n",
      "Epoch: 1137 Loss: 15.733819007873535  acc_train_error 41.1125%  acc_test_error 50.0%\n",
      "Epoch: 1138 Loss: 15.720547676086426  acc_train_error 41.1125%  acc_test_error 50.0%\n",
      "Epoch: 1139 Loss: 15.707711219787598  acc_train_error 41.1%  acc_test_error 50.0%\n",
      "Epoch: 1140 Loss: 15.695034980773926  acc_train_error 41.0875%  acc_test_error 50.0%\n",
      "Epoch: 1141 Loss: 15.682574272155762  acc_train_error 41.075%  acc_test_error 50.0%\n",
      "Epoch: 1142 Loss: 15.67076301574707  acc_train_error 41.0625%  acc_test_error 50.0%\n",
      "Epoch: 1143 Loss: 15.659225463867188  acc_train_error 41.0625%  acc_test_error 50.0%\n",
      "Epoch: 1144 Loss: 15.6478271484375  acc_train_error 41.05%  acc_test_error 50.0%\n",
      "Epoch: 1145 Loss: 15.636415481567383  acc_train_error 41.0375%  acc_test_error 50.0%\n",
      "Epoch: 1146 Loss: 15.625061988830566  acc_train_error 41.025%  acc_test_error 50.0%\n",
      "Epoch: 1147 Loss: 15.613749504089355  acc_train_error 41.0125%  acc_test_error 50.0%\n",
      "Epoch: 1148 Loss: 15.602315902709961  acc_train_error 41.0125%  acc_test_error 50.0%\n",
      "Epoch: 1149 Loss: 15.590861320495605  acc_train_error 41.0%  acc_test_error 50.0%\n",
      "Epoch: 1150 Loss: 15.579508781433105  acc_train_error 40.9875%  acc_test_error 50.0%\n",
      "Epoch: 1151 Loss: 15.568384170532227  acc_train_error 40.975%  acc_test_error 50.0%\n",
      "Epoch: 1152 Loss: 15.557541847229004  acc_train_error 40.975%  acc_test_error 50.0%\n",
      "Epoch: 1153 Loss: 15.546727180480957  acc_train_error 40.9625%  acc_test_error 50.0%\n",
      "Epoch: 1154 Loss: 15.535578727722168  acc_train_error 40.9375%  acc_test_error 50.0%\n",
      "Epoch: 1155 Loss: 15.524282455444336  acc_train_error 40.925%  acc_test_error 50.0%\n",
      "Epoch: 1156 Loss: 15.51321029663086  acc_train_error 40.9125%  acc_test_error 50.0%\n",
      "Epoch: 1157 Loss: 15.50243854522705  acc_train_error 40.9125%  acc_test_error 50.0%\n",
      "Epoch: 1158 Loss: 15.491576194763184  acc_train_error 40.9%  acc_test_error 50.0%\n",
      "Epoch: 1159 Loss: 15.480656623840332  acc_train_error 40.8875%  acc_test_error 50.0%\n",
      "Epoch: 1160 Loss: 15.469931602478027  acc_train_error 40.875%  acc_test_error 50.0%\n",
      "Epoch: 1161 Loss: 15.459366798400879  acc_train_error 40.875%  acc_test_error 50.0%\n",
      "Epoch: 1162 Loss: 15.448904991149902  acc_train_error 40.8625%  acc_test_error 50.0%\n",
      "Epoch: 1163 Loss: 15.438526153564453  acc_train_error 40.85%  acc_test_error 50.0%\n",
      "Epoch: 1164 Loss: 15.428193092346191  acc_train_error 40.8375%  acc_test_error 50.0%\n",
      "Epoch: 1165 Loss: 15.417799949645996  acc_train_error 40.825%  acc_test_error 50.0%\n",
      "Epoch: 1166 Loss: 15.407400131225586  acc_train_error 40.8125%  acc_test_error 50.0%\n",
      "Epoch: 1167 Loss: 15.396818161010742  acc_train_error 40.8125%  acc_test_error 50.0%\n",
      "Epoch: 1168 Loss: 15.38595962524414  acc_train_error 40.8%  acc_test_error 50.0%\n",
      "Epoch: 1169 Loss: 15.375181198120117  acc_train_error 40.7875%  acc_test_error 50.0%\n",
      "Epoch: 1170 Loss: 15.364479064941406  acc_train_error 40.775%  acc_test_error 50.0%\n",
      "Epoch: 1171 Loss: 15.353907585144043  acc_train_error 40.7625%  acc_test_error 50.0%\n",
      "Epoch: 1172 Loss: 15.343388557434082  acc_train_error 40.75%  acc_test_error 50.0%\n",
      "Epoch: 1173 Loss: 15.332634925842285  acc_train_error 40.7375%  acc_test_error 50.0%\n",
      "Epoch: 1174 Loss: 15.321887969970703  acc_train_error 40.725%  acc_test_error 50.0%\n",
      "Epoch: 1175 Loss: 15.311086654663086  acc_train_error 40.7125%  acc_test_error 50.0%\n",
      "Epoch: 1176 Loss: 15.30016803741455  acc_train_error 40.7%  acc_test_error 50.0%\n",
      "Epoch: 1177 Loss: 15.289424896240234  acc_train_error 40.7%  acc_test_error 50.0%\n",
      "Epoch: 1178 Loss: 15.278793334960938  acc_train_error 40.6875%  acc_test_error 50.0%\n",
      "Epoch: 1179 Loss: 15.268155097961426  acc_train_error 40.675%  acc_test_error 50.0%\n",
      "Epoch: 1180 Loss: 15.257378578186035  acc_train_error 40.6625%  acc_test_error 50.0%\n",
      "Epoch: 1181 Loss: 15.24664306640625  acc_train_error 40.65%  acc_test_error 50.0%\n",
      "Epoch: 1182 Loss: 15.236002922058105  acc_train_error 40.6375%  acc_test_error 50.0%\n",
      "Epoch: 1183 Loss: 15.225492477416992  acc_train_error 40.625%  acc_test_error 50.0%\n",
      "Epoch: 1184 Loss: 15.215075492858887  acc_train_error 40.6125%  acc_test_error 50.0%\n",
      "Epoch: 1185 Loss: 15.20435905456543  acc_train_error 40.6%  acc_test_error 50.0%\n",
      "Epoch: 1186 Loss: 15.193306922912598  acc_train_error 40.5875%  acc_test_error 50.0%\n",
      "Epoch: 1187 Loss: 15.181866645812988  acc_train_error 40.575%  acc_test_error 50.0%\n",
      "Epoch: 1188 Loss: 15.17053508758545  acc_train_error 40.5625%  acc_test_error 50.0%\n",
      "Epoch: 1189 Loss: 15.15885066986084  acc_train_error 40.55%  acc_test_error 50.0%\n",
      "Epoch: 1190 Loss: 15.147218704223633  acc_train_error 40.5375%  acc_test_error 50.0%\n",
      "Epoch: 1191 Loss: 15.135787963867188  acc_train_error 40.525%  acc_test_error 50.0%\n",
      "Epoch: 1192 Loss: 15.123927116394043  acc_train_error 40.5125%  acc_test_error 50.0%\n",
      "Epoch: 1193 Loss: 15.112326622009277  acc_train_error 40.5%  acc_test_error 50.0%\n",
      "Epoch: 1194 Loss: 15.10078239440918  acc_train_error 40.4875%  acc_test_error 50.0%\n",
      "Epoch: 1195 Loss: 15.089247703552246  acc_train_error 40.475%  acc_test_error 50.0%\n",
      "Epoch: 1196 Loss: 15.077649116516113  acc_train_error 40.4625%  acc_test_error 50.0%\n",
      "Epoch: 1197 Loss: 15.066424369812012  acc_train_error 40.45%  acc_test_error 50.0%\n",
      "Epoch: 1198 Loss: 15.05563735961914  acc_train_error 40.4375%  acc_test_error 50.0%\n",
      "Epoch: 1199 Loss: 15.04509162902832  acc_train_error 40.425%  acc_test_error 50.0%\n",
      "Epoch: 1200 Loss: 15.034687995910645  acc_train_error 40.4125%  acc_test_error 50.0%\n",
      "Epoch: 1201 Loss: 15.024382591247559  acc_train_error 40.4%  acc_test_error 50.0%\n",
      "Epoch: 1202 Loss: 15.014053344726562  acc_train_error 40.3875%  acc_test_error 50.0%\n",
      "Epoch: 1203 Loss: 15.003752708435059  acc_train_error 40.375%  acc_test_error 50.0%\n",
      "Epoch: 1204 Loss: 14.993517875671387  acc_train_error 40.3625%  acc_test_error 50.0%\n",
      "Epoch: 1205 Loss: 14.98332405090332  acc_train_error 40.35%  acc_test_error 50.0%\n",
      "Epoch: 1206 Loss: 14.973149299621582  acc_train_error 40.3375%  acc_test_error 50.0%\n",
      "Epoch: 1207 Loss: 14.963011741638184  acc_train_error 40.325%  acc_test_error 50.0%\n",
      "Epoch: 1208 Loss: 14.952787399291992  acc_train_error 40.3125%  acc_test_error 50.0%\n",
      "Epoch: 1209 Loss: 14.942464828491211  acc_train_error 40.2875%  acc_test_error 50.0%\n",
      "Epoch: 1210 Loss: 14.932037353515625  acc_train_error 40.275%  acc_test_error 50.0%\n",
      "Epoch: 1211 Loss: 14.921455383300781  acc_train_error 40.2625%  acc_test_error 50.0%\n",
      "Epoch: 1212 Loss: 14.910985946655273  acc_train_error 40.2375%  acc_test_error 50.0%\n",
      "Epoch: 1213 Loss: 14.900561332702637  acc_train_error 40.2125%  acc_test_error 50.0%\n",
      "Epoch: 1214 Loss: 14.889904975891113  acc_train_error 40.2%  acc_test_error 50.0%\n",
      "Epoch: 1215 Loss: 14.879085540771484  acc_train_error 40.1875%  acc_test_error 50.0%\n",
      "Epoch: 1216 Loss: 14.868453025817871  acc_train_error 40.1625%  acc_test_error 50.0%\n",
      "Epoch: 1217 Loss: 14.857945442199707  acc_train_error 40.15%  acc_test_error 50.0%\n",
      "Epoch: 1218 Loss: 14.84754753112793  acc_train_error 40.1375%  acc_test_error 50.0%\n",
      "Epoch: 1219 Loss: 14.837242126464844  acc_train_error 40.1125%  acc_test_error 50.0%\n",
      "Epoch: 1220 Loss: 14.826951026916504  acc_train_error 40.1%  acc_test_error 50.0%\n",
      "Epoch: 1221 Loss: 14.816679954528809  acc_train_error 40.0875%  acc_test_error 50.0%\n",
      "Epoch: 1222 Loss: 14.806452751159668  acc_train_error 40.0625%  acc_test_error 50.0%\n",
      "Epoch: 1223 Loss: 14.796317100524902  acc_train_error 40.0375%  acc_test_error 50.0%\n",
      "Epoch: 1224 Loss: 14.786199569702148  acc_train_error 40.025%  acc_test_error 50.0%\n",
      "Epoch: 1225 Loss: 14.776097297668457  acc_train_error 40.0125%  acc_test_error 50.0%\n",
      "Epoch: 1226 Loss: 14.766047477722168  acc_train_error 39.9875%  acc_test_error 50.0%\n",
      "Epoch: 1227 Loss: 14.75601577758789  acc_train_error 39.975%  acc_test_error 50.0%\n",
      "Epoch: 1228 Loss: 14.745953559875488  acc_train_error 39.9625%  acc_test_error 50.0%\n",
      "Epoch: 1229 Loss: 14.73569107055664  acc_train_error 39.9375%  acc_test_error 50.0%\n",
      "Epoch: 1230 Loss: 14.725442886352539  acc_train_error 39.9125%  acc_test_error 50.0%\n",
      "Epoch: 1231 Loss: 14.715243339538574  acc_train_error 39.9%  acc_test_error 50.0%\n",
      "Epoch: 1232 Loss: 14.705036163330078  acc_train_error 39.875%  acc_test_error 50.0%\n",
      "Epoch: 1233 Loss: 14.694945335388184  acc_train_error 39.8625%  acc_test_error 50.0%\n",
      "Epoch: 1234 Loss: 14.684892654418945  acc_train_error 39.85%  acc_test_error 50.0%\n",
      "Epoch: 1235 Loss: 14.67487621307373  acc_train_error 39.825%  acc_test_error 50.0%\n",
      "Epoch: 1236 Loss: 14.664849281311035  acc_train_error 39.8%  acc_test_error 50.0%\n",
      "Epoch: 1237 Loss: 14.654810905456543  acc_train_error 39.775%  acc_test_error 50.0%\n",
      "Epoch: 1238 Loss: 14.644612312316895  acc_train_error 39.7625%  acc_test_error 50.0%\n",
      "Epoch: 1239 Loss: 14.634193420410156  acc_train_error 39.75%  acc_test_error 50.0%\n",
      "Epoch: 1240 Loss: 14.623645782470703  acc_train_error 39.725%  acc_test_error 50.0%\n",
      "Epoch: 1241 Loss: 14.612740516662598  acc_train_error 39.7125%  acc_test_error 50.0%\n",
      "Epoch: 1242 Loss: 14.601216316223145  acc_train_error 39.7%  acc_test_error 50.0%\n",
      "Epoch: 1243 Loss: 14.58984088897705  acc_train_error 39.675%  acc_test_error 50.0%\n",
      "Epoch: 1244 Loss: 14.578511238098145  acc_train_error 39.6625%  acc_test_error 50.0%\n",
      "Epoch: 1245 Loss: 14.567201614379883  acc_train_error 39.65%  acc_test_error 50.0%\n",
      "Epoch: 1246 Loss: 14.556105613708496  acc_train_error 39.6375%  acc_test_error 50.0%\n",
      "Epoch: 1247 Loss: 14.54489517211914  acc_train_error 39.625%  acc_test_error 50.0%\n",
      "Epoch: 1248 Loss: 14.53298568725586  acc_train_error 39.625%  acc_test_error 50.0%\n",
      "Epoch: 1249 Loss: 14.52029800415039  acc_train_error 39.6125%  acc_test_error 50.0%\n",
      "Epoch: 1250 Loss: 14.507818222045898  acc_train_error 39.5875%  acc_test_error 50.0%\n",
      "Epoch: 1251 Loss: 14.495620727539062  acc_train_error 39.575%  acc_test_error 50.0%\n",
      "Epoch: 1252 Loss: 14.48367977142334  acc_train_error 39.5625%  acc_test_error 50.0%\n",
      "Epoch: 1253 Loss: 14.4720458984375  acc_train_error 39.55%  acc_test_error 50.0%\n",
      "Epoch: 1254 Loss: 14.460328102111816  acc_train_error 39.5375%  acc_test_error 50.0%\n",
      "Epoch: 1255 Loss: 14.448627471923828  acc_train_error 39.525%  acc_test_error 50.0%\n",
      "Epoch: 1256 Loss: 14.437324523925781  acc_train_error 39.5%  acc_test_error 50.0%\n",
      "Epoch: 1257 Loss: 14.426440238952637  acc_train_error 39.4875%  acc_test_error 50.0%\n",
      "Epoch: 1258 Loss: 14.415732383728027  acc_train_error 39.475%  acc_test_error 50.0%\n",
      "Epoch: 1259 Loss: 14.404972076416016  acc_train_error 39.4875%  acc_test_error 50.0%\n",
      "Epoch: 1260 Loss: 14.39445686340332  acc_train_error 39.475%  acc_test_error 50.0%\n",
      "Epoch: 1261 Loss: 14.383918762207031  acc_train_error 39.4625%  acc_test_error 50.0%\n",
      "Epoch: 1262 Loss: 14.373292922973633  acc_train_error 39.45%  acc_test_error 50.0%\n",
      "Epoch: 1263 Loss: 14.362783432006836  acc_train_error 39.425%  acc_test_error 50.0%\n",
      "Epoch: 1264 Loss: 14.352293014526367  acc_train_error 39.425%  acc_test_error 50.0%\n",
      "Epoch: 1265 Loss: 14.342050552368164  acc_train_error 39.4125%  acc_test_error 50.0%\n",
      "Epoch: 1266 Loss: 14.331731796264648  acc_train_error 39.4%  acc_test_error 50.0%\n",
      "Epoch: 1267 Loss: 14.321239471435547  acc_train_error 39.3875%  acc_test_error 50.0%\n",
      "Epoch: 1268 Loss: 14.310805320739746  acc_train_error 39.3875%  acc_test_error 50.0%\n",
      "Epoch: 1269 Loss: 14.299891471862793  acc_train_error 39.375%  acc_test_error 50.0%\n",
      "Epoch: 1270 Loss: 14.288026809692383  acc_train_error 39.3625%  acc_test_error 50.0%\n",
      "Epoch: 1271 Loss: 14.276102066040039  acc_train_error 39.3625%  acc_test_error 50.0%\n",
      "Epoch: 1272 Loss: 14.264257431030273  acc_train_error 39.35%  acc_test_error 50.0%\n",
      "Epoch: 1273 Loss: 14.25239372253418  acc_train_error 39.3375%  acc_test_error 50.0%\n",
      "Epoch: 1274 Loss: 14.240673065185547  acc_train_error 39.325%  acc_test_error 50.0%\n",
      "Epoch: 1275 Loss: 14.22959041595459  acc_train_error 39.325%  acc_test_error 50.0%\n",
      "Epoch: 1276 Loss: 14.218574523925781  acc_train_error 39.3125%  acc_test_error 50.0%\n",
      "Epoch: 1277 Loss: 14.206818580627441  acc_train_error 39.3%  acc_test_error 50.0%\n",
      "Epoch: 1278 Loss: 14.195401191711426  acc_train_error 39.3%  acc_test_error 50.0%\n",
      "Epoch: 1279 Loss: 14.184253692626953  acc_train_error 39.2875%  acc_test_error 50.0%\n",
      "Epoch: 1280 Loss: 14.17334270477295  acc_train_error 39.275%  acc_test_error 50.0%\n",
      "Epoch: 1281 Loss: 14.161971092224121  acc_train_error 39.2625%  acc_test_error 50.0%\n",
      "Epoch: 1282 Loss: 14.149977684020996  acc_train_error 39.275%  acc_test_error 50.0%\n",
      "Epoch: 1283 Loss: 14.138359069824219  acc_train_error 39.2625%  acc_test_error 50.0%\n",
      "Epoch: 1284 Loss: 14.12716007232666  acc_train_error 39.25%  acc_test_error 50.0%\n",
      "Epoch: 1285 Loss: 14.116327285766602  acc_train_error 39.2375%  acc_test_error 50.0%\n",
      "Epoch: 1286 Loss: 14.10588264465332  acc_train_error 39.2375%  acc_test_error 50.0%\n",
      "Epoch: 1287 Loss: 14.095620155334473  acc_train_error 39.225%  acc_test_error 50.0%\n",
      "Epoch: 1288 Loss: 14.085421562194824  acc_train_error 39.2125%  acc_test_error 50.0%\n",
      "Epoch: 1289 Loss: 14.075308799743652  acc_train_error 39.2125%  acc_test_error 50.0%\n",
      "Epoch: 1290 Loss: 14.065274238586426  acc_train_error 39.2%  acc_test_error 50.0%\n",
      "Epoch: 1291 Loss: 14.055407524108887  acc_train_error 39.1875%  acc_test_error 50.0%\n",
      "Epoch: 1292 Loss: 14.045632362365723  acc_train_error 39.1875%  acc_test_error 50.0%\n",
      "Epoch: 1293 Loss: 14.035953521728516  acc_train_error 39.175%  acc_test_error 50.0%\n",
      "Epoch: 1294 Loss: 14.02641487121582  acc_train_error 39.1625%  acc_test_error 50.0%\n",
      "Epoch: 1295 Loss: 14.01683235168457  acc_train_error 39.15%  acc_test_error 50.0%\n",
      "Epoch: 1296 Loss: 14.007086753845215  acc_train_error 39.1375%  acc_test_error 50.0%\n",
      "Epoch: 1297 Loss: 13.997312545776367  acc_train_error 39.1375%  acc_test_error 50.0%\n",
      "Epoch: 1298 Loss: 13.987363815307617  acc_train_error 39.125%  acc_test_error 50.0%\n",
      "Epoch: 1299 Loss: 13.977084159851074  acc_train_error 39.1125%  acc_test_error 50.0%\n",
      "Epoch: 1300 Loss: 13.967008590698242  acc_train_error 39.1%  acc_test_error 50.0%\n",
      "Epoch: 1301 Loss: 13.95720386505127  acc_train_error 39.0875%  acc_test_error 50.0%\n",
      "Epoch: 1302 Loss: 13.947545051574707  acc_train_error 39.075%  acc_test_error 50.0%\n",
      "Epoch: 1303 Loss: 13.938029289245605  acc_train_error 39.075%  acc_test_error 50.0%\n",
      "Epoch: 1304 Loss: 13.92863655090332  acc_train_error 39.0625%  acc_test_error 50.0%\n",
      "Epoch: 1305 Loss: 13.919291496276855  acc_train_error 39.05%  acc_test_error 50.0%\n",
      "Epoch: 1306 Loss: 13.909939765930176  acc_train_error 39.0375%  acc_test_error 50.0%\n",
      "Epoch: 1307 Loss: 13.900712966918945  acc_train_error 39.0375%  acc_test_error 50.0%\n",
      "Epoch: 1308 Loss: 13.89132022857666  acc_train_error 39.025%  acc_test_error 50.0%\n",
      "Epoch: 1309 Loss: 13.881629943847656  acc_train_error 39.0125%  acc_test_error 50.0%\n",
      "Epoch: 1310 Loss: 13.871476173400879  acc_train_error 39.0%  acc_test_error 50.0%\n",
      "Epoch: 1311 Loss: 13.86059284210205  acc_train_error 38.9875%  acc_test_error 50.0%\n",
      "Epoch: 1312 Loss: 13.849319458007812  acc_train_error 38.975%  acc_test_error 50.0%\n",
      "Epoch: 1313 Loss: 13.838468551635742  acc_train_error 38.9625%  acc_test_error 50.0%\n",
      "Epoch: 1314 Loss: 13.828046798706055  acc_train_error 38.9625%  acc_test_error 50.0%\n",
      "Epoch: 1315 Loss: 13.81749439239502  acc_train_error 38.95%  acc_test_error 50.0%\n",
      "Epoch: 1316 Loss: 13.80688190460205  acc_train_error 38.9375%  acc_test_error 50.0%\n",
      "Epoch: 1317 Loss: 13.796253204345703  acc_train_error 38.8375%  acc_test_error 50.4375%\n",
      "Epoch: 1318 Loss: 13.78514289855957  acc_train_error 38.4875%  acc_test_error 52.125%\n",
      "Epoch: 1319 Loss: 13.7741060256958  acc_train_error 38.375%  acc_test_error 52.5625%\n",
      "Epoch: 1320 Loss: 13.763516426086426  acc_train_error 38.2375%  acc_test_error 53.1875%\n",
      "Epoch: 1321 Loss: 13.752626419067383  acc_train_error 38.175%  acc_test_error 53.4375%\n",
      "Epoch: 1322 Loss: 13.741744041442871  acc_train_error 38.1375%  acc_test_error 53.5625%\n",
      "Epoch: 1323 Loss: 13.731245994567871  acc_train_error 38.1%  acc_test_error 53.6875%\n",
      "Epoch: 1324 Loss: 13.720417022705078  acc_train_error 38.075%  acc_test_error 53.8125%\n",
      "Epoch: 1325 Loss: 13.708723068237305  acc_train_error 38.0375%  acc_test_error 53.9375%\n",
      "Epoch: 1326 Loss: 13.697021484375  acc_train_error 38.0125%  acc_test_error 54.0%\n",
      "Epoch: 1327 Loss: 13.685876846313477  acc_train_error 38.0%  acc_test_error 54.0%\n",
      "Epoch: 1328 Loss: 13.675241470336914  acc_train_error 37.9875%  acc_test_error 54.0625%\n",
      "Epoch: 1329 Loss: 13.664947509765625  acc_train_error 37.9625%  acc_test_error 54.125%\n",
      "Epoch: 1330 Loss: 13.654891014099121  acc_train_error 37.9375%  acc_test_error 54.1875%\n",
      "Epoch: 1331 Loss: 13.644790649414062  acc_train_error 37.9375%  acc_test_error 54.1875%\n",
      "Epoch: 1332 Loss: 13.634774208068848  acc_train_error 37.9%  acc_test_error 54.3125%\n",
      "Epoch: 1333 Loss: 13.624994277954102  acc_train_error 37.875%  acc_test_error 54.375%\n",
      "Epoch: 1334 Loss: 13.615367889404297  acc_train_error 37.85%  acc_test_error 54.4375%\n",
      "Epoch: 1335 Loss: 13.605810165405273  acc_train_error 37.8375%  acc_test_error 54.5%\n",
      "Epoch: 1336 Loss: 13.596404075622559  acc_train_error 37.825%  acc_test_error 54.5%\n",
      "Epoch: 1337 Loss: 13.587106704711914  acc_train_error 37.8125%  acc_test_error 54.5625%\n",
      "Epoch: 1338 Loss: 13.577573776245117  acc_train_error 37.7625%  acc_test_error 54.75%\n",
      "Epoch: 1339 Loss: 13.567977905273438  acc_train_error 37.75%  acc_test_error 54.8125%\n",
      "Epoch: 1340 Loss: 13.558503150939941  acc_train_error 37.725%  acc_test_error 54.875%\n",
      "Epoch: 1341 Loss: 13.54906940460205  acc_train_error 37.6875%  acc_test_error 55.0625%\n",
      "Epoch: 1342 Loss: 13.539514541625977  acc_train_error 37.6625%  acc_test_error 55.125%\n",
      "Epoch: 1343 Loss: 13.530096054077148  acc_train_error 37.6375%  acc_test_error 55.25%\n",
      "Epoch: 1344 Loss: 13.52082633972168  acc_train_error 37.6%  acc_test_error 55.375%\n",
      "Epoch: 1345 Loss: 13.511589050292969  acc_train_error 37.5875%  acc_test_error 55.4375%\n",
      "Epoch: 1346 Loss: 13.502386093139648  acc_train_error 37.55%  acc_test_error 55.5625%\n",
      "Epoch: 1347 Loss: 13.493167877197266  acc_train_error 37.5375%  acc_test_error 55.625%\n",
      "Epoch: 1348 Loss: 13.484055519104004  acc_train_error 37.5125%  acc_test_error 55.6875%\n",
      "Epoch: 1349 Loss: 13.475029945373535  acc_train_error 37.475%  acc_test_error 55.8125%\n",
      "Epoch: 1350 Loss: 13.46608829498291  acc_train_error 37.45%  acc_test_error 55.875%\n",
      "Epoch: 1351 Loss: 13.457113265991211  acc_train_error 37.425%  acc_test_error 56.0%\n",
      "Epoch: 1352 Loss: 13.44795036315918  acc_train_error 37.375%  acc_test_error 56.1875%\n",
      "Epoch: 1353 Loss: 13.438844680786133  acc_train_error 37.3375%  acc_test_error 56.375%\n",
      "Epoch: 1354 Loss: 13.429817199707031  acc_train_error 37.3125%  acc_test_error 56.4375%\n",
      "Epoch: 1355 Loss: 13.420614242553711  acc_train_error 37.2625%  acc_test_error 56.6875%\n",
      "Epoch: 1356 Loss: 13.411417007446289  acc_train_error 37.2125%  acc_test_error 56.875%\n",
      "Epoch: 1357 Loss: 13.402106285095215  acc_train_error 37.1375%  acc_test_error 57.125%\n",
      "Epoch: 1358 Loss: 13.392699241638184  acc_train_error 37.1%  acc_test_error 57.1875%\n",
      "Epoch: 1359 Loss: 13.383403778076172  acc_train_error 37.0375%  acc_test_error 57.25%\n",
      "Epoch: 1360 Loss: 13.374018669128418  acc_train_error 36.9625%  acc_test_error 57.375%\n",
      "Epoch: 1361 Loss: 13.364458084106445  acc_train_error 36.925%  acc_test_error 57.4375%\n",
      "Epoch: 1362 Loss: 13.355032920837402  acc_train_error 36.85%  acc_test_error 57.5625%\n",
      "Epoch: 1363 Loss: 13.345741271972656  acc_train_error 36.7625%  acc_test_error 57.6875%\n",
      "Epoch: 1364 Loss: 13.336502075195312  acc_train_error 36.7125%  acc_test_error 57.75%\n",
      "Epoch: 1365 Loss: 13.327332496643066  acc_train_error 36.6375%  acc_test_error 57.8125%\n",
      "Epoch: 1366 Loss: 13.318284034729004  acc_train_error 36.55%  acc_test_error 57.875%\n",
      "Epoch: 1367 Loss: 13.309297561645508  acc_train_error 36.4375%  acc_test_error 58.0%\n",
      "Epoch: 1368 Loss: 13.300225257873535  acc_train_error 36.3625%  acc_test_error 58.0625%\n",
      "Epoch: 1369 Loss: 13.291106224060059  acc_train_error 36.2625%  acc_test_error 58.125%\n",
      "Epoch: 1370 Loss: 13.281645774841309  acc_train_error 36.175%  acc_test_error 58.1875%\n",
      "Epoch: 1371 Loss: 13.27228832244873  acc_train_error 36.1%  acc_test_error 58.25%\n",
      "Epoch: 1372 Loss: 13.263014793395996  acc_train_error 36.025%  acc_test_error 58.3125%\n",
      "Epoch: 1373 Loss: 13.253809928894043  acc_train_error 35.95%  acc_test_error 58.3125%\n",
      "Epoch: 1374 Loss: 13.244722366333008  acc_train_error 35.9%  acc_test_error 58.3125%\n",
      "Epoch: 1375 Loss: 13.235688209533691  acc_train_error 35.825%  acc_test_error 58.375%\n",
      "Epoch: 1376 Loss: 13.22622299194336  acc_train_error 35.7125%  acc_test_error 58.375%\n",
      "Epoch: 1377 Loss: 13.216843605041504  acc_train_error 35.5875%  acc_test_error 58.4375%\n",
      "Epoch: 1378 Loss: 13.207597732543945  acc_train_error 35.5%  acc_test_error 58.4375%\n",
      "Epoch: 1379 Loss: 13.198404312133789  acc_train_error 35.35%  acc_test_error 58.4375%\n",
      "Epoch: 1380 Loss: 13.189262390136719  acc_train_error 35.2%  acc_test_error 58.5%\n",
      "Epoch: 1381 Loss: 13.180212020874023  acc_train_error 35.075%  acc_test_error 58.5%\n",
      "Epoch: 1382 Loss: 13.171211242675781  acc_train_error 34.9625%  acc_test_error 58.5%\n",
      "Epoch: 1383 Loss: 13.162247657775879  acc_train_error 34.8625%  acc_test_error 58.5625%\n",
      "Epoch: 1384 Loss: 13.153327941894531  acc_train_error 34.775%  acc_test_error 58.5625%\n",
      "Epoch: 1385 Loss: 13.144485473632812  acc_train_error 34.725%  acc_test_error 58.5625%\n",
      "Epoch: 1386 Loss: 13.135674476623535  acc_train_error 34.7%  acc_test_error 58.5625%\n",
      "Epoch: 1387 Loss: 13.126897811889648  acc_train_error 34.65%  acc_test_error 58.5625%\n",
      "Epoch: 1388 Loss: 13.118125915527344  acc_train_error 34.625%  acc_test_error 58.5625%\n",
      "Epoch: 1389 Loss: 13.109383583068848  acc_train_error 34.5875%  acc_test_error 58.5625%\n",
      "Epoch: 1390 Loss: 13.100676536560059  acc_train_error 34.55%  acc_test_error 58.5625%\n",
      "Epoch: 1391 Loss: 13.092008590698242  acc_train_error 34.5125%  acc_test_error 58.5625%\n",
      "Epoch: 1392 Loss: 13.083373069763184  acc_train_error 34.4875%  acc_test_error 58.5625%\n",
      "Epoch: 1393 Loss: 13.07477855682373  acc_train_error 34.475%  acc_test_error 58.5%\n",
      "Epoch: 1394 Loss: 13.066202163696289  acc_train_error 34.45%  acc_test_error 58.5%\n",
      "Epoch: 1395 Loss: 13.057629585266113  acc_train_error 34.4125%  acc_test_error 58.5%\n",
      "Epoch: 1396 Loss: 13.049010276794434  acc_train_error 34.3875%  acc_test_error 58.5%\n",
      "Epoch: 1397 Loss: 13.0401611328125  acc_train_error 34.35%  acc_test_error 58.5%\n",
      "Epoch: 1398 Loss: 13.031373023986816  acc_train_error 34.325%  acc_test_error 58.5%\n",
      "Epoch: 1399 Loss: 13.022638320922852  acc_train_error 34.3%  acc_test_error 58.5%\n",
      "Epoch: 1400 Loss: 13.013951301574707  acc_train_error 34.2625%  acc_test_error 58.5%\n",
      "Epoch: 1401 Loss: 13.005304336547852  acc_train_error 34.225%  acc_test_error 58.5%\n",
      "Epoch: 1402 Loss: 12.996692657470703  acc_train_error 34.2%  acc_test_error 58.5%\n",
      "Epoch: 1403 Loss: 12.987872123718262  acc_train_error 34.1625%  acc_test_error 58.5%\n",
      "Epoch: 1404 Loss: 12.978870391845703  acc_train_error 34.125%  acc_test_error 58.5%\n",
      "Epoch: 1405 Loss: 12.969953536987305  acc_train_error 34.0875%  acc_test_error 58.5%\n",
      "Epoch: 1406 Loss: 12.961065292358398  acc_train_error 34.075%  acc_test_error 58.4375%\n",
      "Epoch: 1407 Loss: 12.952227592468262  acc_train_error 34.05%  acc_test_error 58.4375%\n",
      "Epoch: 1408 Loss: 12.943474769592285  acc_train_error 34.025%  acc_test_error 58.4375%\n",
      "Epoch: 1409 Loss: 12.934774398803711  acc_train_error 34.0%  acc_test_error 58.375%\n",
      "Epoch: 1410 Loss: 12.926094055175781  acc_train_error 33.975%  acc_test_error 58.375%\n",
      "Epoch: 1411 Loss: 12.917463302612305  acc_train_error 33.95%  acc_test_error 58.375%\n",
      "Epoch: 1412 Loss: 12.90888786315918  acc_train_error 33.9375%  acc_test_error 58.3125%\n",
      "Epoch: 1413 Loss: 12.900367736816406  acc_train_error 33.925%  acc_test_error 58.25%\n",
      "Epoch: 1414 Loss: 12.891875267028809  acc_train_error 33.9%  acc_test_error 58.25%\n",
      "Epoch: 1415 Loss: 12.883320808410645  acc_train_error 33.875%  acc_test_error 58.25%\n",
      "Epoch: 1416 Loss: 12.87467098236084  acc_train_error 33.85%  acc_test_error 58.1875%\n",
      "Epoch: 1417 Loss: 12.866043090820312  acc_train_error 33.825%  acc_test_error 58.1875%\n",
      "Epoch: 1418 Loss: 12.857465744018555  acc_train_error 33.8125%  acc_test_error 58.125%\n",
      "Epoch: 1419 Loss: 12.848925590515137  acc_train_error 33.7625%  acc_test_error 58.125%\n",
      "Epoch: 1420 Loss: 12.840441703796387  acc_train_error 33.75%  acc_test_error 58.0625%\n",
      "Epoch: 1421 Loss: 12.831987380981445  acc_train_error 33.725%  acc_test_error 58.0625%\n",
      "Epoch: 1422 Loss: 12.823562622070312  acc_train_error 33.7125%  acc_test_error 58.0%\n",
      "Epoch: 1423 Loss: 12.815186500549316  acc_train_error 33.7%  acc_test_error 58.0%\n",
      "Epoch: 1424 Loss: 12.806818962097168  acc_train_error 33.6875%  acc_test_error 57.9375%\n",
      "Epoch: 1425 Loss: 12.79849624633789  acc_train_error 33.6625%  acc_test_error 57.9375%\n",
      "Epoch: 1426 Loss: 12.790180206298828  acc_train_error 33.65%  acc_test_error 57.875%\n",
      "Epoch: 1427 Loss: 12.781903266906738  acc_train_error 33.6375%  acc_test_error 57.875%\n",
      "Epoch: 1428 Loss: 12.77365779876709  acc_train_error 33.6125%  acc_test_error 57.8125%\n",
      "Epoch: 1429 Loss: 12.765413284301758  acc_train_error 33.6125%  acc_test_error 57.75%\n",
      "Epoch: 1430 Loss: 12.757197380065918  acc_train_error 33.6%  acc_test_error 57.75%\n",
      "Epoch: 1431 Loss: 12.749011039733887  acc_train_error 33.575%  acc_test_error 57.6875%\n",
      "Epoch: 1432 Loss: 12.74085807800293  acc_train_error 33.5625%  acc_test_error 57.6875%\n",
      "Epoch: 1433 Loss: 12.732723236083984  acc_train_error 33.55%  acc_test_error 57.625%\n",
      "Epoch: 1434 Loss: 12.724611282348633  acc_train_error 33.5375%  acc_test_error 57.5625%\n",
      "Epoch: 1435 Loss: 12.71639347076416  acc_train_error 33.5%  acc_test_error 57.5625%\n",
      "Epoch: 1436 Loss: 12.70820426940918  acc_train_error 33.5%  acc_test_error 57.5%\n",
      "Epoch: 1437 Loss: 12.700045585632324  acc_train_error 33.4625%  acc_test_error 57.5%\n",
      "Epoch: 1438 Loss: 12.691923141479492  acc_train_error 33.4625%  acc_test_error 57.4375%\n",
      "Epoch: 1439 Loss: 12.683839797973633  acc_train_error 33.4375%  acc_test_error 57.4375%\n",
      "Epoch: 1440 Loss: 12.675800323486328  acc_train_error 33.4125%  acc_test_error 57.375%\n",
      "Epoch: 1441 Loss: 12.667807579040527  acc_train_error 33.4%  acc_test_error 57.375%\n",
      "Epoch: 1442 Loss: 12.659852981567383  acc_train_error 33.4%  acc_test_error 57.3125%\n",
      "Epoch: 1443 Loss: 12.651930809020996  acc_train_error 33.3875%  acc_test_error 57.25%\n",
      "Epoch: 1444 Loss: 12.644037246704102  acc_train_error 33.3625%  acc_test_error 57.25%\n",
      "Epoch: 1445 Loss: 12.636137962341309  acc_train_error 33.3625%  acc_test_error 57.1875%\n",
      "Epoch: 1446 Loss: 12.628260612487793  acc_train_error 33.3375%  acc_test_error 57.1875%\n",
      "Epoch: 1447 Loss: 12.620408058166504  acc_train_error 33.3375%  acc_test_error 57.125%\n",
      "Epoch: 1448 Loss: 12.612581253051758  acc_train_error 33.3125%  acc_test_error 57.0625%\n",
      "Epoch: 1449 Loss: 12.604777336120605  acc_train_error 33.3125%  acc_test_error 57.0625%\n",
      "Epoch: 1450 Loss: 12.5969877243042  acc_train_error 33.3%  acc_test_error 57.0%\n",
      "Epoch: 1451 Loss: 12.589094161987305  acc_train_error 33.3%  acc_test_error 56.9375%\n",
      "Epoch: 1452 Loss: 12.5809326171875  acc_train_error 33.2625%  acc_test_error 56.9375%\n",
      "Epoch: 1453 Loss: 12.572798728942871  acc_train_error 33.275%  acc_test_error 56.875%\n",
      "Epoch: 1454 Loss: 12.56474781036377  acc_train_error 33.25%  acc_test_error 56.875%\n",
      "Epoch: 1455 Loss: 12.556750297546387  acc_train_error 33.25%  acc_test_error 56.8125%\n",
      "Epoch: 1456 Loss: 12.548835754394531  acc_train_error 33.225%  acc_test_error 56.8125%\n",
      "Epoch: 1457 Loss: 12.54096794128418  acc_train_error 33.225%  acc_test_error 56.75%\n",
      "Epoch: 1458 Loss: 12.533143997192383  acc_train_error 33.2%  acc_test_error 56.75%\n",
      "Epoch: 1459 Loss: 12.525318145751953  acc_train_error 33.2%  acc_test_error 56.6875%\n",
      "Epoch: 1460 Loss: 12.517520904541016  acc_train_error 33.175%  acc_test_error 56.6875%\n",
      "Epoch: 1461 Loss: 12.509765625  acc_train_error 33.175%  acc_test_error 56.625%\n",
      "Epoch: 1462 Loss: 12.502023696899414  acc_train_error 33.175%  acc_test_error 56.5625%\n",
      "Epoch: 1463 Loss: 12.494325637817383  acc_train_error 33.15%  acc_test_error 56.5625%\n",
      "Epoch: 1464 Loss: 12.486620903015137  acc_train_error 33.1375%  acc_test_error 56.5%\n",
      "Epoch: 1465 Loss: 12.47890853881836  acc_train_error 33.1125%  acc_test_error 56.5%\n",
      "Epoch: 1466 Loss: 12.471240997314453  acc_train_error 33.1125%  acc_test_error 56.4375%\n",
      "Epoch: 1467 Loss: 12.463571548461914  acc_train_error 33.0875%  acc_test_error 56.4375%\n",
      "Epoch: 1468 Loss: 12.455944061279297  acc_train_error 33.0875%  acc_test_error 56.375%\n",
      "Epoch: 1469 Loss: 12.448347091674805  acc_train_error 33.0625%  acc_test_error 56.375%\n",
      "Epoch: 1470 Loss: 12.440786361694336  acc_train_error 33.05%  acc_test_error 56.3125%\n",
      "Epoch: 1471 Loss: 12.433266639709473  acc_train_error 33.05%  acc_test_error 56.3125%\n",
      "Epoch: 1472 Loss: 12.425763130187988  acc_train_error 33.025%  acc_test_error 56.25%\n",
      "Epoch: 1473 Loss: 12.418288230895996  acc_train_error 33.0125%  acc_test_error 56.25%\n",
      "Epoch: 1474 Loss: 12.410821914672852  acc_train_error 33.0%  acc_test_error 56.1875%\n",
      "Epoch: 1475 Loss: 12.403360366821289  acc_train_error 32.9875%  acc_test_error 56.1875%\n",
      "Epoch: 1476 Loss: 12.3956298828125  acc_train_error 32.9625%  acc_test_error 56.125%\n",
      "Epoch: 1477 Loss: 12.387941360473633  acc_train_error 32.9375%  acc_test_error 56.125%\n",
      "Epoch: 1478 Loss: 12.380322456359863  acc_train_error 32.9125%  acc_test_error 56.125%\n",
      "Epoch: 1479 Loss: 12.37275505065918  acc_train_error 32.9%  acc_test_error 56.0625%\n",
      "Epoch: 1480 Loss: 12.365233421325684  acc_train_error 32.8875%  acc_test_error 56.0625%\n",
      "Epoch: 1481 Loss: 12.357782363891602  acc_train_error 32.8625%  acc_test_error 56.0625%\n",
      "Epoch: 1482 Loss: 12.35039234161377  acc_train_error 32.85%  acc_test_error 56.0%\n",
      "Epoch: 1483 Loss: 12.343038558959961  acc_train_error 32.825%  acc_test_error 56.0%\n",
      "Epoch: 1484 Loss: 12.335732460021973  acc_train_error 32.825%  acc_test_error 55.9375%\n",
      "Epoch: 1485 Loss: 12.328428268432617  acc_train_error 32.8%  acc_test_error 55.9375%\n",
      "Epoch: 1486 Loss: 12.321162223815918  acc_train_error 32.8%  acc_test_error 55.875%\n",
      "Epoch: 1487 Loss: 12.313921928405762  acc_train_error 32.775%  acc_test_error 55.875%\n",
      "Epoch: 1488 Loss: 12.3067045211792  acc_train_error 32.775%  acc_test_error 55.8125%\n",
      "Epoch: 1489 Loss: 12.299509048461914  acc_train_error 32.75%  acc_test_error 55.8125%\n",
      "Epoch: 1490 Loss: 12.292325973510742  acc_train_error 32.75%  acc_test_error 55.75%\n",
      "Epoch: 1491 Loss: 12.285158157348633  acc_train_error 32.725%  acc_test_error 55.75%\n",
      "Epoch: 1492 Loss: 12.278007507324219  acc_train_error 32.725%  acc_test_error 55.6875%\n",
      "Epoch: 1493 Loss: 12.27086353302002  acc_train_error 32.7125%  acc_test_error 55.6875%\n",
      "Epoch: 1494 Loss: 12.263751029968262  acc_train_error 32.7%  acc_test_error 55.625%\n",
      "Epoch: 1495 Loss: 12.256589889526367  acc_train_error 32.6875%  acc_test_error 55.625%\n",
      "Epoch: 1496 Loss: 12.249377250671387  acc_train_error 32.6625%  acc_test_error 55.5625%\n",
      "Epoch: 1497 Loss: 12.242180824279785  acc_train_error 32.65%  acc_test_error 55.5625%\n",
      "Epoch: 1498 Loss: 12.235011100769043  acc_train_error 32.625%  acc_test_error 55.5625%\n",
      "Epoch: 1499 Loss: 12.227867126464844  acc_train_error 32.625%  acc_test_error 55.5%\n",
      "Epoch: 1500 Loss: 12.220739364624023  acc_train_error 32.625%  acc_test_error 55.5%\n",
      "Epoch: 1501 Loss: 12.213593482971191  acc_train_error 32.6125%  acc_test_error 55.4375%\n",
      "Epoch: 1502 Loss: 12.206476211547852  acc_train_error 32.6%  acc_test_error 55.4375%\n",
      "Epoch: 1503 Loss: 12.19937801361084  acc_train_error 32.6%  acc_test_error 55.375%\n",
      "Epoch: 1504 Loss: 12.192300796508789  acc_train_error 32.575%  acc_test_error 55.375%\n",
      "Epoch: 1505 Loss: 12.185247421264648  acc_train_error 32.575%  acc_test_error 55.3125%\n",
      "Epoch: 1506 Loss: 12.178194999694824  acc_train_error 32.575%  acc_test_error 55.3125%\n",
      "Epoch: 1507 Loss: 12.171171188354492  acc_train_error 32.5625%  acc_test_error 55.25%\n",
      "Epoch: 1508 Loss: 12.164145469665527  acc_train_error 32.55%  acc_test_error 55.25%\n",
      "Epoch: 1509 Loss: 12.157084465026855  acc_train_error 32.55%  acc_test_error 55.1875%\n",
      "Epoch: 1510 Loss: 12.149959564208984  acc_train_error 32.5375%  acc_test_error 55.1875%\n",
      "Epoch: 1511 Loss: 12.142867088317871  acc_train_error 32.5375%  acc_test_error 55.125%\n",
      "Epoch: 1512 Loss: 12.135777473449707  acc_train_error 32.5125%  acc_test_error 55.125%\n",
      "Epoch: 1513 Loss: 12.128361701965332  acc_train_error 32.5125%  acc_test_error 55.0625%\n",
      "Epoch: 1514 Loss: 12.121004104614258  acc_train_error 32.5%  acc_test_error 55.0625%\n",
      "Epoch: 1515 Loss: 12.113682746887207  acc_train_error 32.475%  acc_test_error 55.0625%\n",
      "Epoch: 1516 Loss: 12.106424331665039  acc_train_error 32.475%  acc_test_error 55.0%\n",
      "Epoch: 1517 Loss: 12.099242210388184  acc_train_error 32.4375%  acc_test_error 55.0%\n",
      "Epoch: 1518 Loss: 12.09207534790039  acc_train_error 32.4375%  acc_test_error 54.9375%\n",
      "Epoch: 1519 Loss: 12.084921836853027  acc_train_error 32.425%  acc_test_error 54.9375%\n",
      "Epoch: 1520 Loss: 12.07780647277832  acc_train_error 32.4125%  acc_test_error 54.875%\n",
      "Epoch: 1521 Loss: 12.070738792419434  acc_train_error 32.4125%  acc_test_error 54.8125%\n",
      "Epoch: 1522 Loss: 12.063722610473633  acc_train_error 32.4%  acc_test_error 54.8125%\n",
      "Epoch: 1523 Loss: 12.056711196899414  acc_train_error 32.4%  acc_test_error 54.75%\n",
      "Epoch: 1524 Loss: 12.049727439880371  acc_train_error 32.3875%  acc_test_error 54.75%\n",
      "Epoch: 1525 Loss: 12.042767524719238  acc_train_error 32.375%  acc_test_error 54.6875%\n",
      "Epoch: 1526 Loss: 12.035808563232422  acc_train_error 32.3875%  acc_test_error 54.625%\n",
      "Epoch: 1527 Loss: 12.028888702392578  acc_train_error 32.375%  acc_test_error 54.625%\n",
      "Epoch: 1528 Loss: 12.02197265625  acc_train_error 32.3625%  acc_test_error 54.5625%\n",
      "Epoch: 1529 Loss: 12.015080451965332  acc_train_error 32.3625%  acc_test_error 54.5%\n",
      "Epoch: 1530 Loss: 12.008180618286133  acc_train_error 32.3375%  acc_test_error 54.5%\n",
      "Epoch: 1531 Loss: 12.001317024230957  acc_train_error 32.35%  acc_test_error 54.4375%\n",
      "Epoch: 1532 Loss: 11.994457244873047  acc_train_error 32.3375%  acc_test_error 54.375%\n",
      "Epoch: 1533 Loss: 11.98762321472168  acc_train_error 32.325%  acc_test_error 54.375%\n",
      "Epoch: 1534 Loss: 11.980769157409668  acc_train_error 32.3375%  acc_test_error 54.3125%\n",
      "Epoch: 1535 Loss: 11.97394847869873  acc_train_error 32.3125%  acc_test_error 54.3125%\n",
      "Epoch: 1536 Loss: 11.96712875366211  acc_train_error 32.3125%  acc_test_error 54.25%\n",
      "Epoch: 1537 Loss: 11.960318565368652  acc_train_error 32.3125%  acc_test_error 54.25%\n",
      "Epoch: 1538 Loss: 11.953512191772461  acc_train_error 32.2875%  acc_test_error 54.1875%\n",
      "Epoch: 1539 Loss: 11.94674015045166  acc_train_error 32.2875%  acc_test_error 54.1875%\n",
      "Epoch: 1540 Loss: 11.939973831176758  acc_train_error 32.275%  acc_test_error 54.125%\n",
      "Epoch: 1541 Loss: 11.933232307434082  acc_train_error 32.275%  acc_test_error 54.125%\n",
      "Epoch: 1542 Loss: 11.926496505737305  acc_train_error 32.275%  acc_test_error 54.0625%\n",
      "Epoch: 1543 Loss: 11.919792175292969  acc_train_error 32.2625%  acc_test_error 54.0625%\n",
      "Epoch: 1544 Loss: 11.913090705871582  acc_train_error 32.2625%  acc_test_error 54.0%\n",
      "Epoch: 1545 Loss: 11.90642261505127  acc_train_error 32.2625%  acc_test_error 54.0%\n",
      "Epoch: 1546 Loss: 11.89974594116211  acc_train_error 32.2375%  acc_test_error 53.9375%\n",
      "Epoch: 1547 Loss: 11.893089294433594  acc_train_error 32.25%  acc_test_error 53.875%\n",
      "Epoch: 1548 Loss: 11.886439323425293  acc_train_error 32.225%  acc_test_error 53.875%\n",
      "Epoch: 1549 Loss: 11.87980842590332  acc_train_error 32.2375%  acc_test_error 53.8125%\n",
      "Epoch: 1550 Loss: 11.873185157775879  acc_train_error 32.2125%  acc_test_error 53.8125%\n",
      "Epoch: 1551 Loss: 11.86658000946045  acc_train_error 32.225%  acc_test_error 53.75%\n",
      "Epoch: 1552 Loss: 11.859976768493652  acc_train_error 32.225%  acc_test_error 53.75%\n",
      "Epoch: 1553 Loss: 11.853384971618652  acc_train_error 32.2125%  acc_test_error 53.6875%\n",
      "Epoch: 1554 Loss: 11.846789360046387  acc_train_error 32.2%  acc_test_error 53.6875%\n",
      "Epoch: 1555 Loss: 11.840214729309082  acc_train_error 32.1875%  acc_test_error 53.625%\n",
      "Epoch: 1556 Loss: 11.83364200592041  acc_train_error 32.1875%  acc_test_error 53.625%\n",
      "Epoch: 1557 Loss: 11.827088356018066  acc_train_error 32.175%  acc_test_error 53.5625%\n",
      "Epoch: 1558 Loss: 11.820528984069824  acc_train_error 32.175%  acc_test_error 53.5625%\n",
      "Epoch: 1559 Loss: 11.813992500305176  acc_train_error 32.175%  acc_test_error 53.5%\n",
      "Epoch: 1560 Loss: 11.80746841430664  acc_train_error 32.1625%  acc_test_error 53.5%\n",
      "Epoch: 1561 Loss: 11.80096435546875  acc_train_error 32.1625%  acc_test_error 53.4375%\n",
      "Epoch: 1562 Loss: 11.794450759887695  acc_train_error 32.15%  acc_test_error 53.4375%\n",
      "Epoch: 1563 Loss: 11.78795337677002  acc_train_error 32.1375%  acc_test_error 53.375%\n",
      "Epoch: 1564 Loss: 11.781477928161621  acc_train_error 32.1125%  acc_test_error 53.375%\n",
      "Epoch: 1565 Loss: 11.77501106262207  acc_train_error 32.1125%  acc_test_error 53.3125%\n",
      "Epoch: 1566 Loss: 11.768545150756836  acc_train_error 32.1%  acc_test_error 53.3125%\n",
      "Epoch: 1567 Loss: 11.762092590332031  acc_train_error 32.075%  acc_test_error 53.3125%\n",
      "Epoch: 1568 Loss: 11.75563907623291  acc_train_error 32.075%  acc_test_error 53.25%\n",
      "Epoch: 1569 Loss: 11.749221801757812  acc_train_error 32.0625%  acc_test_error 53.25%\n",
      "Epoch: 1570 Loss: 11.742785453796387  acc_train_error 32.0625%  acc_test_error 53.1875%\n",
      "Epoch: 1571 Loss: 11.736369132995605  acc_train_error 31.9125%  acc_test_error 53.1875%\n",
      "Epoch: 1572 Loss: 11.729948997497559  acc_train_error 31.8875%  acc_test_error 53.125%\n",
      "Epoch: 1573 Loss: 11.723548889160156  acc_train_error 31.8375%  acc_test_error 53.125%\n",
      "Epoch: 1574 Loss: 11.717154502868652  acc_train_error 31.825%  acc_test_error 53.0625%\n",
      "Epoch: 1575 Loss: 11.710769653320312  acc_train_error 31.7875%  acc_test_error 53.0625%\n",
      "Epoch: 1576 Loss: 11.704386711120605  acc_train_error 31.7625%  acc_test_error 53.0%\n",
      "Epoch: 1577 Loss: 11.698004722595215  acc_train_error 31.75%  acc_test_error 52.9375%\n",
      "Epoch: 1578 Loss: 11.691659927368164  acc_train_error 31.7%  acc_test_error 52.9375%\n",
      "Epoch: 1579 Loss: 11.68529224395752  acc_train_error 31.6625%  acc_test_error 52.875%\n",
      "Epoch: 1580 Loss: 11.678933143615723  acc_train_error 31.625%  acc_test_error 52.875%\n",
      "Epoch: 1581 Loss: 11.67257308959961  acc_train_error 31.6125%  acc_test_error 52.8125%\n",
      "Epoch: 1582 Loss: 11.666240692138672  acc_train_error 31.575%  acc_test_error 52.8125%\n",
      "Epoch: 1583 Loss: 11.659911155700684  acc_train_error 31.55%  acc_test_error 52.75%\n",
      "Epoch: 1584 Loss: 11.653572082519531  acc_train_error 31.525%  acc_test_error 52.6875%\n",
      "Epoch: 1585 Loss: 11.647249221801758  acc_train_error 31.4875%  acc_test_error 52.6875%\n",
      "Epoch: 1586 Loss: 11.640942573547363  acc_train_error 31.4625%  acc_test_error 52.625%\n",
      "Epoch: 1587 Loss: 11.634629249572754  acc_train_error 31.425%  acc_test_error 52.625%\n",
      "Epoch: 1588 Loss: 11.628317832946777  acc_train_error 31.4%  acc_test_error 52.5625%\n",
      "Epoch: 1589 Loss: 11.622038841247559  acc_train_error 31.3625%  acc_test_error 52.5625%\n",
      "Epoch: 1590 Loss: 11.615743637084961  acc_train_error 31.3375%  acc_test_error 52.5%\n",
      "Epoch: 1591 Loss: 11.609451293945312  acc_train_error 31.3125%  acc_test_error 52.4375%\n",
      "Epoch: 1592 Loss: 11.603160858154297  acc_train_error 31.275%  acc_test_error 52.4375%\n",
      "Epoch: 1593 Loss: 11.596896171569824  acc_train_error 31.25%  acc_test_error 52.375%\n",
      "Epoch: 1594 Loss: 11.59062385559082  acc_train_error 31.2125%  acc_test_error 52.375%\n",
      "Epoch: 1595 Loss: 11.584354400634766  acc_train_error 31.175%  acc_test_error 52.3125%\n",
      "Epoch: 1596 Loss: 11.578105926513672  acc_train_error 31.175%  acc_test_error 52.25%\n",
      "Epoch: 1597 Loss: 11.571852684020996  acc_train_error 31.15%  acc_test_error 52.25%\n",
      "Epoch: 1598 Loss: 11.565608024597168  acc_train_error 31.125%  acc_test_error 52.1875%\n",
      "Epoch: 1599 Loss: 11.55939769744873  acc_train_error 31.1%  acc_test_error 52.1875%\n",
      "Epoch: 1600 Loss: 11.553167343139648  acc_train_error 31.075%  acc_test_error 52.125%\n",
      "Epoch: 1601 Loss: 11.54694938659668  acc_train_error 31.05%  acc_test_error 52.125%\n",
      "Epoch: 1602 Loss: 11.54074478149414  acc_train_error 31.0375%  acc_test_error 52.0625%\n",
      "Epoch: 1603 Loss: 11.534531593322754  acc_train_error 31.0%  acc_test_error 52.0625%\n",
      "Epoch: 1604 Loss: 11.528324127197266  acc_train_error 31.0%  acc_test_error 52.0%\n",
      "Epoch: 1605 Loss: 11.522134780883789  acc_train_error 30.9875%  acc_test_error 51.9375%\n",
      "Epoch: 1606 Loss: 11.515928268432617  acc_train_error 30.9625%  acc_test_error 51.9375%\n",
      "Epoch: 1607 Loss: 11.50972843170166  acc_train_error 30.95%  acc_test_error 51.875%\n",
      "Epoch: 1608 Loss: 11.50354290008545  acc_train_error 30.925%  acc_test_error 51.875%\n",
      "Epoch: 1609 Loss: 11.49735164642334  acc_train_error 30.9125%  acc_test_error 51.8125%\n",
      "Epoch: 1610 Loss: 11.491150856018066  acc_train_error 30.8875%  acc_test_error 51.8125%\n",
      "Epoch: 1611 Loss: 11.48498249053955  acc_train_error 30.8875%  acc_test_error 51.75%\n",
      "Epoch: 1612 Loss: 11.478792190551758  acc_train_error 30.85%  acc_test_error 51.75%\n",
      "Epoch: 1613 Loss: 11.472611427307129  acc_train_error 30.8375%  acc_test_error 51.6875%\n",
      "Epoch: 1614 Loss: 11.466443061828613  acc_train_error 30.8125%  acc_test_error 51.6875%\n",
      "Epoch: 1615 Loss: 11.460267066955566  acc_train_error 30.8%  acc_test_error 51.625%\n",
      "Epoch: 1616 Loss: 11.454108238220215  acc_train_error 30.775%  acc_test_error 51.625%\n",
      "Epoch: 1617 Loss: 11.44794750213623  acc_train_error 30.75%  acc_test_error 51.625%\n",
      "Epoch: 1618 Loss: 11.441800117492676  acc_train_error 30.7375%  acc_test_error 51.5625%\n",
      "Epoch: 1619 Loss: 11.435662269592285  acc_train_error 30.7125%  acc_test_error 51.5625%\n",
      "Epoch: 1620 Loss: 11.42952823638916  acc_train_error 30.6875%  acc_test_error 51.5%\n",
      "Epoch: 1621 Loss: 11.423401832580566  acc_train_error 30.675%  acc_test_error 51.5%\n",
      "Epoch: 1622 Loss: 11.417292594909668  acc_train_error 30.6625%  acc_test_error 51.4375%\n",
      "Epoch: 1623 Loss: 11.411178588867188  acc_train_error 30.6375%  acc_test_error 51.4375%\n",
      "Epoch: 1624 Loss: 11.405078887939453  acc_train_error 30.6125%  acc_test_error 51.4375%\n",
      "Epoch: 1625 Loss: 11.3989896774292  acc_train_error 30.6%  acc_test_error 51.375%\n",
      "Epoch: 1626 Loss: 11.39291000366211  acc_train_error 30.5625%  acc_test_error 51.375%\n",
      "Epoch: 1627 Loss: 11.386834144592285  acc_train_error 30.525%  acc_test_error 51.375%\n",
      "Epoch: 1628 Loss: 11.380767822265625  acc_train_error 30.5%  acc_test_error 51.3125%\n",
      "Epoch: 1629 Loss: 11.374702453613281  acc_train_error 30.4625%  acc_test_error 51.3125%\n",
      "Epoch: 1630 Loss: 11.368640899658203  acc_train_error 30.4125%  acc_test_error 51.3125%\n",
      "Epoch: 1631 Loss: 11.362590789794922  acc_train_error 30.4%  acc_test_error 51.25%\n",
      "Epoch: 1632 Loss: 11.35654067993164  acc_train_error 30.35%  acc_test_error 51.25%\n",
      "Epoch: 1633 Loss: 11.350493431091309  acc_train_error 30.325%  acc_test_error 51.25%\n",
      "Epoch: 1634 Loss: 11.344456672668457  acc_train_error 30.2875%  acc_test_error 51.1875%\n",
      "Epoch: 1635 Loss: 11.33842658996582  acc_train_error 30.2375%  acc_test_error 51.1875%\n",
      "Epoch: 1636 Loss: 11.332391738891602  acc_train_error 30.175%  acc_test_error 51.1875%\n",
      "Epoch: 1637 Loss: 11.326361656188965  acc_train_error 30.125%  acc_test_error 51.125%\n",
      "Epoch: 1638 Loss: 11.320337295532227  acc_train_error 30.0125%  acc_test_error 51.125%\n",
      "Epoch: 1639 Loss: 11.314321517944336  acc_train_error 29.875%  acc_test_error 51.125%\n",
      "Epoch: 1640 Loss: 11.308295249938965  acc_train_error 29.75%  acc_test_error 51.0625%\n",
      "Epoch: 1641 Loss: 11.302268981933594  acc_train_error 29.6%  acc_test_error 51.0625%\n",
      "Epoch: 1642 Loss: 11.296249389648438  acc_train_error 29.6%  acc_test_error 51.0625%\n",
      "Epoch: 1643 Loss: 11.290230751037598  acc_train_error 29.6%  acc_test_error 51.0625%\n",
      "Epoch: 1644 Loss: 11.284226417541504  acc_train_error 29.6125%  acc_test_error 51.0%\n",
      "Epoch: 1645 Loss: 11.27822208404541  acc_train_error 29.6125%  acc_test_error 51.0%\n",
      "Epoch: 1646 Loss: 11.27221965789795  acc_train_error 29.6125%  acc_test_error 51.0%\n",
      "Epoch: 1647 Loss: 11.266241073608398  acc_train_error 29.625%  acc_test_error 50.9375%\n",
      "Epoch: 1648 Loss: 11.260252952575684  acc_train_error 29.6125%  acc_test_error 50.9375%\n",
      "Epoch: 1649 Loss: 11.254281997680664  acc_train_error 29.6125%  acc_test_error 50.9375%\n",
      "Epoch: 1650 Loss: 11.24831771850586  acc_train_error 29.6125%  acc_test_error 50.9375%\n",
      "Epoch: 1651 Loss: 11.242353439331055  acc_train_error 29.625%  acc_test_error 50.875%\n",
      "Epoch: 1652 Loss: 11.23639965057373  acc_train_error 29.625%  acc_test_error 50.875%\n",
      "Epoch: 1653 Loss: 11.230453491210938  acc_train_error 29.625%  acc_test_error 50.875%\n",
      "Epoch: 1654 Loss: 11.224523544311523  acc_train_error 29.625%  acc_test_error 50.875%\n",
      "Epoch: 1655 Loss: 11.218579292297363  acc_train_error 29.625%  acc_test_error 50.8125%\n",
      "Epoch: 1656 Loss: 11.212656021118164  acc_train_error 29.625%  acc_test_error 50.8125%\n",
      "Epoch: 1657 Loss: 11.206727027893066  acc_train_error 29.625%  acc_test_error 50.8125%\n",
      "Epoch: 1658 Loss: 11.200807571411133  acc_train_error 29.625%  acc_test_error 50.8125%\n",
      "Epoch: 1659 Loss: 11.19489860534668  acc_train_error 29.6375%  acc_test_error 50.75%\n",
      "Epoch: 1660 Loss: 11.18899154663086  acc_train_error 29.6375%  acc_test_error 50.75%\n",
      "Epoch: 1661 Loss: 11.18309497833252  acc_train_error 29.6375%  acc_test_error 50.75%\n",
      "Epoch: 1662 Loss: 11.177203178405762  acc_train_error 29.6375%  acc_test_error 50.75%\n",
      "Epoch: 1663 Loss: 11.171318054199219  acc_train_error 29.6375%  acc_test_error 50.6875%\n",
      "Epoch: 1664 Loss: 11.165443420410156  acc_train_error 29.6375%  acc_test_error 50.6875%\n",
      "Epoch: 1665 Loss: 11.159571647644043  acc_train_error 29.6375%  acc_test_error 50.6875%\n",
      "Epoch: 1666 Loss: 11.153705596923828  acc_train_error 29.6375%  acc_test_error 50.6875%\n",
      "Epoch: 1667 Loss: 11.147834777832031  acc_train_error 29.65%  acc_test_error 50.625%\n",
      "Epoch: 1668 Loss: 11.141982078552246  acc_train_error 29.65%  acc_test_error 50.625%\n",
      "Epoch: 1669 Loss: 11.136122703552246  acc_train_error 29.65%  acc_test_error 50.625%\n",
      "Epoch: 1670 Loss: 11.130273818969727  acc_train_error 29.65%  acc_test_error 50.625%\n",
      "Epoch: 1671 Loss: 11.124436378479004  acc_train_error 29.65%  acc_test_error 50.5625%\n",
      "Epoch: 1672 Loss: 11.11860179901123  acc_train_error 29.65%  acc_test_error 50.5625%\n",
      "Epoch: 1673 Loss: 11.112768173217773  acc_train_error 29.65%  acc_test_error 50.5625%\n",
      "Epoch: 1674 Loss: 11.106942176818848  acc_train_error 29.65%  acc_test_error 50.5625%\n",
      "Epoch: 1675 Loss: 11.101125717163086  acc_train_error 29.65%  acc_test_error 50.5625%\n",
      "Epoch: 1676 Loss: 11.095330238342285  acc_train_error 29.6625%  acc_test_error 50.5%\n",
      "Epoch: 1677 Loss: 11.089521408081055  acc_train_error 29.6625%  acc_test_error 50.5%\n",
      "Epoch: 1678 Loss: 11.083730697631836  acc_train_error 29.6625%  acc_test_error 50.5%\n",
      "Epoch: 1679 Loss: 11.077942848205566  acc_train_error 29.65%  acc_test_error 50.5%\n",
      "Epoch: 1680 Loss: 11.072165489196777  acc_train_error 29.65%  acc_test_error 50.5%\n",
      "Epoch: 1681 Loss: 11.066389083862305  acc_train_error 29.6625%  acc_test_error 50.4375%\n",
      "Epoch: 1682 Loss: 11.0606050491333  acc_train_error 29.6625%  acc_test_error 50.4375%\n",
      "Epoch: 1683 Loss: 11.054838180541992  acc_train_error 29.6625%  acc_test_error 50.4375%\n",
      "Epoch: 1684 Loss: 11.049077033996582  acc_train_error 29.6625%  acc_test_error 50.4375%\n",
      "Epoch: 1685 Loss: 11.043323516845703  acc_train_error 29.6625%  acc_test_error 50.4375%\n",
      "Epoch: 1686 Loss: 11.037569999694824  acc_train_error 29.6625%  acc_test_error 50.4375%\n",
      "Epoch: 1687 Loss: 11.031822204589844  acc_train_error 29.6625%  acc_test_error 50.375%\n",
      "Epoch: 1688 Loss: 11.02607536315918  acc_train_error 29.6625%  acc_test_error 50.375%\n",
      "Epoch: 1689 Loss: 11.020337104797363  acc_train_error 29.6625%  acc_test_error 50.375%\n",
      "Epoch: 1690 Loss: 11.014605522155762  acc_train_error 29.6625%  acc_test_error 50.375%\n",
      "Epoch: 1691 Loss: 11.008881568908691  acc_train_error 29.6625%  acc_test_error 50.375%\n",
      "Epoch: 1692 Loss: 11.003150939941406  acc_train_error 29.6625%  acc_test_error 50.375%\n",
      "Epoch: 1693 Loss: 10.99742603302002  acc_train_error 29.675%  acc_test_error 50.3125%\n",
      "Epoch: 1694 Loss: 10.991711616516113  acc_train_error 29.6625%  acc_test_error 50.3125%\n",
      "Epoch: 1695 Loss: 10.98598861694336  acc_train_error 29.6625%  acc_test_error 50.3125%\n",
      "Epoch: 1696 Loss: 10.980273246765137  acc_train_error 29.6625%  acc_test_error 50.3125%\n",
      "Epoch: 1697 Loss: 10.974565505981445  acc_train_error 29.6625%  acc_test_error 50.3125%\n",
      "Epoch: 1698 Loss: 10.96886920928955  acc_train_error 29.6625%  acc_test_error 50.3125%\n",
      "Epoch: 1699 Loss: 10.963170051574707  acc_train_error 29.6625%  acc_test_error 50.3125%\n",
      "Epoch: 1700 Loss: 10.957470893859863  acc_train_error 29.675%  acc_test_error 50.25%\n",
      "Epoch: 1701 Loss: 10.951786994934082  acc_train_error 29.675%  acc_test_error 50.25%\n",
      "Epoch: 1702 Loss: 10.946104049682617  acc_train_error 29.6625%  acc_test_error 50.25%\n",
      "Epoch: 1703 Loss: 10.940427780151367  acc_train_error 29.6625%  acc_test_error 50.25%\n",
      "Epoch: 1704 Loss: 10.9347562789917  acc_train_error 29.6625%  acc_test_error 50.25%\n",
      "Epoch: 1705 Loss: 10.929084777832031  acc_train_error 29.6625%  acc_test_error 50.25%\n",
      "Epoch: 1706 Loss: 10.923428535461426  acc_train_error 29.6625%  acc_test_error 50.25%\n",
      "Epoch: 1707 Loss: 10.917767524719238  acc_train_error 29.675%  acc_test_error 50.1875%\n",
      "Epoch: 1708 Loss: 10.912108421325684  acc_train_error 29.675%  acc_test_error 50.1875%\n",
      "Epoch: 1709 Loss: 10.906457901000977  acc_train_error 29.6625%  acc_test_error 50.1875%\n",
      "Epoch: 1710 Loss: 10.90080451965332  acc_train_error 29.6625%  acc_test_error 50.1875%\n",
      "Epoch: 1711 Loss: 10.895172119140625  acc_train_error 29.6625%  acc_test_error 50.1875%\n",
      "Epoch: 1712 Loss: 10.889533042907715  acc_train_error 29.6625%  acc_test_error 50.1875%\n",
      "Epoch: 1713 Loss: 10.88390827178955  acc_train_error 29.6625%  acc_test_error 50.1875%\n",
      "Epoch: 1714 Loss: 10.878287315368652  acc_train_error 29.6625%  acc_test_error 50.1875%\n",
      "Epoch: 1715 Loss: 10.872672080993652  acc_train_error 29.65%  acc_test_error 50.1875%\n",
      "Epoch: 1716 Loss: 10.867057800292969  acc_train_error 29.6625%  acc_test_error 50.125%\n",
      "Epoch: 1717 Loss: 10.861449241638184  acc_train_error 29.6625%  acc_test_error 50.125%\n",
      "Epoch: 1718 Loss: 10.855851173400879  acc_train_error 29.6625%  acc_test_error 50.125%\n",
      "Epoch: 1719 Loss: 10.85024356842041  acc_train_error 29.6625%  acc_test_error 50.125%\n",
      "Epoch: 1720 Loss: 10.844653129577637  acc_train_error 29.6625%  acc_test_error 50.125%\n",
      "Epoch: 1721 Loss: 10.839058876037598  acc_train_error 29.6625%  acc_test_error 50.125%\n",
      "Epoch: 1722 Loss: 10.83347225189209  acc_train_error 29.65%  acc_test_error 50.125%\n",
      "Epoch: 1723 Loss: 10.827888488769531  acc_train_error 29.65%  acc_test_error 50.125%\n",
      "Epoch: 1724 Loss: 10.822307586669922  acc_train_error 29.65%  acc_test_error 50.125%\n",
      "Epoch: 1725 Loss: 10.816731452941895  acc_train_error 29.65%  acc_test_error 50.125%\n",
      "Epoch: 1726 Loss: 10.811166763305664  acc_train_error 29.6625%  acc_test_error 50.0625%\n",
      "Epoch: 1727 Loss: 10.805602073669434  acc_train_error 29.6625%  acc_test_error 50.0625%\n",
      "Epoch: 1728 Loss: 10.800045013427734  acc_train_error 29.65%  acc_test_error 50.0625%\n",
      "Epoch: 1729 Loss: 10.794492721557617  acc_train_error 29.65%  acc_test_error 50.0625%\n",
      "Epoch: 1730 Loss: 10.788938522338867  acc_train_error 29.65%  acc_test_error 50.0625%\n",
      "Epoch: 1731 Loss: 10.783395767211914  acc_train_error 29.65%  acc_test_error 50.0625%\n",
      "Epoch: 1732 Loss: 10.777856826782227  acc_train_error 29.65%  acc_test_error 50.0625%\n",
      "Epoch: 1733 Loss: 10.772323608398438  acc_train_error 29.65%  acc_test_error 50.0625%\n",
      "Epoch: 1734 Loss: 10.766785621643066  acc_train_error 29.6375%  acc_test_error 50.0625%\n",
      "Epoch: 1735 Loss: 10.761262893676758  acc_train_error 29.65%  acc_test_error 50.0%\n",
      "Epoch: 1736 Loss: 10.755733489990234  acc_train_error 29.65%  acc_test_error 50.0%\n",
      "Epoch: 1737 Loss: 10.75021743774414  acc_train_error 29.65%  acc_test_error 50.0%\n",
      "Epoch: 1738 Loss: 10.744702339172363  acc_train_error 29.65%  acc_test_error 50.0%\n",
      "Epoch: 1739 Loss: 10.739190101623535  acc_train_error 29.6375%  acc_test_error 50.0%\n",
      "Epoch: 1740 Loss: 10.733686447143555  acc_train_error 29.6375%  acc_test_error 50.0%\n",
      "Epoch: 1741 Loss: 10.728179931640625  acc_train_error 29.6375%  acc_test_error 50.0%\n",
      "Epoch: 1742 Loss: 10.722676277160645  acc_train_error 29.6375%  acc_test_error 50.0%\n",
      "Epoch: 1743 Loss: 10.717169761657715  acc_train_error 29.6375%  acc_test_error 50.0%\n",
      "Epoch: 1744 Loss: 10.71167278289795  acc_train_error 29.625%  acc_test_error 50.0%\n",
      "Epoch: 1745 Loss: 10.706171035766602  acc_train_error 29.6375%  acc_test_error 50.0%\n",
      "Epoch: 1746 Loss: 10.700676918029785  acc_train_error 29.6375%  acc_test_error 50.0%\n",
      "Epoch: 1747 Loss: 10.695184707641602  acc_train_error 29.6375%  acc_test_error 50.0%\n",
      "Epoch: 1748 Loss: 10.689697265625  acc_train_error 29.6375%  acc_test_error 50.0%\n",
      "Epoch: 1749 Loss: 10.684209823608398  acc_train_error 29.6375%  acc_test_error 50.0%\n",
      "Epoch: 1750 Loss: 10.678730964660645  acc_train_error 29.625%  acc_test_error 50.0%\n",
      "Epoch: 1751 Loss: 10.673254013061523  acc_train_error 29.625%  acc_test_error 50.0%\n",
      "Epoch: 1752 Loss: 10.667789459228516  acc_train_error 29.625%  acc_test_error 50.0%\n",
      "Epoch: 1753 Loss: 10.662321090698242  acc_train_error 29.625%  acc_test_error 50.0%\n",
      "Epoch: 1754 Loss: 10.656864166259766  acc_train_error 29.6375%  acc_test_error 50.0%\n",
      "Epoch: 1755 Loss: 10.651397705078125  acc_train_error 29.625%  acc_test_error 50.0%\n",
      "Epoch: 1756 Loss: 10.6459379196167  acc_train_error 29.625%  acc_test_error 50.0%\n",
      "Epoch: 1757 Loss: 10.640486717224121  acc_train_error 29.625%  acc_test_error 50.0%\n",
      "Epoch: 1758 Loss: 10.635025978088379  acc_train_error 29.625%  acc_test_error 50.0%\n",
      "Epoch: 1759 Loss: 10.629579544067383  acc_train_error 29.625%  acc_test_error 50.0%\n",
      "Epoch: 1760 Loss: 10.624140739440918  acc_train_error 29.625%  acc_test_error 50.0%\n",
      "Epoch: 1761 Loss: 10.61868953704834  acc_train_error 29.6125%  acc_test_error 50.0%\n",
      "Epoch: 1762 Loss: 10.613250732421875  acc_train_error 29.6125%  acc_test_error 50.0%\n",
      "Epoch: 1763 Loss: 10.607812881469727  acc_train_error 29.625%  acc_test_error 50.0%\n",
      "Epoch: 1764 Loss: 10.602373123168945  acc_train_error 29.625%  acc_test_error 50.0%\n",
      "Epoch: 1765 Loss: 10.596927642822266  acc_train_error 29.625%  acc_test_error 50.0%\n",
      "Epoch: 1766 Loss: 10.59150505065918  acc_train_error 29.625%  acc_test_error 50.0%\n",
      "Epoch: 1767 Loss: 10.586075782775879  acc_train_error 29.625%  acc_test_error 50.0%\n",
      "Epoch: 1768 Loss: 10.580648422241211  acc_train_error 29.625%  acc_test_error 50.0%\n",
      "Epoch: 1769 Loss: 10.57521915435791  acc_train_error 29.6375%  acc_test_error 50.0%\n",
      "Epoch: 1770 Loss: 10.569801330566406  acc_train_error 29.625%  acc_test_error 50.0%\n",
      "Epoch: 1771 Loss: 10.564373016357422  acc_train_error 29.625%  acc_test_error 50.0%\n",
      "Epoch: 1772 Loss: 10.558947563171387  acc_train_error 29.625%  acc_test_error 50.0%\n",
      "Epoch: 1773 Loss: 10.5535249710083  acc_train_error 29.625%  acc_test_error 50.0%\n",
      "Epoch: 1774 Loss: 10.548107147216797  acc_train_error 29.625%  acc_test_error 50.0%\n",
      "Epoch: 1775 Loss: 10.542680740356445  acc_train_error 29.625%  acc_test_error 50.0%\n",
      "Epoch: 1776 Loss: 10.53726863861084  acc_train_error 29.6375%  acc_test_error 50.0%\n",
      "Epoch: 1777 Loss: 10.531839370727539  acc_train_error 29.6375%  acc_test_error 50.0%\n",
      "Epoch: 1778 Loss: 10.52642822265625  acc_train_error 29.6375%  acc_test_error 50.0%\n",
      "Epoch: 1779 Loss: 10.521008491516113  acc_train_error 29.625%  acc_test_error 50.0%\n",
      "Epoch: 1780 Loss: 10.515596389770508  acc_train_error 29.625%  acc_test_error 50.0%\n",
      "Epoch: 1781 Loss: 10.510176658630371  acc_train_error 29.625%  acc_test_error 50.0%\n",
      "Epoch: 1782 Loss: 10.50478744506836  acc_train_error 29.625%  acc_test_error 50.0%\n",
      "Epoch: 1783 Loss: 10.499387741088867  acc_train_error 29.6375%  acc_test_error 50.0%\n",
      "Epoch: 1784 Loss: 10.49399471282959  acc_train_error 29.6375%  acc_test_error 50.0%\n",
      "Epoch: 1785 Loss: 10.488603591918945  acc_train_error 29.6375%  acc_test_error 50.0%\n",
      "Epoch: 1786 Loss: 10.4832124710083  acc_train_error 29.625%  acc_test_error 50.0%\n",
      "Epoch: 1787 Loss: 10.477832794189453  acc_train_error 29.625%  acc_test_error 50.0%\n",
      "Epoch: 1788 Loss: 10.472452163696289  acc_train_error 29.625%  acc_test_error 50.0%\n",
      "Epoch: 1789 Loss: 10.46707534790039  acc_train_error 29.625%  acc_test_error 50.0%\n",
      "Epoch: 1790 Loss: 10.461709976196289  acc_train_error 29.625%  acc_test_error 50.0%\n",
      "Epoch: 1791 Loss: 10.456334114074707  acc_train_error 29.6375%  acc_test_error 50.0%\n",
      "Epoch: 1792 Loss: 10.450963973999023  acc_train_error 29.6375%  acc_test_error 50.0%\n",
      "Epoch: 1793 Loss: 10.445595741271973  acc_train_error 29.6375%  acc_test_error 50.0%\n",
      "Epoch: 1794 Loss: 10.44023609161377  acc_train_error 29.625%  acc_test_error 50.0%\n",
      "Epoch: 1795 Loss: 10.4348726272583  acc_train_error 29.625%  acc_test_error 50.0%\n",
      "Epoch: 1796 Loss: 10.429511070251465  acc_train_error 29.625%  acc_test_error 50.0%\n",
      "Epoch: 1797 Loss: 10.424148559570312  acc_train_error 29.625%  acc_test_error 50.0%\n",
      "Epoch: 1798 Loss: 10.418803215026855  acc_train_error 29.625%  acc_test_error 50.0%\n",
      "Epoch: 1799 Loss: 10.413451194763184  acc_train_error 29.6375%  acc_test_error 50.0%\n",
      "Epoch: 1800 Loss: 10.408100128173828  acc_train_error 29.6375%  acc_test_error 50.0%\n",
      "Epoch: 1801 Loss: 10.402761459350586  acc_train_error 29.6375%  acc_test_error 50.0%\n",
      "Epoch: 1802 Loss: 10.397411346435547  acc_train_error 29.625%  acc_test_error 50.0%\n",
      "Epoch: 1803 Loss: 10.392073631286621  acc_train_error 29.625%  acc_test_error 50.0%\n",
      "Epoch: 1804 Loss: 10.386731147766113  acc_train_error 29.625%  acc_test_error 50.0%\n",
      "Epoch: 1805 Loss: 10.381391525268555  acc_train_error 29.625%  acc_test_error 50.0%\n",
      "Epoch: 1806 Loss: 10.376062393188477  acc_train_error 29.6375%  acc_test_error 50.0%\n",
      "Epoch: 1807 Loss: 10.370725631713867  acc_train_error 29.6375%  acc_test_error 50.0%\n",
      "Epoch: 1808 Loss: 10.365400314331055  acc_train_error 29.6375%  acc_test_error 50.0%\n",
      "Epoch: 1809 Loss: 10.360069274902344  acc_train_error 29.6375%  acc_test_error 50.0%\n",
      "Epoch: 1810 Loss: 10.354742050170898  acc_train_error 29.625%  acc_test_error 50.0%\n",
      "Epoch: 1811 Loss: 10.349419593811035  acc_train_error 29.625%  acc_test_error 50.0%\n",
      "Epoch: 1812 Loss: 10.344091415405273  acc_train_error 29.625%  acc_test_error 50.0%\n",
      "Epoch: 1813 Loss: 10.338776588439941  acc_train_error 29.6375%  acc_test_error 50.0%\n",
      "Epoch: 1814 Loss: 10.333455085754395  acc_train_error 29.6375%  acc_test_error 50.0%\n",
      "Epoch: 1815 Loss: 10.328139305114746  acc_train_error 29.6375%  acc_test_error 50.0%\n",
      "Epoch: 1816 Loss: 10.32282829284668  acc_train_error 29.6375%  acc_test_error 50.0%\n",
      "Epoch: 1817 Loss: 10.317517280578613  acc_train_error 29.6375%  acc_test_error 50.0%\n",
      "Epoch: 1818 Loss: 10.312210083007812  acc_train_error 29.6375%  acc_test_error 50.0%\n",
      "Epoch: 1819 Loss: 10.306915283203125  acc_train_error 29.625%  acc_test_error 50.0%\n",
      "Epoch: 1820 Loss: 10.301617622375488  acc_train_error 29.6375%  acc_test_error 50.0%\n",
      "Epoch: 1821 Loss: 10.296323776245117  acc_train_error 29.6375%  acc_test_error 50.0%\n",
      "Epoch: 1822 Loss: 10.291025161743164  acc_train_error 29.6375%  acc_test_error 50.0%\n",
      "Epoch: 1823 Loss: 10.285737037658691  acc_train_error 29.6375%  acc_test_error 50.0%\n",
      "Epoch: 1824 Loss: 10.280444145202637  acc_train_error 29.6375%  acc_test_error 50.0%\n",
      "Epoch: 1825 Loss: 10.275161743164062  acc_train_error 29.6375%  acc_test_error 50.0%\n",
      "Epoch: 1826 Loss: 10.269869804382324  acc_train_error 29.6375%  acc_test_error 50.0%\n",
      "Epoch: 1827 Loss: 10.264585494995117  acc_train_error 29.65%  acc_test_error 50.0%\n",
      "Epoch: 1828 Loss: 10.259296417236328  acc_train_error 29.65%  acc_test_error 50.0%\n",
      "Epoch: 1829 Loss: 10.254013061523438  acc_train_error 29.65%  acc_test_error 50.0%\n",
      "Epoch: 1830 Loss: 10.248733520507812  acc_train_error 29.6375%  acc_test_error 50.0%\n",
      "Epoch: 1831 Loss: 10.243452072143555  acc_train_error 29.6375%  acc_test_error 50.0%\n",
      "Epoch: 1832 Loss: 10.238174438476562  acc_train_error 29.6375%  acc_test_error 50.0%\n",
      "Epoch: 1833 Loss: 10.232891082763672  acc_train_error 29.6375%  acc_test_error 50.0%\n",
      "Epoch: 1834 Loss: 10.227622032165527  acc_train_error 29.65%  acc_test_error 50.0%\n",
      "Epoch: 1835 Loss: 10.222339630126953  acc_train_error 29.65%  acc_test_error 50.0%\n",
      "Epoch: 1836 Loss: 10.217062950134277  acc_train_error 29.65%  acc_test_error 50.0%\n",
      "Epoch: 1837 Loss: 10.21177864074707  acc_train_error 29.65%  acc_test_error 50.0%\n",
      "Epoch: 1838 Loss: 10.206501007080078  acc_train_error 29.65%  acc_test_error 50.0%\n",
      "Epoch: 1839 Loss: 10.201220512390137  acc_train_error 29.6375%  acc_test_error 50.0%\n",
      "Epoch: 1840 Loss: 10.195945739746094  acc_train_error 29.6375%  acc_test_error 50.0%\n",
      "Epoch: 1841 Loss: 10.190671920776367  acc_train_error 29.65%  acc_test_error 50.0%\n",
      "Epoch: 1842 Loss: 10.185389518737793  acc_train_error 29.65%  acc_test_error 50.0%\n",
      "Epoch: 1843 Loss: 10.18010139465332  acc_train_error 29.65%  acc_test_error 50.0%\n",
      "Epoch: 1844 Loss: 10.174805641174316  acc_train_error 29.65%  acc_test_error 50.0%\n",
      "Epoch: 1845 Loss: 10.169514656066895  acc_train_error 29.65%  acc_test_error 50.0%\n",
      "Epoch: 1846 Loss: 10.16422176361084  acc_train_error 29.65%  acc_test_error 50.0%\n",
      "Epoch: 1847 Loss: 10.158939361572266  acc_train_error 29.65%  acc_test_error 50.0%\n",
      "Epoch: 1848 Loss: 10.153654098510742  acc_train_error 29.65%  acc_test_error 50.0%\n",
      "Epoch: 1849 Loss: 10.148378372192383  acc_train_error 29.65%  acc_test_error 50.0%\n",
      "Epoch: 1850 Loss: 10.143101692199707  acc_train_error 29.65%  acc_test_error 50.0%\n",
      "Epoch: 1851 Loss: 10.137829780578613  acc_train_error 29.65%  acc_test_error 50.0%\n",
      "Epoch: 1852 Loss: 10.132566452026367  acc_train_error 29.65%  acc_test_error 50.0%\n",
      "Epoch: 1853 Loss: 10.127298355102539  acc_train_error 29.6625%  acc_test_error 50.0%\n",
      "Epoch: 1854 Loss: 10.122039794921875  acc_train_error 29.6625%  acc_test_error 50.0%\n",
      "Epoch: 1855 Loss: 10.116778373718262  acc_train_error 29.6625%  acc_test_error 50.0%\n",
      "Epoch: 1856 Loss: 10.111517906188965  acc_train_error 29.65%  acc_test_error 50.0%\n",
      "Epoch: 1857 Loss: 10.106264114379883  acc_train_error 29.65%  acc_test_error 50.0%\n",
      "Epoch: 1858 Loss: 10.101003646850586  acc_train_error 29.65%  acc_test_error 50.0%\n",
      "Epoch: 1859 Loss: 10.095732688903809  acc_train_error 29.6625%  acc_test_error 50.0%\n",
      "Epoch: 1860 Loss: 10.090459823608398  acc_train_error 29.6625%  acc_test_error 50.0%\n",
      "Epoch: 1861 Loss: 10.085197448730469  acc_train_error 29.6625%  acc_test_error 50.0%\n",
      "Epoch: 1862 Loss: 10.07993221282959  acc_train_error 29.6625%  acc_test_error 50.0%\n",
      "Epoch: 1863 Loss: 10.074647903442383  acc_train_error 29.6625%  acc_test_error 50.0%\n",
      "Epoch: 1864 Loss: 10.06937026977539  acc_train_error 29.675%  acc_test_error 50.0%\n",
      "Epoch: 1865 Loss: 10.06410026550293  acc_train_error 29.675%  acc_test_error 50.0%\n",
      "Epoch: 1866 Loss: 10.058821678161621  acc_train_error 29.675%  acc_test_error 50.0%\n",
      "Epoch: 1867 Loss: 10.05356216430664  acc_train_error 29.6625%  acc_test_error 50.0%\n",
      "Epoch: 1868 Loss: 10.048298835754395  acc_train_error 29.675%  acc_test_error 50.0%\n",
      "Epoch: 1869 Loss: 10.043038368225098  acc_train_error 29.675%  acc_test_error 50.0%\n",
      "Epoch: 1870 Loss: 10.037769317626953  acc_train_error 29.675%  acc_test_error 50.0%\n",
      "Epoch: 1871 Loss: 10.032509803771973  acc_train_error 29.675%  acc_test_error 50.0%\n",
      "Epoch: 1872 Loss: 10.02724552154541  acc_train_error 29.6875%  acc_test_error 50.0%\n",
      "Epoch: 1873 Loss: 10.021979331970215  acc_train_error 29.6875%  acc_test_error 50.0%\n",
      "Epoch: 1874 Loss: 10.016724586486816  acc_train_error 29.6875%  acc_test_error 50.0%\n",
      "Epoch: 1875 Loss: 10.011463165283203  acc_train_error 29.6875%  acc_test_error 50.0%\n",
      "Epoch: 1876 Loss: 10.006209373474121  acc_train_error 29.6875%  acc_test_error 50.0%\n",
      "Epoch: 1877 Loss: 10.000951766967773  acc_train_error 29.7%  acc_test_error 50.0%\n",
      "Epoch: 1878 Loss: 9.995704650878906  acc_train_error 29.6875%  acc_test_error 50.0%\n",
      "Epoch: 1879 Loss: 9.99045467376709  acc_train_error 29.6875%  acc_test_error 50.0%\n",
      "Epoch: 1880 Loss: 9.985198974609375  acc_train_error 29.6875%  acc_test_error 50.0%\n",
      "Epoch: 1881 Loss: 9.979947090148926  acc_train_error 29.7%  acc_test_error 50.0%\n",
      "Epoch: 1882 Loss: 9.974698066711426  acc_train_error 29.7%  acc_test_error 50.0%\n",
      "Epoch: 1883 Loss: 9.969443321228027  acc_train_error 29.7%  acc_test_error 50.0%\n",
      "Epoch: 1884 Loss: 9.964195251464844  acc_train_error 29.7%  acc_test_error 50.0%\n",
      "Epoch: 1885 Loss: 9.958955764770508  acc_train_error 29.7125%  acc_test_error 50.0%\n",
      "Epoch: 1886 Loss: 9.953704833984375  acc_train_error 29.7125%  acc_test_error 50.0%\n",
      "Epoch: 1887 Loss: 9.948456764221191  acc_train_error 29.7125%  acc_test_error 50.0%\n",
      "Epoch: 1888 Loss: 9.943219184875488  acc_train_error 29.7125%  acc_test_error 50.0%\n",
      "Epoch: 1889 Loss: 9.937976837158203  acc_train_error 29.7125%  acc_test_error 50.0%\n",
      "Epoch: 1890 Loss: 9.932732582092285  acc_train_error 29.725%  acc_test_error 50.0%\n",
      "Epoch: 1891 Loss: 9.927489280700684  acc_train_error 29.725%  acc_test_error 50.0%\n",
      "Epoch: 1892 Loss: 9.922245025634766  acc_train_error 29.7125%  acc_test_error 50.0%\n",
      "Epoch: 1893 Loss: 9.917000770568848  acc_train_error 29.7125%  acc_test_error 50.0%\n",
      "Epoch: 1894 Loss: 9.911760330200195  acc_train_error 29.725%  acc_test_error 50.0%\n",
      "Epoch: 1895 Loss: 9.906511306762695  acc_train_error 29.725%  acc_test_error 50.0%\n",
      "Epoch: 1896 Loss: 9.901265144348145  acc_train_error 29.725%  acc_test_error 50.0%\n",
      "Epoch: 1897 Loss: 9.896026611328125  acc_train_error 29.725%  acc_test_error 50.0%\n",
      "Epoch: 1898 Loss: 9.890789031982422  acc_train_error 29.7375%  acc_test_error 50.0%\n",
      "Epoch: 1899 Loss: 9.8855562210083  acc_train_error 29.7375%  acc_test_error 50.0%\n",
      "Epoch: 1900 Loss: 9.88032341003418  acc_train_error 29.7375%  acc_test_error 50.0%\n",
      "Epoch: 1901 Loss: 9.87509822845459  acc_train_error 29.7375%  acc_test_error 50.0%\n",
      "Epoch: 1902 Loss: 9.869872093200684  acc_train_error 29.75%  acc_test_error 50.0%\n",
      "Epoch: 1903 Loss: 9.864644050598145  acc_train_error 29.75%  acc_test_error 50.0%\n",
      "Epoch: 1904 Loss: 9.859414100646973  acc_train_error 29.75%  acc_test_error 50.0%\n",
      "Epoch: 1905 Loss: 9.854181289672852  acc_train_error 29.7625%  acc_test_error 50.0%\n",
      "Epoch: 1906 Loss: 9.848953247070312  acc_train_error 29.7625%  acc_test_error 50.0%\n",
      "Epoch: 1907 Loss: 9.843722343444824  acc_train_error 29.7625%  acc_test_error 50.0%\n",
      "Epoch: 1908 Loss: 9.838482856750488  acc_train_error 29.75%  acc_test_error 50.0%\n",
      "Epoch: 1909 Loss: 9.833259582519531  acc_train_error 29.7625%  acc_test_error 50.0%\n",
      "Epoch: 1910 Loss: 9.828024864196777  acc_train_error 29.7625%  acc_test_error 50.0%\n",
      "Epoch: 1911 Loss: 9.822803497314453  acc_train_error 29.7625%  acc_test_error 50.0%\n",
      "Epoch: 1912 Loss: 9.81757926940918  acc_train_error 29.775%  acc_test_error 50.0%\n",
      "Epoch: 1913 Loss: 9.812356948852539  acc_train_error 29.775%  acc_test_error 50.0%\n",
      "Epoch: 1914 Loss: 9.807143211364746  acc_train_error 29.775%  acc_test_error 50.0%\n",
      "Epoch: 1915 Loss: 9.801919937133789  acc_train_error 29.775%  acc_test_error 50.0%\n",
      "Epoch: 1916 Loss: 9.796710968017578  acc_train_error 29.7875%  acc_test_error 50.0%\n",
      "Epoch: 1917 Loss: 9.791500091552734  acc_train_error 29.7875%  acc_test_error 50.0%\n",
      "Epoch: 1918 Loss: 9.786285400390625  acc_train_error 29.7875%  acc_test_error 50.0%\n",
      "Epoch: 1919 Loss: 9.781074523925781  acc_train_error 29.7875%  acc_test_error 50.0%\n",
      "Epoch: 1920 Loss: 9.775860786437988  acc_train_error 29.8%  acc_test_error 50.0%\n",
      "Epoch: 1921 Loss: 9.770644187927246  acc_train_error 29.8%  acc_test_error 50.0%\n",
      "Epoch: 1922 Loss: 9.765425682067871  acc_train_error 29.8%  acc_test_error 50.0%\n",
      "Epoch: 1923 Loss: 9.760217666625977  acc_train_error 29.8125%  acc_test_error 50.0%\n",
      "Epoch: 1924 Loss: 9.75500774383545  acc_train_error 29.8125%  acc_test_error 50.0%\n",
      "Epoch: 1925 Loss: 9.749797821044922  acc_train_error 29.8125%  acc_test_error 50.0%\n",
      "Epoch: 1926 Loss: 9.744585037231445  acc_train_error 29.8125%  acc_test_error 50.0%\n",
      "Epoch: 1927 Loss: 9.73938274383545  acc_train_error 29.8125%  acc_test_error 50.0%\n",
      "Epoch: 1928 Loss: 9.734183311462402  acc_train_error 29.8125%  acc_test_error 50.0%\n",
      "Epoch: 1929 Loss: 9.728982925415039  acc_train_error 29.8125%  acc_test_error 50.0%\n",
      "Epoch: 1930 Loss: 9.723773002624512  acc_train_error 29.8125%  acc_test_error 50.0%\n",
      "Epoch: 1931 Loss: 9.718555450439453  acc_train_error 29.825%  acc_test_error 50.0%\n",
      "Epoch: 1932 Loss: 9.713349342346191  acc_train_error 29.825%  acc_test_error 50.0%\n",
      "Epoch: 1933 Loss: 9.708137512207031  acc_train_error 29.825%  acc_test_error 50.0%\n",
      "Epoch: 1934 Loss: 9.702937126159668  acc_train_error 29.825%  acc_test_error 50.0%\n",
      "Epoch: 1935 Loss: 9.697737693786621  acc_train_error 29.8375%  acc_test_error 50.0%\n",
      "Epoch: 1936 Loss: 9.692536354064941  acc_train_error 29.8375%  acc_test_error 50.0%\n",
      "Epoch: 1937 Loss: 9.687335014343262  acc_train_error 29.8375%  acc_test_error 50.0%\n",
      "Epoch: 1938 Loss: 9.682138442993164  acc_train_error 29.8375%  acc_test_error 50.0%\n",
      "Epoch: 1939 Loss: 9.676950454711914  acc_train_error 29.85%  acc_test_error 50.0%\n",
      "Epoch: 1940 Loss: 9.671760559082031  acc_train_error 29.85%  acc_test_error 50.0%\n",
      "Epoch: 1941 Loss: 9.666572570800781  acc_train_error 29.85%  acc_test_error 50.0%\n",
      "Epoch: 1942 Loss: 9.66139030456543  acc_train_error 29.85%  acc_test_error 50.0%\n",
      "Epoch: 1943 Loss: 9.656204223632812  acc_train_error 29.8625%  acc_test_error 50.0%\n",
      "Epoch: 1944 Loss: 9.651029586791992  acc_train_error 29.8625%  acc_test_error 50.0%\n",
      "Epoch: 1945 Loss: 9.645856857299805  acc_train_error 29.8625%  acc_test_error 50.0%\n",
      "Epoch: 1946 Loss: 9.640686988830566  acc_train_error 29.8625%  acc_test_error 50.0%\n",
      "Epoch: 1947 Loss: 9.635519027709961  acc_train_error 29.875%  acc_test_error 50.0%\n",
      "Epoch: 1948 Loss: 9.630356788635254  acc_train_error 29.875%  acc_test_error 50.0%\n",
      "Epoch: 1949 Loss: 9.625192642211914  acc_train_error 29.875%  acc_test_error 50.0%\n",
      "Epoch: 1950 Loss: 9.62002944946289  acc_train_error 29.875%  acc_test_error 50.0%\n",
      "Epoch: 1951 Loss: 9.614869117736816  acc_train_error 29.8875%  acc_test_error 50.0%\n",
      "Epoch: 1952 Loss: 9.609707832336426  acc_train_error 29.8875%  acc_test_error 50.0%\n",
      "Epoch: 1953 Loss: 9.604549407958984  acc_train_error 29.8875%  acc_test_error 50.0%\n",
      "Epoch: 1954 Loss: 9.599384307861328  acc_train_error 29.8875%  acc_test_error 50.0%\n",
      "Epoch: 1955 Loss: 9.594218254089355  acc_train_error 29.9%  acc_test_error 50.0%\n",
      "Epoch: 1956 Loss: 9.589041709899902  acc_train_error 29.9%  acc_test_error 50.0%\n",
      "Epoch: 1957 Loss: 9.583883285522461  acc_train_error 29.9%  acc_test_error 50.0%\n",
      "Epoch: 1958 Loss: 9.578723907470703  acc_train_error 29.9%  acc_test_error 50.0%\n",
      "Epoch: 1959 Loss: 9.573564529418945  acc_train_error 29.9125%  acc_test_error 50.0%\n",
      "Epoch: 1960 Loss: 9.568411827087402  acc_train_error 29.9125%  acc_test_error 50.0%\n",
      "Epoch: 1961 Loss: 9.563264846801758  acc_train_error 29.9125%  acc_test_error 50.0%\n",
      "Epoch: 1962 Loss: 9.558130264282227  acc_train_error 29.9125%  acc_test_error 50.0%\n",
      "Epoch: 1963 Loss: 9.552993774414062  acc_train_error 29.925%  acc_test_error 50.0%\n",
      "Epoch: 1964 Loss: 9.547863960266113  acc_train_error 29.925%  acc_test_error 50.0%\n",
      "Epoch: 1965 Loss: 9.542736053466797  acc_train_error 29.925%  acc_test_error 50.0%\n",
      "Epoch: 1966 Loss: 9.537603378295898  acc_train_error 29.925%  acc_test_error 50.0%\n",
      "Epoch: 1967 Loss: 9.532470703125  acc_train_error 29.9375%  acc_test_error 50.0%\n",
      "Epoch: 1968 Loss: 9.527332305908203  acc_train_error 29.9375%  acc_test_error 50.0%\n",
      "Epoch: 1969 Loss: 9.522201538085938  acc_train_error 29.9375%  acc_test_error 50.0%\n",
      "Epoch: 1970 Loss: 9.517071723937988  acc_train_error 29.9375%  acc_test_error 50.0%\n",
      "Epoch: 1971 Loss: 9.511947631835938  acc_train_error 29.9375%  acc_test_error 50.0%\n",
      "Epoch: 1972 Loss: 9.50683307647705  acc_train_error 29.95%  acc_test_error 50.0%\n",
      "Epoch: 1973 Loss: 9.50172233581543  acc_train_error 29.95%  acc_test_error 50.0%\n",
      "Epoch: 1974 Loss: 9.496609687805176  acc_train_error 29.95%  acc_test_error 50.0%\n",
      "Epoch: 1975 Loss: 9.491501808166504  acc_train_error 29.95%  acc_test_error 50.0%\n",
      "Epoch: 1976 Loss: 9.486403465270996  acc_train_error 29.9625%  acc_test_error 50.0%\n",
      "Epoch: 1977 Loss: 9.481314659118652  acc_train_error 29.9625%  acc_test_error 50.0%\n",
      "Epoch: 1978 Loss: 9.476227760314941  acc_train_error 29.9625%  acc_test_error 50.0%\n",
      "Epoch: 1979 Loss: 9.471151351928711  acc_train_error 29.9625%  acc_test_error 50.0%\n",
      "Epoch: 1980 Loss: 9.466079711914062  acc_train_error 29.9625%  acc_test_error 50.0%\n",
      "Epoch: 1981 Loss: 9.46101188659668  acc_train_error 29.975%  acc_test_error 50.0%\n",
      "Epoch: 1982 Loss: 9.45594596862793  acc_train_error 29.975%  acc_test_error 50.0%\n",
      "Epoch: 1983 Loss: 9.450889587402344  acc_train_error 29.975%  acc_test_error 50.0%\n",
      "Epoch: 1984 Loss: 9.44583511352539  acc_train_error 29.975%  acc_test_error 50.0%\n",
      "Epoch: 1985 Loss: 9.440788269042969  acc_train_error 29.975%  acc_test_error 50.0%\n",
      "Epoch: 1986 Loss: 9.43574333190918  acc_train_error 29.9875%  acc_test_error 50.0%\n",
      "Epoch: 1987 Loss: 9.430708885192871  acc_train_error 29.9875%  acc_test_error 50.0%\n",
      "Epoch: 1988 Loss: 9.425677299499512  acc_train_error 29.9875%  acc_test_error 50.0%\n",
      "Epoch: 1989 Loss: 9.420650482177734  acc_train_error 29.9875%  acc_test_error 50.0%\n",
      "Epoch: 1990 Loss: 9.415633201599121  acc_train_error 29.9875%  acc_test_error 50.0%\n",
      "Epoch: 1991 Loss: 9.410621643066406  acc_train_error 30.0%  acc_test_error 50.0%\n",
      "Epoch: 1992 Loss: 9.405613899230957  acc_train_error 30.0%  acc_test_error 50.0%\n",
      "Epoch: 1993 Loss: 9.400614738464355  acc_train_error 30.0%  acc_test_error 50.0%\n",
      "Epoch: 1994 Loss: 9.395617485046387  acc_train_error 30.0%  acc_test_error 50.0%\n",
      "Epoch: 1995 Loss: 9.390628814697266  acc_train_error 30.0%  acc_test_error 50.0%\n",
      "Epoch: 1996 Loss: 9.385641098022461  acc_train_error 30.0%  acc_test_error 50.0%\n",
      "Epoch: 1997 Loss: 9.380655288696289  acc_train_error 30.0125%  acc_test_error 50.0%\n",
      "Epoch: 1998 Loss: 9.375676155090332  acc_train_error 30.0125%  acc_test_error 50.0%\n",
      "Epoch: 1999 Loss: 9.370701789855957  acc_train_error 30.0125%  acc_test_error 50.0%\n",
      "Epoch: 2000 Loss: 9.36573314666748  acc_train_error 30.0125%  acc_test_error 50.0%\n",
      "Epoch: 2001 Loss: 9.360767364501953  acc_train_error 30.0125%  acc_test_error 50.0%\n",
      "Epoch: 2002 Loss: 9.355806350708008  acc_train_error 30.0125%  acc_test_error 50.0%\n",
      "Epoch: 2003 Loss: 9.350844383239746  acc_train_error 30.025%  acc_test_error 50.0%\n",
      "Epoch: 2004 Loss: 9.345888137817383  acc_train_error 30.025%  acc_test_error 50.0%\n",
      "Epoch: 2005 Loss: 9.340933799743652  acc_train_error 30.0125%  acc_test_error 50.0%\n",
      "Epoch: 2006 Loss: 9.335986137390137  acc_train_error 30.0125%  acc_test_error 50.0%\n",
      "Epoch: 2007 Loss: 9.331040382385254  acc_train_error 30.0125%  acc_test_error 50.0%\n",
      "Epoch: 2008 Loss: 9.326096534729004  acc_train_error 30.0125%  acc_test_error 50.0%\n",
      "Epoch: 2009 Loss: 9.321160316467285  acc_train_error 30.025%  acc_test_error 50.0%\n",
      "Epoch: 2010 Loss: 9.316230773925781  acc_train_error 30.025%  acc_test_error 50.0%\n",
      "Epoch: 2011 Loss: 9.311297416687012  acc_train_error 30.025%  acc_test_error 50.0%\n",
      "Epoch: 2012 Loss: 9.306374549865723  acc_train_error 30.025%  acc_test_error 50.0%\n",
      "Epoch: 2013 Loss: 9.301459312438965  acc_train_error 30.025%  acc_test_error 50.0%\n",
      "Epoch: 2014 Loss: 9.29654598236084  acc_train_error 30.025%  acc_test_error 50.0%\n",
      "Epoch: 2015 Loss: 9.291632652282715  acc_train_error 30.025%  acc_test_error 50.0%\n",
      "Epoch: 2016 Loss: 9.286736488342285  acc_train_error 30.0375%  acc_test_error 50.0%\n",
      "Epoch: 2017 Loss: 9.28183364868164  acc_train_error 30.0375%  acc_test_error 50.0%\n",
      "Epoch: 2018 Loss: 9.276936531066895  acc_train_error 30.0375%  acc_test_error 50.0%\n",
      "Epoch: 2019 Loss: 9.272046089172363  acc_train_error 30.0375%  acc_test_error 50.0%\n",
      "Epoch: 2020 Loss: 9.26716136932373  acc_train_error 30.0375%  acc_test_error 50.0%\n",
      "Epoch: 2021 Loss: 9.26227855682373  acc_train_error 30.0375%  acc_test_error 50.0%\n",
      "Epoch: 2022 Loss: 9.257401466369629  acc_train_error 30.0375%  acc_test_error 50.0%\n",
      "Epoch: 2023 Loss: 9.252524375915527  acc_train_error 30.05%  acc_test_error 50.0%\n",
      "Epoch: 2024 Loss: 9.24765682220459  acc_train_error 30.05%  acc_test_error 50.0%\n",
      "Epoch: 2025 Loss: 9.242790222167969  acc_train_error 30.05%  acc_test_error 50.0%\n",
      "Epoch: 2026 Loss: 9.237926483154297  acc_train_error 30.0375%  acc_test_error 50.0%\n",
      "Epoch: 2027 Loss: 9.233070373535156  acc_train_error 30.0375%  acc_test_error 50.0%\n",
      "Epoch: 2028 Loss: 9.228212356567383  acc_train_error 30.0375%  acc_test_error 50.0%\n",
      "Epoch: 2029 Loss: 9.223367691040039  acc_train_error 30.0375%  acc_test_error 50.0%\n",
      "Epoch: 2030 Loss: 9.21852970123291  acc_train_error 30.05%  acc_test_error 50.0%\n",
      "Epoch: 2031 Loss: 9.213687896728516  acc_train_error 30.05%  acc_test_error 50.0%\n",
      "Epoch: 2032 Loss: 9.20885181427002  acc_train_error 30.05%  acc_test_error 50.0%\n",
      "Epoch: 2033 Loss: 9.204011917114258  acc_train_error 30.05%  acc_test_error 50.0%\n",
      "Epoch: 2034 Loss: 9.199170112609863  acc_train_error 30.05%  acc_test_error 50.0%\n",
      "Epoch: 2035 Loss: 9.194330215454102  acc_train_error 30.05%  acc_test_error 50.0%\n",
      "Epoch: 2036 Loss: 9.189498901367188  acc_train_error 30.0625%  acc_test_error 50.0%\n",
      "Epoch: 2037 Loss: 9.18466854095459  acc_train_error 30.0625%  acc_test_error 50.0%\n",
      "Epoch: 2038 Loss: 9.17984390258789  acc_train_error 30.0625%  acc_test_error 50.0%\n",
      "Epoch: 2039 Loss: 9.175020217895508  acc_train_error 30.0625%  acc_test_error 50.0%\n",
      "Epoch: 2040 Loss: 9.17020034790039  acc_train_error 30.0625%  acc_test_error 50.0%\n",
      "Epoch: 2041 Loss: 9.165393829345703  acc_train_error 30.05%  acc_test_error 50.0%\n",
      "Epoch: 2042 Loss: 9.1605806350708  acc_train_error 30.0625%  acc_test_error 50.0%\n",
      "Epoch: 2043 Loss: 9.155773162841797  acc_train_error 30.0625%  acc_test_error 50.0%\n",
      "Epoch: 2044 Loss: 9.150980949401855  acc_train_error 30.0625%  acc_test_error 50.0%\n",
      "Epoch: 2045 Loss: 9.146183967590332  acc_train_error 30.0625%  acc_test_error 50.0%\n",
      "Epoch: 2046 Loss: 9.141392707824707  acc_train_error 30.0625%  acc_test_error 50.0%\n",
      "Epoch: 2047 Loss: 9.136605262756348  acc_train_error 30.0625%  acc_test_error 50.0%\n",
      "Epoch: 2048 Loss: 9.131819725036621  acc_train_error 30.0625%  acc_test_error 50.0%\n",
      "Epoch: 2049 Loss: 9.127039909362793  acc_train_error 30.075%  acc_test_error 50.0%\n",
      "Epoch: 2050 Loss: 9.122265815734863  acc_train_error 30.075%  acc_test_error 50.0%\n",
      "Epoch: 2051 Loss: 9.117508888244629  acc_train_error 30.075%  acc_test_error 50.0%\n",
      "Epoch: 2052 Loss: 9.11273193359375  acc_train_error 30.075%  acc_test_error 50.0%\n",
      "Epoch: 2053 Loss: 9.107975959777832  acc_train_error 30.075%  acc_test_error 50.0%\n",
      "Epoch: 2054 Loss: 9.10322380065918  acc_train_error 30.075%  acc_test_error 50.0%\n",
      "Epoch: 2055 Loss: 9.09847354888916  acc_train_error 30.075%  acc_test_error 50.0%\n",
      "Epoch: 2056 Loss: 9.093721389770508  acc_train_error 30.0875%  acc_test_error 50.0%\n",
      "Epoch: 2057 Loss: 9.08897876739502  acc_train_error 30.0875%  acc_test_error 50.0%\n",
      "Epoch: 2058 Loss: 9.08423900604248  acc_train_error 30.0875%  acc_test_error 50.0%\n",
      "Epoch: 2059 Loss: 9.079500198364258  acc_train_error 30.075%  acc_test_error 50.0%\n",
      "Epoch: 2060 Loss: 9.074775695800781  acc_train_error 30.075%  acc_test_error 50.0%\n",
      "Epoch: 2061 Loss: 9.070040702819824  acc_train_error 30.075%  acc_test_error 50.0%\n",
      "Epoch: 2062 Loss: 9.065313339233398  acc_train_error 30.0875%  acc_test_error 50.0%\n",
      "Epoch: 2063 Loss: 9.06059455871582  acc_train_error 30.0875%  acc_test_error 50.0%\n",
      "Epoch: 2064 Loss: 9.055879592895508  acc_train_error 30.0875%  acc_test_error 50.0%\n",
      "Epoch: 2065 Loss: 9.051161766052246  acc_train_error 30.0875%  acc_test_error 50.0%\n",
      "Epoch: 2066 Loss: 9.046455383300781  acc_train_error 30.0875%  acc_test_error 50.0%\n",
      "Epoch: 2067 Loss: 9.04174518585205  acc_train_error 30.0875%  acc_test_error 50.0%\n",
      "Epoch: 2068 Loss: 9.037036895751953  acc_train_error 30.1%  acc_test_error 50.0%\n",
      "Epoch: 2069 Loss: 9.032340049743652  acc_train_error 30.1%  acc_test_error 50.0%\n",
      "Epoch: 2070 Loss: 9.027641296386719  acc_train_error 30.1%  acc_test_error 50.0%\n",
      "Epoch: 2071 Loss: 9.022951126098633  acc_train_error 30.1%  acc_test_error 50.0%\n",
      "Epoch: 2072 Loss: 9.018260955810547  acc_train_error 30.1%  acc_test_error 50.0%\n",
      "Epoch: 2073 Loss: 9.01357364654541  acc_train_error 30.1%  acc_test_error 50.0%\n",
      "Epoch: 2074 Loss: 9.008896827697754  acc_train_error 30.1125%  acc_test_error 50.0%\n",
      "Epoch: 2075 Loss: 9.004212379455566  acc_train_error 30.1125%  acc_test_error 50.0%\n",
      "Epoch: 2076 Loss: 8.999547004699707  acc_train_error 30.1125%  acc_test_error 50.0%\n",
      "Epoch: 2077 Loss: 8.994878768920898  acc_train_error 30.1125%  acc_test_error 50.0%\n",
      "Epoch: 2078 Loss: 8.990217208862305  acc_train_error 30.125%  acc_test_error 50.0%\n",
      "Epoch: 2079 Loss: 8.985562324523926  acc_train_error 30.1125%  acc_test_error 50.0%\n",
      "Epoch: 2080 Loss: 8.980914115905762  acc_train_error 30.1125%  acc_test_error 50.0%\n",
      "Epoch: 2081 Loss: 8.976263046264648  acc_train_error 30.1125%  acc_test_error 50.0%\n",
      "Epoch: 2082 Loss: 8.97160816192627  acc_train_error 30.1125%  acc_test_error 50.0%\n",
      "Epoch: 2083 Loss: 8.966971397399902  acc_train_error 30.125%  acc_test_error 50.0%\n",
      "Epoch: 2084 Loss: 8.96233081817627  acc_train_error 30.125%  acc_test_error 50.0%\n",
      "Epoch: 2085 Loss: 8.957688331604004  acc_train_error 30.125%  acc_test_error 50.0%\n",
      "Epoch: 2086 Loss: 8.953058242797852  acc_train_error 30.125%  acc_test_error 50.0%\n",
      "Epoch: 2087 Loss: 8.948427200317383  acc_train_error 30.1375%  acc_test_error 50.0%\n",
      "Epoch: 2088 Loss: 8.943791389465332  acc_train_error 30.1375%  acc_test_error 50.0%\n",
      "Epoch: 2089 Loss: 8.939168930053711  acc_train_error 30.1375%  acc_test_error 50.0%\n",
      "Epoch: 2090 Loss: 8.93454647064209  acc_train_error 30.1375%  acc_test_error 50.0%\n",
      "Epoch: 2091 Loss: 8.929924011230469  acc_train_error 30.15%  acc_test_error 50.0%\n",
      "Epoch: 2092 Loss: 8.925312042236328  acc_train_error 30.15%  acc_test_error 50.0%\n",
      "Epoch: 2093 Loss: 8.92070484161377  acc_train_error 30.15%  acc_test_error 50.0%\n",
      "Epoch: 2094 Loss: 8.916099548339844  acc_train_error 30.1375%  acc_test_error 50.0%\n",
      "Epoch: 2095 Loss: 8.911498069763184  acc_train_error 30.1375%  acc_test_error 50.0%\n",
      "Epoch: 2096 Loss: 8.906900405883789  acc_train_error 30.15%  acc_test_error 50.0%\n",
      "Epoch: 2097 Loss: 8.902311325073242  acc_train_error 30.15%  acc_test_error 50.0%\n",
      "Epoch: 2098 Loss: 8.897722244262695  acc_train_error 30.15%  acc_test_error 50.0%\n",
      "Epoch: 2099 Loss: 8.893139839172363  acc_train_error 30.15%  acc_test_error 50.0%\n",
      "Epoch: 2100 Loss: 8.888555526733398  acc_train_error 30.1625%  acc_test_error 50.0%\n",
      "Epoch: 2101 Loss: 8.8839750289917  acc_train_error 30.1625%  acc_test_error 50.0%\n",
      "Epoch: 2102 Loss: 8.879403114318848  acc_train_error 30.1625%  acc_test_error 50.0%\n",
      "Epoch: 2103 Loss: 8.874829292297363  acc_train_error 30.1625%  acc_test_error 50.0%\n",
      "Epoch: 2104 Loss: 8.870261192321777  acc_train_error 30.175%  acc_test_error 50.0%\n",
      "Epoch: 2105 Loss: 8.865696907043457  acc_train_error 30.175%  acc_test_error 50.0%\n",
      "Epoch: 2106 Loss: 8.861130714416504  acc_train_error 30.1625%  acc_test_error 50.0%\n",
      "Epoch: 2107 Loss: 8.856576919555664  acc_train_error 30.1625%  acc_test_error 50.0%\n",
      "Epoch: 2108 Loss: 8.852020263671875  acc_train_error 30.175%  acc_test_error 50.0%\n",
      "Epoch: 2109 Loss: 8.847467422485352  acc_train_error 30.175%  acc_test_error 50.0%\n",
      "Epoch: 2110 Loss: 8.84292221069336  acc_train_error 30.175%  acc_test_error 50.0%\n",
      "Epoch: 2111 Loss: 8.83837604522705  acc_train_error 30.175%  acc_test_error 50.0%\n",
      "Epoch: 2112 Loss: 8.833836555480957  acc_train_error 30.1875%  acc_test_error 50.0%\n",
      "Epoch: 2113 Loss: 8.829303741455078  acc_train_error 30.1875%  acc_test_error 50.0%\n",
      "Epoch: 2114 Loss: 8.82476806640625  acc_train_error 30.1875%  acc_test_error 50.0%\n",
      "Epoch: 2115 Loss: 8.820235252380371  acc_train_error 30.1875%  acc_test_error 50.0%\n",
      "Epoch: 2116 Loss: 8.81570816040039  acc_train_error 30.2%  acc_test_error 50.0%\n",
      "Epoch: 2117 Loss: 8.811184883117676  acc_train_error 30.2%  acc_test_error 50.0%\n",
      "Epoch: 2118 Loss: 8.80666446685791  acc_train_error 30.2%  acc_test_error 50.0%\n",
      "Epoch: 2119 Loss: 8.80214786529541  acc_train_error 30.2%  acc_test_error 50.0%\n",
      "Epoch: 2120 Loss: 8.797635078430176  acc_train_error 30.2125%  acc_test_error 50.0%\n",
      "Epoch: 2121 Loss: 8.79312801361084  acc_train_error 30.2%  acc_test_error 50.0%\n",
      "Epoch: 2122 Loss: 8.78862190246582  acc_train_error 30.2%  acc_test_error 50.0%\n",
      "Epoch: 2123 Loss: 8.784123420715332  acc_train_error 30.2%  acc_test_error 50.0%\n",
      "Epoch: 2124 Loss: 8.779629707336426  acc_train_error 30.2125%  acc_test_error 50.0%\n",
      "Epoch: 2125 Loss: 8.775137901306152  acc_train_error 30.2125%  acc_test_error 50.0%\n",
      "Epoch: 2126 Loss: 8.77065372467041  acc_train_error 30.2125%  acc_test_error 50.0%\n",
      "Epoch: 2127 Loss: 8.766165733337402  acc_train_error 30.2125%  acc_test_error 50.0%\n",
      "Epoch: 2128 Loss: 8.761682510375977  acc_train_error 30.225%  acc_test_error 50.0%\n",
      "Epoch: 2129 Loss: 8.757210731506348  acc_train_error 30.225%  acc_test_error 50.0%\n",
      "Epoch: 2130 Loss: 8.752735137939453  acc_train_error 30.225%  acc_test_error 50.0%\n",
      "Epoch: 2131 Loss: 8.748270034790039  acc_train_error 30.225%  acc_test_error 50.0%\n",
      "Epoch: 2132 Loss: 8.743804931640625  acc_train_error 30.2375%  acc_test_error 50.0%\n",
      "Epoch: 2133 Loss: 8.739341735839844  acc_train_error 30.2375%  acc_test_error 50.0%\n",
      "Epoch: 2134 Loss: 8.73488712310791  acc_train_error 30.225%  acc_test_error 50.0%\n",
      "Epoch: 2135 Loss: 8.73043155670166  acc_train_error 30.225%  acc_test_error 50.0%\n",
      "Epoch: 2136 Loss: 8.72597885131836  acc_train_error 30.225%  acc_test_error 50.0%\n",
      "Epoch: 2137 Loss: 8.721531867980957  acc_train_error 30.2375%  acc_test_error 50.0%\n",
      "Epoch: 2138 Loss: 8.717092514038086  acc_train_error 30.2375%  acc_test_error 50.0%\n",
      "Epoch: 2139 Loss: 8.712652206420898  acc_train_error 30.2375%  acc_test_error 50.0%\n",
      "Epoch: 2140 Loss: 8.708218574523926  acc_train_error 30.2375%  acc_test_error 50.0%\n",
      "Epoch: 2141 Loss: 8.703783988952637  acc_train_error 30.25%  acc_test_error 50.0%\n",
      "Epoch: 2142 Loss: 8.699358940124512  acc_train_error 30.25%  acc_test_error 50.0%\n",
      "Epoch: 2143 Loss: 8.694931983947754  acc_train_error 30.25%  acc_test_error 50.0%\n",
      "Epoch: 2144 Loss: 8.69051742553711  acc_train_error 30.25%  acc_test_error 50.0%\n",
      "Epoch: 2145 Loss: 8.6860990524292  acc_train_error 30.2375%  acc_test_error 50.0%\n",
      "Epoch: 2146 Loss: 8.681686401367188  acc_train_error 30.25%  acc_test_error 50.0%\n",
      "Epoch: 2147 Loss: 8.677275657653809  acc_train_error 30.25%  acc_test_error 50.0%\n",
      "Epoch: 2148 Loss: 8.672871589660645  acc_train_error 30.25%  acc_test_error 50.0%\n",
      "Epoch: 2149 Loss: 8.66847038269043  acc_train_error 30.25%  acc_test_error 50.0%\n",
      "Epoch: 2150 Loss: 8.664067268371582  acc_train_error 30.25%  acc_test_error 50.0%\n",
      "Epoch: 2151 Loss: 8.659676551818848  acc_train_error 30.2625%  acc_test_error 50.0%\n",
      "Epoch: 2152 Loss: 8.655284881591797  acc_train_error 30.2625%  acc_test_error 50.0%\n",
      "Epoch: 2153 Loss: 8.650890350341797  acc_train_error 30.2625%  acc_test_error 50.0%\n",
      "Epoch: 2154 Loss: 8.646504402160645  acc_train_error 30.2625%  acc_test_error 50.0%\n",
      "Epoch: 2155 Loss: 8.642120361328125  acc_train_error 30.25%  acc_test_error 50.0%\n",
      "Epoch: 2156 Loss: 8.637737274169922  acc_train_error 30.2625%  acc_test_error 50.0%\n",
      "Epoch: 2157 Loss: 8.633360862731934  acc_train_error 30.2625%  acc_test_error 50.0%\n",
      "Epoch: 2158 Loss: 8.628983497619629  acc_train_error 30.2625%  acc_test_error 50.0%\n",
      "Epoch: 2159 Loss: 8.624622344970703  acc_train_error 30.2625%  acc_test_error 50.0%\n",
      "Epoch: 2160 Loss: 8.620260238647461  acc_train_error 30.275%  acc_test_error 50.0%\n",
      "Epoch: 2161 Loss: 8.615900993347168  acc_train_error 30.275%  acc_test_error 50.0%\n",
      "Epoch: 2162 Loss: 8.611542701721191  acc_train_error 30.275%  acc_test_error 50.0%\n",
      "Epoch: 2163 Loss: 8.607193946838379  acc_train_error 30.2625%  acc_test_error 50.0%\n",
      "Epoch: 2164 Loss: 8.6028413772583  acc_train_error 30.2625%  acc_test_error 50.0%\n",
      "Epoch: 2165 Loss: 8.598488807678223  acc_train_error 30.275%  acc_test_error 50.0%\n",
      "Epoch: 2166 Loss: 8.594145774841309  acc_train_error 30.275%  acc_test_error 50.0%\n",
      "Epoch: 2167 Loss: 8.589798927307129  acc_train_error 30.275%  acc_test_error 50.0%\n",
      "Epoch: 2168 Loss: 8.585455894470215  acc_train_error 30.275%  acc_test_error 50.0%\n",
      "Epoch: 2169 Loss: 8.581123352050781  acc_train_error 30.275%  acc_test_error 50.0%\n",
      "Epoch: 2170 Loss: 8.576786994934082  acc_train_error 30.2875%  acc_test_error 50.0%\n",
      "Epoch: 2171 Loss: 8.572455406188965  acc_train_error 30.2875%  acc_test_error 50.0%\n",
      "Epoch: 2172 Loss: 8.568124771118164  acc_train_error 30.275%  acc_test_error 50.0%\n",
      "Epoch: 2173 Loss: 8.563803672790527  acc_train_error 30.275%  acc_test_error 50.0%\n",
      "Epoch: 2174 Loss: 8.559480667114258  acc_train_error 30.275%  acc_test_error 50.0%\n",
      "Epoch: 2175 Loss: 8.555160522460938  acc_train_error 30.2875%  acc_test_error 50.0%\n",
      "Epoch: 2176 Loss: 8.550848007202148  acc_train_error 30.2875%  acc_test_error 50.0%\n",
      "Epoch: 2177 Loss: 8.546536445617676  acc_train_error 30.2875%  acc_test_error 50.0%\n",
      "Epoch: 2178 Loss: 8.542224884033203  acc_train_error 30.2875%  acc_test_error 50.0%\n",
      "Epoch: 2179 Loss: 8.537922859191895  acc_train_error 30.3%  acc_test_error 50.0%\n",
      "Epoch: 2180 Loss: 8.53361988067627  acc_train_error 30.3%  acc_test_error 50.0%\n",
      "Epoch: 2181 Loss: 8.529319763183594  acc_train_error 30.2875%  acc_test_error 50.0%\n",
      "Epoch: 2182 Loss: 8.5250244140625  acc_train_error 30.2875%  acc_test_error 50.0%\n",
      "Epoch: 2183 Loss: 8.520730972290039  acc_train_error 30.3%  acc_test_error 50.0%\n",
      "Epoch: 2184 Loss: 8.516434669494629  acc_train_error 30.3%  acc_test_error 50.0%\n",
      "Epoch: 2185 Loss: 8.51214599609375  acc_train_error 30.3%  acc_test_error 50.0%\n",
      "Epoch: 2186 Loss: 8.507855415344238  acc_train_error 30.3%  acc_test_error 50.0%\n",
      "Epoch: 2187 Loss: 8.503567695617676  acc_train_error 30.3125%  acc_test_error 50.0%\n",
      "Epoch: 2188 Loss: 8.49928092956543  acc_train_error 30.3125%  acc_test_error 50.0%\n",
      "Epoch: 2189 Loss: 8.494996070861816  acc_train_error 30.3%  acc_test_error 50.0%\n",
      "Epoch: 2190 Loss: 8.49071979522705  acc_train_error 30.3%  acc_test_error 50.0%\n",
      "Epoch: 2191 Loss: 8.486435890197754  acc_train_error 30.3125%  acc_test_error 50.0%\n",
      "Epoch: 2192 Loss: 8.482154846191406  acc_train_error 30.3125%  acc_test_error 50.0%\n",
      "Epoch: 2193 Loss: 8.477877616882324  acc_train_error 30.3125%  acc_test_error 50.0%\n",
      "Epoch: 2194 Loss: 8.473600387573242  acc_train_error 30.3125%  acc_test_error 50.0%\n",
      "Epoch: 2195 Loss: 8.469331741333008  acc_train_error 30.325%  acc_test_error 50.0%\n",
      "Epoch: 2196 Loss: 8.46506118774414  acc_train_error 30.325%  acc_test_error 50.0%\n",
      "Epoch: 2197 Loss: 8.460793495178223  acc_train_error 30.3125%  acc_test_error 50.0%\n",
      "Epoch: 2198 Loss: 8.456527709960938  acc_train_error 30.3125%  acc_test_error 50.0%\n",
      "Epoch: 2199 Loss: 8.45226001739502  acc_train_error 30.325%  acc_test_error 50.0%\n",
      "Epoch: 2200 Loss: 8.447998046875  acc_train_error 30.325%  acc_test_error 50.0%\n",
      "Epoch: 2201 Loss: 8.443735122680664  acc_train_error 30.325%  acc_test_error 50.0%\n",
      "Epoch: 2202 Loss: 8.439477920532227  acc_train_error 30.325%  acc_test_error 50.0%\n",
      "Epoch: 2203 Loss: 8.435223579406738  acc_train_error 30.325%  acc_test_error 50.0%\n",
      "Epoch: 2204 Loss: 8.4309720993042  acc_train_error 30.325%  acc_test_error 50.0%\n",
      "Epoch: 2205 Loss: 8.426717758178711  acc_train_error 30.325%  acc_test_error 50.0%\n",
      "Epoch: 2206 Loss: 8.42246150970459  acc_train_error 30.325%  acc_test_error 50.0%\n",
      "Epoch: 2207 Loss: 8.418213844299316  acc_train_error 30.325%  acc_test_error 50.0%\n",
      "Epoch: 2208 Loss: 8.413963317871094  acc_train_error 30.325%  acc_test_error 50.0%\n",
      "Epoch: 2209 Loss: 8.409717559814453  acc_train_error 30.325%  acc_test_error 50.0%\n",
      "Epoch: 2210 Loss: 8.405471801757812  acc_train_error 30.325%  acc_test_error 50.0%\n",
      "Epoch: 2211 Loss: 8.401228904724121  acc_train_error 30.325%  acc_test_error 50.0%\n",
      "Epoch: 2212 Loss: 8.396995544433594  acc_train_error 30.325%  acc_test_error 50.0%\n",
      "Epoch: 2213 Loss: 8.39276123046875  acc_train_error 30.3375%  acc_test_error 50.0%\n",
      "Epoch: 2214 Loss: 8.388526916503906  acc_train_error 30.325%  acc_test_error 50.0%\n",
      "Epoch: 2215 Loss: 8.384296417236328  acc_train_error 30.325%  acc_test_error 50.0%\n",
      "Epoch: 2216 Loss: 8.380066871643066  acc_train_error 30.325%  acc_test_error 50.0%\n",
      "Epoch: 2217 Loss: 8.375842094421387  acc_train_error 30.325%  acc_test_error 50.0%\n",
      "Epoch: 2218 Loss: 8.37161922454834  acc_train_error 30.3375%  acc_test_error 50.0%\n",
      "Epoch: 2219 Loss: 8.367398262023926  acc_train_error 30.3375%  acc_test_error 50.0%\n",
      "Epoch: 2220 Loss: 8.363181114196777  acc_train_error 30.325%  acc_test_error 50.0%\n",
      "Epoch: 2221 Loss: 8.358922004699707  acc_train_error 30.325%  acc_test_error 50.0%\n",
      "Epoch: 2222 Loss: 8.354668617248535  acc_train_error 30.325%  acc_test_error 50.0%\n",
      "Epoch: 2223 Loss: 8.350417137145996  acc_train_error 30.325%  acc_test_error 50.0%\n",
      "Epoch: 2224 Loss: 8.346168518066406  acc_train_error 30.325%  acc_test_error 50.0%\n",
      "Epoch: 2225 Loss: 8.341928482055664  acc_train_error 30.3125%  acc_test_error 50.0%\n",
      "Epoch: 2226 Loss: 8.337690353393555  acc_train_error 30.3125%  acc_test_error 50.0%\n",
      "Epoch: 2227 Loss: 8.333455085754395  acc_train_error 30.3125%  acc_test_error 50.0%\n",
      "Epoch: 2228 Loss: 8.329228401184082  acc_train_error 30.3125%  acc_test_error 50.0%\n",
      "Epoch: 2229 Loss: 8.325000762939453  acc_train_error 30.3125%  acc_test_error 50.0%\n",
      "Epoch: 2230 Loss: 8.320791244506836  acc_train_error 30.3125%  acc_test_error 50.0%\n",
      "Epoch: 2231 Loss: 8.316577911376953  acc_train_error 30.3125%  acc_test_error 50.0%\n",
      "Epoch: 2232 Loss: 8.31236743927002  acc_train_error 30.3125%  acc_test_error 50.0%\n",
      "Epoch: 2233 Loss: 8.308158874511719  acc_train_error 30.3125%  acc_test_error 50.0%\n",
      "Epoch: 2234 Loss: 8.303959846496582  acc_train_error 30.3125%  acc_test_error 50.0%\n",
      "Epoch: 2235 Loss: 8.299759864807129  acc_train_error 30.3125%  acc_test_error 50.0%\n",
      "Epoch: 2236 Loss: 8.295568466186523  acc_train_error 30.3%  acc_test_error 50.0%\n",
      "Epoch: 2237 Loss: 8.291375160217285  acc_train_error 30.3%  acc_test_error 50.0%\n",
      "Epoch: 2238 Loss: 8.287188529968262  acc_train_error 30.3%  acc_test_error 50.0%\n",
      "Epoch: 2239 Loss: 8.283004760742188  acc_train_error 30.3125%  acc_test_error 50.0%\n",
      "Epoch: 2240 Loss: 8.278826713562012  acc_train_error 30.3125%  acc_test_error 50.0%\n",
      "Epoch: 2241 Loss: 8.274646759033203  acc_train_error 30.3%  acc_test_error 50.0%\n",
      "Epoch: 2242 Loss: 8.270478248596191  acc_train_error 30.3%  acc_test_error 50.0%\n",
      "Epoch: 2243 Loss: 8.266308784484863  acc_train_error 30.3%  acc_test_error 50.0%\n",
      "Epoch: 2244 Loss: 8.262134552001953  acc_train_error 30.3%  acc_test_error 50.0%\n",
      "Epoch: 2245 Loss: 8.257969856262207  acc_train_error 30.3125%  acc_test_error 50.0%\n",
      "Epoch: 2246 Loss: 8.253792762756348  acc_train_error 30.3125%  acc_test_error 50.0%\n",
      "Epoch: 2247 Loss: 8.24962043762207  acc_train_error 30.3125%  acc_test_error 50.0%\n",
      "Epoch: 2248 Loss: 8.245450973510742  acc_train_error 30.3%  acc_test_error 50.0%\n",
      "Epoch: 2249 Loss: 8.241290092468262  acc_train_error 30.3%  acc_test_error 50.0%\n",
      "Epoch: 2250 Loss: 8.237133979797363  acc_train_error 30.3125%  acc_test_error 50.0%\n",
      "Epoch: 2251 Loss: 8.232976913452148  acc_train_error 30.3125%  acc_test_error 50.0%\n",
      "Epoch: 2252 Loss: 8.228825569152832  acc_train_error 30.3125%  acc_test_error 50.0%\n",
      "Epoch: 2253 Loss: 8.224672317504883  acc_train_error 30.3125%  acc_test_error 50.0%\n",
      "Epoch: 2254 Loss: 8.220532417297363  acc_train_error 30.3125%  acc_test_error 50.0%\n",
      "Epoch: 2255 Loss: 8.216387748718262  acc_train_error 30.325%  acc_test_error 50.0%\n",
      "Epoch: 2256 Loss: 8.21224308013916  acc_train_error 30.3125%  acc_test_error 50.0%\n",
      "Epoch: 2257 Loss: 8.208101272583008  acc_train_error 30.3125%  acc_test_error 50.0%\n",
      "Epoch: 2258 Loss: 8.203963279724121  acc_train_error 30.3125%  acc_test_error 50.0%\n",
      "Epoch: 2259 Loss: 8.199828147888184  acc_train_error 30.3125%  acc_test_error 50.0%\n",
      "Epoch: 2260 Loss: 8.195690155029297  acc_train_error 30.325%  acc_test_error 50.0%\n",
      "Epoch: 2261 Loss: 8.191567420959473  acc_train_error 30.325%  acc_test_error 50.0%\n",
      "Epoch: 2262 Loss: 8.187440872192383  acc_train_error 30.325%  acc_test_error 50.0%\n",
      "Epoch: 2263 Loss: 8.183318138122559  acc_train_error 30.325%  acc_test_error 50.0%\n",
      "Epoch: 2264 Loss: 8.179197311401367  acc_train_error 30.3125%  acc_test_error 50.0%\n",
      "Epoch: 2265 Loss: 8.17507553100586  acc_train_error 30.3125%  acc_test_error 50.0%\n",
      "Epoch: 2266 Loss: 8.170969009399414  acc_train_error 30.325%  acc_test_error 50.0%\n",
      "Epoch: 2267 Loss: 8.166853904724121  acc_train_error 30.325%  acc_test_error 50.0%\n",
      "Epoch: 2268 Loss: 8.162740707397461  acc_train_error 30.325%  acc_test_error 50.0%\n",
      "Epoch: 2269 Loss: 8.158634185791016  acc_train_error 30.325%  acc_test_error 50.0%\n",
      "Epoch: 2270 Loss: 8.154531478881836  acc_train_error 30.325%  acc_test_error 50.0%\n",
      "Epoch: 2271 Loss: 8.150422096252441  acc_train_error 30.3375%  acc_test_error 50.0%\n",
      "Epoch: 2272 Loss: 8.146322250366211  acc_train_error 30.325%  acc_test_error 50.0%\n",
      "Epoch: 2273 Loss: 8.142229080200195  acc_train_error 30.325%  acc_test_error 50.0%\n",
      "Epoch: 2274 Loss: 8.138134956359863  acc_train_error 30.325%  acc_test_error 50.0%\n",
      "Epoch: 2275 Loss: 8.134035110473633  acc_train_error 30.325%  acc_test_error 50.0%\n",
      "Epoch: 2276 Loss: 8.12995719909668  acc_train_error 30.3375%  acc_test_error 50.0%\n",
      "Epoch: 2277 Loss: 8.125866889953613  acc_train_error 30.3375%  acc_test_error 50.0%\n",
      "Epoch: 2278 Loss: 8.121790885925293  acc_train_error 30.3375%  acc_test_error 50.0%\n",
      "Epoch: 2279 Loss: 8.117696762084961  acc_train_error 30.325%  acc_test_error 50.0%\n",
      "Epoch: 2280 Loss: 8.113632202148438  acc_train_error 30.325%  acc_test_error 50.0%\n",
      "Epoch: 2281 Loss: 8.109545707702637  acc_train_error 30.325%  acc_test_error 50.0%\n",
      "Epoch: 2282 Loss: 8.10547924041748  acc_train_error 30.325%  acc_test_error 50.0%\n",
      "Epoch: 2283 Loss: 8.101398468017578  acc_train_error 30.3375%  acc_test_error 50.0%\n",
      "Epoch: 2284 Loss: 8.097326278686523  acc_train_error 30.3375%  acc_test_error 50.0%\n",
      "Epoch: 2285 Loss: 8.093256950378418  acc_train_error 30.3375%  acc_test_error 50.0%\n",
      "Epoch: 2286 Loss: 8.089181900024414  acc_train_error 30.325%  acc_test_error 50.0%\n",
      "Epoch: 2287 Loss: 8.085119247436523  acc_train_error 30.325%  acc_test_error 50.0%\n",
      "Epoch: 2288 Loss: 8.081048011779785  acc_train_error 30.3375%  acc_test_error 50.0%\n",
      "Epoch: 2289 Loss: 8.076988220214844  acc_train_error 30.3375%  acc_test_error 50.0%\n",
      "Epoch: 2290 Loss: 8.072924613952637  acc_train_error 30.3375%  acc_test_error 50.0%\n",
      "Epoch: 2291 Loss: 8.068868637084961  acc_train_error 30.3375%  acc_test_error 50.0%\n",
      "Epoch: 2292 Loss: 8.064804077148438  acc_train_error 30.3375%  acc_test_error 50.0%\n",
      "Epoch: 2293 Loss: 8.060755729675293  acc_train_error 30.325%  acc_test_error 50.0%\n",
      "Epoch: 2294 Loss: 8.056699752807617  acc_train_error 30.3375%  acc_test_error 50.0%\n",
      "Epoch: 2295 Loss: 8.052656173706055  acc_train_error 30.3375%  acc_test_error 50.0%\n",
      "Epoch: 2296 Loss: 8.048604011535645  acc_train_error 30.3375%  acc_test_error 50.0%\n",
      "Epoch: 2297 Loss: 8.044564247131348  acc_train_error 30.3375%  acc_test_error 50.0%\n",
      "Epoch: 2298 Loss: 8.040517807006836  acc_train_error 30.3375%  acc_test_error 50.0%\n",
      "Epoch: 2299 Loss: 8.036480903625488  acc_train_error 30.3375%  acc_test_error 50.0%\n",
      "Epoch: 2300 Loss: 8.032438278198242  acc_train_error 30.3375%  acc_test_error 50.0%\n",
      "Epoch: 2301 Loss: 8.02840518951416  acc_train_error 30.3375%  acc_test_error 50.0%\n",
      "Epoch: 2302 Loss: 8.024364471435547  acc_train_error 30.3375%  acc_test_error 50.0%\n",
      "Epoch: 2303 Loss: 8.020336151123047  acc_train_error 30.3375%  acc_test_error 50.0%\n",
      "Epoch: 2304 Loss: 8.016305923461914  acc_train_error 30.3375%  acc_test_error 50.0%\n",
      "Epoch: 2305 Loss: 8.012273788452148  acc_train_error 30.35%  acc_test_error 50.0%\n",
      "Epoch: 2306 Loss: 8.008261680603027  acc_train_error 30.35%  acc_test_error 50.0%\n",
      "Epoch: 2307 Loss: 8.00422477722168  acc_train_error 30.3375%  acc_test_error 50.0%\n",
      "Epoch: 2308 Loss: 8.000187873840332  acc_train_error 30.3375%  acc_test_error 50.0%\n",
      "Epoch: 2309 Loss: 7.996155738830566  acc_train_error 30.35%  acc_test_error 50.0%\n",
      "Epoch: 2310 Loss: 7.992120265960693  acc_train_error 30.35%  acc_test_error 50.0%\n",
      "Epoch: 2311 Loss: 7.988094329833984  acc_train_error 30.35%  acc_test_error 50.0%\n",
      "Epoch: 2312 Loss: 7.984063625335693  acc_train_error 30.35%  acc_test_error 50.0%\n",
      "Epoch: 2313 Loss: 7.980043888092041  acc_train_error 30.3625%  acc_test_error 50.0%\n",
      "Epoch: 2314 Loss: 7.976021766662598  acc_train_error 30.3625%  acc_test_error 50.0%\n",
      "Epoch: 2315 Loss: 7.971996307373047  acc_train_error 30.3625%  acc_test_error 50.0%\n",
      "Epoch: 2316 Loss: 7.967987537384033  acc_train_error 30.3625%  acc_test_error 50.0%\n",
      "Epoch: 2317 Loss: 7.963969707489014  acc_train_error 30.375%  acc_test_error 50.0%\n",
      "Epoch: 2318 Loss: 7.9599609375  acc_train_error 30.3625%  acc_test_error 50.0%\n",
      "Epoch: 2319 Loss: 7.955949783325195  acc_train_error 30.3625%  acc_test_error 50.0%\n",
      "Epoch: 2320 Loss: 7.951949119567871  acc_train_error 30.3625%  acc_test_error 50.0%\n",
      "Epoch: 2321 Loss: 7.947944641113281  acc_train_error 30.375%  acc_test_error 50.0%\n",
      "Epoch: 2322 Loss: 7.943944931030273  acc_train_error 30.375%  acc_test_error 50.0%\n",
      "Epoch: 2323 Loss: 7.939946174621582  acc_train_error 30.375%  acc_test_error 50.0%\n",
      "Epoch: 2324 Loss: 7.935947895050049  acc_train_error 30.375%  acc_test_error 50.0%\n",
      "Epoch: 2325 Loss: 7.931960582733154  acc_train_error 30.3875%  acc_test_error 50.0%\n",
      "Epoch: 2326 Loss: 7.927966594696045  acc_train_error 30.3875%  acc_test_error 50.0%\n",
      "Epoch: 2327 Loss: 7.923974990844727  acc_train_error 30.3875%  acc_test_error 50.0%\n",
      "Epoch: 2328 Loss: 7.919994354248047  acc_train_error 30.3875%  acc_test_error 50.0%\n",
      "Epoch: 2329 Loss: 7.916006565093994  acc_train_error 30.3875%  acc_test_error 50.0%\n",
      "Epoch: 2330 Loss: 7.912031173706055  acc_train_error 30.3875%  acc_test_error 50.0%\n",
      "Epoch: 2331 Loss: 7.908051490783691  acc_train_error 30.3875%  acc_test_error 50.0%\n",
      "Epoch: 2332 Loss: 7.904079914093018  acc_train_error 30.3875%  acc_test_error 50.0%\n",
      "Epoch: 2333 Loss: 7.900106430053711  acc_train_error 30.4%  acc_test_error 50.0%\n",
      "Epoch: 2334 Loss: 7.8961334228515625  acc_train_error 30.4%  acc_test_error 50.0%\n",
      "Epoch: 2335 Loss: 7.892169952392578  acc_train_error 30.4%  acc_test_error 50.0%\n",
      "Epoch: 2336 Loss: 7.8881964683532715  acc_train_error 30.3875%  acc_test_error 50.0%\n",
      "Epoch: 2337 Loss: 7.884236812591553  acc_train_error 30.4%  acc_test_error 50.0%\n",
      "Epoch: 2338 Loss: 7.880265712738037  acc_train_error 30.4%  acc_test_error 50.0%\n",
      "Epoch: 2339 Loss: 7.876311302185059  acc_train_error 30.4%  acc_test_error 50.0%\n",
      "Epoch: 2340 Loss: 7.872351169586182  acc_train_error 30.4%  acc_test_error 50.0%\n",
      "Epoch: 2341 Loss: 7.868399620056152  acc_train_error 30.4%  acc_test_error 50.0%\n",
      "Epoch: 2342 Loss: 7.86444616317749  acc_train_error 30.4125%  acc_test_error 50.0%\n",
      "Epoch: 2343 Loss: 7.860503196716309  acc_train_error 30.4125%  acc_test_error 50.0%\n",
      "Epoch: 2344 Loss: 7.856552600860596  acc_train_error 30.4%  acc_test_error 50.0%\n",
      "Epoch: 2345 Loss: 7.852604866027832  acc_train_error 30.4%  acc_test_error 50.0%\n",
      "Epoch: 2346 Loss: 7.848669052124023  acc_train_error 30.4125%  acc_test_error 50.0%\n",
      "Epoch: 2347 Loss: 7.844720840454102  acc_train_error 30.4125%  acc_test_error 50.0%\n",
      "Epoch: 2348 Loss: 7.840787887573242  acc_train_error 30.4125%  acc_test_error 50.0%\n",
      "Epoch: 2349 Loss: 7.8368449211120605  acc_train_error 30.4125%  acc_test_error 50.0%\n",
      "Epoch: 2350 Loss: 7.832910060882568  acc_train_error 30.4125%  acc_test_error 50.0%\n",
      "Epoch: 2351 Loss: 7.828980922698975  acc_train_error 30.425%  acc_test_error 50.0%\n",
      "Epoch: 2352 Loss: 7.825048923492432  acc_train_error 30.4125%  acc_test_error 50.0%\n",
      "Epoch: 2353 Loss: 7.821128845214844  acc_train_error 30.4125%  acc_test_error 50.0%\n",
      "Epoch: 2354 Loss: 7.817201137542725  acc_train_error 30.4125%  acc_test_error 50.0%\n",
      "Epoch: 2355 Loss: 7.813282012939453  acc_train_error 30.4125%  acc_test_error 50.0%\n",
      "Epoch: 2356 Loss: 7.809360504150391  acc_train_error 30.425%  acc_test_error 50.0%\n",
      "Epoch: 2357 Loss: 7.805442810058594  acc_train_error 30.425%  acc_test_error 50.0%\n",
      "Epoch: 2358 Loss: 7.801525592803955  acc_train_error 30.425%  acc_test_error 50.0%\n",
      "Epoch: 2359 Loss: 7.7976155281066895  acc_train_error 30.425%  acc_test_error 50.0%\n",
      "Epoch: 2360 Loss: 7.793702125549316  acc_train_error 30.425%  acc_test_error 50.0%\n",
      "Epoch: 2361 Loss: 7.789794445037842  acc_train_error 30.425%  acc_test_error 50.0%\n",
      "Epoch: 2362 Loss: 7.785891532897949  acc_train_error 30.425%  acc_test_error 50.0%\n",
      "Epoch: 2363 Loss: 7.781984806060791  acc_train_error 30.425%  acc_test_error 50.0%\n",
      "Epoch: 2364 Loss: 7.778088092803955  acc_train_error 30.425%  acc_test_error 50.0%\n",
      "Epoch: 2365 Loss: 7.7741875648498535  acc_train_error 30.4375%  acc_test_error 50.0%\n",
      "Epoch: 2366 Loss: 7.770296096801758  acc_train_error 30.4375%  acc_test_error 50.0%\n",
      "Epoch: 2367 Loss: 7.766393184661865  acc_train_error 30.4375%  acc_test_error 50.0%\n",
      "Epoch: 2368 Loss: 7.762501239776611  acc_train_error 30.425%  acc_test_error 50.0%\n",
      "Epoch: 2369 Loss: 7.758607387542725  acc_train_error 30.425%  acc_test_error 50.0%\n",
      "Epoch: 2370 Loss: 7.75471305847168  acc_train_error 30.4375%  acc_test_error 50.0%\n",
      "Epoch: 2371 Loss: 7.750824928283691  acc_train_error 30.4375%  acc_test_error 50.0%\n",
      "Epoch: 2372 Loss: 7.746940612792969  acc_train_error 30.4375%  acc_test_error 50.0%\n",
      "Epoch: 2373 Loss: 7.743062496185303  acc_train_error 30.4375%  acc_test_error 50.0%\n",
      "Epoch: 2374 Loss: 7.7391767501831055  acc_train_error 30.4375%  acc_test_error 50.0%\n",
      "Epoch: 2375 Loss: 7.7353034019470215  acc_train_error 30.425%  acc_test_error 50.0%\n",
      "Epoch: 2376 Loss: 7.731420040130615  acc_train_error 30.425%  acc_test_error 50.0%\n",
      "Epoch: 2377 Loss: 7.727546691894531  acc_train_error 30.4375%  acc_test_error 50.0%\n",
      "Epoch: 2378 Loss: 7.723670482635498  acc_train_error 30.4375%  acc_test_error 50.0%\n",
      "Epoch: 2379 Loss: 7.719801902770996  acc_train_error 30.4375%  acc_test_error 50.0%\n",
      "Epoch: 2380 Loss: 7.7159223556518555  acc_train_error 30.4375%  acc_test_error 50.0%\n",
      "Epoch: 2381 Loss: 7.712059020996094  acc_train_error 30.4375%  acc_test_error 50.0%\n",
      "Epoch: 2382 Loss: 7.708186149597168  acc_train_error 30.4375%  acc_test_error 50.0%\n",
      "Epoch: 2383 Loss: 7.704329490661621  acc_train_error 30.45%  acc_test_error 50.0%\n",
      "Epoch: 2384 Loss: 7.700468063354492  acc_train_error 30.4375%  acc_test_error 50.0%\n",
      "Epoch: 2385 Loss: 7.696606636047363  acc_train_error 30.4375%  acc_test_error 50.0%\n",
      "Epoch: 2386 Loss: 7.692750930786133  acc_train_error 30.4375%  acc_test_error 50.0%\n",
      "Epoch: 2387 Loss: 7.6888933181762695  acc_train_error 30.4375%  acc_test_error 50.0%\n",
      "Epoch: 2388 Loss: 7.685044288635254  acc_train_error 30.45%  acc_test_error 50.0%\n",
      "Epoch: 2389 Loss: 7.681192874908447  acc_train_error 30.45%  acc_test_error 50.0%\n",
      "Epoch: 2390 Loss: 7.677346229553223  acc_train_error 30.45%  acc_test_error 50.0%\n",
      "Epoch: 2391 Loss: 7.673496246337891  acc_train_error 30.45%  acc_test_error 50.0%\n",
      "Epoch: 2392 Loss: 7.669654846191406  acc_train_error 30.4375%  acc_test_error 50.0%\n",
      "Epoch: 2393 Loss: 7.66580867767334  acc_train_error 30.45%  acc_test_error 50.0%\n",
      "Epoch: 2394 Loss: 7.661969184875488  acc_train_error 30.45%  acc_test_error 50.0%\n",
      "Epoch: 2395 Loss: 7.658133506774902  acc_train_error 30.45%  acc_test_error 50.0%\n",
      "Epoch: 2396 Loss: 7.654289722442627  acc_train_error 30.45%  acc_test_error 50.0%\n",
      "Epoch: 2397 Loss: 7.6504597663879395  acc_train_error 30.45%  acc_test_error 50.0%\n",
      "Epoch: 2398 Loss: 7.6466240882873535  acc_train_error 30.4625%  acc_test_error 50.0%\n",
      "Epoch: 2399 Loss: 7.642797946929932  acc_train_error 30.4625%  acc_test_error 50.0%\n",
      "Epoch: 2400 Loss: 7.6389665603637695  acc_train_error 30.4625%  acc_test_error 50.0%\n",
      "Epoch: 2401 Loss: 7.635146141052246  acc_train_error 30.4625%  acc_test_error 50.0%\n",
      "Epoch: 2402 Loss: 7.631319046020508  acc_train_error 30.4625%  acc_test_error 50.0%\n",
      "Epoch: 2403 Loss: 7.627495765686035  acc_train_error 30.4625%  acc_test_error 50.0%\n",
      "Epoch: 2404 Loss: 7.62367582321167  acc_train_error 30.4625%  acc_test_error 50.0%\n",
      "Epoch: 2405 Loss: 7.6198554039001465  acc_train_error 30.4625%  acc_test_error 50.0%\n",
      "Epoch: 2406 Loss: 7.616043567657471  acc_train_error 30.4625%  acc_test_error 50.0%\n",
      "Epoch: 2407 Loss: 7.6122283935546875  acc_train_error 30.475%  acc_test_error 50.0%\n",
      "Epoch: 2408 Loss: 7.608420372009277  acc_train_error 30.475%  acc_test_error 50.0%\n",
      "Epoch: 2409 Loss: 7.604607105255127  acc_train_error 30.475%  acc_test_error 50.0%\n",
      "Epoch: 2410 Loss: 7.60080099105835  acc_train_error 30.475%  acc_test_error 50.0%\n",
      "Epoch: 2411 Loss: 7.596991539001465  acc_train_error 30.475%  acc_test_error 50.0%\n",
      "Epoch: 2412 Loss: 7.593192100524902  acc_train_error 30.4875%  acc_test_error 50.0%\n",
      "Epoch: 2413 Loss: 7.589388370513916  acc_train_error 30.4875%  acc_test_error 50.0%\n",
      "Epoch: 2414 Loss: 7.585593223571777  acc_train_error 30.4875%  acc_test_error 50.0%\n",
      "Epoch: 2415 Loss: 7.581794738769531  acc_train_error 30.4875%  acc_test_error 50.0%\n",
      "Epoch: 2416 Loss: 7.577993392944336  acc_train_error 30.5%  acc_test_error 50.0%\n",
      "Epoch: 2417 Loss: 7.574199199676514  acc_train_error 30.5%  acc_test_error 50.0%\n",
      "Epoch: 2418 Loss: 7.570413112640381  acc_train_error 30.5125%  acc_test_error 50.0%\n",
      "Epoch: 2419 Loss: 7.566623210906982  acc_train_error 30.5125%  acc_test_error 50.0%\n",
      "Epoch: 2420 Loss: 7.56283712387085  acc_train_error 30.5125%  acc_test_error 50.0%\n",
      "Epoch: 2421 Loss: 7.559061527252197  acc_train_error 30.525%  acc_test_error 50.0%\n",
      "Epoch: 2422 Loss: 7.555277347564697  acc_train_error 30.5375%  acc_test_error 50.0%\n",
      "Epoch: 2423 Loss: 7.551499843597412  acc_train_error 30.55%  acc_test_error 50.0%\n",
      "Epoch: 2424 Loss: 7.547731876373291  acc_train_error 30.5625%  acc_test_error 50.0%\n",
      "Epoch: 2425 Loss: 7.543960094451904  acc_train_error 30.575%  acc_test_error 50.0%\n",
      "Epoch: 2426 Loss: 7.540185928344727  acc_train_error 30.5875%  acc_test_error 50.0%\n",
      "Epoch: 2427 Loss: 7.536415100097656  acc_train_error 30.6%  acc_test_error 50.0%\n",
      "Epoch: 2428 Loss: 7.532655715942383  acc_train_error 30.6125%  acc_test_error 50.0%\n",
      "Epoch: 2429 Loss: 7.5288872718811035  acc_train_error 30.75%  acc_test_error 50.0%\n",
      "Epoch: 2430 Loss: 7.52512788772583  acc_train_error 30.95%  acc_test_error 50.0%\n",
      "Epoch: 2431 Loss: 7.521368026733398  acc_train_error 31.1125%  acc_test_error 50.0%\n",
      "Epoch: 2432 Loss: 7.51761531829834  acc_train_error 31.35%  acc_test_error 50.0%\n",
      "Epoch: 2433 Loss: 7.513861179351807  acc_train_error 31.4%  acc_test_error 50.0%\n",
      "Epoch: 2434 Loss: 7.510106563568115  acc_train_error 31.4375%  acc_test_error 50.0%\n",
      "Epoch: 2435 Loss: 7.506366729736328  acc_train_error 31.475%  acc_test_error 50.0%\n",
      "Epoch: 2436 Loss: 7.502613544464111  acc_train_error 31.5125%  acc_test_error 50.0%\n",
      "Epoch: 2437 Loss: 7.498873710632324  acc_train_error 31.5375%  acc_test_error 50.0%\n",
      "Epoch: 2438 Loss: 7.495124340057373  acc_train_error 31.5625%  acc_test_error 50.0%\n",
      "Epoch: 2439 Loss: 7.491402626037598  acc_train_error 31.5875%  acc_test_error 50.0%\n",
      "Epoch: 2440 Loss: 7.4876627922058105  acc_train_error 31.725%  acc_test_error 50.0%\n",
      "Epoch: 2441 Loss: 7.483922004699707  acc_train_error 31.85%  acc_test_error 50.0%\n",
      "Epoch: 2442 Loss: 7.480198383331299  acc_train_error 31.8625%  acc_test_error 50.0%\n",
      "Epoch: 2443 Loss: 7.476461887359619  acc_train_error 31.8625%  acc_test_error 50.0%\n",
      "Epoch: 2444 Loss: 7.472738265991211  acc_train_error 31.875%  acc_test_error 50.0%\n",
      "Epoch: 2445 Loss: 7.469010829925537  acc_train_error 31.8875%  acc_test_error 50.0%\n",
      "Epoch: 2446 Loss: 7.465291976928711  acc_train_error 31.9%  acc_test_error 50.0%\n",
      "Epoch: 2447 Loss: 7.46156644821167  acc_train_error 31.9125%  acc_test_error 50.0%\n",
      "Epoch: 2448 Loss: 7.457855224609375  acc_train_error 31.925%  acc_test_error 50.0%\n",
      "Epoch: 2449 Loss: 7.454134464263916  acc_train_error 31.9375%  acc_test_error 50.0%\n",
      "Epoch: 2450 Loss: 7.450427055358887  acc_train_error 31.95%  acc_test_error 50.0%\n",
      "Epoch: 2451 Loss: 7.446714878082275  acc_train_error 31.95%  acc_test_error 50.0%\n",
      "Epoch: 2452 Loss: 7.443011283874512  acc_train_error 31.9625%  acc_test_error 50.0%\n",
      "Epoch: 2453 Loss: 7.439306259155273  acc_train_error 31.975%  acc_test_error 50.0%\n",
      "Epoch: 2454 Loss: 7.43558931350708  acc_train_error 31.975%  acc_test_error 50.0%\n",
      "Epoch: 2455 Loss: 7.431907653808594  acc_train_error 31.9875%  acc_test_error 50.0%\n",
      "Epoch: 2456 Loss: 7.4282073974609375  acc_train_error 32.0%  acc_test_error 50.0%\n",
      "Epoch: 2457 Loss: 7.424509048461914  acc_train_error 31.9875%  acc_test_error 50.0%\n",
      "Epoch: 2458 Loss: 7.420811176300049  acc_train_error 32.0%  acc_test_error 50.0%\n",
      "Epoch: 2459 Loss: 7.417128562927246  acc_train_error 32.0125%  acc_test_error 50.0%\n",
      "Epoch: 2460 Loss: 7.4134416580200195  acc_train_error 32.025%  acc_test_error 50.0%\n",
      "Epoch: 2461 Loss: 7.4097490310668945  acc_train_error 32.025%  acc_test_error 50.0%\n",
      "Epoch: 2462 Loss: 7.406078338623047  acc_train_error 32.0375%  acc_test_error 50.0%\n",
      "Epoch: 2463 Loss: 7.402389049530029  acc_train_error 32.05%  acc_test_error 50.0%\n",
      "Epoch: 2464 Loss: 7.398719310760498  acc_train_error 32.05%  acc_test_error 50.0%\n",
      "Epoch: 2465 Loss: 7.395033359527588  acc_train_error 32.0625%  acc_test_error 50.0%\n",
      "Epoch: 2466 Loss: 7.391366958618164  acc_train_error 32.075%  acc_test_error 50.0%\n",
      "Epoch: 2467 Loss: 7.387700080871582  acc_train_error 32.0875%  acc_test_error 50.0%\n",
      "Epoch: 2468 Loss: 7.384027004241943  acc_train_error 32.1%  acc_test_error 50.0%\n",
      "Epoch: 2469 Loss: 7.380356788635254  acc_train_error 32.125%  acc_test_error 50.0%\n",
      "Epoch: 2470 Loss: 7.376699447631836  acc_train_error 32.1375%  acc_test_error 50.0%\n",
      "Epoch: 2471 Loss: 7.373027801513672  acc_train_error 32.1375%  acc_test_error 50.0%\n",
      "Epoch: 2472 Loss: 7.3693718910217285  acc_train_error 32.15%  acc_test_error 50.0%\n",
      "Epoch: 2473 Loss: 7.365715980529785  acc_train_error 32.1625%  acc_test_error 50.0%\n",
      "Epoch: 2474 Loss: 7.362052917480469  acc_train_error 32.175%  acc_test_error 50.0%\n",
      "Epoch: 2475 Loss: 7.358392238616943  acc_train_error 32.1875%  acc_test_error 50.0%\n",
      "Epoch: 2476 Loss: 7.3547492027282715  acc_train_error 32.1875%  acc_test_error 50.0%\n",
      "Epoch: 2477 Loss: 7.351099014282227  acc_train_error 32.2%  acc_test_error 50.0%\n",
      "Epoch: 2478 Loss: 7.347441673278809  acc_train_error 32.2125%  acc_test_error 50.0%\n",
      "Epoch: 2479 Loss: 7.343803405761719  acc_train_error 32.225%  acc_test_error 50.0%\n",
      "Epoch: 2480 Loss: 7.340154647827148  acc_train_error 32.225%  acc_test_error 50.0%\n",
      "Epoch: 2481 Loss: 7.33651065826416  acc_train_error 32.2375%  acc_test_error 50.0%\n",
      "Epoch: 2482 Loss: 7.332865238189697  acc_train_error 32.25%  acc_test_error 50.0%\n",
      "Epoch: 2483 Loss: 7.32923698425293  acc_train_error 32.25%  acc_test_error 50.0%\n",
      "Epoch: 2484 Loss: 7.325602054595947  acc_train_error 32.2625%  acc_test_error 50.0%\n",
      "Epoch: 2485 Loss: 7.321964740753174  acc_train_error 32.275%  acc_test_error 50.0%\n",
      "Epoch: 2486 Loss: 7.318334102630615  acc_train_error 32.275%  acc_test_error 50.0%\n",
      "Epoch: 2487 Loss: 7.314709663391113  acc_train_error 32.2875%  acc_test_error 50.0%\n",
      "Epoch: 2488 Loss: 7.311086177825928  acc_train_error 32.3%  acc_test_error 50.0%\n",
      "Epoch: 2489 Loss: 7.307460784912109  acc_train_error 32.3125%  acc_test_error 50.0%\n",
      "Epoch: 2490 Loss: 7.3038434982299805  acc_train_error 32.325%  acc_test_error 50.0%\n",
      "Epoch: 2491 Loss: 7.300212383270264  acc_train_error 32.325%  acc_test_error 50.0%\n",
      "Epoch: 2492 Loss: 7.296614170074463  acc_train_error 32.3375%  acc_test_error 50.0%\n",
      "Epoch: 2493 Loss: 7.293001174926758  acc_train_error 32.35%  acc_test_error 50.0%\n",
      "Epoch: 2494 Loss: 7.289386749267578  acc_train_error 32.3625%  acc_test_error 50.0%\n",
      "Epoch: 2495 Loss: 7.2857794761657715  acc_train_error 32.375%  acc_test_error 50.0%\n",
      "Epoch: 2496 Loss: 7.282174110412598  acc_train_error 32.3875%  acc_test_error 50.0%\n",
      "Epoch: 2497 Loss: 7.278568267822266  acc_train_error 32.4%  acc_test_error 50.0%\n",
      "Epoch: 2498 Loss: 7.274963855743408  acc_train_error 32.4125%  acc_test_error 50.0%\n",
      "Epoch: 2499 Loss: 7.2713541984558105  acc_train_error 32.425%  acc_test_error 50.0%\n",
      "Epoch: 2500 Loss: 7.267765045166016  acc_train_error 32.4375%  acc_test_error 50.0%\n",
      "Epoch: 2501 Loss: 7.264167785644531  acc_train_error 32.4375%  acc_test_error 50.0%\n",
      "Epoch: 2502 Loss: 7.260574817657471  acc_train_error 32.45%  acc_test_error 50.0%\n",
      "Epoch: 2503 Loss: 7.256985664367676  acc_train_error 32.45%  acc_test_error 50.0%\n",
      "Epoch: 2504 Loss: 7.253395080566406  acc_train_error 32.45%  acc_test_error 50.0%\n",
      "Epoch: 2505 Loss: 7.24981164932251  acc_train_error 32.45%  acc_test_error 50.0%\n",
      "Epoch: 2506 Loss: 7.2462286949157715  acc_train_error 32.45%  acc_test_error 50.0%\n",
      "Epoch: 2507 Loss: 7.242648124694824  acc_train_error 32.4625%  acc_test_error 50.0%\n",
      "Epoch: 2508 Loss: 7.239069938659668  acc_train_error 32.4625%  acc_test_error 50.0%\n",
      "Epoch: 2509 Loss: 7.2354960441589355  acc_train_error 32.475%  acc_test_error 50.0%\n",
      "Epoch: 2510 Loss: 7.231915473937988  acc_train_error 32.475%  acc_test_error 50.0%\n",
      "Epoch: 2511 Loss: 7.228350639343262  acc_train_error 32.475%  acc_test_error 50.0%\n",
      "Epoch: 2512 Loss: 7.224783420562744  acc_train_error 32.4875%  acc_test_error 50.0%\n",
      "Epoch: 2513 Loss: 7.221217155456543  acc_train_error 32.4875%  acc_test_error 50.0%\n",
      "Epoch: 2514 Loss: 7.217652797698975  acc_train_error 32.5%  acc_test_error 50.0%\n",
      "Epoch: 2515 Loss: 7.214090824127197  acc_train_error 32.5%  acc_test_error 50.0%\n",
      "Epoch: 2516 Loss: 7.210533618927002  acc_train_error 32.5%  acc_test_error 50.0%\n",
      "Epoch: 2517 Loss: 7.206979751586914  acc_train_error 32.5125%  acc_test_error 50.0%\n",
      "Epoch: 2518 Loss: 7.203427791595459  acc_train_error 32.5125%  acc_test_error 50.0%\n",
      "Epoch: 2519 Loss: 7.199875831604004  acc_train_error 32.5125%  acc_test_error 50.0%\n",
      "Epoch: 2520 Loss: 7.1963348388671875  acc_train_error 32.525%  acc_test_error 50.0%\n",
      "Epoch: 2521 Loss: 7.19278621673584  acc_train_error 32.525%  acc_test_error 50.0%\n",
      "Epoch: 2522 Loss: 7.189249038696289  acc_train_error 32.5375%  acc_test_error 50.0%\n",
      "Epoch: 2523 Loss: 7.185708999633789  acc_train_error 32.5375%  acc_test_error 50.0%\n",
      "Epoch: 2524 Loss: 7.182169437408447  acc_train_error 32.5375%  acc_test_error 50.0%\n",
      "Epoch: 2525 Loss: 7.178633213043213  acc_train_error 32.55%  acc_test_error 50.0%\n",
      "Epoch: 2526 Loss: 7.175088882446289  acc_train_error 32.55%  acc_test_error 50.0%\n",
      "Epoch: 2527 Loss: 7.17156457901001  acc_train_error 32.55%  acc_test_error 50.0%\n",
      "Epoch: 2528 Loss: 7.168033599853516  acc_train_error 32.5625%  acc_test_error 50.0%\n",
      "Epoch: 2529 Loss: 7.164509296417236  acc_train_error 32.5625%  acc_test_error 50.0%\n",
      "Epoch: 2530 Loss: 7.160982131958008  acc_train_error 32.5625%  acc_test_error 50.0%\n",
      "Epoch: 2531 Loss: 7.157461643218994  acc_train_error 32.575%  acc_test_error 50.0%\n",
      "Epoch: 2532 Loss: 7.153942108154297  acc_train_error 32.575%  acc_test_error 50.0%\n",
      "Epoch: 2533 Loss: 7.150421142578125  acc_train_error 32.575%  acc_test_error 50.0%\n",
      "Epoch: 2534 Loss: 7.146907329559326  acc_train_error 32.575%  acc_test_error 50.0%\n",
      "Epoch: 2535 Loss: 7.1433916091918945  acc_train_error 32.5875%  acc_test_error 50.0%\n",
      "Epoch: 2536 Loss: 7.139878749847412  acc_train_error 32.5875%  acc_test_error 50.0%\n",
      "Epoch: 2537 Loss: 7.136362552642822  acc_train_error 32.5875%  acc_test_error 50.0%\n",
      "Epoch: 2538 Loss: 7.132853031158447  acc_train_error 32.5875%  acc_test_error 50.0%\n",
      "Epoch: 2539 Loss: 7.129343509674072  acc_train_error 32.6%  acc_test_error 50.0%\n",
      "Epoch: 2540 Loss: 7.1258392333984375  acc_train_error 32.6%  acc_test_error 50.0%\n",
      "Epoch: 2541 Loss: 7.122334003448486  acc_train_error 32.6%  acc_test_error 50.0%\n",
      "Epoch: 2542 Loss: 7.118833065032959  acc_train_error 32.5875%  acc_test_error 50.0%\n",
      "Epoch: 2543 Loss: 7.115333557128906  acc_train_error 32.6%  acc_test_error 50.0%\n",
      "Epoch: 2544 Loss: 7.1118340492248535  acc_train_error 32.6%  acc_test_error 50.0%\n",
      "Epoch: 2545 Loss: 7.108335494995117  acc_train_error 32.6%  acc_test_error 50.0%\n",
      "Epoch: 2546 Loss: 7.1048407554626465  acc_train_error 32.6125%  acc_test_error 50.0%\n",
      "Epoch: 2547 Loss: 7.101340293884277  acc_train_error 32.6125%  acc_test_error 50.0%\n",
      "Epoch: 2548 Loss: 7.097847938537598  acc_train_error 32.6125%  acc_test_error 50.0%\n",
      "Epoch: 2549 Loss: 7.094351291656494  acc_train_error 32.6125%  acc_test_error 50.0%\n",
      "Epoch: 2550 Loss: 7.090867042541504  acc_train_error 32.625%  acc_test_error 50.0%\n",
      "Epoch: 2551 Loss: 7.087376117706299  acc_train_error 32.625%  acc_test_error 50.0%\n",
      "Epoch: 2552 Loss: 7.083889007568359  acc_train_error 32.625%  acc_test_error 50.0%\n",
      "Epoch: 2553 Loss: 7.0804033279418945  acc_train_error 32.6375%  acc_test_error 50.0%\n",
      "Epoch: 2554 Loss: 7.076920509338379  acc_train_error 32.6375%  acc_test_error 50.0%\n",
      "Epoch: 2555 Loss: 7.073441028594971  acc_train_error 32.6375%  acc_test_error 50.0%\n",
      "Epoch: 2556 Loss: 7.0699615478515625  acc_train_error 32.65%  acc_test_error 50.0%\n",
      "Epoch: 2557 Loss: 7.066486835479736  acc_train_error 32.65%  acc_test_error 50.0%\n",
      "Epoch: 2558 Loss: 7.063016414642334  acc_train_error 32.65%  acc_test_error 50.0%\n",
      "Epoch: 2559 Loss: 7.059545993804932  acc_train_error 32.65%  acc_test_error 50.0%\n",
      "Epoch: 2560 Loss: 7.0560760498046875  acc_train_error 32.6625%  acc_test_error 50.0%\n",
      "Epoch: 2561 Loss: 7.052609920501709  acc_train_error 32.6625%  acc_test_error 50.0%\n",
      "Epoch: 2562 Loss: 7.0491437911987305  acc_train_error 32.6625%  acc_test_error 50.0%\n",
      "Epoch: 2563 Loss: 7.045677185058594  acc_train_error 32.675%  acc_test_error 50.0%\n",
      "Epoch: 2564 Loss: 7.042217254638672  acc_train_error 32.675%  acc_test_error 50.0%\n",
      "Epoch: 2565 Loss: 7.03875732421875  acc_train_error 32.675%  acc_test_error 50.0%\n",
      "Epoch: 2566 Loss: 7.035297870635986  acc_train_error 32.675%  acc_test_error 50.0%\n",
      "Epoch: 2567 Loss: 7.031839847564697  acc_train_error 32.675%  acc_test_error 50.0%\n",
      "Epoch: 2568 Loss: 7.028385639190674  acc_train_error 32.675%  acc_test_error 50.0%\n",
      "Epoch: 2569 Loss: 7.024933338165283  acc_train_error 32.675%  acc_test_error 50.0%\n",
      "Epoch: 2570 Loss: 7.021482467651367  acc_train_error 32.6875%  acc_test_error 50.0%\n",
      "Epoch: 2571 Loss: 7.018035411834717  acc_train_error 32.6875%  acc_test_error 50.0%\n",
      "Epoch: 2572 Loss: 7.014587879180908  acc_train_error 32.6875%  acc_test_error 50.0%\n",
      "Epoch: 2573 Loss: 7.011139869689941  acc_train_error 32.7%  acc_test_error 50.0%\n",
      "Epoch: 2574 Loss: 7.007695198059082  acc_train_error 32.7%  acc_test_error 50.0%\n",
      "Epoch: 2575 Loss: 7.0042572021484375  acc_train_error 32.7%  acc_test_error 50.0%\n",
      "Epoch: 2576 Loss: 7.0008158683776855  acc_train_error 32.7%  acc_test_error 50.0%\n",
      "Epoch: 2577 Loss: 6.997376441955566  acc_train_error 32.7125%  acc_test_error 50.0%\n",
      "Epoch: 2578 Loss: 6.993941307067871  acc_train_error 32.7125%  acc_test_error 50.0%\n",
      "Epoch: 2579 Loss: 6.990508079528809  acc_train_error 32.7125%  acc_test_error 50.0%\n",
      "Epoch: 2580 Loss: 6.987072944641113  acc_train_error 32.725%  acc_test_error 50.0%\n",
      "Epoch: 2581 Loss: 6.983646869659424  acc_train_error 32.725%  acc_test_error 50.0%\n",
      "Epoch: 2582 Loss: 6.980212688446045  acc_train_error 32.725%  acc_test_error 50.0%\n",
      "Epoch: 2583 Loss: 6.976786136627197  acc_train_error 32.725%  acc_test_error 50.0%\n",
      "Epoch: 2584 Loss: 6.973357200622559  acc_train_error 32.7375%  acc_test_error 50.0%\n",
      "Epoch: 2585 Loss: 6.969931125640869  acc_train_error 32.725%  acc_test_error 50.0%\n",
      "Epoch: 2586 Loss: 6.966507911682129  acc_train_error 32.725%  acc_test_error 50.0%\n",
      "Epoch: 2587 Loss: 6.963083744049072  acc_train_error 32.7375%  acc_test_error 50.0%\n",
      "Epoch: 2588 Loss: 6.959661960601807  acc_train_error 32.7375%  acc_test_error 50.0%\n",
      "Epoch: 2589 Loss: 6.956245422363281  acc_train_error 32.7375%  acc_test_error 50.0%\n",
      "Epoch: 2590 Loss: 6.952828407287598  acc_train_error 32.7375%  acc_test_error 50.0%\n",
      "Epoch: 2591 Loss: 6.949411392211914  acc_train_error 32.75%  acc_test_error 50.0%\n",
      "Epoch: 2592 Loss: 6.945992946624756  acc_train_error 32.75%  acc_test_error 50.0%\n",
      "Epoch: 2593 Loss: 6.942568302154541  acc_train_error 32.75%  acc_test_error 50.0%\n",
      "Epoch: 2594 Loss: 6.939141750335693  acc_train_error 32.7625%  acc_test_error 50.0%\n",
      "Epoch: 2595 Loss: 6.935721397399902  acc_train_error 32.7625%  acc_test_error 50.0%\n",
      "Epoch: 2596 Loss: 6.932304382324219  acc_train_error 32.775%  acc_test_error 50.0%\n",
      "Epoch: 2597 Loss: 6.928886413574219  acc_train_error 32.775%  acc_test_error 50.0%\n",
      "Epoch: 2598 Loss: 6.925471305847168  acc_train_error 32.775%  acc_test_error 50.0%\n",
      "Epoch: 2599 Loss: 6.922062397003174  acc_train_error 32.8%  acc_test_error 50.0%\n",
      "Epoch: 2600 Loss: 6.918652534484863  acc_train_error 32.8%  acc_test_error 50.0%\n",
      "Epoch: 2601 Loss: 6.91524600982666  acc_train_error 32.8125%  acc_test_error 50.0%\n",
      "Epoch: 2602 Loss: 6.911838531494141  acc_train_error 32.8125%  acc_test_error 50.0%\n",
      "Epoch: 2603 Loss: 6.9084391593933105  acc_train_error 32.8125%  acc_test_error 50.0%\n",
      "Epoch: 2604 Loss: 6.905036926269531  acc_train_error 32.825%  acc_test_error 50.0%\n",
      "Epoch: 2605 Loss: 6.901639461517334  acc_train_error 32.825%  acc_test_error 50.0%\n",
      "Epoch: 2606 Loss: 6.898241996765137  acc_train_error 32.825%  acc_test_error 50.0%\n",
      "Epoch: 2607 Loss: 6.894848346710205  acc_train_error 32.8375%  acc_test_error 50.0%\n",
      "Epoch: 2608 Loss: 6.8914570808410645  acc_train_error 32.8375%  acc_test_error 50.0%\n",
      "Epoch: 2609 Loss: 6.888064861297607  acc_train_error 32.8375%  acc_test_error 50.0%\n",
      "Epoch: 2610 Loss: 6.884675025939941  acc_train_error 32.85%  acc_test_error 50.0%\n",
      "Epoch: 2611 Loss: 6.881290912628174  acc_train_error 32.85%  acc_test_error 50.0%\n",
      "Epoch: 2612 Loss: 6.877904891967773  acc_train_error 32.85%  acc_test_error 50.0%\n",
      "Epoch: 2613 Loss: 6.874520301818848  acc_train_error 32.8625%  acc_test_error 50.0%\n",
      "Epoch: 2614 Loss: 6.8711395263671875  acc_train_error 32.8625%  acc_test_error 50.0%\n",
      "Epoch: 2615 Loss: 6.8677592277526855  acc_train_error 32.8625%  acc_test_error 50.0%\n",
      "Epoch: 2616 Loss: 6.864381790161133  acc_train_error 32.875%  acc_test_error 50.0%\n",
      "Epoch: 2617 Loss: 6.861006259918213  acc_train_error 32.875%  acc_test_error 50.0%\n",
      "Epoch: 2618 Loss: 6.857630729675293  acc_train_error 32.875%  acc_test_error 50.0%\n",
      "Epoch: 2619 Loss: 6.854256629943848  acc_train_error 32.8875%  acc_test_error 50.0%\n",
      "Epoch: 2620 Loss: 6.85089111328125  acc_train_error 32.8875%  acc_test_error 50.0%\n",
      "Epoch: 2621 Loss: 6.847521781921387  acc_train_error 32.8875%  acc_test_error 50.0%\n",
      "Epoch: 2622 Loss: 6.84415340423584  acc_train_error 32.9%  acc_test_error 50.0%\n",
      "Epoch: 2623 Loss: 6.840791702270508  acc_train_error 32.9%  acc_test_error 50.0%\n",
      "Epoch: 2624 Loss: 6.837426662445068  acc_train_error 32.9%  acc_test_error 50.0%\n",
      "Epoch: 2625 Loss: 6.834066390991211  acc_train_error 32.9125%  acc_test_error 50.0%\n",
      "Epoch: 2626 Loss: 6.830705642700195  acc_train_error 32.9125%  acc_test_error 50.0%\n",
      "Epoch: 2627 Loss: 6.827349662780762  acc_train_error 32.925%  acc_test_error 50.0%\n",
      "Epoch: 2628 Loss: 6.823990821838379  acc_train_error 32.925%  acc_test_error 50.0%\n",
      "Epoch: 2629 Loss: 6.8206353187561035  acc_train_error 32.925%  acc_test_error 50.0%\n",
      "Epoch: 2630 Loss: 6.817279815673828  acc_train_error 32.9375%  acc_test_error 50.0%\n",
      "Epoch: 2631 Loss: 6.813925266265869  acc_train_error 32.9375%  acc_test_error 50.0%\n",
      "Epoch: 2632 Loss: 6.810575485229492  acc_train_error 32.9375%  acc_test_error 50.0%\n",
      "Epoch: 2633 Loss: 6.80722713470459  acc_train_error 32.95%  acc_test_error 50.0%\n",
      "Epoch: 2634 Loss: 6.8038787841796875  acc_train_error 32.95%  acc_test_error 50.0%\n",
      "Epoch: 2635 Loss: 6.800534248352051  acc_train_error 32.9625%  acc_test_error 50.0%\n",
      "Epoch: 2636 Loss: 6.797189235687256  acc_train_error 32.975%  acc_test_error 50.0%\n",
      "Epoch: 2637 Loss: 6.7938456535339355  acc_train_error 32.9875%  acc_test_error 50.0%\n",
      "Epoch: 2638 Loss: 6.790505886077881  acc_train_error 32.9875%  acc_test_error 50.0%\n",
      "Epoch: 2639 Loss: 6.787170886993408  acc_train_error 33.0%  acc_test_error 50.0%\n",
      "Epoch: 2640 Loss: 6.783833026885986  acc_train_error 33.0%  acc_test_error 50.0%\n",
      "Epoch: 2641 Loss: 6.780495643615723  acc_train_error 33.0%  acc_test_error 50.0%\n",
      "Epoch: 2642 Loss: 6.777164459228516  acc_train_error 33.0125%  acc_test_error 50.0%\n",
      "Epoch: 2643 Loss: 6.773828506469727  acc_train_error 33.0125%  acc_test_error 50.0%\n",
      "Epoch: 2644 Loss: 6.770496368408203  acc_train_error 33.0125%  acc_test_error 50.0%\n",
      "Epoch: 2645 Loss: 6.76716947555542  acc_train_error 33.025%  acc_test_error 50.0%\n",
      "Epoch: 2646 Loss: 6.763838768005371  acc_train_error 33.025%  acc_test_error 50.0%\n",
      "Epoch: 2647 Loss: 6.7605109214782715  acc_train_error 33.025%  acc_test_error 50.0%\n",
      "Epoch: 2648 Loss: 6.757187843322754  acc_train_error 33.0375%  acc_test_error 50.0%\n",
      "Epoch: 2649 Loss: 6.753859996795654  acc_train_error 33.0375%  acc_test_error 50.0%\n",
      "Epoch: 2650 Loss: 6.750537395477295  acc_train_error 33.0375%  acc_test_error 50.0%\n",
      "Epoch: 2651 Loss: 6.747210502624512  acc_train_error 33.05%  acc_test_error 50.0%\n",
      "Epoch: 2652 Loss: 6.743892669677734  acc_train_error 33.05%  acc_test_error 50.0%\n",
      "Epoch: 2653 Loss: 6.740569591522217  acc_train_error 33.0625%  acc_test_error 50.0%\n",
      "Epoch: 2654 Loss: 6.737251281738281  acc_train_error 33.075%  acc_test_error 50.0%\n",
      "Epoch: 2655 Loss: 6.73393440246582  acc_train_error 33.075%  acc_test_error 50.0%\n",
      "Epoch: 2656 Loss: 6.730620384216309  acc_train_error 33.075%  acc_test_error 50.0%\n",
      "Epoch: 2657 Loss: 6.727304458618164  acc_train_error 33.0875%  acc_test_error 50.0%\n",
      "Epoch: 2658 Loss: 6.723993301391602  acc_train_error 33.0875%  acc_test_error 50.0%\n",
      "Epoch: 2659 Loss: 6.720685958862305  acc_train_error 33.0875%  acc_test_error 50.0%\n",
      "Epoch: 2660 Loss: 6.717375755310059  acc_train_error 33.1%  acc_test_error 50.0%\n",
      "Epoch: 2661 Loss: 6.714069366455078  acc_train_error 33.1%  acc_test_error 50.0%\n",
      "Epoch: 2662 Loss: 6.710763454437256  acc_train_error 33.1%  acc_test_error 50.0%\n",
      "Epoch: 2663 Loss: 6.707461833953857  acc_train_error 33.1125%  acc_test_error 50.0%\n",
      "Epoch: 2664 Loss: 6.704160690307617  acc_train_error 33.1125%  acc_test_error 50.0%\n",
      "Epoch: 2665 Loss: 6.700859069824219  acc_train_error 33.1125%  acc_test_error 50.0%\n",
      "Epoch: 2666 Loss: 6.697564125061035  acc_train_error 33.125%  acc_test_error 50.0%\n",
      "Epoch: 2667 Loss: 6.694267272949219  acc_train_error 33.125%  acc_test_error 50.0%\n",
      "Epoch: 2668 Loss: 6.690968990325928  acc_train_error 33.125%  acc_test_error 50.0%\n",
      "Epoch: 2669 Loss: 6.68767786026001  acc_train_error 33.1375%  acc_test_error 50.0%\n",
      "Epoch: 2670 Loss: 6.684387683868408  acc_train_error 33.1375%  acc_test_error 50.0%\n",
      "Epoch: 2671 Loss: 6.681098461151123  acc_train_error 33.15%  acc_test_error 50.0%\n",
      "Epoch: 2672 Loss: 6.6778106689453125  acc_train_error 33.1625%  acc_test_error 50.0%\n",
      "Epoch: 2673 Loss: 6.674526691436768  acc_train_error 33.1625%  acc_test_error 50.0%\n",
      "Epoch: 2674 Loss: 6.671239852905273  acc_train_error 33.1625%  acc_test_error 50.0%\n",
      "Epoch: 2675 Loss: 6.6679582595825195  acc_train_error 33.175%  acc_test_error 50.0%\n",
      "Epoch: 2676 Loss: 6.664678573608398  acc_train_error 33.175%  acc_test_error 50.0%\n",
      "Epoch: 2677 Loss: 6.6613993644714355  acc_train_error 33.175%  acc_test_error 50.0%\n",
      "Epoch: 2678 Loss: 6.658121109008789  acc_train_error 33.1875%  acc_test_error 50.0%\n",
      "Epoch: 2679 Loss: 6.654848098754883  acc_train_error 33.1875%  acc_test_error 50.0%\n",
      "Epoch: 2680 Loss: 6.65157413482666  acc_train_error 33.1875%  acc_test_error 50.0%\n",
      "Epoch: 2681 Loss: 6.64830207824707  acc_train_error 33.2%  acc_test_error 50.0%\n",
      "Epoch: 2682 Loss: 6.645029544830322  acc_train_error 33.2%  acc_test_error 50.0%\n",
      "Epoch: 2683 Loss: 6.641762733459473  acc_train_error 33.2125%  acc_test_error 50.0%\n",
      "Epoch: 2684 Loss: 6.638493537902832  acc_train_error 33.225%  acc_test_error 50.0%\n",
      "Epoch: 2685 Loss: 6.635227203369141  acc_train_error 33.225%  acc_test_error 50.0%\n",
      "Epoch: 2686 Loss: 6.631962299346924  acc_train_error 33.225%  acc_test_error 50.0%\n",
      "Epoch: 2687 Loss: 6.628698348999023  acc_train_error 33.2375%  acc_test_error 50.0%\n",
      "Epoch: 2688 Loss: 6.6254353523254395  acc_train_error 33.2375%  acc_test_error 50.0%\n",
      "Epoch: 2689 Loss: 6.622176170349121  acc_train_error 33.2375%  acc_test_error 50.0%\n",
      "Epoch: 2690 Loss: 6.618917465209961  acc_train_error 33.2375%  acc_test_error 50.0%\n",
      "Epoch: 2691 Loss: 6.615659236907959  acc_train_error 33.25%  acc_test_error 50.0%\n",
      "Epoch: 2692 Loss: 6.612402439117432  acc_train_error 33.25%  acc_test_error 50.0%\n",
      "Epoch: 2693 Loss: 6.609147071838379  acc_train_error 33.25%  acc_test_error 50.0%\n",
      "Epoch: 2694 Loss: 6.605893135070801  acc_train_error 33.275%  acc_test_error 50.0%\n",
      "Epoch: 2695 Loss: 6.6026411056518555  acc_train_error 33.275%  acc_test_error 50.0%\n",
      "Epoch: 2696 Loss: 6.599392414093018  acc_train_error 33.275%  acc_test_error 50.0%\n",
      "Epoch: 2697 Loss: 6.59614372253418  acc_train_error 33.2875%  acc_test_error 50.0%\n",
      "Epoch: 2698 Loss: 6.592896461486816  acc_train_error 33.2875%  acc_test_error 50.0%\n",
      "Epoch: 2699 Loss: 6.589639663696289  acc_train_error 33.2875%  acc_test_error 50.0%\n",
      "Epoch: 2700 Loss: 6.586373805999756  acc_train_error 33.3%  acc_test_error 50.0%\n",
      "Epoch: 2701 Loss: 6.583112716674805  acc_train_error 33.3%  acc_test_error 50.0%\n",
      "Epoch: 2702 Loss: 6.579851150512695  acc_train_error 33.3125%  acc_test_error 50.0%\n",
      "Epoch: 2703 Loss: 6.576598167419434  acc_train_error 33.325%  acc_test_error 50.0%\n",
      "Epoch: 2704 Loss: 6.573348522186279  acc_train_error 33.325%  acc_test_error 50.0%\n",
      "Epoch: 2705 Loss: 6.5701093673706055  acc_train_error 33.325%  acc_test_error 50.0%\n",
      "Epoch: 2706 Loss: 6.566866874694824  acc_train_error 33.3375%  acc_test_error 50.0%\n",
      "Epoch: 2707 Loss: 6.563627243041992  acc_train_error 33.35%  acc_test_error 50.0%\n",
      "Epoch: 2708 Loss: 6.560386657714844  acc_train_error 33.3625%  acc_test_error 50.0%\n",
      "Epoch: 2709 Loss: 6.557153701782227  acc_train_error 33.3625%  acc_test_error 50.0%\n",
      "Epoch: 2710 Loss: 6.553921222686768  acc_train_error 33.3625%  acc_test_error 50.0%\n",
      "Epoch: 2711 Loss: 6.550692081451416  acc_train_error 33.375%  acc_test_error 50.0%\n",
      "Epoch: 2712 Loss: 6.547467231750488  acc_train_error 33.375%  acc_test_error 50.0%\n",
      "Epoch: 2713 Loss: 6.544238567352295  acc_train_error 33.3875%  acc_test_error 50.0%\n",
      "Epoch: 2714 Loss: 6.541017055511475  acc_train_error 33.4%  acc_test_error 50.0%\n",
      "Epoch: 2715 Loss: 6.537792682647705  acc_train_error 33.4%  acc_test_error 50.0%\n",
      "Epoch: 2716 Loss: 6.534574508666992  acc_train_error 33.4125%  acc_test_error 50.0%\n",
      "Epoch: 2717 Loss: 6.531354904174805  acc_train_error 33.4125%  acc_test_error 50.0%\n",
      "Epoch: 2718 Loss: 6.528139114379883  acc_train_error 33.4125%  acc_test_error 50.0%\n",
      "Epoch: 2719 Loss: 6.5249199867248535  acc_train_error 33.4375%  acc_test_error 50.0%\n",
      "Epoch: 2720 Loss: 6.5217084884643555  acc_train_error 33.4375%  acc_test_error 50.0%\n",
      "Epoch: 2721 Loss: 6.518496990203857  acc_train_error 33.4375%  acc_test_error 50.0%\n",
      "Epoch: 2722 Loss: 6.515288829803467  acc_train_error 33.45%  acc_test_error 50.0%\n",
      "Epoch: 2723 Loss: 6.512077808380127  acc_train_error 33.45%  acc_test_error 50.0%\n",
      "Epoch: 2724 Loss: 6.5088725090026855  acc_train_error 33.45%  acc_test_error 50.0%\n",
      "Epoch: 2725 Loss: 6.505662441253662  acc_train_error 33.4625%  acc_test_error 50.0%\n",
      "Epoch: 2726 Loss: 6.502459526062012  acc_train_error 33.475%  acc_test_error 50.0%\n",
      "Epoch: 2727 Loss: 6.499255657196045  acc_train_error 33.475%  acc_test_error 50.0%\n",
      "Epoch: 2728 Loss: 6.4960527420043945  acc_train_error 33.4875%  acc_test_error 50.0%\n",
      "Epoch: 2729 Loss: 6.492851257324219  acc_train_error 33.4875%  acc_test_error 50.0%\n",
      "Epoch: 2730 Loss: 6.489654541015625  acc_train_error 33.4875%  acc_test_error 50.0%\n",
      "Epoch: 2731 Loss: 6.486451148986816  acc_train_error 33.5%  acc_test_error 50.0%\n",
      "Epoch: 2732 Loss: 6.4832634925842285  acc_train_error 33.5125%  acc_test_error 50.0%\n",
      "Epoch: 2733 Loss: 6.480067253112793  acc_train_error 33.5125%  acc_test_error 50.0%\n",
      "Epoch: 2734 Loss: 6.476877212524414  acc_train_error 33.5125%  acc_test_error 50.0%\n",
      "Epoch: 2735 Loss: 6.4736857414245605  acc_train_error 33.525%  acc_test_error 50.0%\n",
      "Epoch: 2736 Loss: 6.470498561859131  acc_train_error 33.5375%  acc_test_error 50.0%\n",
      "Epoch: 2737 Loss: 6.467312335968018  acc_train_error 33.5375%  acc_test_error 50.0%\n",
      "Epoch: 2738 Loss: 6.464127540588379  acc_train_error 33.55%  acc_test_error 50.0%\n",
      "Epoch: 2739 Loss: 6.4609479904174805  acc_train_error 33.55%  acc_test_error 50.0%\n",
      "Epoch: 2740 Loss: 6.457772731781006  acc_train_error 33.55%  acc_test_error 50.0%\n",
      "Epoch: 2741 Loss: 6.454596996307373  acc_train_error 33.55%  acc_test_error 50.0%\n",
      "Epoch: 2742 Loss: 6.451427459716797  acc_train_error 33.5625%  acc_test_error 50.0%\n",
      "Epoch: 2743 Loss: 6.4482526779174805  acc_train_error 33.575%  acc_test_error 50.0%\n",
      "Epoch: 2744 Loss: 6.445085048675537  acc_train_error 33.575%  acc_test_error 50.0%\n",
      "Epoch: 2745 Loss: 6.441917896270752  acc_train_error 33.5875%  acc_test_error 50.0%\n",
      "Epoch: 2746 Loss: 6.43874979019165  acc_train_error 33.5875%  acc_test_error 50.0%\n",
      "Epoch: 2747 Loss: 6.435586452484131  acc_train_error 33.5875%  acc_test_error 50.0%\n",
      "Epoch: 2748 Loss: 6.432423114776611  acc_train_error 33.6%  acc_test_error 50.0%\n",
      "Epoch: 2749 Loss: 6.429259777069092  acc_train_error 33.6%  acc_test_error 50.0%\n",
      "Epoch: 2750 Loss: 6.4260993003845215  acc_train_error 33.6%  acc_test_error 50.0%\n",
      "Epoch: 2751 Loss: 6.422939300537109  acc_train_error 33.6125%  acc_test_error 50.0%\n",
      "Epoch: 2752 Loss: 6.41978645324707  acc_train_error 33.625%  acc_test_error 50.0%\n",
      "Epoch: 2753 Loss: 6.416629791259766  acc_train_error 33.625%  acc_test_error 50.0%\n",
      "Epoch: 2754 Loss: 6.413483619689941  acc_train_error 33.6375%  acc_test_error 50.0%\n",
      "Epoch: 2755 Loss: 6.4103312492370605  acc_train_error 33.6375%  acc_test_error 50.0%\n",
      "Epoch: 2756 Loss: 6.407186508178711  acc_train_error 33.6375%  acc_test_error 50.0%\n",
      "Epoch: 2757 Loss: 6.404038906097412  acc_train_error 33.65%  acc_test_error 50.0%\n",
      "Epoch: 2758 Loss: 6.400896072387695  acc_train_error 33.65%  acc_test_error 50.0%\n",
      "Epoch: 2759 Loss: 6.397756099700928  acc_train_error 33.65%  acc_test_error 50.0%\n",
      "Epoch: 2760 Loss: 6.3946123123168945  acc_train_error 33.675%  acc_test_error 50.0%\n",
      "Epoch: 2761 Loss: 6.391470432281494  acc_train_error 33.675%  acc_test_error 50.0%\n",
      "Epoch: 2762 Loss: 6.388331413269043  acc_train_error 33.675%  acc_test_error 50.0%\n",
      "Epoch: 2763 Loss: 6.385193347930908  acc_train_error 33.6875%  acc_test_error 50.0%\n",
      "Epoch: 2764 Loss: 6.382057189941406  acc_train_error 33.6875%  acc_test_error 50.0%\n",
      "Epoch: 2765 Loss: 6.3789215087890625  acc_train_error 33.6875%  acc_test_error 50.0%\n",
      "Epoch: 2766 Loss: 6.375792503356934  acc_train_error 33.6875%  acc_test_error 50.0%\n",
      "Epoch: 2767 Loss: 6.372659683227539  acc_train_error 33.7%  acc_test_error 50.0%\n",
      "Epoch: 2768 Loss: 6.369534969329834  acc_train_error 33.7%  acc_test_error 50.0%\n",
      "Epoch: 2769 Loss: 6.3664116859436035  acc_train_error 33.7%  acc_test_error 50.0%\n",
      "Epoch: 2770 Loss: 6.363288879394531  acc_train_error 33.7125%  acc_test_error 50.0%\n",
      "Epoch: 2771 Loss: 6.360169887542725  acc_train_error 33.7125%  acc_test_error 50.0%\n",
      "Epoch: 2772 Loss: 6.357051849365234  acc_train_error 33.7125%  acc_test_error 50.0%\n",
      "Epoch: 2773 Loss: 6.353943347930908  acc_train_error 33.7125%  acc_test_error 50.0%\n",
      "Epoch: 2774 Loss: 6.350828647613525  acc_train_error 33.7125%  acc_test_error 50.0%\n",
      "Epoch: 2775 Loss: 6.347719192504883  acc_train_error 33.725%  acc_test_error 50.0%\n",
      "Epoch: 2776 Loss: 6.3446149826049805  acc_train_error 33.725%  acc_test_error 50.0%\n",
      "Epoch: 2777 Loss: 6.341505527496338  acc_train_error 33.7375%  acc_test_error 50.0%\n",
      "Epoch: 2778 Loss: 6.338403224945068  acc_train_error 33.7375%  acc_test_error 50.0%\n",
      "Epoch: 2779 Loss: 6.33530330657959  acc_train_error 33.7375%  acc_test_error 50.0%\n",
      "Epoch: 2780 Loss: 6.332204818725586  acc_train_error 33.75%  acc_test_error 50.0%\n",
      "Epoch: 2781 Loss: 6.329106330871582  acc_train_error 33.7375%  acc_test_error 50.0%\n",
      "Epoch: 2782 Loss: 6.326011657714844  acc_train_error 33.75%  acc_test_error 50.0%\n",
      "Epoch: 2783 Loss: 6.3229146003723145  acc_train_error 33.7625%  acc_test_error 50.0%\n",
      "Epoch: 2784 Loss: 6.319827556610107  acc_train_error 33.7625%  acc_test_error 50.0%\n",
      "Epoch: 2785 Loss: 6.31673526763916  acc_train_error 33.7625%  acc_test_error 50.0%\n",
      "Epoch: 2786 Loss: 6.313644886016846  acc_train_error 33.7625%  acc_test_error 50.0%\n",
      "Epoch: 2787 Loss: 6.310564994812012  acc_train_error 33.775%  acc_test_error 50.0%\n",
      "Epoch: 2788 Loss: 6.307473659515381  acc_train_error 33.775%  acc_test_error 50.0%\n",
      "Epoch: 2789 Loss: 6.304393768310547  acc_train_error 33.775%  acc_test_error 50.0%\n",
      "Epoch: 2790 Loss: 6.301309585571289  acc_train_error 33.775%  acc_test_error 50.0%\n",
      "Epoch: 2791 Loss: 6.2982306480407715  acc_train_error 33.775%  acc_test_error 50.0%\n",
      "Epoch: 2792 Loss: 6.2951555252075195  acc_train_error 33.7875%  acc_test_error 50.0%\n",
      "Epoch: 2793 Loss: 6.292074203491211  acc_train_error 33.7875%  acc_test_error 50.0%\n",
      "Epoch: 2794 Loss: 6.289007186889648  acc_train_error 33.7875%  acc_test_error 50.0%\n",
      "Epoch: 2795 Loss: 6.28593111038208  acc_train_error 33.7875%  acc_test_error 50.0%\n",
      "Epoch: 2796 Loss: 6.282861709594727  acc_train_error 33.8%  acc_test_error 50.0%\n",
      "Epoch: 2797 Loss: 6.279791355133057  acc_train_error 33.8%  acc_test_error 50.0%\n",
      "Epoch: 2798 Loss: 6.276726722717285  acc_train_error 33.8%  acc_test_error 50.0%\n",
      "Epoch: 2799 Loss: 6.273650646209717  acc_train_error 33.8125%  acc_test_error 50.0%\n",
      "Epoch: 2800 Loss: 6.270596981048584  acc_train_error 33.8125%  acc_test_error 50.0%\n",
      "Epoch: 2801 Loss: 6.267526149749756  acc_train_error 33.825%  acc_test_error 50.0%\n",
      "Epoch: 2802 Loss: 6.26447057723999  acc_train_error 33.825%  acc_test_error 50.0%\n",
      "Epoch: 2803 Loss: 6.261409759521484  acc_train_error 33.825%  acc_test_error 50.0%\n",
      "Epoch: 2804 Loss: 6.258353233337402  acc_train_error 33.825%  acc_test_error 50.0%\n",
      "Epoch: 2805 Loss: 6.2552947998046875  acc_train_error 33.8375%  acc_test_error 50.0%\n",
      "Epoch: 2806 Loss: 6.2522454261779785  acc_train_error 33.8375%  acc_test_error 50.0%\n",
      "Epoch: 2807 Loss: 6.2491865158081055  acc_train_error 33.8375%  acc_test_error 50.0%\n",
      "Epoch: 2808 Loss: 6.246138572692871  acc_train_error 33.8375%  acc_test_error 50.0%\n",
      "Epoch: 2809 Loss: 6.243086338043213  acc_train_error 33.85%  acc_test_error 50.0%\n",
      "Epoch: 2810 Loss: 6.240038871765137  acc_train_error 33.85%  acc_test_error 50.0%\n",
      "Epoch: 2811 Loss: 6.236991882324219  acc_train_error 33.85%  acc_test_error 50.0%\n",
      "Epoch: 2812 Loss: 6.233944892883301  acc_train_error 33.85%  acc_test_error 50.0%\n",
      "Epoch: 2813 Loss: 6.230905532836914  acc_train_error 33.875%  acc_test_error 50.0%\n",
      "Epoch: 2814 Loss: 6.2278618812561035  acc_train_error 33.875%  acc_test_error 50.0%\n",
      "Epoch: 2815 Loss: 6.224826812744141  acc_train_error 33.875%  acc_test_error 50.0%\n",
      "Epoch: 2816 Loss: 6.2217864990234375  acc_train_error 33.875%  acc_test_error 50.0%\n",
      "Epoch: 2817 Loss: 6.218748569488525  acc_train_error 33.875%  acc_test_error 50.0%\n",
      "Epoch: 2818 Loss: 6.215713977813721  acc_train_error 33.875%  acc_test_error 50.0%\n",
      "Epoch: 2819 Loss: 6.212680816650391  acc_train_error 33.8875%  acc_test_error 50.0%\n",
      "Epoch: 2820 Loss: 6.209649562835693  acc_train_error 33.8875%  acc_test_error 50.0%\n",
      "Epoch: 2821 Loss: 6.206620693206787  acc_train_error 33.8875%  acc_test_error 50.0%\n",
      "Epoch: 2822 Loss: 6.203590393066406  acc_train_error 33.8875%  acc_test_error 50.0%\n",
      "Epoch: 2823 Loss: 6.200563430786133  acc_train_error 33.9%  acc_test_error 50.0%\n",
      "Epoch: 2824 Loss: 6.197539329528809  acc_train_error 33.9125%  acc_test_error 50.0%\n",
      "Epoch: 2825 Loss: 6.194511890411377  acc_train_error 33.9125%  acc_test_error 50.0%\n",
      "Epoch: 2826 Loss: 6.19148588180542  acc_train_error 33.9125%  acc_test_error 50.0%\n",
      "Epoch: 2827 Loss: 6.188464641571045  acc_train_error 33.9125%  acc_test_error 50.0%\n",
      "Epoch: 2828 Loss: 6.185445308685303  acc_train_error 33.9125%  acc_test_error 50.0%\n",
      "Epoch: 2829 Loss: 6.182425498962402  acc_train_error 33.9125%  acc_test_error 50.0%\n",
      "Epoch: 2830 Loss: 6.179409980773926  acc_train_error 33.925%  acc_test_error 50.0%\n",
      "Epoch: 2831 Loss: 6.176394462585449  acc_train_error 33.925%  acc_test_error 50.0%\n",
      "Epoch: 2832 Loss: 6.173379898071289  acc_train_error 33.9375%  acc_test_error 50.0%\n",
      "Epoch: 2833 Loss: 6.170365333557129  acc_train_error 33.9375%  acc_test_error 50.0%\n",
      "Epoch: 2834 Loss: 6.167358875274658  acc_train_error 33.95%  acc_test_error 50.0%\n",
      "Epoch: 2835 Loss: 6.164349555969238  acc_train_error 33.95%  acc_test_error 50.0%\n",
      "Epoch: 2836 Loss: 6.161341667175293  acc_train_error 33.95%  acc_test_error 50.0%\n",
      "Epoch: 2837 Loss: 6.158334732055664  acc_train_error 33.95%  acc_test_error 50.0%\n",
      "Epoch: 2838 Loss: 6.155332088470459  acc_train_error 33.95%  acc_test_error 50.0%\n",
      "Epoch: 2839 Loss: 6.152329921722412  acc_train_error 33.95%  acc_test_error 50.0%\n",
      "Epoch: 2840 Loss: 6.1493306159973145  acc_train_error 33.975%  acc_test_error 50.0%\n",
      "Epoch: 2841 Loss: 6.146330833435059  acc_train_error 33.975%  acc_test_error 50.0%\n",
      "Epoch: 2842 Loss: 6.143335819244385  acc_train_error 33.975%  acc_test_error 50.0%\n",
      "Epoch: 2843 Loss: 6.140336990356445  acc_train_error 33.975%  acc_test_error 50.0%\n",
      "Epoch: 2844 Loss: 6.137346267700195  acc_train_error 33.975%  acc_test_error 50.0%\n",
      "Epoch: 2845 Loss: 6.134354591369629  acc_train_error 33.9875%  acc_test_error 50.0%\n",
      "Epoch: 2846 Loss: 6.131363391876221  acc_train_error 33.9875%  acc_test_error 50.0%\n",
      "Epoch: 2847 Loss: 6.1283745765686035  acc_train_error 33.9875%  acc_test_error 50.0%\n",
      "Epoch: 2848 Loss: 6.125392913818359  acc_train_error 34.0%  acc_test_error 50.0%\n",
      "Epoch: 2849 Loss: 6.1224045753479  acc_train_error 34.0%  acc_test_error 50.0%\n",
      "Epoch: 2850 Loss: 6.119420528411865  acc_train_error 34.0125%  acc_test_error 50.0%\n",
      "Epoch: 2851 Loss: 6.116438388824463  acc_train_error 34.0125%  acc_test_error 50.0%\n",
      "Epoch: 2852 Loss: 6.113458633422852  acc_train_error 34.0125%  acc_test_error 50.0%\n",
      "Epoch: 2853 Loss: 6.110474109649658  acc_train_error 34.0125%  acc_test_error 50.0%\n",
      "Epoch: 2854 Loss: 6.107499599456787  acc_train_error 34.0125%  acc_test_error 50.0%\n",
      "Epoch: 2855 Loss: 6.104518413543701  acc_train_error 34.0375%  acc_test_error 50.0%\n",
      "Epoch: 2856 Loss: 6.101538181304932  acc_train_error 34.0375%  acc_test_error 50.0%\n",
      "Epoch: 2857 Loss: 6.09855842590332  acc_train_error 34.0375%  acc_test_error 50.0%\n",
      "Epoch: 2858 Loss: 6.095582962036133  acc_train_error 34.0375%  acc_test_error 50.0%\n",
      "Epoch: 2859 Loss: 6.092605113983154  acc_train_error 34.0375%  acc_test_error 50.0%\n",
      "Epoch: 2860 Loss: 6.089631080627441  acc_train_error 34.05%  acc_test_error 50.0%\n",
      "Epoch: 2861 Loss: 6.086659908294678  acc_train_error 34.05%  acc_test_error 50.0%\n",
      "Epoch: 2862 Loss: 6.083685874938965  acc_train_error 34.0625%  acc_test_error 50.0%\n",
      "Epoch: 2863 Loss: 6.080715179443359  acc_train_error 34.0625%  acc_test_error 50.0%\n",
      "Epoch: 2864 Loss: 6.077744960784912  acc_train_error 34.0625%  acc_test_error 50.0%\n",
      "Epoch: 2865 Loss: 6.074778079986572  acc_train_error 34.075%  acc_test_error 50.0%\n",
      "Epoch: 2866 Loss: 6.071809768676758  acc_train_error 34.075%  acc_test_error 50.0%\n",
      "Epoch: 2867 Loss: 6.068848609924316  acc_train_error 34.0875%  acc_test_error 50.0%\n",
      "Epoch: 2868 Loss: 6.065883159637451  acc_train_error 34.0875%  acc_test_error 50.0%\n",
      "Epoch: 2869 Loss: 6.062924861907959  acc_train_error 34.0875%  acc_test_error 50.0%\n",
      "Epoch: 2870 Loss: 6.059960842132568  acc_train_error 34.1%  acc_test_error 50.0%\n",
      "Epoch: 2871 Loss: 6.057003974914551  acc_train_error 34.1%  acc_test_error 50.0%\n",
      "Epoch: 2872 Loss: 6.054042816162109  acc_train_error 34.1%  acc_test_error 50.0%\n",
      "Epoch: 2873 Loss: 6.051089286804199  acc_train_error 34.1125%  acc_test_error 50.0%\n",
      "Epoch: 2874 Loss: 6.048129558563232  acc_train_error 34.125%  acc_test_error 50.0%\n",
      "Epoch: 2875 Loss: 6.045174598693848  acc_train_error 34.125%  acc_test_error 50.0%\n",
      "Epoch: 2876 Loss: 6.0422210693359375  acc_train_error 34.125%  acc_test_error 50.0%\n",
      "Epoch: 2877 Loss: 6.03926944732666  acc_train_error 34.125%  acc_test_error 50.0%\n",
      "Epoch: 2878 Loss: 6.036317825317383  acc_train_error 34.15%  acc_test_error 50.0%\n",
      "Epoch: 2879 Loss: 6.033369064331055  acc_train_error 34.15%  acc_test_error 50.0%\n",
      "Epoch: 2880 Loss: 6.030418395996094  acc_train_error 34.15%  acc_test_error 50.0%\n",
      "Epoch: 2881 Loss: 6.027471542358398  acc_train_error 34.15%  acc_test_error 50.0%\n",
      "Epoch: 2882 Loss: 6.024527072906494  acc_train_error 34.1625%  acc_test_error 50.0%\n",
      "Epoch: 2883 Loss: 6.021582126617432  acc_train_error 34.1875%  acc_test_error 50.0%\n",
      "Epoch: 2884 Loss: 6.018641471862793  acc_train_error 34.1875%  acc_test_error 50.0%\n",
      "Epoch: 2885 Loss: 6.015695095062256  acc_train_error 34.2%  acc_test_error 50.0%\n",
      "Epoch: 2886 Loss: 6.012756824493408  acc_train_error 34.2%  acc_test_error 50.0%\n",
      "Epoch: 2887 Loss: 6.009820938110352  acc_train_error 34.2125%  acc_test_error 50.0%\n",
      "Epoch: 2888 Loss: 6.00688362121582  acc_train_error 34.225%  acc_test_error 50.0%\n",
      "Epoch: 2889 Loss: 6.003946781158447  acc_train_error 34.2375%  acc_test_error 50.0%\n",
      "Epoch: 2890 Loss: 6.001016616821289  acc_train_error 34.2375%  acc_test_error 50.0%\n",
      "Epoch: 2891 Loss: 5.998083114624023  acc_train_error 34.25%  acc_test_error 50.0%\n",
      "Epoch: 2892 Loss: 5.995152950286865  acc_train_error 34.25%  acc_test_error 50.0%\n",
      "Epoch: 2893 Loss: 5.992222785949707  acc_train_error 34.2625%  acc_test_error 50.0%\n",
      "Epoch: 2894 Loss: 5.989294528961182  acc_train_error 34.2625%  acc_test_error 50.0%\n",
      "Epoch: 2895 Loss: 5.9863667488098145  acc_train_error 34.2625%  acc_test_error 50.0%\n",
      "Epoch: 2896 Loss: 5.983442306518555  acc_train_error 34.275%  acc_test_error 50.0%\n",
      "Epoch: 2897 Loss: 5.98051643371582  acc_train_error 34.2875%  acc_test_error 50.0%\n",
      "Epoch: 2898 Loss: 5.977595806121826  acc_train_error 34.3%  acc_test_error 50.0%\n",
      "Epoch: 2899 Loss: 5.974678039550781  acc_train_error 34.3%  acc_test_error 50.0%\n",
      "Epoch: 2900 Loss: 5.971759796142578  acc_train_error 34.3125%  acc_test_error 50.0%\n",
      "Epoch: 2901 Loss: 5.968844413757324  acc_train_error 34.3125%  acc_test_error 50.0%\n",
      "Epoch: 2902 Loss: 5.9659295082092285  acc_train_error 34.3125%  acc_test_error 50.0%\n",
      "Epoch: 2903 Loss: 5.963021278381348  acc_train_error 34.325%  acc_test_error 50.0%\n",
      "Epoch: 2904 Loss: 5.960104465484619  acc_train_error 34.325%  acc_test_error 50.0%\n",
      "Epoch: 2905 Loss: 5.957198619842529  acc_train_error 34.3375%  acc_test_error 50.0%\n",
      "Epoch: 2906 Loss: 5.954293251037598  acc_train_error 34.3375%  acc_test_error 50.0%\n",
      "Epoch: 2907 Loss: 5.951392650604248  acc_train_error 34.35%  acc_test_error 50.0%\n",
      "Epoch: 2908 Loss: 5.948487281799316  acc_train_error 34.3625%  acc_test_error 50.0%\n",
      "Epoch: 2909 Loss: 5.945584774017334  acc_train_error 34.3625%  acc_test_error 50.0%\n",
      "Epoch: 2910 Loss: 5.942689895629883  acc_train_error 34.3625%  acc_test_error 50.0%\n",
      "Epoch: 2911 Loss: 5.939795017242432  acc_train_error 34.375%  acc_test_error 50.0%\n",
      "Epoch: 2912 Loss: 5.936901092529297  acc_train_error 34.375%  acc_test_error 50.0%\n",
      "Epoch: 2913 Loss: 5.93400764465332  acc_train_error 34.375%  acc_test_error 50.0%\n",
      "Epoch: 2914 Loss: 5.931118965148926  acc_train_error 34.3875%  acc_test_error 50.0%\n",
      "Epoch: 2915 Loss: 5.928229808807373  acc_train_error 34.3875%  acc_test_error 50.0%\n",
      "Epoch: 2916 Loss: 5.925345420837402  acc_train_error 34.4%  acc_test_error 50.0%\n",
      "Epoch: 2917 Loss: 5.922457218170166  acc_train_error 34.4%  acc_test_error 50.0%\n",
      "Epoch: 2918 Loss: 5.9195733070373535  acc_train_error 34.4%  acc_test_error 50.0%\n",
      "Epoch: 2919 Loss: 5.916688919067383  acc_train_error 34.4125%  acc_test_error 50.0%\n",
      "Epoch: 2920 Loss: 5.9138031005859375  acc_train_error 34.4125%  acc_test_error 50.0%\n",
      "Epoch: 2921 Loss: 5.910923480987549  acc_train_error 34.425%  acc_test_error 50.0%\n",
      "Epoch: 2922 Loss: 5.908044338226318  acc_train_error 34.425%  acc_test_error 50.0%\n",
      "Epoch: 2923 Loss: 5.9051618576049805  acc_train_error 34.425%  acc_test_error 50.0%\n",
      "Epoch: 2924 Loss: 5.902291774749756  acc_train_error 34.4375%  acc_test_error 50.0%\n",
      "Epoch: 2925 Loss: 5.899416923522949  acc_train_error 34.4375%  acc_test_error 50.0%\n",
      "Epoch: 2926 Loss: 5.896543502807617  acc_train_error 34.4375%  acc_test_error 50.0%\n",
      "Epoch: 2927 Loss: 5.893674850463867  acc_train_error 34.45%  acc_test_error 50.0%\n",
      "Epoch: 2928 Loss: 5.890803813934326  acc_train_error 34.4625%  acc_test_error 50.0%\n",
      "Epoch: 2929 Loss: 5.887935161590576  acc_train_error 34.4625%  acc_test_error 50.0%\n",
      "Epoch: 2930 Loss: 5.885068893432617  acc_train_error 34.475%  acc_test_error 50.0%\n",
      "Epoch: 2931 Loss: 5.882203578948975  acc_train_error 34.475%  acc_test_error 50.0%\n",
      "Epoch: 2932 Loss: 5.879340648651123  acc_train_error 34.4875%  acc_test_error 50.0%\n",
      "Epoch: 2933 Loss: 5.876479625701904  acc_train_error 34.4875%  acc_test_error 50.0%\n",
      "Epoch: 2934 Loss: 5.873621940612793  acc_train_error 34.4875%  acc_test_error 50.0%\n",
      "Epoch: 2935 Loss: 5.870763778686523  acc_train_error 34.5%  acc_test_error 50.0%\n",
      "Epoch: 2936 Loss: 5.867908000946045  acc_train_error 34.5%  acc_test_error 50.0%\n",
      "Epoch: 2937 Loss: 5.865055084228516  acc_train_error 34.5125%  acc_test_error 50.0%\n",
      "Epoch: 2938 Loss: 5.862202167510986  acc_train_error 34.5125%  acc_test_error 50.0%\n",
      "Epoch: 2939 Loss: 5.859354496002197  acc_train_error 34.55%  acc_test_error 50.0%\n",
      "Epoch: 2940 Loss: 5.856510162353516  acc_train_error 34.5625%  acc_test_error 50.0%\n",
      "Epoch: 2941 Loss: 5.853665351867676  acc_train_error 34.5875%  acc_test_error 50.0%\n",
      "Epoch: 2942 Loss: 5.850818634033203  acc_train_error 34.6%  acc_test_error 50.0%\n",
      "Epoch: 2943 Loss: 5.847981929779053  acc_train_error 34.6125%  acc_test_error 50.0%\n",
      "Epoch: 2944 Loss: 5.845141887664795  acc_train_error 34.6375%  acc_test_error 50.0%\n",
      "Epoch: 2945 Loss: 5.842302322387695  acc_train_error 34.65%  acc_test_error 50.0%\n",
      "Epoch: 2946 Loss: 5.8394670486450195  acc_train_error 34.675%  acc_test_error 50.0%\n",
      "Epoch: 2947 Loss: 5.836635112762451  acc_train_error 34.7%  acc_test_error 50.0%\n",
      "Epoch: 2948 Loss: 5.833802223205566  acc_train_error 34.7125%  acc_test_error 50.0%\n",
      "Epoch: 2949 Loss: 5.830970287322998  acc_train_error 34.7375%  acc_test_error 50.0%\n",
      "Epoch: 2950 Loss: 5.828141689300537  acc_train_error 34.75%  acc_test_error 50.0%\n",
      "Epoch: 2951 Loss: 5.825316905975342  acc_train_error 34.775%  acc_test_error 50.0%\n",
      "Epoch: 2952 Loss: 5.822494983673096  acc_train_error 34.7875%  acc_test_error 50.0%\n",
      "Epoch: 2953 Loss: 5.819674491882324  acc_train_error 34.7875%  acc_test_error 50.0%\n",
      "Epoch: 2954 Loss: 5.816859722137451  acc_train_error 34.8%  acc_test_error 50.0%\n",
      "Epoch: 2955 Loss: 5.8140411376953125  acc_train_error 34.825%  acc_test_error 50.0%\n",
      "Epoch: 2956 Loss: 5.8112311363220215  acc_train_error 34.825%  acc_test_error 50.0%\n",
      "Epoch: 2957 Loss: 5.808420658111572  acc_train_error 34.8125%  acc_test_error 50.0%\n",
      "Epoch: 2958 Loss: 5.805609226226807  acc_train_error 34.85%  acc_test_error 50.0%\n",
      "Epoch: 2959 Loss: 5.802801132202148  acc_train_error 34.8375%  acc_test_error 50.0%\n",
      "Epoch: 2960 Loss: 5.799993515014648  acc_train_error 34.8375%  acc_test_error 50.0%\n",
      "Epoch: 2961 Loss: 5.797189235687256  acc_train_error 34.8375%  acc_test_error 50.0%\n",
      "Epoch: 2962 Loss: 5.7943878173828125  acc_train_error 34.85%  acc_test_error 50.0%\n",
      "Epoch: 2963 Loss: 5.791588306427002  acc_train_error 34.85%  acc_test_error 50.0%\n",
      "Epoch: 2964 Loss: 5.788789749145508  acc_train_error 34.85%  acc_test_error 50.0%\n",
      "Epoch: 2965 Loss: 5.785991668701172  acc_train_error 34.85%  acc_test_error 50.0%\n",
      "Epoch: 2966 Loss: 5.783195972442627  acc_train_error 34.8625%  acc_test_error 50.0%\n",
      "Epoch: 2967 Loss: 5.780400276184082  acc_train_error 34.8625%  acc_test_error 50.0%\n",
      "Epoch: 2968 Loss: 5.777609348297119  acc_train_error 34.8625%  acc_test_error 50.0%\n",
      "Epoch: 2969 Loss: 5.774813652038574  acc_train_error 34.875%  acc_test_error 50.0%\n",
      "Epoch: 2970 Loss: 5.772025108337402  acc_train_error 34.875%  acc_test_error 50.0%\n",
      "Epoch: 2971 Loss: 5.769233703613281  acc_train_error 34.8875%  acc_test_error 50.0%\n",
      "Epoch: 2972 Loss: 5.766448497772217  acc_train_error 34.8875%  acc_test_error 50.0%\n",
      "Epoch: 2973 Loss: 5.763662338256836  acc_train_error 34.8875%  acc_test_error 50.0%\n",
      "Epoch: 2974 Loss: 5.760876178741455  acc_train_error 34.9%  acc_test_error 50.0%\n",
      "Epoch: 2975 Loss: 5.758098125457764  acc_train_error 34.9%  acc_test_error 50.0%\n",
      "Epoch: 2976 Loss: 5.755317687988281  acc_train_error 34.9125%  acc_test_error 50.0%\n",
      "Epoch: 2977 Loss: 5.752536296844482  acc_train_error 34.9125%  acc_test_error 50.0%\n",
      "Epoch: 2978 Loss: 5.749764919281006  acc_train_error 34.9125%  acc_test_error 50.0%\n",
      "Epoch: 2979 Loss: 5.7469916343688965  acc_train_error 34.925%  acc_test_error 50.0%\n",
      "Epoch: 2980 Loss: 5.744222164154053  acc_train_error 34.925%  acc_test_error 50.0%\n",
      "Epoch: 2981 Loss: 5.741449356079102  acc_train_error 34.925%  acc_test_error 50.0%\n",
      "Epoch: 2982 Loss: 5.738681793212891  acc_train_error 34.925%  acc_test_error 50.0%\n",
      "Epoch: 2983 Loss: 5.735919952392578  acc_train_error 34.9375%  acc_test_error 50.0%\n",
      "Epoch: 2984 Loss: 5.733150482177734  acc_train_error 34.9375%  acc_test_error 50.0%\n",
      "Epoch: 2985 Loss: 5.730391025543213  acc_train_error 34.9375%  acc_test_error 50.0%\n",
      "Epoch: 2986 Loss: 5.727628707885742  acc_train_error 34.9375%  acc_test_error 50.0%\n",
      "Epoch: 2987 Loss: 5.724868297576904  acc_train_error 34.95%  acc_test_error 50.0%\n",
      "Epoch: 2988 Loss: 5.722110271453857  acc_train_error 34.95%  acc_test_error 50.0%\n",
      "Epoch: 2989 Loss: 5.719351291656494  acc_train_error 34.95%  acc_test_error 50.0%\n",
      "Epoch: 2990 Loss: 5.716599464416504  acc_train_error 34.9625%  acc_test_error 50.0%\n",
      "Epoch: 2991 Loss: 5.713846683502197  acc_train_error 34.9625%  acc_test_error 50.0%\n",
      "Epoch: 2992 Loss: 5.711094856262207  acc_train_error 34.9625%  acc_test_error 50.0%\n",
      "Epoch: 2993 Loss: 5.70834493637085  acc_train_error 34.975%  acc_test_error 50.0%\n",
      "Epoch: 2994 Loss: 5.705599308013916  acc_train_error 34.975%  acc_test_error 50.0%\n",
      "Epoch: 2995 Loss: 5.702853202819824  acc_train_error 34.975%  acc_test_error 50.0%\n",
      "Epoch: 2996 Loss: 5.700109958648682  acc_train_error 34.975%  acc_test_error 50.0%\n",
      "Epoch: 2997 Loss: 5.6973700523376465  acc_train_error 34.9875%  acc_test_error 50.0%\n",
      "Epoch: 2998 Loss: 5.694632053375244  acc_train_error 34.9875%  acc_test_error 50.0%\n",
      "Epoch: 2999 Loss: 5.69188928604126  acc_train_error 34.9875%  acc_test_error 50.0%\n",
      "Epoch: 3000 Loss: 5.689154148101807  acc_train_error 35.0125%  acc_test_error 50.0%\n",
      "Epoch: 3001 Loss: 5.6864190101623535  acc_train_error 35.0125%  acc_test_error 50.0%\n",
      "Epoch: 3002 Loss: 5.683684825897217  acc_train_error 35.0125%  acc_test_error 50.0%\n",
      "Epoch: 3003 Loss: 5.6809492111206055  acc_train_error 35.025%  acc_test_error 50.0%\n",
      "Epoch: 3004 Loss: 5.678224563598633  acc_train_error 35.025%  acc_test_error 50.0%\n",
      "Epoch: 3005 Loss: 5.675495624542236  acc_train_error 35.025%  acc_test_error 50.0%\n",
      "Epoch: 3006 Loss: 5.672766208648682  acc_train_error 35.0375%  acc_test_error 50.0%\n",
      "Epoch: 3007 Loss: 5.670042991638184  acc_train_error 35.0375%  acc_test_error 50.0%\n",
      "Epoch: 3008 Loss: 5.667317867279053  acc_train_error 35.0375%  acc_test_error 50.0%\n",
      "Epoch: 3009 Loss: 5.664597988128662  acc_train_error 35.05%  acc_test_error 50.0%\n",
      "Epoch: 3010 Loss: 5.661879062652588  acc_train_error 35.05%  acc_test_error 50.0%\n",
      "Epoch: 3011 Loss: 5.659161567687988  acc_train_error 35.075%  acc_test_error 50.0%\n",
      "Epoch: 3012 Loss: 5.656440734863281  acc_train_error 35.075%  acc_test_error 50.0%\n",
      "Epoch: 3013 Loss: 5.653731346130371  acc_train_error 35.0875%  acc_test_error 50.0%\n",
      "Epoch: 3014 Loss: 5.65101432800293  acc_train_error 35.0875%  acc_test_error 50.0%\n",
      "Epoch: 3015 Loss: 5.6483025550842285  acc_train_error 35.1%  acc_test_error 50.0%\n",
      "Epoch: 3016 Loss: 5.645590305328369  acc_train_error 35.1125%  acc_test_error 50.0%\n",
      "Epoch: 3017 Loss: 5.642886638641357  acc_train_error 35.1125%  acc_test_error 50.0%\n",
      "Epoch: 3018 Loss: 5.640178203582764  acc_train_error 35.125%  acc_test_error 50.0%\n",
      "Epoch: 3019 Loss: 5.637472152709961  acc_train_error 35.125%  acc_test_error 50.0%\n",
      "Epoch: 3020 Loss: 5.634769439697266  acc_train_error 35.1375%  acc_test_error 50.0%\n",
      "Epoch: 3021 Loss: 5.632070541381836  acc_train_error 35.1375%  acc_test_error 50.0%\n",
      "Epoch: 3022 Loss: 5.629373550415039  acc_train_error 35.1625%  acc_test_error 50.0%\n",
      "Epoch: 3023 Loss: 5.626675128936768  acc_train_error 35.1625%  acc_test_error 50.0%\n",
      "Epoch: 3024 Loss: 5.623983860015869  acc_train_error 35.175%  acc_test_error 50.0%\n",
      "Epoch: 3025 Loss: 5.621290683746338  acc_train_error 35.175%  acc_test_error 50.0%\n",
      "Epoch: 3026 Loss: 5.6186041831970215  acc_train_error 35.1875%  acc_test_error 50.0%\n",
      "Epoch: 3027 Loss: 5.615913391113281  acc_train_error 35.1875%  acc_test_error 50.0%\n",
      "Epoch: 3028 Loss: 5.61322546005249  acc_train_error 35.2%  acc_test_error 50.0%\n",
      "Epoch: 3029 Loss: 5.610543251037598  acc_train_error 35.2%  acc_test_error 50.0%\n",
      "Epoch: 3030 Loss: 5.6078596115112305  acc_train_error 35.2125%  acc_test_error 50.0%\n",
      "Epoch: 3031 Loss: 5.605178356170654  acc_train_error 35.2125%  acc_test_error 50.0%\n",
      "Epoch: 3032 Loss: 5.602494239807129  acc_train_error 35.225%  acc_test_error 50.0%\n",
      "Epoch: 3033 Loss: 5.599820137023926  acc_train_error 35.225%  acc_test_error 50.0%\n",
      "Epoch: 3034 Loss: 5.597141742706299  acc_train_error 35.225%  acc_test_error 50.0%\n",
      "Epoch: 3035 Loss: 5.594460964202881  acc_train_error 35.2375%  acc_test_error 50.0%\n",
      "Epoch: 3036 Loss: 5.591790676116943  acc_train_error 35.2375%  acc_test_error 50.0%\n",
      "Epoch: 3037 Loss: 5.589117050170898  acc_train_error 35.25%  acc_test_error 50.0%\n",
      "Epoch: 3038 Loss: 5.58644437789917  acc_train_error 35.2625%  acc_test_error 50.0%\n",
      "Epoch: 3039 Loss: 5.583776950836182  acc_train_error 35.275%  acc_test_error 50.0%\n",
      "Epoch: 3040 Loss: 5.581108570098877  acc_train_error 35.275%  acc_test_error 50.0%\n",
      "Epoch: 3041 Loss: 5.578441619873047  acc_train_error 35.2875%  acc_test_error 50.0%\n",
      "Epoch: 3042 Loss: 5.575780391693115  acc_train_error 35.2875%  acc_test_error 50.0%\n",
      "Epoch: 3043 Loss: 5.573116779327393  acc_train_error 35.3%  acc_test_error 50.0%\n",
      "Epoch: 3044 Loss: 5.570453643798828  acc_train_error 35.3%  acc_test_error 50.0%\n",
      "Epoch: 3045 Loss: 5.56779670715332  acc_train_error 35.3125%  acc_test_error 50.0%\n",
      "Epoch: 3046 Loss: 5.565135955810547  acc_train_error 35.3125%  acc_test_error 50.0%\n",
      "Epoch: 3047 Loss: 5.562482833862305  acc_train_error 35.3125%  acc_test_error 50.0%\n",
      "Epoch: 3048 Loss: 5.55982780456543  acc_train_error 35.325%  acc_test_error 50.0%\n",
      "Epoch: 3049 Loss: 5.5571746826171875  acc_train_error 35.3375%  acc_test_error 50.0%\n",
      "Epoch: 3050 Loss: 5.554516315460205  acc_train_error 35.35%  acc_test_error 50.0%\n",
      "Epoch: 3051 Loss: 5.551873683929443  acc_train_error 35.35%  acc_test_error 50.0%\n",
      "Epoch: 3052 Loss: 5.549219608306885  acc_train_error 35.3625%  acc_test_error 50.0%\n",
      "Epoch: 3053 Loss: 5.546553134918213  acc_train_error 35.525%  acc_test_error 50.0%\n",
      "Epoch: 3054 Loss: 5.543890476226807  acc_train_error 35.575%  acc_test_error 50.0%\n",
      "Epoch: 3055 Loss: 5.541234493255615  acc_train_error 35.8%  acc_test_error 50.0%\n",
      "Epoch: 3056 Loss: 5.538572788238525  acc_train_error 35.8125%  acc_test_error 50.0%\n",
      "Epoch: 3057 Loss: 5.535928249359131  acc_train_error 35.825%  acc_test_error 50.0%\n",
      "Epoch: 3058 Loss: 5.533275604248047  acc_train_error 35.8375%  acc_test_error 50.0%\n",
      "Epoch: 3059 Loss: 5.530623912811279  acc_train_error 35.85%  acc_test_error 50.0%\n",
      "Epoch: 3060 Loss: 5.527985572814941  acc_train_error 35.8625%  acc_test_error 50.0%\n",
      "Epoch: 3061 Loss: 5.5253400802612305  acc_train_error 35.875%  acc_test_error 50.0%\n",
      "Epoch: 3062 Loss: 5.522699356079102  acc_train_error 35.8875%  acc_test_error 50.0%\n",
      "Epoch: 3063 Loss: 5.520058631896973  acc_train_error 35.9%  acc_test_error 50.0%\n",
      "Epoch: 3064 Loss: 5.5174241065979  acc_train_error 35.9%  acc_test_error 50.0%\n",
      "Epoch: 3065 Loss: 5.5147881507873535  acc_train_error 35.9125%  acc_test_error 50.0%\n",
      "Epoch: 3066 Loss: 5.51215124130249  acc_train_error 35.925%  acc_test_error 50.0%\n",
      "Epoch: 3067 Loss: 5.509526252746582  acc_train_error 35.925%  acc_test_error 50.0%\n",
      "Epoch: 3068 Loss: 5.50689172744751  acc_train_error 35.95%  acc_test_error 50.0%\n",
      "Epoch: 3069 Loss: 5.504261493682861  acc_train_error 35.9625%  acc_test_error 50.0%\n",
      "Epoch: 3070 Loss: 5.501632213592529  acc_train_error 35.975%  acc_test_error 50.0%\n",
      "Epoch: 3071 Loss: 5.499007701873779  acc_train_error 35.9875%  acc_test_error 50.0%\n",
      "Epoch: 3072 Loss: 5.4963884353637695  acc_train_error 35.9875%  acc_test_error 50.0%\n",
      "Epoch: 3073 Loss: 5.493758678436279  acc_train_error 36.0%  acc_test_error 50.0%\n",
      "Epoch: 3074 Loss: 5.491145610809326  acc_train_error 36.025%  acc_test_error 50.0%\n",
      "Epoch: 3075 Loss: 5.488522529602051  acc_train_error 36.0375%  acc_test_error 50.0%\n",
      "Epoch: 3076 Loss: 5.4859113693237305  acc_train_error 36.0375%  acc_test_error 50.0%\n",
      "Epoch: 3077 Loss: 5.483294486999512  acc_train_error 36.05%  acc_test_error 50.0%\n",
      "Epoch: 3078 Loss: 5.480686664581299  acc_train_error 36.05%  acc_test_error 50.0%\n",
      "Epoch: 3079 Loss: 5.478076457977295  acc_train_error 36.0625%  acc_test_error 50.0%\n",
      "Epoch: 3080 Loss: 5.475467681884766  acc_train_error 36.0625%  acc_test_error 50.0%\n",
      "Epoch: 3081 Loss: 5.4728569984436035  acc_train_error 36.0875%  acc_test_error 50.0%\n",
      "Epoch: 3082 Loss: 5.47025203704834  acc_train_error 36.1%  acc_test_error 50.0%\n",
      "Epoch: 3083 Loss: 5.467652797698975  acc_train_error 36.1%  acc_test_error 50.0%\n",
      "Epoch: 3084 Loss: 5.465043544769287  acc_train_error 36.1125%  acc_test_error 50.0%\n",
      "Epoch: 3085 Loss: 5.462449073791504  acc_train_error 36.1125%  acc_test_error 50.0%\n",
      "Epoch: 3086 Loss: 5.459841251373291  acc_train_error 36.125%  acc_test_error 50.0%\n",
      "Epoch: 3087 Loss: 5.457245826721191  acc_train_error 36.15%  acc_test_error 50.0%\n",
      "Epoch: 3088 Loss: 5.454625129699707  acc_train_error 36.175%  acc_test_error 50.0%\n",
      "Epoch: 3089 Loss: 5.452017307281494  acc_train_error 36.1875%  acc_test_error 50.0%\n",
      "Epoch: 3090 Loss: 5.449408531188965  acc_train_error 36.1875%  acc_test_error 50.0%\n",
      "Epoch: 3091 Loss: 5.446794033050537  acc_train_error 36.2125%  acc_test_error 50.0%\n",
      "Epoch: 3092 Loss: 5.444189071655273  acc_train_error 36.2125%  acc_test_error 50.0%\n",
      "Epoch: 3093 Loss: 5.441585540771484  acc_train_error 36.225%  acc_test_error 50.0%\n",
      "Epoch: 3094 Loss: 5.438981533050537  acc_train_error 36.25%  acc_test_error 50.0%\n",
      "Epoch: 3095 Loss: 5.436379909515381  acc_train_error 36.2625%  acc_test_error 50.0%\n",
      "Epoch: 3096 Loss: 5.4337873458862305  acc_train_error 36.2625%  acc_test_error 50.0%\n",
      "Epoch: 3097 Loss: 5.431181907653809  acc_train_error 36.2875%  acc_test_error 50.0%\n",
      "Epoch: 3098 Loss: 5.428594589233398  acc_train_error 36.2875%  acc_test_error 50.0%\n",
      "Epoch: 3099 Loss: 5.425998687744141  acc_train_error 36.2875%  acc_test_error 50.0%\n",
      "Epoch: 3100 Loss: 5.4234089851379395  acc_train_error 36.3125%  acc_test_error 50.0%\n",
      "Epoch: 3101 Loss: 5.420821189880371  acc_train_error 36.325%  acc_test_error 50.0%\n",
      "Epoch: 3102 Loss: 5.4182305335998535  acc_train_error 36.325%  acc_test_error 50.0%\n",
      "Epoch: 3103 Loss: 5.415651321411133  acc_train_error 36.3375%  acc_test_error 50.0%\n",
      "Epoch: 3104 Loss: 5.41306209564209  acc_train_error 36.35%  acc_test_error 50.0%\n",
      "Epoch: 3105 Loss: 5.410489082336426  acc_train_error 36.35%  acc_test_error 50.0%\n",
      "Epoch: 3106 Loss: 5.407903671264648  acc_train_error 36.375%  acc_test_error 50.0%\n",
      "Epoch: 3107 Loss: 5.405330657958984  acc_train_error 36.375%  acc_test_error 50.0%\n",
      "Epoch: 3108 Loss: 5.402759075164795  acc_train_error 36.3875%  acc_test_error 50.0%\n",
      "Epoch: 3109 Loss: 5.400177478790283  acc_train_error 36.4%  acc_test_error 50.0%\n",
      "Epoch: 3110 Loss: 5.397611618041992  acc_train_error 36.4%  acc_test_error 50.0%\n",
      "Epoch: 3111 Loss: 5.3950324058532715  acc_train_error 36.4125%  acc_test_error 50.0%\n",
      "Epoch: 3112 Loss: 5.392473220825195  acc_train_error 36.425%  acc_test_error 50.0%\n",
      "Epoch: 3113 Loss: 5.3899030685424805  acc_train_error 36.425%  acc_test_error 50.0%\n",
      "Epoch: 3114 Loss: 5.387333869934082  acc_train_error 36.4375%  acc_test_error 50.0%\n",
      "Epoch: 3115 Loss: 5.384768962860107  acc_train_error 36.45%  acc_test_error 50.0%\n",
      "Epoch: 3116 Loss: 5.382205963134766  acc_train_error 36.4625%  acc_test_error 50.0%\n",
      "Epoch: 3117 Loss: 5.379650115966797  acc_train_error 36.4625%  acc_test_error 50.0%\n",
      "Epoch: 3118 Loss: 5.377078533172607  acc_train_error 36.475%  acc_test_error 50.0%\n",
      "Epoch: 3119 Loss: 5.374531269073486  acc_train_error 36.4875%  acc_test_error 50.0%\n",
      "Epoch: 3120 Loss: 5.371971130371094  acc_train_error 36.4875%  acc_test_error 50.0%\n",
      "Epoch: 3121 Loss: 5.369410514831543  acc_train_error 36.4875%  acc_test_error 50.0%\n",
      "Epoch: 3122 Loss: 5.366864204406738  acc_train_error 36.5%  acc_test_error 50.0%\n",
      "Epoch: 3123 Loss: 5.364309787750244  acc_train_error 36.5125%  acc_test_error 50.0%\n",
      "Epoch: 3124 Loss: 5.361757755279541  acc_train_error 36.5125%  acc_test_error 50.0%\n",
      "Epoch: 3125 Loss: 5.359209060668945  acc_train_error 36.525%  acc_test_error 50.0%\n",
      "Epoch: 3126 Loss: 5.356658458709717  acc_train_error 36.5375%  acc_test_error 50.0%\n",
      "Epoch: 3127 Loss: 5.35410737991333  acc_train_error 36.5375%  acc_test_error 50.0%\n",
      "Epoch: 3128 Loss: 5.351564407348633  acc_train_error 36.55%  acc_test_error 50.0%\n",
      "Epoch: 3129 Loss: 5.349018096923828  acc_train_error 36.5625%  acc_test_error 50.0%\n",
      "Epoch: 3130 Loss: 5.346473693847656  acc_train_error 36.5625%  acc_test_error 50.0%\n",
      "Epoch: 3131 Loss: 5.343932151794434  acc_train_error 36.5875%  acc_test_error 50.0%\n",
      "Epoch: 3132 Loss: 5.341389179229736  acc_train_error 36.5875%  acc_test_error 50.0%\n",
      "Epoch: 3133 Loss: 5.338850021362305  acc_train_error 36.5875%  acc_test_error 50.0%\n",
      "Epoch: 3134 Loss: 5.336309909820557  acc_train_error 36.6125%  acc_test_error 50.0%\n",
      "Epoch: 3135 Loss: 5.333776950836182  acc_train_error 36.6125%  acc_test_error 50.0%\n",
      "Epoch: 3136 Loss: 5.331235408782959  acc_train_error 36.6125%  acc_test_error 50.0%\n",
      "Epoch: 3137 Loss: 5.3287034034729  acc_train_error 36.625%  acc_test_error 50.0%\n",
      "Epoch: 3138 Loss: 5.326173305511475  acc_train_error 36.6375%  acc_test_error 50.0%\n",
      "Epoch: 3139 Loss: 5.323639392852783  acc_train_error 36.6375%  acc_test_error 50.0%\n",
      "Epoch: 3140 Loss: 5.321117401123047  acc_train_error 36.65%  acc_test_error 50.0%\n",
      "Epoch: 3141 Loss: 5.3185906410217285  acc_train_error 36.65%  acc_test_error 50.0%\n",
      "Epoch: 3142 Loss: 5.316061973571777  acc_train_error 36.6625%  acc_test_error 50.0%\n",
      "Epoch: 3143 Loss: 5.313543319702148  acc_train_error 36.675%  acc_test_error 50.0%\n",
      "Epoch: 3144 Loss: 5.311022758483887  acc_train_error 36.675%  acc_test_error 50.0%\n",
      "Epoch: 3145 Loss: 5.308499336242676  acc_train_error 36.675%  acc_test_error 50.0%\n",
      "Epoch: 3146 Loss: 5.305985927581787  acc_train_error 36.6875%  acc_test_error 50.0%\n",
      "Epoch: 3147 Loss: 5.303467273712158  acc_train_error 36.7%  acc_test_error 50.0%\n",
      "Epoch: 3148 Loss: 5.300954341888428  acc_train_error 36.7%  acc_test_error 50.0%\n",
      "Epoch: 3149 Loss: 5.298443794250488  acc_train_error 36.7125%  acc_test_error 50.0%\n",
      "Epoch: 3150 Loss: 5.29592752456665  acc_train_error 36.7375%  acc_test_error 50.0%\n",
      "Epoch: 3151 Loss: 5.293421745300293  acc_train_error 36.7625%  acc_test_error 50.0%\n",
      "Epoch: 3152 Loss: 5.29090690612793  acc_train_error 36.775%  acc_test_error 50.0%\n",
      "Epoch: 3153 Loss: 5.288407325744629  acc_train_error 36.8125%  acc_test_error 50.0%\n",
      "Epoch: 3154 Loss: 5.285898685455322  acc_train_error 36.825%  acc_test_error 50.0%\n",
      "Epoch: 3155 Loss: 5.283393859863281  acc_train_error 36.8375%  acc_test_error 50.0%\n",
      "Epoch: 3156 Loss: 5.2808942794799805  acc_train_error 36.875%  acc_test_error 50.0%\n",
      "Epoch: 3157 Loss: 5.278385162353516  acc_train_error 36.8875%  acc_test_error 50.0%\n",
      "Epoch: 3158 Loss: 5.27589225769043  acc_train_error 36.9%  acc_test_error 50.0%\n",
      "Epoch: 3159 Loss: 5.273392200469971  acc_train_error 36.9125%  acc_test_error 50.0%\n",
      "Epoch: 3160 Loss: 5.270888805389404  acc_train_error 36.9375%  acc_test_error 50.0%\n",
      "Epoch: 3161 Loss: 5.268396854400635  acc_train_error 36.975%  acc_test_error 50.0%\n",
      "Epoch: 3162 Loss: 5.2659010887146  acc_train_error 36.975%  acc_test_error 50.0%\n",
      "Epoch: 3163 Loss: 5.263406276702881  acc_train_error 37.0125%  acc_test_error 50.0%\n",
      "Epoch: 3164 Loss: 5.2609148025512695  acc_train_error 37.0125%  acc_test_error 50.0%\n",
      "Epoch: 3165 Loss: 5.258424758911133  acc_train_error 37.025%  acc_test_error 50.0%\n",
      "Epoch: 3166 Loss: 5.25593376159668  acc_train_error 37.0375%  acc_test_error 50.0%\n",
      "Epoch: 3167 Loss: 5.253450870513916  acc_train_error 37.0625%  acc_test_error 50.0%\n",
      "Epoch: 3168 Loss: 5.250959873199463  acc_train_error 37.075%  acc_test_error 50.0%\n",
      "Epoch: 3169 Loss: 5.248483657836914  acc_train_error 37.1%  acc_test_error 50.0%\n",
      "Epoch: 3170 Loss: 5.245996952056885  acc_train_error 37.1125%  acc_test_error 50.0%\n",
      "Epoch: 3171 Loss: 5.2435102462768555  acc_train_error 37.125%  acc_test_error 50.0%\n",
      "Epoch: 3172 Loss: 5.241038799285889  acc_train_error 37.15%  acc_test_error 50.0%\n",
      "Epoch: 3173 Loss: 5.238555908203125  acc_train_error 37.1625%  acc_test_error 50.0%\n",
      "Epoch: 3174 Loss: 5.236073970794678  acc_train_error 37.1875%  acc_test_error 50.0%\n",
      "Epoch: 3175 Loss: 5.233603000640869  acc_train_error 37.2125%  acc_test_error 50.0%\n",
      "Epoch: 3176 Loss: 5.231125354766846  acc_train_error 37.225%  acc_test_error 50.0%\n",
      "Epoch: 3177 Loss: 5.228646278381348  acc_train_error 37.2375%  acc_test_error 50.0%\n",
      "Epoch: 3178 Loss: 5.2261786460876465  acc_train_error 37.25%  acc_test_error 50.0%\n",
      "Epoch: 3179 Loss: 5.223707675933838  acc_train_error 37.275%  acc_test_error 50.0%\n",
      "Epoch: 3180 Loss: 5.221231937408447  acc_train_error 37.2875%  acc_test_error 50.0%\n",
      "Epoch: 3181 Loss: 5.2187700271606445  acc_train_error 37.3%  acc_test_error 50.0%\n",
      "Epoch: 3182 Loss: 5.2162981033325195  acc_train_error 37.325%  acc_test_error 50.0%\n",
      "Epoch: 3183 Loss: 5.213831424713135  acc_train_error 37.35%  acc_test_error 50.0%\n",
      "Epoch: 3184 Loss: 5.211369514465332  acc_train_error 37.3625%  acc_test_error 50.0%\n",
      "Epoch: 3185 Loss: 5.208905220031738  acc_train_error 37.3875%  acc_test_error 50.0%\n",
      "Epoch: 3186 Loss: 5.206448078155518  acc_train_error 37.3875%  acc_test_error 50.0%\n",
      "Epoch: 3187 Loss: 5.203988075256348  acc_train_error 37.3875%  acc_test_error 50.0%\n",
      "Epoch: 3188 Loss: 5.2015228271484375  acc_train_error 37.4125%  acc_test_error 50.0%\n",
      "Epoch: 3189 Loss: 5.199063301086426  acc_train_error 37.425%  acc_test_error 50.0%\n",
      "Epoch: 3190 Loss: 5.196610450744629  acc_train_error 37.4375%  acc_test_error 50.0%\n",
      "Epoch: 3191 Loss: 5.194164276123047  acc_train_error 37.45%  acc_test_error 50.0%\n",
      "Epoch: 3192 Loss: 5.191699981689453  acc_train_error 37.4625%  acc_test_error 50.0%\n",
      "Epoch: 3193 Loss: 5.1892499923706055  acc_train_error 37.4875%  acc_test_error 50.0%\n",
      "Epoch: 3194 Loss: 5.1867995262146  acc_train_error 37.4875%  acc_test_error 50.0%\n",
      "Epoch: 3195 Loss: 5.1843461990356445  acc_train_error 37.5125%  acc_test_error 50.0%\n",
      "Epoch: 3196 Loss: 5.1819167137146  acc_train_error 37.5125%  acc_test_error 50.0%\n",
      "Epoch: 3197 Loss: 5.179459095001221  acc_train_error 37.525%  acc_test_error 50.0%\n",
      "Epoch: 3198 Loss: 5.177009105682373  acc_train_error 37.55%  acc_test_error 50.0%\n",
      "Epoch: 3199 Loss: 5.174570083618164  acc_train_error 37.55%  acc_test_error 50.0%\n",
      "Epoch: 3200 Loss: 5.172138214111328  acc_train_error 37.55%  acc_test_error 50.0%\n",
      "Epoch: 3201 Loss: 5.169689178466797  acc_train_error 37.575%  acc_test_error 50.0%\n",
      "Epoch: 3202 Loss: 5.167243957519531  acc_train_error 37.5875%  acc_test_error 50.0%\n",
      "Epoch: 3203 Loss: 5.164813041687012  acc_train_error 37.5875%  acc_test_error 50.0%\n",
      "Epoch: 3204 Loss: 5.16238260269165  acc_train_error 37.6%  acc_test_error 50.0%\n",
      "Epoch: 3205 Loss: 5.159935474395752  acc_train_error 37.6375%  acc_test_error 50.0%\n",
      "Epoch: 3206 Loss: 5.157501220703125  acc_train_error 37.6375%  acc_test_error 50.0%\n",
      "Epoch: 3207 Loss: 5.155065059661865  acc_train_error 37.65%  acc_test_error 50.0%\n",
      "Epoch: 3208 Loss: 5.152640342712402  acc_train_error 37.6625%  acc_test_error 50.0%\n",
      "Epoch: 3209 Loss: 5.150206089019775  acc_train_error 37.7%  acc_test_error 50.0%\n",
      "Epoch: 3210 Loss: 5.147770404815674  acc_train_error 37.7%  acc_test_error 50.0%\n",
      "Epoch: 3211 Loss: 5.1453399658203125  acc_train_error 37.725%  acc_test_error 50.0%\n",
      "Epoch: 3212 Loss: 5.142927646636963  acc_train_error 37.725%  acc_test_error 50.0%\n",
      "Epoch: 3213 Loss: 5.1404852867126465  acc_train_error 37.75%  acc_test_error 50.0%\n",
      "Epoch: 3214 Loss: 5.138054847717285  acc_train_error 37.7625%  acc_test_error 50.0%\n",
      "Epoch: 3215 Loss: 5.135638236999512  acc_train_error 37.775%  acc_test_error 50.0%\n",
      "Epoch: 3216 Loss: 5.133208274841309  acc_train_error 37.7875%  acc_test_error 50.0%\n",
      "Epoch: 3217 Loss: 5.1307806968688965  acc_train_error 37.8%  acc_test_error 50.0%\n",
      "Epoch: 3218 Loss: 5.128375053405762  acc_train_error 37.8%  acc_test_error 50.0%\n",
      "Epoch: 3219 Loss: 5.125938892364502  acc_train_error 37.8375%  acc_test_error 50.0%\n",
      "Epoch: 3220 Loss: 5.123520374298096  acc_train_error 37.8375%  acc_test_error 50.0%\n",
      "Epoch: 3221 Loss: 5.121117115020752  acc_train_error 37.85%  acc_test_error 50.0%\n",
      "Epoch: 3222 Loss: 5.118683338165283  acc_train_error 37.875%  acc_test_error 50.0%\n",
      "Epoch: 3223 Loss: 5.116271018981934  acc_train_error 37.875%  acc_test_error 50.0%\n",
      "Epoch: 3224 Loss: 5.113874435424805  acc_train_error 37.875%  acc_test_error 50.0%\n",
      "Epoch: 3225 Loss: 5.111445903778076  acc_train_error 37.9125%  acc_test_error 50.0%\n",
      "Epoch: 3226 Loss: 5.109042167663574  acc_train_error 37.925%  acc_test_error 50.0%\n",
      "Epoch: 3227 Loss: 5.106629848480225  acc_train_error 37.925%  acc_test_error 50.0%\n",
      "Epoch: 3228 Loss: 5.104217052459717  acc_train_error 37.9375%  acc_test_error 50.0%\n",
      "Epoch: 3229 Loss: 5.101824760437012  acc_train_error 37.9375%  acc_test_error 50.0%\n",
      "Epoch: 3230 Loss: 5.099408149719238  acc_train_error 37.975%  acc_test_error 50.0%\n",
      "Epoch: 3231 Loss: 5.097005844116211  acc_train_error 37.9875%  acc_test_error 50.0%\n",
      "Epoch: 3232 Loss: 5.09461784362793  acc_train_error 37.9875%  acc_test_error 50.0%\n",
      "Epoch: 3233 Loss: 5.092202186584473  acc_train_error 37.9875%  acc_test_error 50.0%\n",
      "Epoch: 3234 Loss: 5.089813232421875  acc_train_error 38.0%  acc_test_error 50.0%\n",
      "Epoch: 3235 Loss: 5.087399482727051  acc_train_error 38.0375%  acc_test_error 50.0%\n",
      "Epoch: 3236 Loss: 5.085017681121826  acc_train_error 38.0375%  acc_test_error 50.0%\n",
      "Epoch: 3237 Loss: 5.08261251449585  acc_train_error 38.0375%  acc_test_error 50.0%\n",
      "Epoch: 3238 Loss: 5.0802106857299805  acc_train_error 38.075%  acc_test_error 50.0%\n",
      "Epoch: 3239 Loss: 5.077839374542236  acc_train_error 38.075%  acc_test_error 50.0%\n",
      "Epoch: 3240 Loss: 5.075425624847412  acc_train_error 38.0875%  acc_test_error 50.0%\n",
      "Epoch: 3241 Loss: 5.073056221008301  acc_train_error 38.0875%  acc_test_error 50.0%\n",
      "Epoch: 3242 Loss: 5.070653915405273  acc_train_error 38.1%  acc_test_error 50.0%\n",
      "Epoch: 3243 Loss: 5.068281650543213  acc_train_error 38.1%  acc_test_error 50.0%\n",
      "Epoch: 3244 Loss: 5.065883636474609  acc_train_error 38.125%  acc_test_error 50.0%\n",
      "Epoch: 3245 Loss: 5.063509941101074  acc_train_error 38.1375%  acc_test_error 50.0%\n",
      "Epoch: 3246 Loss: 5.0611114501953125  acc_train_error 38.15%  acc_test_error 50.0%\n",
      "Epoch: 3247 Loss: 5.058745861053467  acc_train_error 38.15%  acc_test_error 50.0%\n",
      "Epoch: 3248 Loss: 5.056349754333496  acc_train_error 38.1625%  acc_test_error 50.0%\n",
      "Epoch: 3249 Loss: 5.053980350494385  acc_train_error 38.1625%  acc_test_error 50.0%\n",
      "Epoch: 3250 Loss: 5.05158805847168  acc_train_error 38.2%  acc_test_error 50.0%\n",
      "Epoch: 3251 Loss: 5.049220561981201  acc_train_error 38.2%  acc_test_error 50.0%\n",
      "Epoch: 3252 Loss: 5.046835899353027  acc_train_error 38.2%  acc_test_error 50.0%\n",
      "Epoch: 3253 Loss: 5.044473171234131  acc_train_error 38.2%  acc_test_error 50.0%\n",
      "Epoch: 3254 Loss: 5.042088031768799  acc_train_error 38.2%  acc_test_error 50.0%\n",
      "Epoch: 3255 Loss: 5.039723873138428  acc_train_error 38.2125%  acc_test_error 50.0%\n",
      "Epoch: 3256 Loss: 5.037343978881836  acc_train_error 38.2375%  acc_test_error 50.0%\n",
      "Epoch: 3257 Loss: 5.034976959228516  acc_train_error 38.2375%  acc_test_error 50.0%\n",
      "Epoch: 3258 Loss: 5.032605171203613  acc_train_error 38.2375%  acc_test_error 50.0%\n",
      "Epoch: 3259 Loss: 5.030246257781982  acc_train_error 38.2375%  acc_test_error 50.0%\n",
      "Epoch: 3260 Loss: 5.027872085571289  acc_train_error 38.275%  acc_test_error 50.0%\n",
      "Epoch: 3261 Loss: 5.025515079498291  acc_train_error 38.275%  acc_test_error 50.0%\n",
      "Epoch: 3262 Loss: 5.023141384124756  acc_train_error 38.275%  acc_test_error 50.0%\n",
      "Epoch: 3263 Loss: 5.020787239074707  acc_train_error 38.275%  acc_test_error 50.0%\n",
      "Epoch: 3264 Loss: 5.018418312072754  acc_train_error 38.275%  acc_test_error 50.0%\n",
      "Epoch: 3265 Loss: 5.016063690185547  acc_train_error 38.275%  acc_test_error 50.0%\n",
      "Epoch: 3266 Loss: 5.013698101043701  acc_train_error 38.3125%  acc_test_error 50.0%\n",
      "Epoch: 3267 Loss: 5.011352062225342  acc_train_error 38.3125%  acc_test_error 50.0%\n",
      "Epoch: 3268 Loss: 5.008984088897705  acc_train_error 38.325%  acc_test_error 50.0%\n",
      "Epoch: 3269 Loss: 5.006640434265137  acc_train_error 38.325%  acc_test_error 50.0%\n",
      "Epoch: 3270 Loss: 5.004274845123291  acc_train_error 38.325%  acc_test_error 50.0%\n",
      "Epoch: 3271 Loss: 5.0019330978393555  acc_train_error 38.325%  acc_test_error 50.0%\n",
      "Epoch: 3272 Loss: 4.999567031860352  acc_train_error 38.35%  acc_test_error 50.0%\n",
      "Epoch: 3273 Loss: 4.997231483459473  acc_train_error 38.35%  acc_test_error 50.0%\n",
      "Epoch: 3274 Loss: 4.99486780166626  acc_train_error 38.3625%  acc_test_error 50.0%\n",
      "Epoch: 3275 Loss: 4.99253511428833  acc_train_error 38.3625%  acc_test_error 50.0%\n",
      "Epoch: 3276 Loss: 4.990168571472168  acc_train_error 38.3875%  acc_test_error 50.0%\n",
      "Epoch: 3277 Loss: 4.987846374511719  acc_train_error 38.3875%  acc_test_error 50.0%\n",
      "Epoch: 3278 Loss: 4.985480785369873  acc_train_error 38.4%  acc_test_error 50.0%\n",
      "Epoch: 3279 Loss: 4.983157157897949  acc_train_error 38.4%  acc_test_error 50.0%\n",
      "Epoch: 3280 Loss: 4.98079776763916  acc_train_error 38.425%  acc_test_error 50.0%\n",
      "Epoch: 3281 Loss: 4.9784770011901855  acc_train_error 38.4125%  acc_test_error 50.0%\n",
      "Epoch: 3282 Loss: 4.976115703582764  acc_train_error 38.4375%  acc_test_error 50.0%\n",
      "Epoch: 3283 Loss: 4.973803520202637  acc_train_error 38.425%  acc_test_error 50.0%\n",
      "Epoch: 3284 Loss: 4.971457481384277  acc_train_error 38.425%  acc_test_error 50.0%\n",
      "Epoch: 3285 Loss: 4.969111442565918  acc_train_error 38.425%  acc_test_error 50.0%\n",
      "Epoch: 3286 Loss: 4.96679162979126  acc_train_error 38.425%  acc_test_error 50.0%\n",
      "Epoch: 3287 Loss: 4.964440822601318  acc_train_error 38.4375%  acc_test_error 50.0%\n",
      "Epoch: 3288 Loss: 4.962128162384033  acc_train_error 38.4375%  acc_test_error 50.0%\n",
      "Epoch: 3289 Loss: 4.959775447845459  acc_train_error 38.45%  acc_test_error 50.0%\n",
      "Epoch: 3290 Loss: 4.9574713706970215  acc_train_error 38.4375%  acc_test_error 50.0%\n",
      "Epoch: 3291 Loss: 4.955135822296143  acc_train_error 38.4375%  acc_test_error 50.0%\n",
      "Epoch: 3292 Loss: 4.952795028686523  acc_train_error 38.4625%  acc_test_error 50.0%\n",
      "Epoch: 3293 Loss: 4.950484275817871  acc_train_error 38.4625%  acc_test_error 50.0%\n",
      "Epoch: 3294 Loss: 4.94813871383667  acc_train_error 38.475%  acc_test_error 50.0%\n",
      "Epoch: 3295 Loss: 4.945836544036865  acc_train_error 38.475%  acc_test_error 50.0%\n",
      "Epoch: 3296 Loss: 4.943508148193359  acc_train_error 38.475%  acc_test_error 50.0%\n",
      "Epoch: 3297 Loss: 4.9411725997924805  acc_train_error 38.4875%  acc_test_error 50.0%\n",
      "Epoch: 3298 Loss: 4.938872814178467  acc_train_error 38.475%  acc_test_error 50.0%\n",
      "Epoch: 3299 Loss: 4.9365339279174805  acc_train_error 38.5%  acc_test_error 50.0%\n",
      "Epoch: 3300 Loss: 4.934231281280518  acc_train_error 38.4875%  acc_test_error 50.0%\n",
      "Epoch: 3301 Loss: 4.931894302368164  acc_train_error 38.5125%  acc_test_error 50.0%\n",
      "Epoch: 3302 Loss: 4.92960262298584  acc_train_error 38.5125%  acc_test_error 50.0%\n",
      "Epoch: 3303 Loss: 4.927278518676758  acc_train_error 38.5%  acc_test_error 50.0%\n",
      "Epoch: 3304 Loss: 4.924962043762207  acc_train_error 38.5%  acc_test_error 50.0%\n",
      "Epoch: 3305 Loss: 4.922659397125244  acc_train_error 38.5%  acc_test_error 50.0%\n",
      "Epoch: 3306 Loss: 4.920331954956055  acc_train_error 38.525%  acc_test_error 50.0%\n",
      "Epoch: 3307 Loss: 4.9180426597595215  acc_train_error 38.5%  acc_test_error 50.0%\n",
      "Epoch: 3308 Loss: 4.915724277496338  acc_train_error 38.5%  acc_test_error 50.0%\n",
      "Epoch: 3309 Loss: 4.913407325744629  acc_train_error 38.5125%  acc_test_error 50.0%\n",
      "Epoch: 3310 Loss: 4.911126136779785  acc_train_error 38.5%  acc_test_error 50.0%\n",
      "Epoch: 3311 Loss: 4.908812046051025  acc_train_error 38.5%  acc_test_error 50.0%\n",
      "Epoch: 3312 Loss: 4.906498432159424  acc_train_error 38.5125%  acc_test_error 50.0%\n",
      "Epoch: 3313 Loss: 4.904214382171631  acc_train_error 38.5125%  acc_test_error 50.0%\n",
      "Epoch: 3314 Loss: 4.9019060134887695  acc_train_error 38.4875%  acc_test_error 50.0%\n",
      "Epoch: 3315 Loss: 4.899595737457275  acc_train_error 38.5375%  acc_test_error 50.0%\n",
      "Epoch: 3316 Loss: 4.89732027053833  acc_train_error 38.5%  acc_test_error 50.0%\n",
      "Epoch: 3317 Loss: 4.895014762878418  acc_train_error 38.4875%  acc_test_error 50.0%\n",
      "Epoch: 3318 Loss: 4.892707824707031  acc_train_error 38.525%  acc_test_error 50.0%\n",
      "Epoch: 3319 Loss: 4.8904266357421875  acc_train_error 38.525%  acc_test_error 50.0%\n",
      "Epoch: 3320 Loss: 4.888130187988281  acc_train_error 38.525%  acc_test_error 50.0%\n",
      "Epoch: 3321 Loss: 4.885828495025635  acc_train_error 38.525%  acc_test_error 50.0%\n",
      "Epoch: 3322 Loss: 4.883552551269531  acc_train_error 38.5125%  acc_test_error 50.0%\n",
      "Epoch: 3323 Loss: 4.881255149841309  acc_train_error 38.5125%  acc_test_error 50.0%\n",
      "Epoch: 3324 Loss: 4.8789496421813965  acc_train_error 38.525%  acc_test_error 50.0%\n",
      "Epoch: 3325 Loss: 4.876682758331299  acc_train_error 38.5125%  acc_test_error 50.0%\n",
      "Epoch: 3326 Loss: 4.87439489364624  acc_train_error 38.5%  acc_test_error 50.0%\n",
      "Epoch: 3327 Loss: 4.872087478637695  acc_train_error 38.525%  acc_test_error 50.0%\n",
      "Epoch: 3328 Loss: 4.869826793670654  acc_train_error 38.525%  acc_test_error 50.0%\n",
      "Epoch: 3329 Loss: 4.867536544799805  acc_train_error 38.5125%  acc_test_error 50.0%\n",
      "Epoch: 3330 Loss: 4.8652496337890625  acc_train_error 38.5125%  acc_test_error 50.0%\n",
      "Epoch: 3331 Loss: 4.862961769104004  acc_train_error 38.5125%  acc_test_error 50.0%\n",
      "Epoch: 3332 Loss: 4.860696315765381  acc_train_error 38.5125%  acc_test_error 50.0%\n",
      "Epoch: 3333 Loss: 4.858409881591797  acc_train_error 38.5%  acc_test_error 50.0%\n",
      "Epoch: 3334 Loss: 4.856110095977783  acc_train_error 38.525%  acc_test_error 50.0%\n",
      "Epoch: 3335 Loss: 4.8538689613342285  acc_train_error 38.5125%  acc_test_error 50.0%\n",
      "Epoch: 3336 Loss: 4.851585388183594  acc_train_error 38.5125%  acc_test_error 50.0%\n",
      "Epoch: 3337 Loss: 4.849307060241699  acc_train_error 38.5125%  acc_test_error 50.0%\n",
      "Epoch: 3338 Loss: 4.847031116485596  acc_train_error 38.5125%  acc_test_error 50.0%\n",
      "Epoch: 3339 Loss: 4.844747543334961  acc_train_error 38.5%  acc_test_error 50.0%\n",
      "Epoch: 3340 Loss: 4.842495441436768  acc_train_error 38.5%  acc_test_error 50.0%\n",
      "Epoch: 3341 Loss: 4.8402228355407715  acc_train_error 38.5%  acc_test_error 50.0%\n",
      "Epoch: 3342 Loss: 4.83795166015625  acc_train_error 38.5%  acc_test_error 50.0%\n",
      "Epoch: 3343 Loss: 4.835665702819824  acc_train_error 38.5125%  acc_test_error 50.0%\n",
      "Epoch: 3344 Loss: 4.833423614501953  acc_train_error 38.5125%  acc_test_error 50.0%\n",
      "Epoch: 3345 Loss: 4.831157684326172  acc_train_error 38.525%  acc_test_error 50.0%\n",
      "Epoch: 3346 Loss: 4.8288893699646  acc_train_error 38.525%  acc_test_error 50.0%\n",
      "Epoch: 3347 Loss: 4.826629161834717  acc_train_error 38.5%  acc_test_error 50.0%\n",
      "Epoch: 3348 Loss: 4.8243408203125  acc_train_error 38.55%  acc_test_error 50.0%\n",
      "Epoch: 3349 Loss: 4.822108745574951  acc_train_error 38.55%  acc_test_error 50.0%\n",
      "Epoch: 3350 Loss: 4.819842338562012  acc_train_error 38.55%  acc_test_error 50.0%\n",
      "Epoch: 3351 Loss: 4.817587852478027  acc_train_error 38.5375%  acc_test_error 50.0%\n",
      "Epoch: 3352 Loss: 4.8153228759765625  acc_train_error 38.5375%  acc_test_error 50.0%\n",
      "Epoch: 3353 Loss: 4.81306266784668  acc_train_error 38.5375%  acc_test_error 50.0%\n",
      "Epoch: 3354 Loss: 4.810782432556152  acc_train_error 38.575%  acc_test_error 50.0%\n",
      "Epoch: 3355 Loss: 4.808558940887451  acc_train_error 38.5625%  acc_test_error 50.0%\n",
      "Epoch: 3356 Loss: 4.806300163269043  acc_train_error 38.5625%  acc_test_error 50.0%\n",
      "Epoch: 3357 Loss: 4.804042816162109  acc_train_error 38.575%  acc_test_error 50.0%\n",
      "Epoch: 3358 Loss: 4.8017897605896  acc_train_error 38.575%  acc_test_error 50.0%\n",
      "Epoch: 3359 Loss: 4.799544334411621  acc_train_error 38.575%  acc_test_error 50.0%\n",
      "Epoch: 3360 Loss: 4.797289848327637  acc_train_error 38.575%  acc_test_error 50.0%\n",
      "Epoch: 3361 Loss: 4.795023441314697  acc_train_error 38.6%  acc_test_error 50.0%\n",
      "Epoch: 3362 Loss: 4.7928056716918945  acc_train_error 38.6%  acc_test_error 50.0%\n",
      "Epoch: 3363 Loss: 4.790553092956543  acc_train_error 38.6125%  acc_test_error 50.0%\n",
      "Epoch: 3364 Loss: 4.788304805755615  acc_train_error 38.625%  acc_test_error 50.0%\n",
      "Epoch: 3365 Loss: 4.786060333251953  acc_train_error 38.625%  acc_test_error 50.0%\n",
      "Epoch: 3366 Loss: 4.783824920654297  acc_train_error 38.625%  acc_test_error 50.0%\n",
      "Epoch: 3367 Loss: 4.78157901763916  acc_train_error 38.625%  acc_test_error 50.0%\n",
      "Epoch: 3368 Loss: 4.779316425323486  acc_train_error 38.6625%  acc_test_error 50.0%\n",
      "Epoch: 3369 Loss: 4.777110576629639  acc_train_error 38.65%  acc_test_error 50.0%\n",
      "Epoch: 3370 Loss: 4.774866580963135  acc_train_error 38.65%  acc_test_error 50.0%\n",
      "Epoch: 3371 Loss: 4.772627353668213  acc_train_error 38.6625%  acc_test_error 50.0%\n",
      "Epoch: 3372 Loss: 4.770391464233398  acc_train_error 38.675%  acc_test_error 50.0%\n",
      "Epoch: 3373 Loss: 4.768167018890381  acc_train_error 38.675%  acc_test_error 50.0%\n",
      "Epoch: 3374 Loss: 4.765925884246826  acc_train_error 38.6625%  acc_test_error 50.0%\n",
      "Epoch: 3375 Loss: 4.763670921325684  acc_train_error 38.7125%  acc_test_error 50.0%\n",
      "Epoch: 3376 Loss: 4.761475563049316  acc_train_error 38.6875%  acc_test_error 50.0%\n",
      "Epoch: 3377 Loss: 4.759242534637451  acc_train_error 38.7125%  acc_test_error 50.0%\n",
      "Epoch: 3378 Loss: 4.757009506225586  acc_train_error 38.7%  acc_test_error 50.0%\n",
      "Epoch: 3379 Loss: 4.7547807693481445  acc_train_error 38.725%  acc_test_error 50.0%\n",
      "Epoch: 3380 Loss: 4.752561092376709  acc_train_error 38.7125%  acc_test_error 50.0%\n",
      "Epoch: 3381 Loss: 4.750330448150635  acc_train_error 38.725%  acc_test_error 50.0%\n",
      "Epoch: 3382 Loss: 4.748106002807617  acc_train_error 38.725%  acc_test_error 50.0%\n",
      "Epoch: 3383 Loss: 4.745889186859131  acc_train_error 38.7125%  acc_test_error 50.0%\n",
      "Epoch: 3384 Loss: 4.743663787841797  acc_train_error 38.725%  acc_test_error 50.0%\n",
      "Epoch: 3385 Loss: 4.741442680358887  acc_train_error 38.725%  acc_test_error 50.0%\n",
      "Epoch: 3386 Loss: 4.7392072677612305  acc_train_error 38.725%  acc_test_error 50.0%\n",
      "Epoch: 3387 Loss: 4.737014293670654  acc_train_error 38.725%  acc_test_error 50.0%\n",
      "Epoch: 3388 Loss: 4.73479700088501  acc_train_error 38.75%  acc_test_error 50.0%\n",
      "Epoch: 3389 Loss: 4.732585430145264  acc_train_error 38.725%  acc_test_error 50.0%\n",
      "Epoch: 3390 Loss: 4.730369567871094  acc_train_error 38.75%  acc_test_error 50.0%\n",
      "Epoch: 3391 Loss: 4.728154182434082  acc_train_error 38.75%  acc_test_error 50.0%\n",
      "Epoch: 3392 Loss: 4.725945949554443  acc_train_error 38.75%  acc_test_error 50.0%\n",
      "Epoch: 3393 Loss: 4.723734378814697  acc_train_error 38.75%  acc_test_error 50.0%\n",
      "Epoch: 3394 Loss: 4.721522808074951  acc_train_error 38.75%  acc_test_error 50.0%\n",
      "Epoch: 3395 Loss: 4.7193217277526855  acc_train_error 38.75%  acc_test_error 50.0%\n",
      "Epoch: 3396 Loss: 4.71711540222168  acc_train_error 38.75%  acc_test_error 50.0%\n",
      "Epoch: 3397 Loss: 4.714911460876465  acc_train_error 38.75%  acc_test_error 50.0%\n",
      "Epoch: 3398 Loss: 4.712713241577148  acc_train_error 38.75%  acc_test_error 50.0%\n",
      "Epoch: 3399 Loss: 4.710485458374023  acc_train_error 38.775%  acc_test_error 50.0%\n",
      "Epoch: 3400 Loss: 4.708319664001465  acc_train_error 38.7625%  acc_test_error 50.0%\n",
      "Epoch: 3401 Loss: 4.706118583679199  acc_train_error 38.7625%  acc_test_error 50.0%\n",
      "Epoch: 3402 Loss: 4.703924655914307  acc_train_error 38.7625%  acc_test_error 50.0%\n",
      "Epoch: 3403 Loss: 4.701725482940674  acc_train_error 38.775%  acc_test_error 50.0%\n",
      "Epoch: 3404 Loss: 4.699536323547363  acc_train_error 38.775%  acc_test_error 50.0%\n",
      "Epoch: 3405 Loss: 4.6973395347595215  acc_train_error 38.7625%  acc_test_error 50.0%\n",
      "Epoch: 3406 Loss: 4.695150375366211  acc_train_error 38.7625%  acc_test_error 50.0%\n",
      "Epoch: 3407 Loss: 4.692955493927002  acc_train_error 38.775%  acc_test_error 50.0%\n",
      "Epoch: 3408 Loss: 4.690768718719482  acc_train_error 38.775%  acc_test_error 50.0%\n",
      "Epoch: 3409 Loss: 4.688579082489014  acc_train_error 38.775%  acc_test_error 50.0%\n",
      "Epoch: 3410 Loss: 4.686389923095703  acc_train_error 38.7875%  acc_test_error 50.0%\n",
      "Epoch: 3411 Loss: 4.684207439422607  acc_train_error 38.7875%  acc_test_error 50.0%\n",
      "Epoch: 3412 Loss: 4.682018280029297  acc_train_error 38.7875%  acc_test_error 50.0%\n",
      "Epoch: 3413 Loss: 4.679839134216309  acc_train_error 38.7875%  acc_test_error 50.0%\n",
      "Epoch: 3414 Loss: 4.677650451660156  acc_train_error 38.7875%  acc_test_error 50.0%\n",
      "Epoch: 3415 Loss: 4.675471305847168  acc_train_error 38.7875%  acc_test_error 50.0%\n",
      "Epoch: 3416 Loss: 4.673290729522705  acc_train_error 38.8%  acc_test_error 50.0%\n",
      "Epoch: 3417 Loss: 4.671104431152344  acc_train_error 38.8%  acc_test_error 50.0%\n",
      "Epoch: 3418 Loss: 4.668930530548096  acc_train_error 38.8%  acc_test_error 50.0%\n",
      "Epoch: 3419 Loss: 4.666747570037842  acc_train_error 38.8125%  acc_test_error 50.0%\n",
      "Epoch: 3420 Loss: 4.664577960968018  acc_train_error 38.8125%  acc_test_error 50.0%\n",
      "Epoch: 3421 Loss: 4.6624016761779785  acc_train_error 38.825%  acc_test_error 50.0%\n",
      "Epoch: 3422 Loss: 4.660221576690674  acc_train_error 38.825%  acc_test_error 50.0%\n",
      "Epoch: 3423 Loss: 4.658056259155273  acc_train_error 38.825%  acc_test_error 50.0%\n",
      "Epoch: 3424 Loss: 4.655882835388184  acc_train_error 38.825%  acc_test_error 50.0%\n",
      "Epoch: 3425 Loss: 4.65371036529541  acc_train_error 38.825%  acc_test_error 50.0%\n",
      "Epoch: 3426 Loss: 4.651546001434326  acc_train_error 38.825%  acc_test_error 50.0%\n",
      "Epoch: 3427 Loss: 4.649377822875977  acc_train_error 38.825%  acc_test_error 50.0%\n",
      "Epoch: 3428 Loss: 4.647208213806152  acc_train_error 38.8375%  acc_test_error 50.0%\n",
      "Epoch: 3429 Loss: 4.645047187805176  acc_train_error 38.8375%  acc_test_error 50.0%\n",
      "Epoch: 3430 Loss: 4.642883777618408  acc_train_error 38.8375%  acc_test_error 50.0%\n",
      "Epoch: 3431 Loss: 4.640717506408691  acc_train_error 38.85%  acc_test_error 50.0%\n",
      "Epoch: 3432 Loss: 4.638558864593506  acc_train_error 38.85%  acc_test_error 50.0%\n",
      "Epoch: 3433 Loss: 4.636399269104004  acc_train_error 38.85%  acc_test_error 50.0%\n",
      "Epoch: 3434 Loss: 4.634237289428711  acc_train_error 38.85%  acc_test_error 50.0%\n",
      "Epoch: 3435 Loss: 4.632084369659424  acc_train_error 38.85%  acc_test_error 50.0%\n",
      "Epoch: 3436 Loss: 4.629926681518555  acc_train_error 38.85%  acc_test_error 50.0%\n",
      "Epoch: 3437 Loss: 4.627768516540527  acc_train_error 38.8875%  acc_test_error 50.0%\n",
      "Epoch: 3438 Loss: 4.6256184577941895  acc_train_error 38.8625%  acc_test_error 50.0%\n",
      "Epoch: 3439 Loss: 4.623467922210693  acc_train_error 38.85%  acc_test_error 50.0%\n",
      "Epoch: 3440 Loss: 4.62131404876709  acc_train_error 38.8625%  acc_test_error 50.0%\n",
      "Epoch: 3441 Loss: 4.619167327880859  acc_train_error 38.8625%  acc_test_error 50.0%\n",
      "Epoch: 3442 Loss: 4.617018222808838  acc_train_error 38.8625%  acc_test_error 50.0%\n",
      "Epoch: 3443 Loss: 4.614869117736816  acc_train_error 38.8625%  acc_test_error 50.0%\n",
      "Epoch: 3444 Loss: 4.612720966339111  acc_train_error 38.8625%  acc_test_error 50.0%\n",
      "Epoch: 3445 Loss: 4.61057710647583  acc_train_error 38.8625%  acc_test_error 50.0%\n",
      "Epoch: 3446 Loss: 4.608434677124023  acc_train_error 38.8625%  acc_test_error 50.0%\n",
      "Epoch: 3447 Loss: 4.606289386749268  acc_train_error 38.8625%  acc_test_error 50.0%\n",
      "Epoch: 3448 Loss: 4.604143142700195  acc_train_error 38.875%  acc_test_error 50.0%\n",
      "Epoch: 3449 Loss: 4.602005958557129  acc_train_error 38.875%  acc_test_error 50.0%\n",
      "Epoch: 3450 Loss: 4.599863529205322  acc_train_error 38.8625%  acc_test_error 50.0%\n",
      "Epoch: 3451 Loss: 4.597724914550781  acc_train_error 38.8625%  acc_test_error 50.0%\n",
      "Epoch: 3452 Loss: 4.595582008361816  acc_train_error 38.8875%  acc_test_error 50.0%\n",
      "Epoch: 3453 Loss: 4.593448638916016  acc_train_error 38.8875%  acc_test_error 50.0%\n",
      "Epoch: 3454 Loss: 4.59131383895874  acc_train_error 38.8875%  acc_test_error 50.0%\n",
      "Epoch: 3455 Loss: 4.589178085327148  acc_train_error 38.875%  acc_test_error 50.0%\n",
      "Epoch: 3456 Loss: 4.587039470672607  acc_train_error 38.9%  acc_test_error 50.0%\n",
      "Epoch: 3457 Loss: 4.5849103927612305  acc_train_error 38.9125%  acc_test_error 50.0%\n",
      "Epoch: 3458 Loss: 4.582780361175537  acc_train_error 38.9%  acc_test_error 50.0%\n",
      "Epoch: 3459 Loss: 4.580650329589844  acc_train_error 38.9%  acc_test_error 50.0%\n",
      "Epoch: 3460 Loss: 4.578520774841309  acc_train_error 38.875%  acc_test_error 50.0%\n",
      "Epoch: 3461 Loss: 4.576390743255615  acc_train_error 38.8875%  acc_test_error 50.0%\n",
      "Epoch: 3462 Loss: 4.574265956878662  acc_train_error 38.8875%  acc_test_error 50.0%\n",
      "Epoch: 3463 Loss: 4.572142601013184  acc_train_error 38.8875%  acc_test_error 50.0%\n",
      "Epoch: 3464 Loss: 4.570016384124756  acc_train_error 38.8875%  acc_test_error 50.0%\n",
      "Epoch: 3465 Loss: 4.567892551422119  acc_train_error 38.875%  acc_test_error 50.0%\n",
      "Epoch: 3466 Loss: 4.56577205657959  acc_train_error 38.875%  acc_test_error 50.0%\n",
      "Epoch: 3467 Loss: 4.563647270202637  acc_train_error 38.875%  acc_test_error 50.0%\n",
      "Epoch: 3468 Loss: 4.5615315437316895  acc_train_error 38.875%  acc_test_error 50.0%\n",
      "Epoch: 3469 Loss: 4.559412479400635  acc_train_error 38.875%  acc_test_error 50.0%\n",
      "Epoch: 3470 Loss: 4.5572943687438965  acc_train_error 38.875%  acc_test_error 50.0%\n",
      "Epoch: 3471 Loss: 4.555178642272949  acc_train_error 38.875%  acc_test_error 50.0%\n",
      "Epoch: 3472 Loss: 4.553058624267578  acc_train_error 38.875%  acc_test_error 50.0%\n",
      "Epoch: 3473 Loss: 4.550948619842529  acc_train_error 38.875%  acc_test_error 50.0%\n",
      "Epoch: 3474 Loss: 4.548835754394531  acc_train_error 38.875%  acc_test_error 50.0%\n",
      "Epoch: 3475 Loss: 4.546722888946533  acc_train_error 38.8625%  acc_test_error 50.0%\n",
      "Epoch: 3476 Loss: 4.544611930847168  acc_train_error 38.8625%  acc_test_error 50.0%\n",
      "Epoch: 3477 Loss: 4.542503833770752  acc_train_error 38.8625%  acc_test_error 50.0%\n",
      "Epoch: 3478 Loss: 4.54038667678833  acc_train_error 38.8875%  acc_test_error 50.0%\n",
      "Epoch: 3479 Loss: 4.538284778594971  acc_train_error 38.8875%  acc_test_error 50.0%\n",
      "Epoch: 3480 Loss: 4.5361785888671875  acc_train_error 38.8875%  acc_test_error 50.0%\n",
      "Epoch: 3481 Loss: 4.534071445465088  acc_train_error 38.8875%  acc_test_error 50.0%\n",
      "Epoch: 3482 Loss: 4.5319647789001465  acc_train_error 38.8875%  acc_test_error 50.0%\n",
      "Epoch: 3483 Loss: 4.529862403869629  acc_train_error 38.8875%  acc_test_error 50.0%\n",
      "Epoch: 3484 Loss: 4.527759075164795  acc_train_error 38.8875%  acc_test_error 50.0%\n",
      "Epoch: 3485 Loss: 4.525660037994385  acc_train_error 38.9%  acc_test_error 50.0%\n",
      "Epoch: 3486 Loss: 4.523558139801025  acc_train_error 38.9%  acc_test_error 50.0%\n",
      "Epoch: 3487 Loss: 4.52145528793335  acc_train_error 38.9%  acc_test_error 50.0%\n",
      "Epoch: 3488 Loss: 4.519363880157471  acc_train_error 38.9125%  acc_test_error 50.0%\n",
      "Epoch: 3489 Loss: 4.5172648429870605  acc_train_error 38.9%  acc_test_error 50.0%\n",
      "Epoch: 3490 Loss: 4.515169620513916  acc_train_error 38.9%  acc_test_error 50.0%\n",
      "Epoch: 3491 Loss: 4.513075828552246  acc_train_error 38.9%  acc_test_error 50.0%\n",
      "Epoch: 3492 Loss: 4.510983467102051  acc_train_error 38.9125%  acc_test_error 50.0%\n",
      "Epoch: 3493 Loss: 4.508892059326172  acc_train_error 38.9125%  acc_test_error 50.0%\n",
      "Epoch: 3494 Loss: 4.506799221038818  acc_train_error 38.925%  acc_test_error 50.0%\n",
      "Epoch: 3495 Loss: 4.504711151123047  acc_train_error 38.9125%  acc_test_error 50.0%\n",
      "Epoch: 3496 Loss: 4.502620697021484  acc_train_error 38.9125%  acc_test_error 50.0%\n",
      "Epoch: 3497 Loss: 4.500535011291504  acc_train_error 38.9125%  acc_test_error 50.0%\n",
      "Epoch: 3498 Loss: 4.498448848724365  acc_train_error 38.9125%  acc_test_error 50.0%\n",
      "Epoch: 3499 Loss: 4.496363162994385  acc_train_error 38.925%  acc_test_error 50.0%\n",
      "Epoch: 3500 Loss: 4.4942803382873535  acc_train_error 38.925%  acc_test_error 50.0%\n",
      "Epoch: 3501 Loss: 4.492198467254639  acc_train_error 38.925%  acc_test_error 50.0%\n",
      "Epoch: 3502 Loss: 4.490115165710449  acc_train_error 38.925%  acc_test_error 50.0%\n",
      "Epoch: 3503 Loss: 4.488035202026367  acc_train_error 38.925%  acc_test_error 50.0%\n",
      "Epoch: 3504 Loss: 4.485956192016602  acc_train_error 38.9125%  acc_test_error 50.0%\n",
      "Epoch: 3505 Loss: 4.483879566192627  acc_train_error 38.9125%  acc_test_error 50.0%\n",
      "Epoch: 3506 Loss: 4.481800079345703  acc_train_error 38.9125%  acc_test_error 50.0%\n",
      "Epoch: 3507 Loss: 4.47972297668457  acc_train_error 38.9125%  acc_test_error 50.0%\n",
      "Epoch: 3508 Loss: 4.477649688720703  acc_train_error 38.925%  acc_test_error 50.0%\n",
      "Epoch: 3509 Loss: 4.475574493408203  acc_train_error 38.925%  acc_test_error 50.0%\n",
      "Epoch: 3510 Loss: 4.473500728607178  acc_train_error 38.925%  acc_test_error 50.0%\n",
      "Epoch: 3511 Loss: 4.471428871154785  acc_train_error 38.9375%  acc_test_error 50.0%\n",
      "Epoch: 3512 Loss: 4.469357967376709  acc_train_error 38.9375%  acc_test_error 50.0%\n",
      "Epoch: 3513 Loss: 4.467288970947266  acc_train_error 38.9375%  acc_test_error 50.0%\n",
      "Epoch: 3514 Loss: 4.4652204513549805  acc_train_error 38.9375%  acc_test_error 50.0%\n",
      "Epoch: 3515 Loss: 4.4631500244140625  acc_train_error 38.9375%  acc_test_error 50.0%\n",
      "Epoch: 3516 Loss: 4.461085796356201  acc_train_error 38.925%  acc_test_error 50.0%\n",
      "Epoch: 3517 Loss: 4.459017276763916  acc_train_error 38.925%  acc_test_error 50.0%\n",
      "Epoch: 3518 Loss: 4.456952095031738  acc_train_error 38.925%  acc_test_error 50.0%\n",
      "Epoch: 3519 Loss: 4.45488977432251  acc_train_error 38.925%  acc_test_error 50.0%\n",
      "Epoch: 3520 Loss: 4.452826976776123  acc_train_error 38.925%  acc_test_error 50.0%\n",
      "Epoch: 3521 Loss: 4.450765132904053  acc_train_error 38.925%  acc_test_error 50.0%\n",
      "Epoch: 3522 Loss: 4.448705673217773  acc_train_error 38.9125%  acc_test_error 50.0%\n",
      "Epoch: 3523 Loss: 4.4466447830200195  acc_train_error 38.925%  acc_test_error 50.0%\n",
      "Epoch: 3524 Loss: 4.444589614868164  acc_train_error 38.9125%  acc_test_error 50.0%\n",
      "Epoch: 3525 Loss: 4.442531585693359  acc_train_error 38.9125%  acc_test_error 50.0%\n",
      "Epoch: 3526 Loss: 4.440475940704346  acc_train_error 38.9125%  acc_test_error 50.0%\n",
      "Epoch: 3527 Loss: 4.438419818878174  acc_train_error 38.9125%  acc_test_error 50.0%\n",
      "Epoch: 3528 Loss: 4.436366558074951  acc_train_error 38.9125%  acc_test_error 50.0%\n",
      "Epoch: 3529 Loss: 4.4343132972717285  acc_train_error 38.9125%  acc_test_error 50.0%\n",
      "Epoch: 3530 Loss: 4.432262420654297  acc_train_error 38.9125%  acc_test_error 50.0%\n",
      "Epoch: 3531 Loss: 4.430211544036865  acc_train_error 38.9125%  acc_test_error 50.0%\n",
      "Epoch: 3532 Loss: 4.428163051605225  acc_train_error 38.9125%  acc_test_error 50.0%\n",
      "Epoch: 3533 Loss: 4.426114559173584  acc_train_error 38.9125%  acc_test_error 50.0%\n",
      "Epoch: 3534 Loss: 4.424065113067627  acc_train_error 38.9125%  acc_test_error 50.0%\n",
      "Epoch: 3535 Loss: 4.422019004821777  acc_train_error 38.9125%  acc_test_error 50.0%\n",
      "Epoch: 3536 Loss: 4.419973850250244  acc_train_error 38.9125%  acc_test_error 50.0%\n",
      "Epoch: 3537 Loss: 4.417929649353027  acc_train_error 38.9125%  acc_test_error 50.0%\n",
      "Epoch: 3538 Loss: 4.415886402130127  acc_train_error 38.9125%  acc_test_error 50.0%\n",
      "Epoch: 3539 Loss: 4.413843631744385  acc_train_error 38.9125%  acc_test_error 50.0%\n",
      "Epoch: 3540 Loss: 4.411803722381592  acc_train_error 38.9125%  acc_test_error 50.0%\n",
      "Epoch: 3541 Loss: 4.409762859344482  acc_train_error 38.9375%  acc_test_error 50.0%\n",
      "Epoch: 3542 Loss: 4.407724380493164  acc_train_error 38.9375%  acc_test_error 50.0%\n",
      "Epoch: 3543 Loss: 4.405686378479004  acc_train_error 38.9375%  acc_test_error 50.0%\n",
      "Epoch: 3544 Loss: 4.403650283813477  acc_train_error 38.95%  acc_test_error 50.0%\n",
      "Epoch: 3545 Loss: 4.401611804962158  acc_train_error 38.95%  acc_test_error 50.0%\n",
      "Epoch: 3546 Loss: 4.39957857131958  acc_train_error 38.9625%  acc_test_error 50.0%\n",
      "Epoch: 3547 Loss: 4.397543907165527  acc_train_error 38.95%  acc_test_error 50.0%\n",
      "Epoch: 3548 Loss: 4.395511150360107  acc_train_error 38.9625%  acc_test_error 50.0%\n",
      "Epoch: 3549 Loss: 4.393477439880371  acc_train_error 38.9625%  acc_test_error 50.0%\n",
      "Epoch: 3550 Loss: 4.391448974609375  acc_train_error 38.9625%  acc_test_error 50.0%\n",
      "Epoch: 3551 Loss: 4.389416217803955  acc_train_error 38.9625%  acc_test_error 50.0%\n",
      "Epoch: 3552 Loss: 4.387389659881592  acc_train_error 38.9625%  acc_test_error 50.0%\n",
      "Epoch: 3553 Loss: 4.385362148284912  acc_train_error 38.9625%  acc_test_error 50.0%\n",
      "Epoch: 3554 Loss: 4.383335590362549  acc_train_error 38.9625%  acc_test_error 50.0%\n",
      "Epoch: 3555 Loss: 4.381308078765869  acc_train_error 38.9625%  acc_test_error 50.0%\n",
      "Epoch: 3556 Loss: 4.379282474517822  acc_train_error 38.95%  acc_test_error 50.0%\n",
      "Epoch: 3557 Loss: 4.377257823944092  acc_train_error 38.95%  acc_test_error 50.0%\n",
      "Epoch: 3558 Loss: 4.375236511230469  acc_train_error 38.95%  acc_test_error 50.0%\n",
      "Epoch: 3559 Loss: 4.37321138381958  acc_train_error 38.9625%  acc_test_error 50.0%\n",
      "Epoch: 3560 Loss: 4.371191024780273  acc_train_error 38.975%  acc_test_error 50.0%\n",
      "Epoch: 3561 Loss: 4.369170665740967  acc_train_error 38.9625%  acc_test_error 50.0%\n",
      "Epoch: 3562 Loss: 4.367151737213135  acc_train_error 38.975%  acc_test_error 50.0%\n",
      "Epoch: 3563 Loss: 4.365132808685303  acc_train_error 38.975%  acc_test_error 50.0%\n",
      "Epoch: 3564 Loss: 4.3631157875061035  acc_train_error 38.9625%  acc_test_error 50.0%\n",
      "Epoch: 3565 Loss: 4.361100196838379  acc_train_error 38.975%  acc_test_error 50.0%\n",
      "Epoch: 3566 Loss: 4.359083652496338  acc_train_error 38.975%  acc_test_error 50.0%\n",
      "Epoch: 3567 Loss: 4.357069492340088  acc_train_error 38.975%  acc_test_error 50.0%\n",
      "Epoch: 3568 Loss: 4.3550543785095215  acc_train_error 38.975%  acc_test_error 50.0%\n",
      "Epoch: 3569 Loss: 4.353041172027588  acc_train_error 38.975%  acc_test_error 50.0%\n",
      "Epoch: 3570 Loss: 4.351030349731445  acc_train_error 38.975%  acc_test_error 50.0%\n",
      "Epoch: 3571 Loss: 4.349019527435303  acc_train_error 38.975%  acc_test_error 50.0%\n",
      "Epoch: 3572 Loss: 4.347009181976318  acc_train_error 38.975%  acc_test_error 50.0%\n",
      "Epoch: 3573 Loss: 4.345000267028809  acc_train_error 38.975%  acc_test_error 50.0%\n",
      "Epoch: 3574 Loss: 4.342990875244141  acc_train_error 38.9875%  acc_test_error 50.0%\n",
      "Epoch: 3575 Loss: 4.340986251831055  acc_train_error 38.9875%  acc_test_error 50.0%\n",
      "Epoch: 3576 Loss: 4.338978290557861  acc_train_error 38.9875%  acc_test_error 50.0%\n",
      "Epoch: 3577 Loss: 4.336973667144775  acc_train_error 39.0%  acc_test_error 50.0%\n",
      "Epoch: 3578 Loss: 4.334967136383057  acc_train_error 39.0%  acc_test_error 50.0%\n",
      "Epoch: 3579 Loss: 4.332962989807129  acc_train_error 39.0125%  acc_test_error 50.0%\n",
      "Epoch: 3580 Loss: 4.330958843231201  acc_train_error 39.0125%  acc_test_error 50.0%\n",
      "Epoch: 3581 Loss: 4.3289570808410645  acc_train_error 39.0125%  acc_test_error 50.0%\n",
      "Epoch: 3582 Loss: 4.326956272125244  acc_train_error 39.0125%  acc_test_error 50.0%\n",
      "Epoch: 3583 Loss: 4.324954986572266  acc_train_error 39.025%  acc_test_error 50.0%\n",
      "Epoch: 3584 Loss: 4.3229570388793945  acc_train_error 39.025%  acc_test_error 50.0%\n",
      "Epoch: 3585 Loss: 4.320957183837891  acc_train_error 39.025%  acc_test_error 50.0%\n",
      "Epoch: 3586 Loss: 4.318960666656494  acc_train_error 39.0375%  acc_test_error 50.0%\n",
      "Epoch: 3587 Loss: 4.316962718963623  acc_train_error 39.05%  acc_test_error 50.0%\n",
      "Epoch: 3588 Loss: 4.314966678619385  acc_train_error 39.05%  acc_test_error 50.0%\n",
      "Epoch: 3589 Loss: 4.312972068786621  acc_train_error 39.0625%  acc_test_error 50.0%\n",
      "Epoch: 3590 Loss: 4.310978412628174  acc_train_error 39.0625%  acc_test_error 50.0%\n",
      "Epoch: 3591 Loss: 4.308985233306885  acc_train_error 39.0625%  acc_test_error 50.0%\n",
      "Epoch: 3592 Loss: 4.306992530822754  acc_train_error 39.0625%  acc_test_error 50.0%\n",
      "Epoch: 3593 Loss: 4.3050031661987305  acc_train_error 39.0625%  acc_test_error 50.0%\n",
      "Epoch: 3594 Loss: 4.303011417388916  acc_train_error 39.075%  acc_test_error 50.0%\n",
      "Epoch: 3595 Loss: 4.301022529602051  acc_train_error 39.075%  acc_test_error 50.0%\n",
      "Epoch: 3596 Loss: 4.299032211303711  acc_train_error 39.075%  acc_test_error 50.0%\n",
      "Epoch: 3597 Loss: 4.2970476150512695  acc_train_error 39.075%  acc_test_error 50.0%\n",
      "Epoch: 3598 Loss: 4.295060157775879  acc_train_error 39.075%  acc_test_error 50.0%\n",
      "Epoch: 3599 Loss: 4.293078422546387  acc_train_error 39.0625%  acc_test_error 50.0%\n",
      "Epoch: 3600 Loss: 4.291092395782471  acc_train_error 39.075%  acc_test_error 50.0%\n",
      "Epoch: 3601 Loss: 4.289113521575928  acc_train_error 39.05%  acc_test_error 50.0%\n",
      "Epoch: 3602 Loss: 4.2871294021606445  acc_train_error 39.0125%  acc_test_error 50.0%\n",
      "Epoch: 3603 Loss: 4.285144805908203  acc_train_error 39.0375%  acc_test_error 50.0%\n",
      "Epoch: 3604 Loss: 4.2831597328186035  acc_train_error 38.975%  acc_test_error 50.0%\n",
      "Epoch: 3605 Loss: 4.2811760902404785  acc_train_error 38.9%  acc_test_error 50.0%\n",
      "Epoch: 3606 Loss: 4.279191493988037  acc_train_error 38.875%  acc_test_error 50.0%\n",
      "Epoch: 3607 Loss: 4.277209758758545  acc_train_error 38.85%  acc_test_error 50.0%\n",
      "Epoch: 3608 Loss: 4.27522611618042  acc_train_error 38.8375%  acc_test_error 50.0%\n",
      "Epoch: 3609 Loss: 4.273244380950928  acc_train_error 38.8%  acc_test_error 50.0%\n",
      "Epoch: 3610 Loss: 4.271265506744385  acc_train_error 38.7625%  acc_test_error 50.0%\n",
      "Epoch: 3611 Loss: 4.269287586212158  acc_train_error 38.75%  acc_test_error 50.0%\n",
      "Epoch: 3612 Loss: 4.26731014251709  acc_train_error 38.7%  acc_test_error 50.0%\n",
      "Epoch: 3613 Loss: 4.265329360961914  acc_train_error 38.675%  acc_test_error 50.0%\n",
      "Epoch: 3614 Loss: 4.263350486755371  acc_train_error 38.6625%  acc_test_error 50.0%\n",
      "Epoch: 3615 Loss: 4.261374473571777  acc_train_error 38.65%  acc_test_error 50.0%\n",
      "Epoch: 3616 Loss: 4.2593994140625  acc_train_error 38.65%  acc_test_error 50.0%\n",
      "Epoch: 3617 Loss: 4.257424354553223  acc_train_error 38.65%  acc_test_error 50.0%\n",
      "Epoch: 3618 Loss: 4.25545072555542  acc_train_error 38.65%  acc_test_error 50.0%\n",
      "Epoch: 3619 Loss: 4.253475189208984  acc_train_error 38.625%  acc_test_error 50.0%\n",
      "Epoch: 3620 Loss: 4.25150203704834  acc_train_error 38.6%  acc_test_error 50.0%\n",
      "Epoch: 3621 Loss: 4.249529838562012  acc_train_error 38.5875%  acc_test_error 50.0%\n",
      "Epoch: 3622 Loss: 4.247559070587158  acc_train_error 38.575%  acc_test_error 50.0%\n",
      "Epoch: 3623 Loss: 4.245588302612305  acc_train_error 38.55%  acc_test_error 50.0%\n",
      "Epoch: 3624 Loss: 4.243607044219971  acc_train_error 38.575%  acc_test_error 50.0%\n",
      "Epoch: 3625 Loss: 4.241618633270264  acc_train_error 38.6%  acc_test_error 50.0%\n",
      "Epoch: 3626 Loss: 4.239633560180664  acc_train_error 38.6%  acc_test_error 50.0%\n",
      "Epoch: 3627 Loss: 4.2376508712768555  acc_train_error 38.625%  acc_test_error 50.0%\n",
      "Epoch: 3628 Loss: 4.235668659210205  acc_train_error 38.625%  acc_test_error 50.0%\n",
      "Epoch: 3629 Loss: 4.233687400817871  acc_train_error 38.6375%  acc_test_error 50.0%\n",
      "Epoch: 3630 Loss: 4.231711387634277  acc_train_error 38.6375%  acc_test_error 50.0%\n",
      "Epoch: 3631 Loss: 4.229733467102051  acc_train_error 38.65%  acc_test_error 50.0%\n",
      "Epoch: 3632 Loss: 4.227761268615723  acc_train_error 38.65%  acc_test_error 50.0%\n",
      "Epoch: 3633 Loss: 4.2257914543151855  acc_train_error 38.65%  acc_test_error 50.0%\n",
      "Epoch: 3634 Loss: 4.223822116851807  acc_train_error 38.65%  acc_test_error 50.0%\n",
      "Epoch: 3635 Loss: 4.221856117248535  acc_train_error 38.65%  acc_test_error 50.0%\n",
      "Epoch: 3636 Loss: 4.21989107131958  acc_train_error 38.6375%  acc_test_error 50.0%\n",
      "Epoch: 3637 Loss: 4.217929363250732  acc_train_error 38.6375%  acc_test_error 50.0%\n",
      "Epoch: 3638 Loss: 4.215967178344727  acc_train_error 38.6375%  acc_test_error 50.0%\n",
      "Epoch: 3639 Loss: 4.214007377624512  acc_train_error 38.6375%  acc_test_error 50.0%\n",
      "Epoch: 3640 Loss: 4.212047100067139  acc_train_error 38.6375%  acc_test_error 50.0%\n",
      "Epoch: 3641 Loss: 4.21008825302124  acc_train_error 38.6375%  acc_test_error 50.0%\n",
      "Epoch: 3642 Loss: 4.208131313323975  acc_train_error 38.6375%  acc_test_error 50.0%\n",
      "Epoch: 3643 Loss: 4.206177234649658  acc_train_error 38.6375%  acc_test_error 50.0%\n",
      "Epoch: 3644 Loss: 4.204221248626709  acc_train_error 38.6375%  acc_test_error 50.0%\n",
      "Epoch: 3645 Loss: 4.202268600463867  acc_train_error 38.6375%  acc_test_error 50.0%\n",
      "Epoch: 3646 Loss: 4.200316905975342  acc_train_error 38.625%  acc_test_error 50.0%\n",
      "Epoch: 3647 Loss: 4.198365688323975  acc_train_error 38.625%  acc_test_error 50.0%\n",
      "Epoch: 3648 Loss: 4.196412086486816  acc_train_error 38.625%  acc_test_error 50.0%\n",
      "Epoch: 3649 Loss: 4.19446325302124  acc_train_error 38.6125%  acc_test_error 50.0%\n",
      "Epoch: 3650 Loss: 4.192513942718506  acc_train_error 38.6125%  acc_test_error 50.0%\n",
      "Epoch: 3651 Loss: 4.1905646324157715  acc_train_error 38.6125%  acc_test_error 50.0%\n",
      "Epoch: 3652 Loss: 4.188618183135986  acc_train_error 38.625%  acc_test_error 50.0%\n",
      "Epoch: 3653 Loss: 4.186672210693359  acc_train_error 38.6125%  acc_test_error 50.0%\n",
      "Epoch: 3654 Loss: 4.184729099273682  acc_train_error 38.6125%  acc_test_error 50.0%\n",
      "Epoch: 3655 Loss: 4.182784080505371  acc_train_error 38.6125%  acc_test_error 50.0%\n",
      "Epoch: 3656 Loss: 4.180841445922852  acc_train_error 38.6125%  acc_test_error 50.0%\n",
      "Epoch: 3657 Loss: 4.178897380828857  acc_train_error 38.6125%  acc_test_error 50.0%\n",
      "Epoch: 3658 Loss: 4.1769561767578125  acc_train_error 38.6125%  acc_test_error 50.0%\n",
      "Epoch: 3659 Loss: 4.1750168800354  acc_train_error 38.6125%  acc_test_error 50.0%\n",
      "Epoch: 3660 Loss: 4.173077583312988  acc_train_error 38.6125%  acc_test_error 50.0%\n",
      "Epoch: 3661 Loss: 4.171139240264893  acc_train_error 38.6125%  acc_test_error 50.0%\n",
      "Epoch: 3662 Loss: 4.169200420379639  acc_train_error 38.6%  acc_test_error 50.0%\n",
      "Epoch: 3663 Loss: 4.167263507843018  acc_train_error 38.6%  acc_test_error 50.0%\n",
      "Epoch: 3664 Loss: 4.1653289794921875  acc_train_error 38.6%  acc_test_error 50.0%\n",
      "Epoch: 3665 Loss: 4.163393497467041  acc_train_error 38.6%  acc_test_error 50.0%\n",
      "Epoch: 3666 Loss: 4.161459922790527  acc_train_error 38.6%  acc_test_error 50.0%\n",
      "Epoch: 3667 Loss: 4.15952730178833  acc_train_error 38.6%  acc_test_error 50.0%\n",
      "Epoch: 3668 Loss: 4.157595157623291  acc_train_error 38.6%  acc_test_error 50.0%\n",
      "Epoch: 3669 Loss: 4.155666351318359  acc_train_error 38.6%  acc_test_error 50.0%\n",
      "Epoch: 3670 Loss: 4.153735637664795  acc_train_error 38.6%  acc_test_error 50.0%\n",
      "Epoch: 3671 Loss: 4.15180778503418  acc_train_error 38.6%  acc_test_error 50.0%\n",
      "Epoch: 3672 Loss: 4.149880886077881  acc_train_error 38.6%  acc_test_error 50.0%\n",
      "Epoch: 3673 Loss: 4.147953987121582  acc_train_error 38.6%  acc_test_error 50.0%\n",
      "Epoch: 3674 Loss: 4.146027088165283  acc_train_error 38.6%  acc_test_error 50.0%\n",
      "Epoch: 3675 Loss: 4.144101619720459  acc_train_error 38.6%  acc_test_error 50.0%\n",
      "Epoch: 3676 Loss: 4.142178058624268  acc_train_error 38.6%  acc_test_error 50.0%\n",
      "Epoch: 3677 Loss: 4.140255451202393  acc_train_error 38.6125%  acc_test_error 50.0%\n",
      "Epoch: 3678 Loss: 4.138334274291992  acc_train_error 38.6125%  acc_test_error 50.0%\n",
      "Epoch: 3679 Loss: 4.136412620544434  acc_train_error 38.6%  acc_test_error 50.0%\n",
      "Epoch: 3680 Loss: 4.134495258331299  acc_train_error 38.6%  acc_test_error 50.0%\n",
      "Epoch: 3681 Loss: 4.132575988769531  acc_train_error 38.6%  acc_test_error 50.0%\n",
      "Epoch: 3682 Loss: 4.130659580230713  acc_train_error 38.6125%  acc_test_error 50.0%\n",
      "Epoch: 3683 Loss: 4.128742218017578  acc_train_error 38.6125%  acc_test_error 50.0%\n",
      "Epoch: 3684 Loss: 4.126826763153076  acc_train_error 38.6125%  acc_test_error 50.0%\n",
      "Epoch: 3685 Loss: 4.124912261962891  acc_train_error 38.625%  acc_test_error 50.0%\n",
      "Epoch: 3686 Loss: 4.122999668121338  acc_train_error 38.625%  acc_test_error 50.0%\n",
      "Epoch: 3687 Loss: 4.121087551116943  acc_train_error 38.625%  acc_test_error 50.0%\n",
      "Epoch: 3688 Loss: 4.119175910949707  acc_train_error 38.625%  acc_test_error 50.0%\n",
      "Epoch: 3689 Loss: 4.117264747619629  acc_train_error 38.625%  acc_test_error 50.0%\n",
      "Epoch: 3690 Loss: 4.115355014801025  acc_train_error 38.625%  acc_test_error 50.0%\n",
      "Epoch: 3691 Loss: 4.113447666168213  acc_train_error 38.625%  acc_test_error 50.0%\n",
      "Epoch: 3692 Loss: 4.111539363861084  acc_train_error 38.6375%  acc_test_error 50.0%\n",
      "Epoch: 3693 Loss: 4.109633445739746  acc_train_error 38.6375%  acc_test_error 50.0%\n",
      "Epoch: 3694 Loss: 4.107727527618408  acc_train_error 38.6375%  acc_test_error 50.0%\n",
      "Epoch: 3695 Loss: 4.105822563171387  acc_train_error 38.65%  acc_test_error 50.0%\n",
      "Epoch: 3696 Loss: 4.103919506072998  acc_train_error 38.6375%  acc_test_error 50.0%\n",
      "Epoch: 3697 Loss: 4.102014541625977  acc_train_error 38.65%  acc_test_error 50.0%\n",
      "Epoch: 3698 Loss: 4.1001129150390625  acc_train_error 38.65%  acc_test_error 50.0%\n",
      "Epoch: 3699 Loss: 4.098209857940674  acc_train_error 38.6625%  acc_test_error 50.0%\n",
      "Epoch: 3700 Loss: 4.096310615539551  acc_train_error 38.6625%  acc_test_error 50.0%\n",
      "Epoch: 3701 Loss: 4.0944132804870605  acc_train_error 38.675%  acc_test_error 50.0%\n",
      "Epoch: 3702 Loss: 4.092517375946045  acc_train_error 38.65%  acc_test_error 50.0%\n",
      "Epoch: 3703 Loss: 4.090620517730713  acc_train_error 38.6625%  acc_test_error 50.0%\n",
      "Epoch: 3704 Loss: 4.088728427886963  acc_train_error 38.6375%  acc_test_error 50.0%\n",
      "Epoch: 3705 Loss: 4.086833953857422  acc_train_error 38.625%  acc_test_error 50.0%\n",
      "Epoch: 3706 Loss: 4.084944248199463  acc_train_error 38.625%  acc_test_error 50.0%\n",
      "Epoch: 3707 Loss: 4.083050727844238  acc_train_error 38.6%  acc_test_error 50.0%\n",
      "Epoch: 3708 Loss: 4.081162929534912  acc_train_error 38.6%  acc_test_error 50.0%\n",
      "Epoch: 3709 Loss: 4.079274654388428  acc_train_error 38.6%  acc_test_error 50.0%\n",
      "Epoch: 3710 Loss: 4.077387809753418  acc_train_error 38.5875%  acc_test_error 50.0%\n",
      "Epoch: 3711 Loss: 4.075500011444092  acc_train_error 38.5875%  acc_test_error 50.0%\n",
      "Epoch: 3712 Loss: 4.073614597320557  acc_train_error 38.5875%  acc_test_error 50.0%\n",
      "Epoch: 3713 Loss: 4.071728706359863  acc_train_error 38.5625%  acc_test_error 50.0%\n",
      "Epoch: 3714 Loss: 4.069847583770752  acc_train_error 38.5625%  acc_test_error 50.0%\n",
      "Epoch: 3715 Loss: 4.067962169647217  acc_train_error 38.5625%  acc_test_error 50.0%\n",
      "Epoch: 3716 Loss: 4.066081523895264  acc_train_error 38.5375%  acc_test_error 50.0%\n",
      "Epoch: 3717 Loss: 4.064197063446045  acc_train_error 38.5375%  acc_test_error 50.0%\n",
      "Epoch: 3718 Loss: 4.062318801879883  acc_train_error 38.525%  acc_test_error 50.0%\n",
      "Epoch: 3719 Loss: 4.06043815612793  acc_train_error 38.5%  acc_test_error 50.0%\n",
      "Epoch: 3720 Loss: 4.058557510375977  acc_train_error 38.5125%  acc_test_error 50.0%\n",
      "Epoch: 3721 Loss: 4.05667781829834  acc_train_error 38.5%  acc_test_error 50.0%\n",
      "Epoch: 3722 Loss: 4.054802894592285  acc_train_error 38.5%  acc_test_error 50.0%\n",
      "Epoch: 3723 Loss: 4.052927494049072  acc_train_error 38.4875%  acc_test_error 50.0%\n",
      "Epoch: 3724 Loss: 4.051050662994385  acc_train_error 38.4625%  acc_test_error 50.0%\n",
      "Epoch: 3725 Loss: 4.049163818359375  acc_train_error 38.5%  acc_test_error 50.0%\n",
      "Epoch: 3726 Loss: 4.0472636222839355  acc_train_error 38.5125%  acc_test_error 50.0%\n",
      "Epoch: 3727 Loss: 4.045363426208496  acc_train_error 38.5625%  acc_test_error 50.0%\n",
      "Epoch: 3728 Loss: 4.043466091156006  acc_train_error 38.5875%  acc_test_error 50.0%\n",
      "Epoch: 3729 Loss: 4.04157018661499  acc_train_error 38.6375%  acc_test_error 50.0%\n",
      "Epoch: 3730 Loss: 4.039679527282715  acc_train_error 38.75%  acc_test_error 50.0%\n",
      "Epoch: 3731 Loss: 4.037789344787598  acc_train_error 38.8625%  acc_test_error 50.0%\n",
      "Epoch: 3732 Loss: 4.035900592803955  acc_train_error 39.025%  acc_test_error 50.0%\n",
      "Epoch: 3733 Loss: 4.0340166091918945  acc_train_error 39.1125%  acc_test_error 50.0%\n",
      "Epoch: 3734 Loss: 4.032131195068359  acc_train_error 39.125%  acc_test_error 50.0%\n",
      "Epoch: 3735 Loss: 4.030249118804932  acc_train_error 39.1625%  acc_test_error 50.0%\n",
      "Epoch: 3736 Loss: 4.028369426727295  acc_train_error 39.1625%  acc_test_error 50.0%\n",
      "Epoch: 3737 Loss: 4.026489734649658  acc_train_error 39.175%  acc_test_error 50.0%\n",
      "Epoch: 3738 Loss: 4.024611949920654  acc_train_error 39.1875%  acc_test_error 50.0%\n",
      "Epoch: 3739 Loss: 4.022736549377441  acc_train_error 39.225%  acc_test_error 50.0%\n",
      "Epoch: 3740 Loss: 4.020859241485596  acc_train_error 39.2375%  acc_test_error 50.0%\n",
      "Epoch: 3741 Loss: 4.01898717880249  acc_train_error 39.25%  acc_test_error 50.0%\n",
      "Epoch: 3742 Loss: 4.017113208770752  acc_train_error 39.25%  acc_test_error 50.0%\n",
      "Epoch: 3743 Loss: 4.015242099761963  acc_train_error 39.2625%  acc_test_error 50.0%\n",
      "Epoch: 3744 Loss: 4.013373374938965  acc_train_error 39.2625%  acc_test_error 50.0%\n",
      "Epoch: 3745 Loss: 4.011503219604492  acc_train_error 39.2875%  acc_test_error 50.0%\n",
      "Epoch: 3746 Loss: 4.009637355804443  acc_train_error 39.2875%  acc_test_error 50.0%\n",
      "Epoch: 3747 Loss: 4.007771968841553  acc_train_error 39.3%  acc_test_error 50.0%\n",
      "Epoch: 3748 Loss: 4.005903720855713  acc_train_error 39.325%  acc_test_error 50.0%\n",
      "Epoch: 3749 Loss: 4.004040241241455  acc_train_error 39.325%  acc_test_error 50.0%\n",
      "Epoch: 3750 Loss: 4.002175807952881  acc_train_error 39.3375%  acc_test_error 50.0%\n",
      "Epoch: 3751 Loss: 4.0003132820129395  acc_train_error 39.3625%  acc_test_error 50.0%\n",
      "Epoch: 3752 Loss: 3.998452663421631  acc_train_error 39.375%  acc_test_error 50.0%\n",
      "Epoch: 3753 Loss: 3.9965922832489014  acc_train_error 39.375%  acc_test_error 50.0%\n",
      "Epoch: 3754 Loss: 3.9947330951690674  acc_train_error 39.3875%  acc_test_error 50.0%\n",
      "Epoch: 3755 Loss: 3.9928736686706543  acc_train_error 39.3875%  acc_test_error 50.0%\n",
      "Epoch: 3756 Loss: 3.9910216331481934  acc_train_error 39.3875%  acc_test_error 50.0%\n",
      "Epoch: 3757 Loss: 3.9891676902770996  acc_train_error 39.4375%  acc_test_error 50.0%\n",
      "Epoch: 3758 Loss: 3.9873147010803223  acc_train_error 39.475%  acc_test_error 50.0%\n",
      "Epoch: 3759 Loss: 3.9854650497436523  acc_train_error 39.525%  acc_test_error 50.0%\n",
      "Epoch: 3760 Loss: 3.983614206314087  acc_train_error 39.55%  acc_test_error 50.0%\n",
      "Epoch: 3761 Loss: 3.981767416000366  acc_train_error 39.5625%  acc_test_error 50.0%\n",
      "Epoch: 3762 Loss: 3.979919672012329  acc_train_error 39.5875%  acc_test_error 50.0%\n",
      "Epoch: 3763 Loss: 3.9780707359313965  acc_train_error 39.6%  acc_test_error 50.0%\n",
      "Epoch: 3764 Loss: 3.976224899291992  acc_train_error 39.6%  acc_test_error 50.0%\n",
      "Epoch: 3765 Loss: 3.9743809700012207  acc_train_error 39.625%  acc_test_error 50.0%\n",
      "Epoch: 3766 Loss: 3.9725358486175537  acc_train_error 39.6375%  acc_test_error 50.0%\n",
      "Epoch: 3767 Loss: 3.970691680908203  acc_train_error 39.65%  acc_test_error 50.0%\n",
      "Epoch: 3768 Loss: 3.968851327896118  acc_train_error 39.65%  acc_test_error 50.0%\n",
      "Epoch: 3769 Loss: 3.9670097827911377  acc_train_error 39.6625%  acc_test_error 50.0%\n",
      "Epoch: 3770 Loss: 3.9651684761047363  acc_train_error 39.6875%  acc_test_error 50.0%\n",
      "Epoch: 3771 Loss: 3.963326930999756  acc_train_error 39.7%  acc_test_error 50.0%\n",
      "Epoch: 3772 Loss: 3.961486339569092  acc_train_error 39.7%  acc_test_error 50.0%\n",
      "Epoch: 3773 Loss: 3.9596457481384277  acc_train_error 39.725%  acc_test_error 50.0%\n",
      "Epoch: 3774 Loss: 3.9578089714050293  acc_train_error 39.7375%  acc_test_error 50.0%\n",
      "Epoch: 3775 Loss: 3.955970525741577  acc_train_error 39.75%  acc_test_error 50.0%\n",
      "Epoch: 3776 Loss: 3.954133987426758  acc_train_error 39.775%  acc_test_error 50.0%\n",
      "Epoch: 3777 Loss: 3.9523000717163086  acc_train_error 39.775%  acc_test_error 50.0%\n",
      "Epoch: 3778 Loss: 3.950468063354492  acc_train_error 39.7875%  acc_test_error 50.0%\n",
      "Epoch: 3779 Loss: 3.9486336708068848  acc_train_error 39.8%  acc_test_error 50.0%\n",
      "Epoch: 3780 Loss: 3.946803569793701  acc_train_error 39.8125%  acc_test_error 50.0%\n",
      "Epoch: 3781 Loss: 3.9449727535247803  acc_train_error 39.825%  acc_test_error 50.0%\n",
      "Epoch: 3782 Loss: 3.9431421756744385  acc_train_error 39.875%  acc_test_error 50.0%\n",
      "Epoch: 3783 Loss: 3.941315174102783  acc_train_error 39.9125%  acc_test_error 50.0%\n",
      "Epoch: 3784 Loss: 3.939486265182495  acc_train_error 40.05%  acc_test_error 50.0%\n",
      "Epoch: 3785 Loss: 3.937659740447998  acc_train_error 40.0875%  acc_test_error 50.0%\n",
      "Epoch: 3786 Loss: 3.93583607673645  acc_train_error 40.15%  acc_test_error 50.0%\n",
      "Epoch: 3787 Loss: 3.9340109825134277  acc_train_error 40.2125%  acc_test_error 50.0%\n",
      "Epoch: 3788 Loss: 3.932185411453247  acc_train_error 40.3%  acc_test_error 50.0%\n",
      "Epoch: 3789 Loss: 3.9303624629974365  acc_train_error 40.375%  acc_test_error 50.0%\n",
      "Epoch: 3790 Loss: 3.9285404682159424  acc_train_error 40.3875%  acc_test_error 50.0%\n",
      "Epoch: 3791 Loss: 3.9267184734344482  acc_train_error 40.3875%  acc_test_error 50.0%\n",
      "Epoch: 3792 Loss: 3.9248998165130615  acc_train_error 40.3875%  acc_test_error 50.0%\n",
      "Epoch: 3793 Loss: 3.9230802059173584  acc_train_error 40.3875%  acc_test_error 50.0%\n",
      "Epoch: 3794 Loss: 3.921260356903076  acc_train_error 40.4%  acc_test_error 50.0%\n",
      "Epoch: 3795 Loss: 3.9194400310516357  acc_train_error 40.4%  acc_test_error 50.0%\n",
      "Epoch: 3796 Loss: 3.9176223278045654  acc_train_error 40.4125%  acc_test_error 50.0%\n",
      "Epoch: 3797 Loss: 3.9158060550689697  acc_train_error 40.4125%  acc_test_error 50.0%\n",
      "Epoch: 3798 Loss: 3.9139881134033203  acc_train_error 40.425%  acc_test_error 50.0%\n",
      "Epoch: 3799 Loss: 3.912184715270996  acc_train_error 40.425%  acc_test_error 50.0%\n",
      "Epoch: 3800 Loss: 3.910360097885132  acc_train_error 40.425%  acc_test_error 50.0%\n",
      "Epoch: 3801 Loss: 3.9085428714752197  acc_train_error 40.425%  acc_test_error 50.0%\n",
      "Epoch: 3802 Loss: 3.9067294597625732  acc_train_error 40.4375%  acc_test_error 50.0%\n",
      "Epoch: 3803 Loss: 3.90493106842041  acc_train_error 40.45%  acc_test_error 50.0%\n",
      "Epoch: 3804 Loss: 3.903109550476074  acc_train_error 40.4625%  acc_test_error 50.0%\n",
      "Epoch: 3805 Loss: 3.901297092437744  acc_train_error 40.4625%  acc_test_error 50.0%\n",
      "Epoch: 3806 Loss: 3.8994860649108887  acc_train_error 40.4625%  acc_test_error 50.0%\n",
      "Epoch: 3807 Loss: 3.8976922035217285  acc_train_error 40.4625%  acc_test_error 50.0%\n",
      "Epoch: 3808 Loss: 3.895871639251709  acc_train_error 40.475%  acc_test_error 50.0%\n",
      "Epoch: 3809 Loss: 3.894063711166382  acc_train_error 40.475%  acc_test_error 50.0%\n",
      "Epoch: 3810 Loss: 3.8922719955444336  acc_train_error 40.475%  acc_test_error 50.0%\n",
      "Epoch: 3811 Loss: 3.890453815460205  acc_train_error 40.5%  acc_test_error 50.0%\n",
      "Epoch: 3812 Loss: 3.8886470794677734  acc_train_error 40.5%  acc_test_error 50.0%\n",
      "Epoch: 3813 Loss: 3.886857509613037  acc_train_error 40.5%  acc_test_error 50.0%\n",
      "Epoch: 3814 Loss: 3.8850433826446533  acc_train_error 40.5%  acc_test_error 50.0%\n",
      "Epoch: 3815 Loss: 3.88323712348938  acc_train_error 40.5125%  acc_test_error 50.0%\n",
      "Epoch: 3816 Loss: 3.8814537525177  acc_train_error 40.5125%  acc_test_error 50.0%\n",
      "Epoch: 3817 Loss: 3.879639148712158  acc_train_error 40.525%  acc_test_error 50.0%\n",
      "Epoch: 3818 Loss: 3.8778486251831055  acc_train_error 40.5375%  acc_test_error 50.0%\n",
      "Epoch: 3819 Loss: 3.8760416507720947  acc_train_error 40.5375%  acc_test_error 50.0%\n",
      "Epoch: 3820 Loss: 3.8742406368255615  acc_train_error 40.5375%  acc_test_error 50.0%\n",
      "Epoch: 3821 Loss: 3.872457504272461  acc_train_error 40.5375%  acc_test_error 50.0%\n",
      "Epoch: 3822 Loss: 3.8706483840942383  acc_train_error 40.5375%  acc_test_error 50.0%\n",
      "Epoch: 3823 Loss: 3.868854284286499  acc_train_error 40.5375%  acc_test_error 50.0%\n",
      "Epoch: 3824 Loss: 3.8670718669891357  acc_train_error 40.55%  acc_test_error 50.0%\n",
      "Epoch: 3825 Loss: 3.8652656078338623  acc_train_error 40.575%  acc_test_error 50.0%\n",
      "Epoch: 3826 Loss: 3.8634884357452393  acc_train_error 40.55%  acc_test_error 50.0%\n",
      "Epoch: 3827 Loss: 3.861682891845703  acc_train_error 40.575%  acc_test_error 50.0%\n",
      "Epoch: 3828 Loss: 3.8598926067352295  acc_train_error 40.575%  acc_test_error 50.0%\n",
      "Epoch: 3829 Loss: 3.858119010925293  acc_train_error 40.5625%  acc_test_error 50.0%\n",
      "Epoch: 3830 Loss: 3.8563144207000732  acc_train_error 40.575%  acc_test_error 50.0%\n",
      "Epoch: 3831 Loss: 3.8545260429382324  acc_train_error 40.575%  acc_test_error 50.0%\n",
      "Epoch: 3832 Loss: 3.8527557849884033  acc_train_error 40.575%  acc_test_error 50.0%\n",
      "Epoch: 3833 Loss: 3.8509521484375  acc_train_error 40.575%  acc_test_error 50.0%\n",
      "Epoch: 3834 Loss: 3.8491790294647217  acc_train_error 40.575%  acc_test_error 50.0%\n",
      "Epoch: 3835 Loss: 3.8473830223083496  acc_train_error 40.575%  acc_test_error 50.0%\n",
      "Epoch: 3836 Loss: 3.8456010818481445  acc_train_error 40.5625%  acc_test_error 50.0%\n",
      "Epoch: 3837 Loss: 3.8438355922698975  acc_train_error 40.5625%  acc_test_error 50.0%\n",
      "Epoch: 3838 Loss: 3.842041015625  acc_train_error 40.5625%  acc_test_error 50.0%\n",
      "Epoch: 3839 Loss: 3.840277910232544  acc_train_error 40.5625%  acc_test_error 50.0%\n",
      "Epoch: 3840 Loss: 3.838486909866333  acc_train_error 40.5625%  acc_test_error 50.0%\n",
      "Epoch: 3841 Loss: 3.836712121963501  acc_train_error 40.5625%  acc_test_error 50.0%\n",
      "Epoch: 3842 Loss: 3.834951639175415  acc_train_error 40.55%  acc_test_error 50.0%\n",
      "Epoch: 3843 Loss: 3.8331644535064697  acc_train_error 40.5375%  acc_test_error 50.0%\n",
      "Epoch: 3844 Loss: 3.831399917602539  acc_train_error 40.5375%  acc_test_error 50.0%\n",
      "Epoch: 3845 Loss: 3.8296148777008057  acc_train_error 40.5375%  acc_test_error 50.0%\n",
      "Epoch: 3846 Loss: 3.827853202819824  acc_train_error 40.5375%  acc_test_error 50.0%\n",
      "Epoch: 3847 Loss: 3.8260693550109863  acc_train_error 40.5375%  acc_test_error 50.0%\n",
      "Epoch: 3848 Loss: 3.824296712875366  acc_train_error 40.5375%  acc_test_error 50.0%\n",
      "Epoch: 3849 Loss: 3.822542905807495  acc_train_error 40.5375%  acc_test_error 50.0%\n",
      "Epoch: 3850 Loss: 3.8207571506500244  acc_train_error 40.5375%  acc_test_error 50.0%\n",
      "Epoch: 3851 Loss: 3.819002151489258  acc_train_error 40.525%  acc_test_error 50.0%\n",
      "Epoch: 3852 Loss: 3.817218780517578  acc_train_error 40.5375%  acc_test_error 50.0%\n",
      "Epoch: 3853 Loss: 3.8154683113098145  acc_train_error 40.525%  acc_test_error 50.0%\n",
      "Epoch: 3854 Loss: 3.813688039779663  acc_train_error 40.525%  acc_test_error 50.0%\n",
      "Epoch: 3855 Loss: 3.811936616897583  acc_train_error 40.525%  acc_test_error 50.0%\n",
      "Epoch: 3856 Loss: 3.8101611137390137  acc_train_error 40.525%  acc_test_error 50.0%\n",
      "Epoch: 3857 Loss: 3.8084092140197754  acc_train_error 40.525%  acc_test_error 50.0%\n",
      "Epoch: 3858 Loss: 3.8066318035125732  acc_train_error 40.525%  acc_test_error 50.0%\n",
      "Epoch: 3859 Loss: 3.804887533187866  acc_train_error 40.525%  acc_test_error 50.0%\n",
      "Epoch: 3860 Loss: 3.803112030029297  acc_train_error 40.525%  acc_test_error 50.0%\n",
      "Epoch: 3861 Loss: 3.8013670444488525  acc_train_error 40.525%  acc_test_error 50.0%\n",
      "Epoch: 3862 Loss: 3.799591541290283  acc_train_error 40.525%  acc_test_error 50.0%\n",
      "Epoch: 3863 Loss: 3.7978498935699463  acc_train_error 40.5125%  acc_test_error 50.0%\n",
      "Epoch: 3864 Loss: 3.796074151992798  acc_train_error 40.5125%  acc_test_error 50.0%\n",
      "Epoch: 3865 Loss: 3.794334650039673  acc_train_error 40.5125%  acc_test_error 50.0%\n",
      "Epoch: 3866 Loss: 3.792574882507324  acc_train_error 40.5125%  acc_test_error 50.0%\n",
      "Epoch: 3867 Loss: 3.790809392929077  acc_train_error 40.5125%  acc_test_error 50.0%\n",
      "Epoch: 3868 Loss: 3.7890660762786865  acc_train_error 40.5125%  acc_test_error 50.0%\n",
      "Epoch: 3869 Loss: 3.787299156188965  acc_train_error 40.5125%  acc_test_error 50.0%\n",
      "Epoch: 3870 Loss: 3.785560369491577  acc_train_error 40.5125%  acc_test_error 50.0%\n",
      "Epoch: 3871 Loss: 3.783792018890381  acc_train_error 40.5125%  acc_test_error 50.0%\n",
      "Epoch: 3872 Loss: 3.7820591926574707  acc_train_error 40.5125%  acc_test_error 50.0%\n",
      "Epoch: 3873 Loss: 3.7803070545196533  acc_train_error 40.4875%  acc_test_error 50.0%\n",
      "Epoch: 3874 Loss: 3.7785444259643555  acc_train_error 40.5%  acc_test_error 50.0%\n",
      "Epoch: 3875 Loss: 3.776810884475708  acc_train_error 40.4875%  acc_test_error 50.0%\n",
      "Epoch: 3876 Loss: 3.7750465869903564  acc_train_error 40.4875%  acc_test_error 50.0%\n",
      "Epoch: 3877 Loss: 3.773317813873291  acc_train_error 40.4875%  acc_test_error 50.0%\n",
      "Epoch: 3878 Loss: 3.7715682983398438  acc_train_error 40.4875%  acc_test_error 50.0%\n",
      "Epoch: 3879 Loss: 3.769808530807495  acc_train_error 40.4875%  acc_test_error 50.0%\n",
      "Epoch: 3880 Loss: 3.7680790424346924  acc_train_error 40.4875%  acc_test_error 50.0%\n",
      "Epoch: 3881 Loss: 3.7663323879241943  acc_train_error 40.4875%  acc_test_error 50.0%\n",
      "Epoch: 3882 Loss: 3.7645769119262695  acc_train_error 40.4875%  acc_test_error 50.0%\n",
      "Epoch: 3883 Loss: 3.7628469467163086  acc_train_error 40.4875%  acc_test_error 50.0%\n",
      "Epoch: 3884 Loss: 3.761103868484497  acc_train_error 40.4875%  acc_test_error 50.0%\n",
      "Epoch: 3885 Loss: 3.759352207183838  acc_train_error 40.4875%  acc_test_error 50.0%\n",
      "Epoch: 3886 Loss: 3.7576234340667725  acc_train_error 40.475%  acc_test_error 50.0%\n",
      "Epoch: 3887 Loss: 3.7558672428131104  acc_train_error 40.4875%  acc_test_error 50.0%\n",
      "Epoch: 3888 Loss: 3.754145860671997  acc_train_error 40.475%  acc_test_error 50.0%\n",
      "Epoch: 3889 Loss: 3.7524092197418213  acc_train_error 40.5%  acc_test_error 50.0%\n",
      "Epoch: 3890 Loss: 3.7506558895111084  acc_train_error 40.5%  acc_test_error 50.0%\n",
      "Epoch: 3891 Loss: 3.748936653137207  acc_train_error 40.5%  acc_test_error 50.0%\n",
      "Epoch: 3892 Loss: 3.747201442718506  acc_train_error 40.5%  acc_test_error 50.0%\n",
      "Epoch: 3893 Loss: 3.7454545497894287  acc_train_error 40.5%  acc_test_error 50.0%\n",
      "Epoch: 3894 Loss: 3.7437379360198975  acc_train_error 40.5%  acc_test_error 50.0%\n",
      "Epoch: 3895 Loss: 3.7420032024383545  acc_train_error 40.5%  acc_test_error 50.0%\n",
      "Epoch: 3896 Loss: 3.7402610778808594  acc_train_error 40.5%  acc_test_error 50.0%\n",
      "Epoch: 3897 Loss: 3.73854398727417  acc_train_error 40.5%  acc_test_error 50.0%\n",
      "Epoch: 3898 Loss: 3.736797571182251  acc_train_error 40.5%  acc_test_error 50.0%\n",
      "Epoch: 3899 Loss: 3.7350893020629883  acc_train_error 40.5%  acc_test_error 50.0%\n",
      "Epoch: 3900 Loss: 3.733358144760132  acc_train_error 40.5125%  acc_test_error 50.0%\n",
      "Epoch: 3901 Loss: 3.7316184043884277  acc_train_error 40.5125%  acc_test_error 50.0%\n",
      "Epoch: 3902 Loss: 3.729910135269165  acc_train_error 40.5125%  acc_test_error 50.0%\n",
      "Epoch: 3903 Loss: 3.7281837463378906  acc_train_error 40.5125%  acc_test_error 50.0%\n",
      "Epoch: 3904 Loss: 3.7264435291290283  acc_train_error 40.525%  acc_test_error 50.0%\n",
      "Epoch: 3905 Loss: 3.724736213684082  acc_train_error 40.525%  acc_test_error 50.0%\n",
      "Epoch: 3906 Loss: 3.7230124473571777  acc_train_error 40.525%  acc_test_error 50.0%\n",
      "Epoch: 3907 Loss: 3.72127628326416  acc_train_error 40.525%  acc_test_error 50.0%\n",
      "Epoch: 3908 Loss: 3.7195706367492676  acc_train_error 40.525%  acc_test_error 50.0%\n",
      "Epoch: 3909 Loss: 3.7178475856781006  acc_train_error 40.525%  acc_test_error 50.0%\n",
      "Epoch: 3910 Loss: 3.7161142826080322  acc_train_error 40.525%  acc_test_error 50.0%\n",
      "Epoch: 3911 Loss: 3.714411735534668  acc_train_error 40.525%  acc_test_error 50.0%\n",
      "Epoch: 3912 Loss: 3.712690591812134  acc_train_error 40.525%  acc_test_error 50.0%\n",
      "Epoch: 3913 Loss: 3.710958242416382  acc_train_error 40.525%  acc_test_error 50.0%\n",
      "Epoch: 3914 Loss: 3.7092573642730713  acc_train_error 40.55%  acc_test_error 50.0%\n",
      "Epoch: 3915 Loss: 3.7075388431549072  acc_train_error 40.55%  acc_test_error 50.0%\n",
      "Epoch: 3916 Loss: 3.705808639526367  acc_train_error 40.55%  acc_test_error 50.0%\n",
      "Epoch: 3917 Loss: 3.7041115760803223  acc_train_error 40.55%  acc_test_error 50.0%\n",
      "Epoch: 3918 Loss: 3.702394485473633  acc_train_error 40.55%  acc_test_error 50.0%\n",
      "Epoch: 3919 Loss: 3.700681209564209  acc_train_error 40.55%  acc_test_error 50.0%\n",
      "Epoch: 3920 Loss: 3.6989543437957764  acc_train_error 40.55%  acc_test_error 50.0%\n",
      "Epoch: 3921 Loss: 3.6972618103027344  acc_train_error 40.55%  acc_test_error 50.0%\n",
      "Epoch: 3922 Loss: 3.695546865463257  acc_train_error 40.55%  acc_test_error 50.0%\n",
      "Epoch: 3923 Loss: 3.6938235759735107  acc_train_error 40.55%  acc_test_error 50.0%\n",
      "Epoch: 3924 Loss: 3.692131280899048  acc_train_error 40.55%  acc_test_error 50.0%\n",
      "Epoch: 3925 Loss: 3.690420150756836  acc_train_error 40.5625%  acc_test_error 50.0%\n",
      "Epoch: 3926 Loss: 3.6886982917785645  acc_train_error 40.575%  acc_test_error 50.0%\n",
      "Epoch: 3927 Loss: 3.687007427215576  acc_train_error 40.575%  acc_test_error 50.0%\n",
      "Epoch: 3928 Loss: 3.68530011177063  acc_train_error 40.575%  acc_test_error 50.0%\n",
      "Epoch: 3929 Loss: 3.6835925579071045  acc_train_error 40.575%  acc_test_error 50.0%\n",
      "Epoch: 3930 Loss: 3.681875705718994  acc_train_error 40.575%  acc_test_error 50.0%\n",
      "Epoch: 3931 Loss: 3.6801841259002686  acc_train_error 40.5875%  acc_test_error 50.0%\n",
      "Epoch: 3932 Loss: 3.6784794330596924  acc_train_error 40.575%  acc_test_error 50.0%\n",
      "Epoch: 3933 Loss: 3.6767637729644775  acc_train_error 40.5875%  acc_test_error 50.0%\n",
      "Epoch: 3934 Loss: 3.675076723098755  acc_train_error 40.5875%  acc_test_error 50.0%\n",
      "Epoch: 3935 Loss: 3.673374652862549  acc_train_error 40.5875%  acc_test_error 50.0%\n",
      "Epoch: 3936 Loss: 3.6716599464416504  acc_train_error 40.6%  acc_test_error 50.0%\n",
      "Epoch: 3937 Loss: 3.669975757598877  acc_train_error 40.6%  acc_test_error 50.0%\n",
      "Epoch: 3938 Loss: 3.6682753562927246  acc_train_error 40.6%  acc_test_error 50.0%\n",
      "Epoch: 3939 Loss: 3.666576385498047  acc_train_error 40.6%  acc_test_error 50.0%\n",
      "Epoch: 3940 Loss: 3.664869546890259  acc_train_error 40.6125%  acc_test_error 50.0%\n",
      "Epoch: 3941 Loss: 3.6631834506988525  acc_train_error 40.6%  acc_test_error 50.0%\n",
      "Epoch: 3942 Loss: 3.6614890098571777  acc_train_error 40.6125%  acc_test_error 50.0%\n",
      "Epoch: 3943 Loss: 3.659780263900757  acc_train_error 40.6125%  acc_test_error 50.0%\n",
      "Epoch: 3944 Loss: 3.6580989360809326  acc_train_error 40.625%  acc_test_error 50.0%\n",
      "Epoch: 3945 Loss: 3.656405448913574  acc_train_error 40.6125%  acc_test_error 50.0%\n",
      "Epoch: 3946 Loss: 3.6546995639801025  acc_train_error 40.625%  acc_test_error 50.0%\n",
      "Epoch: 3947 Loss: 3.6530215740203857  acc_train_error 40.6375%  acc_test_error 50.0%\n",
      "Epoch: 3948 Loss: 3.6513304710388184  acc_train_error 40.625%  acc_test_error 50.0%\n",
      "Epoch: 3949 Loss: 3.6496262550354004  acc_train_error 40.6375%  acc_test_error 50.0%\n",
      "Epoch: 3950 Loss: 3.6479504108428955  acc_train_error 40.6375%  acc_test_error 50.0%\n",
      "Epoch: 3951 Loss: 3.6462581157684326  acc_train_error 40.6375%  acc_test_error 50.0%\n",
      "Epoch: 3952 Loss: 3.6445600986480713  acc_train_error 40.6375%  acc_test_error 50.0%\n",
      "Epoch: 3953 Loss: 3.6428864002227783  acc_train_error 40.6375%  acc_test_error 50.0%\n",
      "Epoch: 3954 Loss: 3.641197681427002  acc_train_error 40.6375%  acc_test_error 50.0%\n",
      "Epoch: 3955 Loss: 3.639495372772217  acc_train_error 40.6375%  acc_test_error 50.0%\n",
      "Epoch: 3956 Loss: 3.6378285884857178  acc_train_error 40.6375%  acc_test_error 50.0%\n",
      "Epoch: 3957 Loss: 3.636136531829834  acc_train_error 40.6625%  acc_test_error 50.0%\n",
      "Epoch: 3958 Loss: 3.6344361305236816  acc_train_error 40.675%  acc_test_error 50.0%\n",
      "Epoch: 3959 Loss: 3.632766008377075  acc_train_error 40.675%  acc_test_error 50.0%\n",
      "Epoch: 3960 Loss: 3.63107967376709  acc_train_error 40.6875%  acc_test_error 50.0%\n",
      "Epoch: 3961 Loss: 3.629394054412842  acc_train_error 40.6875%  acc_test_error 50.0%\n",
      "Epoch: 3962 Loss: 3.627699851989746  acc_train_error 40.6875%  acc_test_error 50.0%\n",
      "Epoch: 3963 Loss: 3.626030445098877  acc_train_error 40.6875%  acc_test_error 50.0%\n",
      "Epoch: 3964 Loss: 3.624346971511841  acc_train_error 40.7%  acc_test_error 50.0%\n",
      "Epoch: 3965 Loss: 3.622652053833008  acc_train_error 40.7%  acc_test_error 50.0%\n",
      "Epoch: 3966 Loss: 3.62099027633667  acc_train_error 40.7125%  acc_test_error 50.0%\n",
      "Epoch: 3967 Loss: 3.6193089485168457  acc_train_error 40.7125%  acc_test_error 50.0%\n",
      "Epoch: 3968 Loss: 3.617629051208496  acc_train_error 40.7125%  acc_test_error 50.0%\n",
      "Epoch: 3969 Loss: 3.615936517715454  acc_train_error 40.7375%  acc_test_error 50.0%\n",
      "Epoch: 3970 Loss: 3.614274263381958  acc_train_error 40.725%  acc_test_error 50.0%\n",
      "Epoch: 3971 Loss: 3.612597942352295  acc_train_error 40.75%  acc_test_error 50.0%\n",
      "Epoch: 3972 Loss: 3.6109201908111572  acc_train_error 40.75%  acc_test_error 50.0%\n",
      "Epoch: 3973 Loss: 3.6092312335968018  acc_train_error 40.7625%  acc_test_error 50.0%\n",
      "Epoch: 3974 Loss: 3.607572317123413  acc_train_error 40.7625%  acc_test_error 50.0%\n",
      "Epoch: 3975 Loss: 3.60589599609375  acc_train_error 40.7625%  acc_test_error 50.0%\n",
      "Epoch: 3976 Loss: 3.60422420501709  acc_train_error 40.775%  acc_test_error 50.0%\n",
      "Epoch: 3977 Loss: 3.6025400161743164  acc_train_error 40.775%  acc_test_error 50.0%\n",
      "Epoch: 3978 Loss: 3.6008830070495605  acc_train_error 40.7875%  acc_test_error 50.0%\n",
      "Epoch: 3979 Loss: 3.599210739135742  acc_train_error 40.7875%  acc_test_error 50.0%\n",
      "Epoch: 3980 Loss: 3.5975396633148193  acc_train_error 40.7875%  acc_test_error 50.0%\n",
      "Epoch: 3981 Loss: 3.5958611965179443  acc_train_error 40.7875%  acc_test_error 50.0%\n",
      "Epoch: 3982 Loss: 3.5942094326019287  acc_train_error 40.8%  acc_test_error 50.0%\n",
      "Epoch: 3983 Loss: 3.5925405025482178  acc_train_error 40.8125%  acc_test_error 50.0%\n",
      "Epoch: 3984 Loss: 3.5908732414245605  acc_train_error 40.8125%  acc_test_error 50.0%\n",
      "Epoch: 3985 Loss: 3.5891947746276855  acc_train_error 40.825%  acc_test_error 50.0%\n",
      "Epoch: 3986 Loss: 3.587545394897461  acc_train_error 40.825%  acc_test_error 50.0%\n",
      "Epoch: 3987 Loss: 3.585880994796753  acc_train_error 40.8375%  acc_test_error 50.0%\n",
      "Epoch: 3988 Loss: 3.584216594696045  acc_train_error 40.8375%  acc_test_error 50.0%\n",
      "Epoch: 3989 Loss: 3.582542657852173  acc_train_error 40.8375%  acc_test_error 50.0%\n",
      "Epoch: 3990 Loss: 3.5808968544006348  acc_train_error 40.8375%  acc_test_error 50.0%\n",
      "Epoch: 3991 Loss: 3.579235792160034  acc_train_error 40.85%  acc_test_error 50.0%\n",
      "Epoch: 3992 Loss: 3.5775740146636963  acc_train_error 40.85%  acc_test_error 50.0%\n",
      "Epoch: 3993 Loss: 3.5759129524230957  acc_train_error 40.85%  acc_test_error 50.0%\n",
      "Epoch: 3994 Loss: 3.57424259185791  acc_train_error 40.85%  acc_test_error 50.0%\n",
      "Epoch: 3995 Loss: 3.572598934173584  acc_train_error 40.85%  acc_test_error 50.0%\n",
      "Epoch: 3996 Loss: 3.5709409713745117  acc_train_error 40.875%  acc_test_error 50.0%\n",
      "Epoch: 3997 Loss: 3.5692849159240723  acc_train_error 40.8875%  acc_test_error 50.0%\n",
      "Epoch: 3998 Loss: 3.5676300525665283  acc_train_error 40.8875%  acc_test_error 50.0%\n",
      "Epoch: 3999 Loss: 3.565962314605713  acc_train_error 40.8875%  acc_test_error 50.0%\n",
      "Epoch: 4000 Loss: 3.5643229484558105  acc_train_error 40.9%  acc_test_error 50.0%\n",
      "Epoch: 4001 Loss: 3.562669277191162  acc_train_error 40.9%  acc_test_error 50.0%\n",
      "Epoch: 4002 Loss: 3.561018705368042  acc_train_error 40.9%  acc_test_error 50.0%\n",
      "Epoch: 4003 Loss: 3.5593674182891846  acc_train_error 40.9%  acc_test_error 50.0%\n",
      "Epoch: 4004 Loss: 3.5577139854431152  acc_train_error 40.9%  acc_test_error 50.0%\n",
      "Epoch: 4005 Loss: 3.556065559387207  acc_train_error 40.9125%  acc_test_error 50.0%\n",
      "Epoch: 4006 Loss: 3.5544028282165527  acc_train_error 40.925%  acc_test_error 50.0%\n",
      "Epoch: 4007 Loss: 3.552769184112549  acc_train_error 40.925%  acc_test_error 50.0%\n",
      "Epoch: 4008 Loss: 3.5511233806610107  acc_train_error 40.925%  acc_test_error 50.0%\n",
      "Epoch: 4009 Loss: 3.549475908279419  acc_train_error 40.9375%  acc_test_error 50.0%\n",
      "Epoch: 4010 Loss: 3.5478291511535645  acc_train_error 40.9375%  acc_test_error 50.0%\n",
      "Epoch: 4011 Loss: 3.5461833477020264  acc_train_error 40.95%  acc_test_error 50.0%\n",
      "Epoch: 4012 Loss: 3.544538974761963  acc_train_error 40.95%  acc_test_error 50.0%\n",
      "Epoch: 4013 Loss: 3.5428810119628906  acc_train_error 40.95%  acc_test_error 50.0%\n",
      "Epoch: 4014 Loss: 3.5412564277648926  acc_train_error 40.9625%  acc_test_error 50.0%\n",
      "Epoch: 4015 Loss: 3.539614200592041  acc_train_error 40.9625%  acc_test_error 50.0%\n",
      "Epoch: 4016 Loss: 3.5379722118377686  acc_train_error 40.9625%  acc_test_error 50.0%\n",
      "Epoch: 4017 Loss: 3.5363306999206543  acc_train_error 40.975%  acc_test_error 50.0%\n",
      "Epoch: 4018 Loss: 3.534691333770752  acc_train_error 40.9875%  acc_test_error 50.0%\n",
      "Epoch: 4019 Loss: 3.533050775527954  acc_train_error 40.9875%  acc_test_error 50.0%\n",
      "Epoch: 4020 Loss: 3.5314109325408936  acc_train_error 40.9875%  acc_test_error 50.0%\n",
      "Epoch: 4021 Loss: 3.5297610759735107  acc_train_error 40.9875%  acc_test_error 50.0%\n",
      "Epoch: 4022 Loss: 3.5281412601470947  acc_train_error 41.0%  acc_test_error 50.0%\n",
      "Epoch: 4023 Loss: 3.5265040397644043  acc_train_error 41.0%  acc_test_error 50.0%\n",
      "Epoch: 4024 Loss: 3.524867296218872  acc_train_error 41.0%  acc_test_error 50.0%\n",
      "Epoch: 4025 Loss: 3.523232936859131  acc_train_error 41.0%  acc_test_error 50.0%\n",
      "Epoch: 4026 Loss: 3.5215981006622314  acc_train_error 41.0125%  acc_test_error 50.0%\n",
      "Epoch: 4027 Loss: 3.5199642181396484  acc_train_error 41.0375%  acc_test_error 50.0%\n",
      "Epoch: 4028 Loss: 3.518331289291382  acc_train_error 41.0375%  acc_test_error 50.0%\n",
      "Epoch: 4029 Loss: 3.516697645187378  acc_train_error 41.0375%  acc_test_error 50.0%\n",
      "Epoch: 4030 Loss: 3.515066623687744  acc_train_error 41.0375%  acc_test_error 50.0%\n",
      "Epoch: 4031 Loss: 3.5134377479553223  acc_train_error 41.0375%  acc_test_error 50.0%\n",
      "Epoch: 4032 Loss: 3.5118067264556885  acc_train_error 41.05%  acc_test_error 50.0%\n",
      "Epoch: 4033 Loss: 3.5101773738861084  acc_train_error 41.05%  acc_test_error 50.0%\n",
      "Epoch: 4034 Loss: 3.508547782897949  acc_train_error 41.05%  acc_test_error 50.0%\n",
      "Epoch: 4035 Loss: 3.506918430328369  acc_train_error 41.05%  acc_test_error 50.0%\n",
      "Epoch: 4036 Loss: 3.5052919387817383  acc_train_error 41.0625%  acc_test_error 50.0%\n",
      "Epoch: 4037 Loss: 3.5036661624908447  acc_train_error 41.0625%  acc_test_error 50.0%\n",
      "Epoch: 4038 Loss: 3.502040386199951  acc_train_error 41.0625%  acc_test_error 50.0%\n",
      "Epoch: 4039 Loss: 3.500413656234741  acc_train_error 41.075%  acc_test_error 50.0%\n",
      "Epoch: 4040 Loss: 3.4987900257110596  acc_train_error 41.0875%  acc_test_error 50.0%\n",
      "Epoch: 4041 Loss: 3.4971654415130615  acc_train_error 41.0875%  acc_test_error 50.0%\n",
      "Epoch: 4042 Loss: 3.4955427646636963  acc_train_error 41.0875%  acc_test_error 50.0%\n",
      "Epoch: 4043 Loss: 3.4939208030700684  acc_train_error 41.0875%  acc_test_error 50.0%\n",
      "Epoch: 4044 Loss: 3.4922990798950195  acc_train_error 41.1%  acc_test_error 50.0%\n",
      "Epoch: 4045 Loss: 3.4906792640686035  acc_train_error 41.1125%  acc_test_error 50.0%\n",
      "Epoch: 4046 Loss: 3.48905873298645  acc_train_error 41.1125%  acc_test_error 50.0%\n",
      "Epoch: 4047 Loss: 3.4874396324157715  acc_train_error 41.1125%  acc_test_error 50.0%\n",
      "Epoch: 4048 Loss: 3.4858205318450928  acc_train_error 41.1125%  acc_test_error 50.0%\n",
      "Epoch: 4049 Loss: 3.4842028617858887  acc_train_error 41.1375%  acc_test_error 50.0%\n",
      "Epoch: 4050 Loss: 3.4825868606567383  acc_train_error 41.1375%  acc_test_error 50.0%\n",
      "Epoch: 4051 Loss: 3.4809696674346924  acc_train_error 41.1375%  acc_test_error 50.0%\n",
      "Epoch: 4052 Loss: 3.4793546199798584  acc_train_error 41.1375%  acc_test_error 50.0%\n",
      "Epoch: 4053 Loss: 3.477739095687866  acc_train_error 41.15%  acc_test_error 50.0%\n",
      "Epoch: 4054 Loss: 3.476125955581665  acc_train_error 41.15%  acc_test_error 50.0%\n",
      "Epoch: 4055 Loss: 3.4745123386383057  acc_train_error 41.15%  acc_test_error 50.0%\n",
      "Epoch: 4056 Loss: 3.472900390625  acc_train_error 41.15%  acc_test_error 50.0%\n",
      "Epoch: 4057 Loss: 3.4712865352630615  acc_train_error 41.15%  acc_test_error 50.0%\n",
      "Epoch: 4058 Loss: 3.469677448272705  acc_train_error 41.175%  acc_test_error 50.0%\n",
      "Epoch: 4059 Loss: 3.468066692352295  acc_train_error 41.1875%  acc_test_error 50.0%\n",
      "Epoch: 4060 Loss: 3.466456890106201  acc_train_error 41.1875%  acc_test_error 50.0%\n",
      "Epoch: 4061 Loss: 3.464848279953003  acc_train_error 41.1875%  acc_test_error 50.0%\n",
      "Epoch: 4062 Loss: 3.4632396697998047  acc_train_error 41.1875%  acc_test_error 50.0%\n",
      "Epoch: 4063 Loss: 3.461632251739502  acc_train_error 41.2%  acc_test_error 50.0%\n",
      "Epoch: 4064 Loss: 3.4600253105163574  acc_train_error 41.2%  acc_test_error 50.0%\n",
      "Epoch: 4065 Loss: 3.458418846130371  acc_train_error 41.2%  acc_test_error 50.0%\n",
      "Epoch: 4066 Loss: 3.4568135738372803  acc_train_error 41.2125%  acc_test_error 50.0%\n",
      "Epoch: 4067 Loss: 3.4552078247070312  acc_train_error 41.2%  acc_test_error 50.0%\n",
      "Epoch: 4068 Loss: 3.4536075592041016  acc_train_error 41.225%  acc_test_error 50.0%\n",
      "Epoch: 4069 Loss: 3.4520022869110107  acc_train_error 41.225%  acc_test_error 50.0%\n",
      "Epoch: 4070 Loss: 3.4504010677337646  acc_train_error 41.225%  acc_test_error 50.0%\n",
      "Epoch: 4071 Loss: 3.448798656463623  acc_train_error 41.225%  acc_test_error 50.0%\n",
      "Epoch: 4072 Loss: 3.447199583053589  acc_train_error 41.225%  acc_test_error 50.0%\n",
      "Epoch: 4073 Loss: 3.4455997943878174  acc_train_error 41.225%  acc_test_error 50.0%\n",
      "Epoch: 4074 Loss: 3.444002389907837  acc_train_error 41.2375%  acc_test_error 50.0%\n",
      "Epoch: 4075 Loss: 3.4424023628234863  acc_train_error 41.25%  acc_test_error 50.0%\n",
      "Epoch: 4076 Loss: 3.440807819366455  acc_train_error 41.25%  acc_test_error 50.0%\n",
      "Epoch: 4077 Loss: 3.439211130142212  acc_train_error 41.2625%  acc_test_error 50.0%\n",
      "Epoch: 4078 Loss: 3.4376180171966553  acc_train_error 41.2625%  acc_test_error 50.0%\n",
      "Epoch: 4079 Loss: 3.4360241889953613  acc_train_error 41.2625%  acc_test_error 50.0%\n",
      "Epoch: 4080 Loss: 3.434432029724121  acc_train_error 41.2625%  acc_test_error 50.0%\n",
      "Epoch: 4081 Loss: 3.4328370094299316  acc_train_error 41.275%  acc_test_error 50.0%\n",
      "Epoch: 4082 Loss: 3.431248903274536  acc_train_error 41.275%  acc_test_error 50.0%\n",
      "Epoch: 4083 Loss: 3.429656982421875  acc_train_error 41.275%  acc_test_error 50.0%\n",
      "Epoch: 4084 Loss: 3.428067207336426  acc_train_error 41.275%  acc_test_error 50.0%\n",
      "Epoch: 4085 Loss: 3.4264774322509766  acc_train_error 41.275%  acc_test_error 50.0%\n",
      "Epoch: 4086 Loss: 3.4248900413513184  acc_train_error 41.275%  acc_test_error 50.0%\n",
      "Epoch: 4087 Loss: 3.4233012199401855  acc_train_error 41.275%  acc_test_error 50.0%\n",
      "Epoch: 4088 Loss: 3.4217145442962646  acc_train_error 41.3%  acc_test_error 50.0%\n",
      "Epoch: 4089 Loss: 3.4201278686523438  acc_train_error 41.3%  acc_test_error 50.0%\n",
      "Epoch: 4090 Loss: 3.4185421466827393  acc_train_error 41.3%  acc_test_error 50.0%\n",
      "Epoch: 4091 Loss: 3.4169561862945557  acc_train_error 41.3%  acc_test_error 50.0%\n",
      "Epoch: 4092 Loss: 3.415374755859375  acc_train_error 41.3125%  acc_test_error 50.0%\n",
      "Epoch: 4093 Loss: 3.413788318634033  acc_train_error 41.3125%  acc_test_error 50.0%\n",
      "Epoch: 4094 Loss: 3.4122068881988525  acc_train_error 41.3125%  acc_test_error 50.0%\n",
      "Epoch: 4095 Loss: 3.4106249809265137  acc_train_error 41.325%  acc_test_error 50.0%\n",
      "Epoch: 4096 Loss: 3.4090445041656494  acc_train_error 41.325%  acc_test_error 50.0%\n",
      "Epoch: 4097 Loss: 3.4074621200561523  acc_train_error 41.325%  acc_test_error 50.0%\n",
      "Epoch: 4098 Loss: 3.4058830738067627  acc_train_error 41.325%  acc_test_error 50.0%\n",
      "Epoch: 4099 Loss: 3.4043033123016357  acc_train_error 41.3375%  acc_test_error 50.0%\n",
      "Epoch: 4100 Loss: 3.402724504470825  acc_train_error 41.3375%  acc_test_error 50.0%\n",
      "Epoch: 4101 Loss: 3.401146650314331  acc_train_error 41.3375%  acc_test_error 50.0%\n",
      "Epoch: 4102 Loss: 3.399570941925049  acc_train_error 41.35%  acc_test_error 50.0%\n",
      "Epoch: 4103 Loss: 3.3979928493499756  acc_train_error 41.35%  acc_test_error 50.0%\n",
      "Epoch: 4104 Loss: 3.3964180946350098  acc_train_error 41.35%  acc_test_error 50.0%\n",
      "Epoch: 4105 Loss: 3.394843101501465  acc_train_error 41.35%  acc_test_error 50.0%\n",
      "Epoch: 4106 Loss: 3.393268346786499  acc_train_error 41.35%  acc_test_error 50.0%\n",
      "Epoch: 4107 Loss: 3.3916962146759033  acc_train_error 41.35%  acc_test_error 50.0%\n",
      "Epoch: 4108 Loss: 3.3901216983795166  acc_train_error 41.3625%  acc_test_error 50.0%\n",
      "Epoch: 4109 Loss: 3.3885512351989746  acc_train_error 41.375%  acc_test_error 50.0%\n",
      "Epoch: 4110 Loss: 3.3869786262512207  acc_train_error 41.3875%  acc_test_error 50.0%\n",
      "Epoch: 4111 Loss: 3.3854076862335205  acc_train_error 41.3875%  acc_test_error 50.0%\n",
      "Epoch: 4112 Loss: 3.383835792541504  acc_train_error 41.3875%  acc_test_error 50.0%\n",
      "Epoch: 4113 Loss: 3.3822667598724365  acc_train_error 41.3875%  acc_test_error 50.0%\n",
      "Epoch: 4114 Loss: 3.38069748878479  acc_train_error 41.3875%  acc_test_error 50.0%\n",
      "Epoch: 4115 Loss: 3.3791298866271973  acc_train_error 41.3875%  acc_test_error 50.0%\n",
      "Epoch: 4116 Loss: 3.377561092376709  acc_train_error 41.4%  acc_test_error 50.0%\n",
      "Epoch: 4117 Loss: 3.375994920730591  acc_train_error 41.4%  acc_test_error 50.0%\n",
      "Epoch: 4118 Loss: 3.3744277954101562  acc_train_error 41.4%  acc_test_error 50.0%\n",
      "Epoch: 4119 Loss: 3.3728623390197754  acc_train_error 41.4125%  acc_test_error 50.0%\n",
      "Epoch: 4120 Loss: 3.3712966442108154  acc_train_error 41.425%  acc_test_error 50.0%\n",
      "Epoch: 4121 Loss: 3.3697328567504883  acc_train_error 41.425%  acc_test_error 50.0%\n",
      "Epoch: 4122 Loss: 3.368169069290161  acc_train_error 41.4375%  acc_test_error 50.0%\n",
      "Epoch: 4123 Loss: 3.3666059970855713  acc_train_error 41.45%  acc_test_error 50.0%\n",
      "Epoch: 4124 Loss: 3.3650436401367188  acc_train_error 41.45%  acc_test_error 50.0%\n",
      "Epoch: 4125 Loss: 3.3634817600250244  acc_train_error 41.45%  acc_test_error 50.0%\n",
      "Epoch: 4126 Loss: 3.36191987991333  acc_train_error 41.45%  acc_test_error 50.0%\n",
      "Epoch: 4127 Loss: 3.360363483428955  acc_train_error 41.45%  acc_test_error 50.0%\n",
      "Epoch: 4128 Loss: 3.35880446434021  acc_train_error 41.45%  acc_test_error 50.0%\n",
      "Epoch: 4129 Loss: 3.357245683670044  acc_train_error 41.4625%  acc_test_error 50.0%\n",
      "Epoch: 4130 Loss: 3.35568904876709  acc_train_error 41.475%  acc_test_error 50.0%\n",
      "Epoch: 4131 Loss: 3.3541321754455566  acc_train_error 41.475%  acc_test_error 50.0%\n",
      "Epoch: 4132 Loss: 3.3525755405426025  acc_train_error 41.475%  acc_test_error 50.0%\n",
      "Epoch: 4133 Loss: 3.3510191440582275  acc_train_error 41.475%  acc_test_error 50.0%\n",
      "Epoch: 4134 Loss: 3.3494656085968018  acc_train_error 41.475%  acc_test_error 50.0%\n",
      "Epoch: 4135 Loss: 3.347910165786743  acc_train_error 41.475%  acc_test_error 50.0%\n",
      "Epoch: 4136 Loss: 3.3463563919067383  acc_train_error 41.475%  acc_test_error 50.0%\n",
      "Epoch: 4137 Loss: 3.344801664352417  acc_train_error 41.4875%  acc_test_error 50.0%\n",
      "Epoch: 4138 Loss: 3.3432493209838867  acc_train_error 41.4875%  acc_test_error 50.0%\n",
      "Epoch: 4139 Loss: 3.3416953086853027  acc_train_error 41.4875%  acc_test_error 50.0%\n",
      "Epoch: 4140 Loss: 3.340142250061035  acc_train_error 41.4875%  acc_test_error 50.0%\n",
      "Epoch: 4141 Loss: 3.3385910987854004  acc_train_error 41.4875%  acc_test_error 50.0%\n",
      "Epoch: 4142 Loss: 3.337038278579712  acc_train_error 41.4875%  acc_test_error 50.0%\n",
      "Epoch: 4143 Loss: 3.335488796234131  acc_train_error 41.5%  acc_test_error 50.0%\n",
      "Epoch: 4144 Loss: 3.3339390754699707  acc_train_error 41.5125%  acc_test_error 50.0%\n",
      "Epoch: 4145 Loss: 3.3323917388916016  acc_train_error 41.525%  acc_test_error 50.0%\n",
      "Epoch: 4146 Loss: 3.330843210220337  acc_train_error 41.525%  acc_test_error 50.0%\n",
      "Epoch: 4147 Loss: 3.329296827316284  acc_train_error 41.525%  acc_test_error 50.0%\n",
      "Epoch: 4148 Loss: 3.3277506828308105  acc_train_error 41.525%  acc_test_error 50.0%\n",
      "Epoch: 4149 Loss: 3.326204776763916  acc_train_error 41.525%  acc_test_error 50.0%\n",
      "Epoch: 4150 Loss: 3.324660539627075  acc_train_error 41.525%  acc_test_error 50.0%\n",
      "Epoch: 4151 Loss: 3.323118209838867  acc_train_error 41.55%  acc_test_error 50.0%\n",
      "Epoch: 4152 Loss: 3.321575164794922  acc_train_error 41.55%  acc_test_error 50.0%\n",
      "Epoch: 4153 Loss: 3.3200340270996094  acc_train_error 41.55%  acc_test_error 50.0%\n",
      "Epoch: 4154 Loss: 3.3184938430786133  acc_train_error 41.55%  acc_test_error 50.0%\n",
      "Epoch: 4155 Loss: 3.3169519901275635  acc_train_error 41.55%  acc_test_error 50.0%\n",
      "Epoch: 4156 Loss: 3.3154120445251465  acc_train_error 41.55%  acc_test_error 50.0%\n",
      "Epoch: 4157 Loss: 3.313873529434204  acc_train_error 41.55%  acc_test_error 50.0%\n",
      "Epoch: 4158 Loss: 3.3123364448547363  acc_train_error 41.5625%  acc_test_error 50.0%\n",
      "Epoch: 4159 Loss: 3.3107988834381104  acc_train_error 41.575%  acc_test_error 50.0%\n",
      "Epoch: 4160 Loss: 3.309262990951538  acc_train_error 41.575%  acc_test_error 50.0%\n",
      "Epoch: 4161 Loss: 3.3077266216278076  acc_train_error 41.575%  acc_test_error 50.0%\n",
      "Epoch: 4162 Loss: 3.3061931133270264  acc_train_error 41.575%  acc_test_error 50.0%\n",
      "Epoch: 4163 Loss: 3.3046576976776123  acc_train_error 41.575%  acc_test_error 50.0%\n",
      "Epoch: 4164 Loss: 3.3031249046325684  acc_train_error 41.5875%  acc_test_error 50.0%\n",
      "Epoch: 4165 Loss: 3.301593780517578  acc_train_error 41.6%  acc_test_error 50.0%\n",
      "Epoch: 4166 Loss: 3.3000614643096924  acc_train_error 41.6%  acc_test_error 50.0%\n",
      "Epoch: 4167 Loss: 3.298532485961914  acc_train_error 41.6125%  acc_test_error 50.0%\n",
      "Epoch: 4168 Loss: 3.29699969291687  acc_train_error 41.6125%  acc_test_error 50.0%\n",
      "Epoch: 4169 Loss: 3.295471429824829  acc_train_error 41.6125%  acc_test_error 50.0%\n",
      "Epoch: 4170 Loss: 3.2939422130584717  acc_train_error 41.6125%  acc_test_error 50.0%\n",
      "Epoch: 4171 Loss: 3.292414665222168  acc_train_error 41.6125%  acc_test_error 50.0%\n",
      "Epoch: 4172 Loss: 3.2908849716186523  acc_train_error 41.6125%  acc_test_error 50.0%\n",
      "Epoch: 4173 Loss: 3.2893590927124023  acc_train_error 41.625%  acc_test_error 50.0%\n",
      "Epoch: 4174 Loss: 3.2878293991088867  acc_train_error 41.6375%  acc_test_error 50.0%\n",
      "Epoch: 4175 Loss: 3.2863054275512695  acc_train_error 41.6375%  acc_test_error 50.0%\n",
      "Epoch: 4176 Loss: 3.2847790718078613  acc_train_error 41.6375%  acc_test_error 50.0%\n",
      "Epoch: 4177 Loss: 3.283254623413086  acc_train_error 41.6375%  acc_test_error 50.0%\n",
      "Epoch: 4178 Loss: 3.2817275524139404  acc_train_error 41.6375%  acc_test_error 50.0%\n",
      "Epoch: 4179 Loss: 3.280205249786377  acc_train_error 41.6375%  acc_test_error 50.0%\n",
      "Epoch: 4180 Loss: 3.278679847717285  acc_train_error 41.675%  acc_test_error 50.0%\n",
      "Epoch: 4181 Loss: 3.2771568298339844  acc_train_error 41.675%  acc_test_error 50.0%\n",
      "Epoch: 4182 Loss: 3.275634527206421  acc_train_error 41.675%  acc_test_error 50.0%\n",
      "Epoch: 4183 Loss: 3.2741141319274902  acc_train_error 41.675%  acc_test_error 50.0%\n",
      "Epoch: 4184 Loss: 3.2725939750671387  acc_train_error 41.675%  acc_test_error 50.0%\n",
      "Epoch: 4185 Loss: 3.2710726261138916  acc_train_error 41.675%  acc_test_error 50.0%\n",
      "Epoch: 4186 Loss: 3.269554615020752  acc_train_error 41.6875%  acc_test_error 50.0%\n",
      "Epoch: 4187 Loss: 3.2680344581604004  acc_train_error 41.7%  acc_test_error 50.0%\n",
      "Epoch: 4188 Loss: 3.266517162322998  acc_train_error 41.7%  acc_test_error 50.0%\n",
      "Epoch: 4189 Loss: 3.2649989128112793  acc_train_error 41.7%  acc_test_error 50.0%\n",
      "Epoch: 4190 Loss: 3.2634809017181396  acc_train_error 41.7%  acc_test_error 50.0%\n",
      "Epoch: 4191 Loss: 3.261963367462158  acc_train_error 41.7%  acc_test_error 50.0%\n",
      "Epoch: 4192 Loss: 3.260448932647705  acc_train_error 41.7125%  acc_test_error 50.0%\n",
      "Epoch: 4193 Loss: 3.2589340209960938  acc_train_error 41.725%  acc_test_error 50.0%\n",
      "Epoch: 4194 Loss: 3.2574212551116943  acc_train_error 41.7375%  acc_test_error 50.0%\n",
      "Epoch: 4195 Loss: 3.2559075355529785  acc_train_error 41.7375%  acc_test_error 50.0%\n",
      "Epoch: 4196 Loss: 3.2543938159942627  acc_train_error 41.75%  acc_test_error 50.0%\n",
      "Epoch: 4197 Loss: 3.252880811691284  acc_train_error 41.75%  acc_test_error 50.0%\n",
      "Epoch: 4198 Loss: 3.2513716220855713  acc_train_error 41.75%  acc_test_error 50.0%\n",
      "Epoch: 4199 Loss: 3.2498602867126465  acc_train_error 41.75%  acc_test_error 50.0%\n",
      "Epoch: 4200 Loss: 3.24834942817688  acc_train_error 41.7625%  acc_test_error 50.0%\n",
      "Epoch: 4201 Loss: 3.2468373775482178  acc_train_error 41.7625%  acc_test_error 50.0%\n",
      "Epoch: 4202 Loss: 3.2453296184539795  acc_train_error 41.775%  acc_test_error 50.0%\n",
      "Epoch: 4203 Loss: 3.2438206672668457  acc_train_error 41.775%  acc_test_error 50.0%\n",
      "Epoch: 4204 Loss: 3.242311716079712  acc_train_error 41.775%  acc_test_error 50.0%\n",
      "Epoch: 4205 Loss: 3.24080491065979  acc_train_error 41.775%  acc_test_error 50.0%\n",
      "Epoch: 4206 Loss: 3.2392985820770264  acc_train_error 41.7875%  acc_test_error 50.0%\n",
      "Epoch: 4207 Loss: 3.2377912998199463  acc_train_error 41.8%  acc_test_error 50.0%\n",
      "Epoch: 4208 Loss: 3.236288070678711  acc_train_error 41.8%  acc_test_error 50.0%\n",
      "Epoch: 4209 Loss: 3.2347843647003174  acc_train_error 41.8125%  acc_test_error 50.0%\n",
      "Epoch: 4210 Loss: 3.233283281326294  acc_train_error 41.8125%  acc_test_error 50.0%\n",
      "Epoch: 4211 Loss: 3.231781005859375  acc_train_error 41.8%  acc_test_error 50.0%\n",
      "Epoch: 4212 Loss: 3.23028302192688  acc_train_error 41.8125%  acc_test_error 50.0%\n",
      "Epoch: 4213 Loss: 3.2287843227386475  acc_train_error 41.8125%  acc_test_error 50.0%\n",
      "Epoch: 4214 Loss: 3.2272849082946777  acc_train_error 41.825%  acc_test_error 50.0%\n",
      "Epoch: 4215 Loss: 3.2257890701293945  acc_train_error 41.825%  acc_test_error 50.0%\n",
      "Epoch: 4216 Loss: 3.2242910861968994  acc_train_error 41.825%  acc_test_error 50.0%\n",
      "Epoch: 4217 Loss: 3.2227959632873535  acc_train_error 41.825%  acc_test_error 50.0%\n",
      "Epoch: 4218 Loss: 3.2213003635406494  acc_train_error 41.825%  acc_test_error 50.0%\n",
      "Epoch: 4219 Loss: 3.2198033332824707  acc_train_error 41.825%  acc_test_error 50.0%\n",
      "Epoch: 4220 Loss: 3.2183077335357666  acc_train_error 41.825%  acc_test_error 50.0%\n",
      "Epoch: 4221 Loss: 3.2168126106262207  acc_train_error 41.825%  acc_test_error 50.0%\n",
      "Epoch: 4222 Loss: 3.215318441390991  acc_train_error 41.8375%  acc_test_error 50.0%\n",
      "Epoch: 4223 Loss: 3.2138240337371826  acc_train_error 41.8375%  acc_test_error 50.0%\n",
      "Epoch: 4224 Loss: 3.212332010269165  acc_train_error 41.8375%  acc_test_error 50.0%\n",
      "Epoch: 4225 Loss: 3.2108402252197266  acc_train_error 41.85%  acc_test_error 50.0%\n",
      "Epoch: 4226 Loss: 3.209351062774658  acc_train_error 41.8375%  acc_test_error 50.0%\n",
      "Epoch: 4227 Loss: 3.207858085632324  acc_train_error 41.8375%  acc_test_error 50.0%\n",
      "Epoch: 4228 Loss: 3.206369400024414  acc_train_error 41.85%  acc_test_error 50.0%\n",
      "Epoch: 4229 Loss: 3.2048799991607666  acc_train_error 41.8625%  acc_test_error 50.0%\n",
      "Epoch: 4230 Loss: 3.2033913135528564  acc_train_error 41.875%  acc_test_error 50.0%\n",
      "Epoch: 4231 Loss: 3.201902151107788  acc_train_error 41.875%  acc_test_error 50.0%\n",
      "Epoch: 4232 Loss: 3.200416326522827  acc_train_error 41.875%  acc_test_error 50.0%\n",
      "Epoch: 4233 Loss: 3.19892954826355  acc_train_error 41.8875%  acc_test_error 50.0%\n",
      "Epoch: 4234 Loss: 3.1974432468414307  acc_train_error 41.9125%  acc_test_error 50.0%\n",
      "Epoch: 4235 Loss: 3.1959586143493652  acc_train_error 41.9125%  acc_test_error 50.0%\n",
      "Epoch: 4236 Loss: 3.194472312927246  acc_train_error 41.9375%  acc_test_error 50.0%\n",
      "Epoch: 4237 Loss: 3.192988872528076  acc_train_error 41.9625%  acc_test_error 50.0%\n",
      "Epoch: 4238 Loss: 3.191504716873169  acc_train_error 42.0%  acc_test_error 50.0%\n",
      "Epoch: 4239 Loss: 3.190023422241211  acc_train_error 42.0125%  acc_test_error 50.0%\n",
      "Epoch: 4240 Loss: 3.188542127609253  acc_train_error 42.0125%  acc_test_error 50.0%\n",
      "Epoch: 4241 Loss: 3.1870596408843994  acc_train_error 42.0375%  acc_test_error 50.0%\n",
      "Epoch: 4242 Loss: 3.185580253601074  acc_train_error 42.075%  acc_test_error 50.0%\n",
      "Epoch: 4243 Loss: 3.184100389480591  acc_train_error 42.0875%  acc_test_error 50.0%\n",
      "Epoch: 4244 Loss: 3.1826205253601074  acc_train_error 42.1125%  acc_test_error 50.0%\n",
      "Epoch: 4245 Loss: 3.181140422821045  acc_train_error 42.15%  acc_test_error 50.0%\n",
      "Epoch: 4246 Loss: 3.179663896560669  acc_train_error 42.15%  acc_test_error 50.0%\n",
      "Epoch: 4247 Loss: 3.1781842708587646  acc_train_error 42.2%  acc_test_error 50.0%\n",
      "Epoch: 4248 Loss: 3.1767077445983887  acc_train_error 42.225%  acc_test_error 50.0%\n",
      "Epoch: 4249 Loss: 3.17523193359375  acc_train_error 42.25%  acc_test_error 50.0%\n",
      "Epoch: 4250 Loss: 3.173755168914795  acc_train_error 42.2625%  acc_test_error 50.0%\n",
      "Epoch: 4251 Loss: 3.1722817420959473  acc_train_error 42.2875%  acc_test_error 50.0%\n",
      "Epoch: 4252 Loss: 3.1708052158355713  acc_train_error 42.35%  acc_test_error 50.0%\n",
      "Epoch: 4253 Loss: 3.1693356037139893  acc_train_error 42.3625%  acc_test_error 50.0%\n",
      "Epoch: 4254 Loss: 3.1678597927093506  acc_train_error 42.425%  acc_test_error 50.0%\n",
      "Epoch: 4255 Loss: 3.1663918495178223  acc_train_error 42.475%  acc_test_error 50.0%\n",
      "Epoch: 4256 Loss: 3.164916753768921  acc_train_error 42.5125%  acc_test_error 50.0%\n",
      "Epoch: 4257 Loss: 3.1634464263916016  acc_train_error 42.5375%  acc_test_error 50.0%\n",
      "Epoch: 4258 Loss: 3.1619772911071777  acc_train_error 42.5875%  acc_test_error 50.0%\n",
      "Epoch: 4259 Loss: 3.1605076789855957  acc_train_error 42.6375%  acc_test_error 50.0%\n",
      "Epoch: 4260 Loss: 3.159040689468384  acc_train_error 42.6625%  acc_test_error 50.0%\n",
      "Epoch: 4261 Loss: 3.1575722694396973  acc_train_error 42.7125%  acc_test_error 50.0%\n",
      "Epoch: 4262 Loss: 3.1561052799224854  acc_train_error 42.7375%  acc_test_error 50.0%\n",
      "Epoch: 4263 Loss: 3.1546363830566406  acc_train_error 42.7875%  acc_test_error 50.0%\n",
      "Epoch: 4264 Loss: 3.1531732082366943  acc_train_error 42.8125%  acc_test_error 50.0%\n",
      "Epoch: 4265 Loss: 3.151705741882324  acc_train_error 42.8625%  acc_test_error 50.0%\n",
      "Epoch: 4266 Loss: 3.1502435207366943  acc_train_error 42.8875%  acc_test_error 50.0%\n",
      "Epoch: 4267 Loss: 3.1487767696380615  acc_train_error 42.95%  acc_test_error 50.0%\n",
      "Epoch: 4268 Loss: 3.14731502532959  acc_train_error 42.9875%  acc_test_error 50.0%\n",
      "Epoch: 4269 Loss: 3.1458513736724854  acc_train_error 43.05%  acc_test_error 50.0%\n",
      "Epoch: 4270 Loss: 3.1443910598754883  acc_train_error 43.075%  acc_test_error 50.0%\n",
      "Epoch: 4271 Loss: 3.142927646636963  acc_train_error 43.2125%  acc_test_error 50.0%\n",
      "Epoch: 4272 Loss: 3.1414692401885986  acc_train_error 43.2375%  acc_test_error 50.0%\n",
      "Epoch: 4273 Loss: 3.140007972717285  acc_train_error 43.3%  acc_test_error 50.0%\n",
      "Epoch: 4274 Loss: 3.1385514736175537  acc_train_error 43.325%  acc_test_error 50.0%\n",
      "Epoch: 4275 Loss: 3.1370911598205566  acc_train_error 43.3375%  acc_test_error 50.0%\n",
      "Epoch: 4276 Loss: 3.135633945465088  acc_train_error 43.35%  acc_test_error 50.0%\n",
      "Epoch: 4277 Loss: 3.134176015853882  acc_train_error 43.3875%  acc_test_error 50.0%\n",
      "Epoch: 4278 Loss: 3.1327223777770996  acc_train_error 43.3875%  acc_test_error 50.0%\n",
      "Epoch: 4279 Loss: 3.13126540184021  acc_train_error 43.4%  acc_test_error 50.0%\n",
      "Epoch: 4280 Loss: 3.1298108100891113  acc_train_error 43.425%  acc_test_error 50.0%\n",
      "Epoch: 4281 Loss: 3.128357172012329  acc_train_error 43.45%  acc_test_error 50.0%\n",
      "Epoch: 4282 Loss: 3.1269032955169678  acc_train_error 43.475%  acc_test_error 50.0%\n",
      "Epoch: 4283 Loss: 3.1254501342773438  acc_train_error 43.5%  acc_test_error 50.0%\n",
      "Epoch: 4284 Loss: 3.124000310897827  acc_train_error 43.55%  acc_test_error 50.0%\n",
      "Epoch: 4285 Loss: 3.122546911239624  acc_train_error 43.625%  acc_test_error 50.0%\n",
      "Epoch: 4286 Loss: 3.1210978031158447  acc_train_error 43.675%  acc_test_error 50.0%\n",
      "Epoch: 4287 Loss: 3.1196486949920654  acc_train_error 43.6875%  acc_test_error 50.0%\n",
      "Epoch: 4288 Loss: 3.1182010173797607  acc_train_error 43.6875%  acc_test_error 50.0%\n",
      "Epoch: 4289 Loss: 3.116748332977295  acc_train_error 43.7125%  acc_test_error 50.0%\n",
      "Epoch: 4290 Loss: 3.1153016090393066  acc_train_error 43.7125%  acc_test_error 50.0%\n",
      "Epoch: 4291 Loss: 3.113852024078369  acc_train_error 43.7125%  acc_test_error 50.0%\n",
      "Epoch: 4292 Loss: 3.112403631210327  acc_train_error 43.7125%  acc_test_error 50.0%\n",
      "Epoch: 4293 Loss: 3.1109583377838135  acc_train_error 43.725%  acc_test_error 50.0%\n",
      "Epoch: 4294 Loss: 3.109510898590088  acc_train_error 43.725%  acc_test_error 50.0%\n",
      "Epoch: 4295 Loss: 3.1080641746520996  acc_train_error 43.725%  acc_test_error 50.0%\n",
      "Epoch: 4296 Loss: 3.1066226959228516  acc_train_error 43.7375%  acc_test_error 50.0%\n",
      "Epoch: 4297 Loss: 3.105177879333496  acc_train_error 43.75%  acc_test_error 50.0%\n",
      "Epoch: 4298 Loss: 3.103736162185669  acc_train_error 43.75%  acc_test_error 50.0%\n",
      "Epoch: 4299 Loss: 3.10229229927063  acc_train_error 43.75%  acc_test_error 50.0%\n",
      "Epoch: 4300 Loss: 3.1008529663085938  acc_train_error 43.75%  acc_test_error 50.0%\n",
      "Epoch: 4301 Loss: 3.0994091033935547  acc_train_error 43.7625%  acc_test_error 50.0%\n",
      "Epoch: 4302 Loss: 3.0979714393615723  acc_train_error 43.7625%  acc_test_error 50.0%\n",
      "Epoch: 4303 Loss: 3.0965309143066406  acc_train_error 43.775%  acc_test_error 50.0%\n",
      "Epoch: 4304 Loss: 3.0950939655303955  acc_train_error 43.775%  acc_test_error 50.0%\n",
      "Epoch: 4305 Loss: 3.093653917312622  acc_train_error 43.8%  acc_test_error 50.0%\n",
      "Epoch: 4306 Loss: 3.092219829559326  acc_train_error 43.8%  acc_test_error 50.0%\n",
      "Epoch: 4307 Loss: 3.0907816886901855  acc_train_error 43.8%  acc_test_error 50.0%\n",
      "Epoch: 4308 Loss: 3.0893468856811523  acc_train_error 43.8125%  acc_test_error 50.0%\n",
      "Epoch: 4309 Loss: 3.0879130363464355  acc_train_error 43.8125%  acc_test_error 50.0%\n",
      "Epoch: 4310 Loss: 3.0864782333374023  acc_train_error 43.8125%  acc_test_error 50.0%\n",
      "Epoch: 4311 Loss: 3.085043430328369  acc_train_error 43.8125%  acc_test_error 50.0%\n",
      "Epoch: 4312 Loss: 3.083611488342285  acc_train_error 43.8125%  acc_test_error 50.0%\n",
      "Epoch: 4313 Loss: 3.082179546356201  acc_train_error 43.8125%  acc_test_error 50.0%\n",
      "Epoch: 4314 Loss: 3.080749273300171  acc_train_error 43.825%  acc_test_error 50.0%\n",
      "Epoch: 4315 Loss: 3.0793204307556152  acc_train_error 43.825%  acc_test_error 50.0%\n",
      "Epoch: 4316 Loss: 3.077892303466797  acc_train_error 43.825%  acc_test_error 50.0%\n",
      "Epoch: 4317 Loss: 3.0764622688293457  acc_train_error 43.8375%  acc_test_error 50.0%\n",
      "Epoch: 4318 Loss: 3.0750346183776855  acc_train_error 43.8375%  acc_test_error 50.0%\n",
      "Epoch: 4319 Loss: 3.0736091136932373  acc_train_error 43.8375%  acc_test_error 50.0%\n",
      "Epoch: 4320 Loss: 3.0721800327301025  acc_train_error 43.85%  acc_test_error 50.0%\n",
      "Epoch: 4321 Loss: 3.07075572013855  acc_train_error 43.85%  acc_test_error 50.0%\n",
      "Epoch: 4322 Loss: 3.0693295001983643  acc_train_error 43.8625%  acc_test_error 50.0%\n",
      "Epoch: 4323 Loss: 3.067904233932495  acc_train_error 43.875%  acc_test_error 50.0%\n",
      "Epoch: 4324 Loss: 3.066480875015259  acc_train_error 43.875%  acc_test_error 50.0%\n",
      "Epoch: 4325 Loss: 3.0650570392608643  acc_train_error 43.875%  acc_test_error 50.0%\n",
      "Epoch: 4326 Loss: 3.0636343955993652  acc_train_error 43.875%  acc_test_error 50.0%\n",
      "Epoch: 4327 Loss: 3.0622122287750244  acc_train_error 43.875%  acc_test_error 50.0%\n",
      "Epoch: 4328 Loss: 3.060790777206421  acc_train_error 43.875%  acc_test_error 50.0%\n",
      "Epoch: 4329 Loss: 3.0593698024749756  acc_train_error 43.8875%  acc_test_error 50.0%\n",
      "Epoch: 4330 Loss: 3.0579514503479004  acc_train_error 43.9%  acc_test_error 50.0%\n",
      "Epoch: 4331 Loss: 3.0565338134765625  acc_train_error 43.9125%  acc_test_error 50.0%\n",
      "Epoch: 4332 Loss: 3.055115222930908  acc_train_error 43.925%  acc_test_error 50.0%\n",
      "Epoch: 4333 Loss: 3.0536980628967285  acc_train_error 43.925%  acc_test_error 50.0%\n",
      "Epoch: 4334 Loss: 3.0522820949554443  acc_train_error 43.925%  acc_test_error 50.0%\n",
      "Epoch: 4335 Loss: 3.0508642196655273  acc_train_error 43.9375%  acc_test_error 50.0%\n",
      "Epoch: 4336 Loss: 3.0494470596313477  acc_train_error 43.9375%  acc_test_error 50.0%\n",
      "Epoch: 4337 Loss: 3.0480329990386963  acc_train_error 43.9375%  acc_test_error 50.0%\n",
      "Epoch: 4338 Loss: 3.0466156005859375  acc_train_error 43.9375%  acc_test_error 50.0%\n",
      "Epoch: 4339 Loss: 3.0452005863189697  acc_train_error 43.9375%  acc_test_error 50.0%\n",
      "Epoch: 4340 Loss: 3.043790817260742  acc_train_error 43.9625%  acc_test_error 50.0%\n",
      "Epoch: 4341 Loss: 3.0423762798309326  acc_train_error 43.9625%  acc_test_error 50.0%\n",
      "Epoch: 4342 Loss: 3.0409631729125977  acc_train_error 43.9625%  acc_test_error 50.0%\n",
      "Epoch: 4343 Loss: 3.0395562648773193  acc_train_error 43.9625%  acc_test_error 50.0%\n",
      "Epoch: 4344 Loss: 3.0381507873535156  acc_train_error 43.9625%  acc_test_error 50.0%\n",
      "Epoch: 4345 Loss: 3.036742925643921  acc_train_error 43.9625%  acc_test_error 50.0%\n",
      "Epoch: 4346 Loss: 3.0353379249572754  acc_train_error 43.9625%  acc_test_error 50.0%\n",
      "Epoch: 4347 Loss: 3.0339314937591553  acc_train_error 43.95%  acc_test_error 50.0%\n",
      "Epoch: 4348 Loss: 3.03252911567688  acc_train_error 43.95%  acc_test_error 50.0%\n",
      "Epoch: 4349 Loss: 3.0311248302459717  acc_train_error 43.95%  acc_test_error 50.0%\n",
      "Epoch: 4350 Loss: 3.0297226905822754  acc_train_error 43.95%  acc_test_error 50.0%\n",
      "Epoch: 4351 Loss: 3.0283193588256836  acc_train_error 43.95%  acc_test_error 50.0%\n",
      "Epoch: 4352 Loss: 3.0269196033477783  acc_train_error 43.95%  acc_test_error 50.0%\n",
      "Epoch: 4353 Loss: 3.0255179405212402  acc_train_error 43.95%  acc_test_error 50.0%\n",
      "Epoch: 4354 Loss: 3.0241177082061768  acc_train_error 43.9375%  acc_test_error 50.0%\n",
      "Epoch: 4355 Loss: 3.0227181911468506  acc_train_error 43.9375%  acc_test_error 50.0%\n",
      "Epoch: 4356 Loss: 3.021320343017578  acc_train_error 43.9375%  acc_test_error 50.0%\n",
      "Epoch: 4357 Loss: 3.019922971725464  acc_train_error 43.95%  acc_test_error 50.0%\n",
      "Epoch: 4358 Loss: 3.018527030944824  acc_train_error 43.95%  acc_test_error 50.0%\n",
      "Epoch: 4359 Loss: 3.017129898071289  acc_train_error 43.95%  acc_test_error 50.0%\n",
      "Epoch: 4360 Loss: 3.0157365798950195  acc_train_error 43.9375%  acc_test_error 50.0%\n",
      "Epoch: 4361 Loss: 3.01434063911438  acc_train_error 43.9375%  acc_test_error 50.0%\n",
      "Epoch: 4362 Loss: 3.012946367263794  acc_train_error 43.9375%  acc_test_error 50.0%\n",
      "Epoch: 4363 Loss: 3.0115528106689453  acc_train_error 43.9375%  acc_test_error 50.0%\n",
      "Epoch: 4364 Loss: 3.0101606845855713  acc_train_error 43.9375%  acc_test_error 50.0%\n",
      "Epoch: 4365 Loss: 3.008769989013672  acc_train_error 43.9375%  acc_test_error 50.0%\n",
      "Epoch: 4366 Loss: 3.0073771476745605  acc_train_error 43.9375%  acc_test_error 50.0%\n",
      "Epoch: 4367 Loss: 3.0059874057769775  acc_train_error 43.9375%  acc_test_error 50.0%\n",
      "Epoch: 4368 Loss: 3.004599094390869  acc_train_error 43.9375%  acc_test_error 50.0%\n",
      "Epoch: 4369 Loss: 3.0032076835632324  acc_train_error 43.9375%  acc_test_error 50.0%\n",
      "Epoch: 4370 Loss: 3.0018224716186523  acc_train_error 43.9375%  acc_test_error 50.0%\n",
      "Epoch: 4371 Loss: 3.000433921813965  acc_train_error 43.9375%  acc_test_error 50.0%\n",
      "Epoch: 4372 Loss: 2.999047040939331  acc_train_error 43.9375%  acc_test_error 50.0%\n",
      "Epoch: 4373 Loss: 2.9976613521575928  acc_train_error 43.925%  acc_test_error 50.0%\n",
      "Epoch: 4374 Loss: 2.996276378631592  acc_train_error 43.925%  acc_test_error 50.0%\n",
      "Epoch: 4375 Loss: 2.9948909282684326  acc_train_error 43.925%  acc_test_error 50.0%\n",
      "Epoch: 4376 Loss: 2.9935083389282227  acc_train_error 43.925%  acc_test_error 50.0%\n",
      "Epoch: 4377 Loss: 2.9921252727508545  acc_train_error 43.925%  acc_test_error 50.0%\n",
      "Epoch: 4378 Loss: 2.990743398666382  acc_train_error 43.925%  acc_test_error 50.0%\n",
      "Epoch: 4379 Loss: 2.9893641471862793  acc_train_error 43.925%  acc_test_error 50.0%\n",
      "Epoch: 4380 Loss: 2.987982749938965  acc_train_error 43.925%  acc_test_error 50.0%\n",
      "Epoch: 4381 Loss: 2.986602783203125  acc_train_error 43.925%  acc_test_error 50.0%\n",
      "Epoch: 4382 Loss: 2.985225200653076  acc_train_error 43.925%  acc_test_error 50.0%\n",
      "Epoch: 4383 Loss: 2.983844757080078  acc_train_error 43.925%  acc_test_error 50.0%\n",
      "Epoch: 4384 Loss: 2.982468605041504  acc_train_error 43.925%  acc_test_error 50.0%\n",
      "Epoch: 4385 Loss: 2.9810919761657715  acc_train_error 43.925%  acc_test_error 50.0%\n",
      "Epoch: 4386 Loss: 2.9797158241271973  acc_train_error 43.925%  acc_test_error 50.0%\n",
      "Epoch: 4387 Loss: 2.9783411026000977  acc_train_error 43.925%  acc_test_error 50.0%\n",
      "Epoch: 4388 Loss: 2.9769656658172607  acc_train_error 43.9125%  acc_test_error 50.0%\n",
      "Epoch: 4389 Loss: 2.9755914211273193  acc_train_error 43.9125%  acc_test_error 50.0%\n",
      "Epoch: 4390 Loss: 2.9742181301116943  acc_train_error 43.9125%  acc_test_error 50.0%\n",
      "Epoch: 4391 Loss: 2.9728479385375977  acc_train_error 43.9125%  acc_test_error 50.0%\n",
      "Epoch: 4392 Loss: 2.9714725017547607  acc_train_error 43.9125%  acc_test_error 50.0%\n",
      "Epoch: 4393 Loss: 2.9701039791107178  acc_train_error 43.9125%  acc_test_error 50.0%\n",
      "Epoch: 4394 Loss: 2.9687328338623047  acc_train_error 43.9125%  acc_test_error 50.0%\n",
      "Epoch: 4395 Loss: 2.967365264892578  acc_train_error 43.9125%  acc_test_error 50.0%\n",
      "Epoch: 4396 Loss: 2.965994358062744  acc_train_error 43.9125%  acc_test_error 50.0%\n",
      "Epoch: 4397 Loss: 2.964628219604492  acc_train_error 43.9125%  acc_test_error 50.0%\n",
      "Epoch: 4398 Loss: 2.963259696960449  acc_train_error 43.9125%  acc_test_error 50.0%\n",
      "Epoch: 4399 Loss: 2.961893320083618  acc_train_error 43.925%  acc_test_error 50.0%\n",
      "Epoch: 4400 Loss: 2.9605259895324707  acc_train_error 43.925%  acc_test_error 50.0%\n",
      "Epoch: 4401 Loss: 2.9591617584228516  acc_train_error 43.925%  acc_test_error 50.0%\n",
      "Epoch: 4402 Loss: 2.957796573638916  acc_train_error 43.925%  acc_test_error 50.0%\n",
      "Epoch: 4403 Loss: 2.9564335346221924  acc_train_error 43.9375%  acc_test_error 50.0%\n",
      "Epoch: 4404 Loss: 2.9550671577453613  acc_train_error 43.9375%  acc_test_error 50.0%\n",
      "Epoch: 4405 Loss: 2.953709363937378  acc_train_error 43.9375%  acc_test_error 50.0%\n",
      "Epoch: 4406 Loss: 2.9523444175720215  acc_train_error 43.9375%  acc_test_error 50.0%\n",
      "Epoch: 4407 Loss: 2.9509847164154053  acc_train_error 43.9375%  acc_test_error 50.0%\n",
      "Epoch: 4408 Loss: 2.949622631072998  acc_train_error 43.9375%  acc_test_error 50.0%\n",
      "Epoch: 4409 Loss: 2.948265314102173  acc_train_error 43.9375%  acc_test_error 50.0%\n",
      "Epoch: 4410 Loss: 2.946903705596924  acc_train_error 43.9375%  acc_test_error 50.0%\n",
      "Epoch: 4411 Loss: 2.9455482959747314  acc_train_error 43.9375%  acc_test_error 50.0%\n",
      "Epoch: 4412 Loss: 2.944190740585327  acc_train_error 43.9375%  acc_test_error 50.0%\n",
      "Epoch: 4413 Loss: 2.9428327083587646  acc_train_error 43.9375%  acc_test_error 50.0%\n",
      "Epoch: 4414 Loss: 2.9414772987365723  acc_train_error 43.9375%  acc_test_error 50.0%\n",
      "Epoch: 4415 Loss: 2.9401233196258545  acc_train_error 43.9375%  acc_test_error 50.0%\n",
      "Epoch: 4416 Loss: 2.9387662410736084  acc_train_error 43.9375%  acc_test_error 50.0%\n",
      "Epoch: 4417 Loss: 2.9374125003814697  acc_train_error 43.9375%  acc_test_error 50.0%\n",
      "Epoch: 4418 Loss: 2.9360597133636475  acc_train_error 43.9375%  acc_test_error 50.0%\n",
      "Epoch: 4419 Loss: 2.9347071647644043  acc_train_error 43.9375%  acc_test_error 50.0%\n",
      "Epoch: 4420 Loss: 2.9333550930023193  acc_train_error 43.9375%  acc_test_error 50.0%\n",
      "Epoch: 4421 Loss: 2.932004451751709  acc_train_error 43.9375%  acc_test_error 50.0%\n",
      "Epoch: 4422 Loss: 2.930654525756836  acc_train_error 43.9375%  acc_test_error 50.0%\n",
      "Epoch: 4423 Loss: 2.929307699203491  acc_train_error 43.9375%  acc_test_error 50.0%\n",
      "Epoch: 4424 Loss: 2.9279582500457764  acc_train_error 43.9375%  acc_test_error 50.0%\n",
      "Epoch: 4425 Loss: 2.9266090393066406  acc_train_error 43.9375%  acc_test_error 50.0%\n",
      "Epoch: 4426 Loss: 2.925261974334717  acc_train_error 43.925%  acc_test_error 50.0%\n",
      "Epoch: 4427 Loss: 2.923915386199951  acc_train_error 43.925%  acc_test_error 50.0%\n",
      "Epoch: 4428 Loss: 2.9225687980651855  acc_train_error 43.925%  acc_test_error 50.0%\n",
      "Epoch: 4429 Loss: 2.921226978302002  acc_train_error 43.925%  acc_test_error 50.0%\n",
      "Epoch: 4430 Loss: 2.9198789596557617  acc_train_error 43.925%  acc_test_error 50.0%\n",
      "Epoch: 4431 Loss: 2.9185357093811035  acc_train_error 43.925%  acc_test_error 50.0%\n",
      "Epoch: 4432 Loss: 2.9171907901763916  acc_train_error 43.925%  acc_test_error 50.0%\n",
      "Epoch: 4433 Loss: 2.9158499240875244  acc_train_error 43.925%  acc_test_error 50.0%\n",
      "Epoch: 4434 Loss: 2.9145069122314453  acc_train_error 43.925%  acc_test_error 50.0%\n",
      "Epoch: 4435 Loss: 2.9131669998168945  acc_train_error 43.925%  acc_test_error 50.0%\n",
      "Epoch: 4436 Loss: 2.9118247032165527  acc_train_error 43.925%  acc_test_error 50.0%\n",
      "Epoch: 4437 Loss: 2.9104835987091064  acc_train_error 43.9375%  acc_test_error 50.0%\n",
      "Epoch: 4438 Loss: 2.909146785736084  acc_train_error 43.925%  acc_test_error 50.0%\n",
      "Epoch: 4439 Loss: 2.907805919647217  acc_train_error 43.925%  acc_test_error 50.0%\n",
      "Epoch: 4440 Loss: 2.9064693450927734  acc_train_error 43.925%  acc_test_error 50.0%\n",
      "Epoch: 4441 Loss: 2.9051294326782227  acc_train_error 43.925%  acc_test_error 50.0%\n",
      "Epoch: 4442 Loss: 2.9037954807281494  acc_train_error 43.925%  acc_test_error 50.0%\n",
      "Epoch: 4443 Loss: 2.9024600982666016  acc_train_error 43.925%  acc_test_error 50.0%\n",
      "Epoch: 4444 Loss: 2.90112566947937  acc_train_error 43.925%  acc_test_error 50.0%\n",
      "Epoch: 4445 Loss: 2.8997902870178223  acc_train_error 43.925%  acc_test_error 50.0%\n",
      "Epoch: 4446 Loss: 2.898455858230591  acc_train_error 43.925%  acc_test_error 50.0%\n",
      "Epoch: 4447 Loss: 2.8971245288848877  acc_train_error 43.925%  acc_test_error 50.0%\n",
      "Epoch: 4448 Loss: 2.895789623260498  acc_train_error 43.925%  acc_test_error 50.0%\n",
      "Epoch: 4449 Loss: 2.894458770751953  acc_train_error 43.9375%  acc_test_error 50.0%\n",
      "Epoch: 4450 Loss: 2.89312481880188  acc_train_error 43.9375%  acc_test_error 50.0%\n",
      "Epoch: 4451 Loss: 2.8917951583862305  acc_train_error 43.9625%  acc_test_error 50.0%\n",
      "Epoch: 4452 Loss: 2.8904640674591064  acc_train_error 43.95%  acc_test_error 50.0%\n",
      "Epoch: 4453 Loss: 2.8891329765319824  acc_train_error 43.9625%  acc_test_error 50.0%\n",
      "Epoch: 4454 Loss: 2.887805700302124  acc_train_error 43.975%  acc_test_error 50.0%\n",
      "Epoch: 4455 Loss: 2.886477470397949  acc_train_error 43.975%  acc_test_error 50.0%\n",
      "Epoch: 4456 Loss: 2.8851499557495117  acc_train_error 43.975%  acc_test_error 50.0%\n",
      "Epoch: 4457 Loss: 2.8838236331939697  acc_train_error 43.975%  acc_test_error 50.0%\n",
      "Epoch: 4458 Loss: 2.8824968338012695  acc_train_error 43.9625%  acc_test_error 50.0%\n",
      "Epoch: 4459 Loss: 2.8811709880828857  acc_train_error 43.975%  acc_test_error 50.0%\n",
      "Epoch: 4460 Loss: 2.8798482418060303  acc_train_error 43.975%  acc_test_error 50.0%\n",
      "Epoch: 4461 Loss: 2.8785204887390137  acc_train_error 43.975%  acc_test_error 50.0%\n",
      "Epoch: 4462 Loss: 2.877199411392212  acc_train_error 43.975%  acc_test_error 50.0%\n",
      "Epoch: 4463 Loss: 2.875875949859619  acc_train_error 43.975%  acc_test_error 50.0%\n",
      "Epoch: 4464 Loss: 2.8745534420013428  acc_train_error 43.975%  acc_test_error 50.0%\n",
      "Epoch: 4465 Loss: 2.873232364654541  acc_train_error 43.975%  acc_test_error 50.0%\n",
      "Epoch: 4466 Loss: 2.8719122409820557  acc_train_error 43.975%  acc_test_error 50.0%\n",
      "Epoch: 4467 Loss: 2.8705894947052  acc_train_error 43.975%  acc_test_error 50.0%\n",
      "Epoch: 4468 Loss: 2.869271993637085  acc_train_error 43.975%  acc_test_error 50.0%\n",
      "Epoch: 4469 Loss: 2.867950677871704  acc_train_error 43.975%  acc_test_error 50.0%\n",
      "Epoch: 4470 Loss: 2.866633653640747  acc_train_error 43.975%  acc_test_error 50.0%\n",
      "Epoch: 4471 Loss: 2.8653159141540527  acc_train_error 43.975%  acc_test_error 50.0%\n",
      "Epoch: 4472 Loss: 2.863999366760254  acc_train_error 43.975%  acc_test_error 50.0%\n",
      "Epoch: 4473 Loss: 2.8626821041107178  acc_train_error 43.975%  acc_test_error 50.0%\n",
      "Epoch: 4474 Loss: 2.861367702484131  acc_train_error 43.975%  acc_test_error 50.0%\n",
      "Epoch: 4475 Loss: 2.8600523471832275  acc_train_error 43.975%  acc_test_error 50.0%\n",
      "Epoch: 4476 Loss: 2.858736991882324  acc_train_error 43.975%  acc_test_error 50.0%\n",
      "Epoch: 4477 Loss: 2.8574254512786865  acc_train_error 43.975%  acc_test_error 50.0%\n",
      "Epoch: 4478 Loss: 2.856111764907837  acc_train_error 43.975%  acc_test_error 50.0%\n",
      "Epoch: 4479 Loss: 2.854799270629883  acc_train_error 43.975%  acc_test_error 50.0%\n",
      "Epoch: 4480 Loss: 2.853489398956299  acc_train_error 43.975%  acc_test_error 50.0%\n",
      "Epoch: 4481 Loss: 2.8521790504455566  acc_train_error 43.975%  acc_test_error 50.0%\n",
      "Epoch: 4482 Loss: 2.8508663177490234  acc_train_error 43.975%  acc_test_error 50.0%\n",
      "Epoch: 4483 Loss: 2.8495564460754395  acc_train_error 43.9875%  acc_test_error 50.0%\n",
      "Epoch: 4484 Loss: 2.8482494354248047  acc_train_error 43.9875%  acc_test_error 50.0%\n",
      "Epoch: 4485 Loss: 2.846940279006958  acc_train_error 43.9875%  acc_test_error 50.0%\n",
      "Epoch: 4486 Loss: 2.8456335067749023  acc_train_error 43.9875%  acc_test_error 50.0%\n",
      "Epoch: 4487 Loss: 2.8443243503570557  acc_train_error 43.9875%  acc_test_error 50.0%\n",
      "Epoch: 4488 Loss: 2.8430216312408447  acc_train_error 43.9875%  acc_test_error 50.0%\n",
      "Epoch: 4489 Loss: 2.841717004776001  acc_train_error 43.975%  acc_test_error 50.0%\n",
      "Epoch: 4490 Loss: 2.840412139892578  acc_train_error 43.975%  acc_test_error 50.0%\n",
      "Epoch: 4491 Loss: 2.8391103744506836  acc_train_error 43.975%  acc_test_error 50.0%\n",
      "Epoch: 4492 Loss: 2.8378071784973145  acc_train_error 43.975%  acc_test_error 50.0%\n",
      "Epoch: 4493 Loss: 2.836503744125366  acc_train_error 43.975%  acc_test_error 50.0%\n",
      "Epoch: 4494 Loss: 2.8352041244506836  acc_train_error 43.975%  acc_test_error 50.0%\n",
      "Epoch: 4495 Loss: 2.8339016437530518  acc_train_error 43.9625%  acc_test_error 50.0%\n",
      "Epoch: 4496 Loss: 2.832602024078369  acc_train_error 43.9625%  acc_test_error 50.0%\n",
      "Epoch: 4497 Loss: 2.8313043117523193  acc_train_error 43.9625%  acc_test_error 50.0%\n",
      "Epoch: 4498 Loss: 2.8300042152404785  acc_train_error 43.9625%  acc_test_error 50.0%\n",
      "Epoch: 4499 Loss: 2.828707456588745  acc_train_error 43.95%  acc_test_error 50.0%\n",
      "Epoch: 4500 Loss: 2.8274085521698  acc_train_error 43.95%  acc_test_error 50.0%\n",
      "Epoch: 4501 Loss: 2.826112985610962  acc_train_error 43.95%  acc_test_error 50.0%\n",
      "Epoch: 4502 Loss: 2.8248181343078613  acc_train_error 43.95%  acc_test_error 50.0%\n",
      "Epoch: 4503 Loss: 2.823521137237549  acc_train_error 43.95%  acc_test_error 50.0%\n",
      "Epoch: 4504 Loss: 2.8222270011901855  acc_train_error 43.95%  acc_test_error 50.0%\n",
      "Epoch: 4505 Loss: 2.8209335803985596  acc_train_error 43.95%  acc_test_error 50.0%\n",
      "Epoch: 4506 Loss: 2.819640874862671  acc_train_error 43.95%  acc_test_error 50.0%\n",
      "Epoch: 4507 Loss: 2.8183488845825195  acc_train_error 43.95%  acc_test_error 50.0%\n",
      "Epoch: 4508 Loss: 2.817054271697998  acc_train_error 43.95%  acc_test_error 50.0%\n",
      "Epoch: 4509 Loss: 2.815762758255005  acc_train_error 43.95%  acc_test_error 50.0%\n",
      "Epoch: 4510 Loss: 2.814473867416382  acc_train_error 43.95%  acc_test_error 50.0%\n",
      "Epoch: 4511 Loss: 2.813183069229126  acc_train_error 43.95%  acc_test_error 50.0%\n",
      "Epoch: 4512 Loss: 2.81189227104187  acc_train_error 43.95%  acc_test_error 50.0%\n",
      "Epoch: 4513 Loss: 2.810603380203247  acc_train_error 43.95%  acc_test_error 50.0%\n",
      "Epoch: 4514 Loss: 2.8093161582946777  acc_train_error 43.95%  acc_test_error 50.0%\n",
      "Epoch: 4515 Loss: 2.80802583694458  acc_train_error 43.95%  acc_test_error 50.0%\n",
      "Epoch: 4516 Loss: 2.8067383766174316  acc_train_error 43.95%  acc_test_error 50.0%\n",
      "Epoch: 4517 Loss: 2.8054535388946533  acc_train_error 43.95%  acc_test_error 50.0%\n",
      "Epoch: 4518 Loss: 2.8041653633117676  acc_train_error 43.95%  acc_test_error 50.0%\n",
      "Epoch: 4519 Loss: 2.802880048751831  acc_train_error 43.95%  acc_test_error 50.0%\n",
      "Epoch: 4520 Loss: 2.8015942573547363  acc_train_error 43.95%  acc_test_error 50.0%\n",
      "Epoch: 4521 Loss: 2.8003106117248535  acc_train_error 43.9625%  acc_test_error 50.0%\n",
      "Epoch: 4522 Loss: 2.7990283966064453  acc_train_error 43.9625%  acc_test_error 50.0%\n",
      "Epoch: 4523 Loss: 2.7977454662323  acc_train_error 43.95%  acc_test_error 50.0%\n",
      "Epoch: 4524 Loss: 2.7964630126953125  acc_train_error 43.9625%  acc_test_error 50.0%\n",
      "Epoch: 4525 Loss: 2.7951831817626953  acc_train_error 43.95%  acc_test_error 50.0%\n",
      "Epoch: 4526 Loss: 2.793900489807129  acc_train_error 43.9625%  acc_test_error 50.0%\n",
      "Epoch: 4527 Loss: 2.7926242351531982  acc_train_error 43.95%  acc_test_error 50.0%\n",
      "Epoch: 4528 Loss: 2.791341543197632  acc_train_error 43.95%  acc_test_error 50.0%\n",
      "Epoch: 4529 Loss: 2.7900619506835938  acc_train_error 43.95%  acc_test_error 50.0%\n",
      "Epoch: 4530 Loss: 2.7887840270996094  acc_train_error 43.95%  acc_test_error 50.0%\n",
      "Epoch: 4531 Loss: 2.7875049114227295  acc_train_error 43.9625%  acc_test_error 50.0%\n",
      "Epoch: 4532 Loss: 2.7862279415130615  acc_train_error 43.95%  acc_test_error 50.0%\n",
      "Epoch: 4533 Loss: 2.7849528789520264  acc_train_error 43.95%  acc_test_error 50.0%\n",
      "Epoch: 4534 Loss: 2.783674716949463  acc_train_error 43.9625%  acc_test_error 50.0%\n",
      "Epoch: 4535 Loss: 2.7824044227600098  acc_train_error 43.95%  acc_test_error 50.0%\n",
      "Epoch: 4536 Loss: 2.7811248302459717  acc_train_error 43.95%  acc_test_error 50.0%\n",
      "Epoch: 4537 Loss: 2.779855251312256  acc_train_error 43.95%  acc_test_error 50.0%\n",
      "Epoch: 4538 Loss: 2.778578996658325  acc_train_error 43.95%  acc_test_error 50.0%\n",
      "Epoch: 4539 Loss: 2.7773075103759766  acc_train_error 43.975%  acc_test_error 50.0%\n",
      "Epoch: 4540 Loss: 2.776036262512207  acc_train_error 43.95%  acc_test_error 50.0%\n",
      "Epoch: 4541 Loss: 2.7747669219970703  acc_train_error 43.95%  acc_test_error 50.0%\n",
      "Epoch: 4542 Loss: 2.7734925746917725  acc_train_error 43.975%  acc_test_error 50.0%\n",
      "Epoch: 4543 Loss: 2.7722253799438477  acc_train_error 43.9375%  acc_test_error 50.0%\n",
      "Epoch: 4544 Loss: 2.770953893661499  acc_train_error 43.975%  acc_test_error 50.0%\n",
      "Epoch: 4545 Loss: 2.769688129425049  acc_train_error 43.95%  acc_test_error 50.0%\n",
      "Epoch: 4546 Loss: 2.7684195041656494  acc_train_error 43.95%  acc_test_error 50.0%\n",
      "Epoch: 4547 Loss: 2.76715087890625  acc_train_error 43.95%  acc_test_error 50.0%\n",
      "Epoch: 4548 Loss: 2.765883445739746  acc_train_error 43.9625%  acc_test_error 50.0%\n",
      "Epoch: 4549 Loss: 2.764620542526245  acc_train_error 43.95%  acc_test_error 50.0%\n",
      "Epoch: 4550 Loss: 2.763349771499634  acc_train_error 43.9625%  acc_test_error 50.0%\n",
      "Epoch: 4551 Loss: 2.762087345123291  acc_train_error 43.95%  acc_test_error 50.0%\n",
      "Epoch: 4552 Loss: 2.7608234882354736  acc_train_error 43.9625%  acc_test_error 50.0%\n",
      "Epoch: 4553 Loss: 2.7595598697662354  acc_train_error 43.95%  acc_test_error 50.0%\n",
      "Epoch: 4554 Loss: 2.7582950592041016  acc_train_error 43.95%  acc_test_error 50.0%\n",
      "Epoch: 4555 Loss: 2.757033109664917  acc_train_error 43.9625%  acc_test_error 50.0%\n",
      "Epoch: 4556 Loss: 2.7557730674743652  acc_train_error 43.95%  acc_test_error 50.0%\n",
      "Epoch: 4557 Loss: 2.754507064819336  acc_train_error 43.9625%  acc_test_error 50.0%\n",
      "Epoch: 4558 Loss: 2.753249168395996  acc_train_error 43.9625%  acc_test_error 50.0%\n",
      "Epoch: 4559 Loss: 2.7519900798797607  acc_train_error 43.9625%  acc_test_error 50.0%\n",
      "Epoch: 4560 Loss: 2.750730276107788  acc_train_error 43.95%  acc_test_error 50.0%\n",
      "Epoch: 4561 Loss: 2.7494680881500244  acc_train_error 43.9625%  acc_test_error 50.0%\n",
      "Epoch: 4562 Loss: 2.748213768005371  acc_train_error 43.9625%  acc_test_error 50.0%\n",
      "Epoch: 4563 Loss: 2.746955394744873  acc_train_error 43.9625%  acc_test_error 50.0%\n",
      "Epoch: 4564 Loss: 2.7456955909729004  acc_train_error 43.9625%  acc_test_error 50.0%\n",
      "Epoch: 4565 Loss: 2.7444393634796143  acc_train_error 43.9625%  acc_test_error 50.0%\n",
      "Epoch: 4566 Loss: 2.743185520172119  acc_train_error 43.9625%  acc_test_error 50.0%\n",
      "Epoch: 4567 Loss: 2.741926670074463  acc_train_error 43.9625%  acc_test_error 50.0%\n",
      "Epoch: 4568 Loss: 2.740671396255493  acc_train_error 43.9625%  acc_test_error 50.0%\n",
      "Epoch: 4569 Loss: 2.7394192218780518  acc_train_error 43.9625%  acc_test_error 50.0%\n",
      "Epoch: 4570 Loss: 2.7381632328033447  acc_train_error 43.9625%  acc_test_error 50.0%\n",
      "Epoch: 4571 Loss: 2.7369117736816406  acc_train_error 43.9625%  acc_test_error 50.0%\n",
      "Epoch: 4572 Loss: 2.735657215118408  acc_train_error 43.9625%  acc_test_error 50.0%\n",
      "Epoch: 4573 Loss: 2.734405040740967  acc_train_error 43.9625%  acc_test_error 50.0%\n",
      "Epoch: 4574 Loss: 2.7331531047821045  acc_train_error 43.9625%  acc_test_error 50.0%\n",
      "Epoch: 4575 Loss: 2.7319018840789795  acc_train_error 43.9625%  acc_test_error 50.0%\n",
      "Epoch: 4576 Loss: 2.7306509017944336  acc_train_error 43.9625%  acc_test_error 50.0%\n",
      "Epoch: 4577 Loss: 2.7294020652770996  acc_train_error 43.9625%  acc_test_error 50.0%\n",
      "Epoch: 4578 Loss: 2.72815203666687  acc_train_error 43.9625%  acc_test_error 50.0%\n",
      "Epoch: 4579 Loss: 2.726902723312378  acc_train_error 43.9625%  acc_test_error 50.0%\n",
      "Epoch: 4580 Loss: 2.725656032562256  acc_train_error 43.9625%  acc_test_error 50.0%\n",
      "Epoch: 4581 Loss: 2.724407196044922  acc_train_error 43.9625%  acc_test_error 50.0%\n",
      "Epoch: 4582 Loss: 2.7231600284576416  acc_train_error 43.9625%  acc_test_error 50.0%\n",
      "Epoch: 4583 Loss: 2.7219133377075195  acc_train_error 43.9625%  acc_test_error 50.0%\n",
      "Epoch: 4584 Loss: 2.7206673622131348  acc_train_error 43.9625%  acc_test_error 50.0%\n",
      "Epoch: 4585 Loss: 2.719420909881592  acc_train_error 44.0%  acc_test_error 50.0%\n",
      "Epoch: 4586 Loss: 2.7181782722473145  acc_train_error 44.0%  acc_test_error 50.0%\n",
      "Epoch: 4587 Loss: 2.716935873031616  acc_train_error 44.0%  acc_test_error 50.0%\n",
      "Epoch: 4588 Loss: 2.715693235397339  acc_train_error 44.0%  acc_test_error 50.0%\n",
      "Epoch: 4589 Loss: 2.714451313018799  acc_train_error 44.0%  acc_test_error 50.0%\n",
      "Epoch: 4590 Loss: 2.7132067680358887  acc_train_error 44.0%  acc_test_error 50.0%\n",
      "Epoch: 4591 Loss: 2.711966037750244  acc_train_error 44.0%  acc_test_error 50.0%\n",
      "Epoch: 4592 Loss: 2.710726737976074  acc_train_error 44.0%  acc_test_error 50.0%\n",
      "Epoch: 4593 Loss: 2.709484577178955  acc_train_error 44.0%  acc_test_error 50.0%\n",
      "Epoch: 4594 Loss: 2.7082464694976807  acc_train_error 44.0%  acc_test_error 50.0%\n",
      "Epoch: 4595 Loss: 2.707007646560669  acc_train_error 44.0%  acc_test_error 50.0%\n",
      "Epoch: 4596 Loss: 2.70576548576355  acc_train_error 44.0125%  acc_test_error 50.0%\n",
      "Epoch: 4597 Loss: 2.704529285430908  acc_train_error 44.0125%  acc_test_error 50.0%\n",
      "Epoch: 4598 Loss: 2.7032904624938965  acc_train_error 44.0125%  acc_test_error 50.0%\n",
      "Epoch: 4599 Loss: 2.7020554542541504  acc_train_error 44.0125%  acc_test_error 50.0%\n",
      "Epoch: 4600 Loss: 2.700819730758667  acc_train_error 44.0125%  acc_test_error 50.0%\n",
      "Epoch: 4601 Loss: 2.6995937824249268  acc_train_error 44.0125%  acc_test_error 50.0%\n",
      "Epoch: 4602 Loss: 2.698347806930542  acc_train_error 44.025%  acc_test_error 50.0%\n",
      "Epoch: 4603 Loss: 2.697115898132324  acc_train_error 44.025%  acc_test_error 50.0%\n",
      "Epoch: 4604 Loss: 2.6958796977996826  acc_train_error 44.0375%  acc_test_error 50.0%\n",
      "Epoch: 4605 Loss: 2.694648027420044  acc_train_error 44.0375%  acc_test_error 50.0%\n",
      "Epoch: 4606 Loss: 2.693413734436035  acc_train_error 44.0375%  acc_test_error 50.0%\n",
      "Epoch: 4607 Loss: 2.6921849250793457  acc_train_error 44.0375%  acc_test_error 50.0%\n",
      "Epoch: 4608 Loss: 2.690950632095337  acc_train_error 44.0375%  acc_test_error 50.0%\n",
      "Epoch: 4609 Loss: 2.6897199153900146  acc_train_error 44.0375%  acc_test_error 50.0%\n",
      "Epoch: 4610 Loss: 2.6884894371032715  acc_train_error 44.05%  acc_test_error 50.0%\n",
      "Epoch: 4611 Loss: 2.687262535095215  acc_train_error 44.05%  acc_test_error 50.0%\n",
      "Epoch: 4612 Loss: 2.6860313415527344  acc_train_error 44.05%  acc_test_error 50.0%\n",
      "Epoch: 4613 Loss: 2.684802293777466  acc_train_error 44.05%  acc_test_error 50.0%\n",
      "Epoch: 4614 Loss: 2.6835758686065674  acc_train_error 44.05%  acc_test_error 50.0%\n",
      "Epoch: 4615 Loss: 2.682347297668457  acc_train_error 44.0625%  acc_test_error 50.0%\n",
      "Epoch: 4616 Loss: 2.681122064590454  acc_train_error 44.05%  acc_test_error 50.0%\n",
      "Epoch: 4617 Loss: 2.6798934936523438  acc_train_error 44.0625%  acc_test_error 50.0%\n",
      "Epoch: 4618 Loss: 2.678668260574341  acc_train_error 44.0625%  acc_test_error 50.0%\n",
      "Epoch: 4619 Loss: 2.677443742752075  acc_train_error 44.075%  acc_test_error 50.0%\n",
      "Epoch: 4620 Loss: 2.6762213706970215  acc_train_error 44.075%  acc_test_error 50.0%\n",
      "Epoch: 4621 Loss: 2.6749982833862305  acc_train_error 44.0875%  acc_test_error 50.0%\n",
      "Epoch: 4622 Loss: 2.6737732887268066  acc_train_error 44.0875%  acc_test_error 50.0%\n",
      "Epoch: 4623 Loss: 2.672553539276123  acc_train_error 44.0875%  acc_test_error 50.0%\n",
      "Epoch: 4624 Loss: 2.6713297367095947  acc_train_error 44.1125%  acc_test_error 50.0%\n",
      "Epoch: 4625 Loss: 2.6701126098632812  acc_train_error 44.1125%  acc_test_error 50.0%\n",
      "Epoch: 4626 Loss: 2.6688852310180664  acc_train_error 44.1125%  acc_test_error 50.0%\n",
      "Epoch: 4627 Loss: 2.667665958404541  acc_train_error 44.1125%  acc_test_error 50.0%\n",
      "Epoch: 4628 Loss: 2.6664512157440186  acc_train_error 44.1125%  acc_test_error 50.0%\n",
      "Epoch: 4629 Loss: 2.6652302742004395  acc_train_error 44.1125%  acc_test_error 50.0%\n",
      "Epoch: 4630 Loss: 2.664010524749756  acc_train_error 44.1125%  acc_test_error 50.0%\n",
      "Epoch: 4631 Loss: 2.6627910137176514  acc_train_error 44.125%  acc_test_error 50.0%\n",
      "Epoch: 4632 Loss: 2.6615865230560303  acc_train_error 44.125%  acc_test_error 50.0%\n",
      "Epoch: 4633 Loss: 2.6603612899780273  acc_train_error 44.125%  acc_test_error 50.0%\n",
      "Epoch: 4634 Loss: 2.6591427326202393  acc_train_error 44.125%  acc_test_error 50.0%\n",
      "Epoch: 4635 Loss: 2.6579296588897705  acc_train_error 44.125%  acc_test_error 50.0%\n",
      "Epoch: 4636 Loss: 2.6567161083221436  acc_train_error 44.1375%  acc_test_error 50.0%\n",
      "Epoch: 4637 Loss: 2.655500650405884  acc_train_error 44.1375%  acc_test_error 50.0%\n",
      "Epoch: 4638 Loss: 2.654287815093994  acc_train_error 44.1375%  acc_test_error 50.0%\n",
      "Epoch: 4639 Loss: 2.653074264526367  acc_train_error 44.1375%  acc_test_error 50.0%\n",
      "Epoch: 4640 Loss: 2.651862144470215  acc_train_error 44.1625%  acc_test_error 50.0%\n",
      "Epoch: 4641 Loss: 2.6506505012512207  acc_train_error 44.1625%  acc_test_error 50.0%\n",
      "Epoch: 4642 Loss: 2.6494405269622803  acc_train_error 44.175%  acc_test_error 50.0%\n",
      "Epoch: 4643 Loss: 2.6482245922088623  acc_train_error 44.175%  acc_test_error 50.0%\n",
      "Epoch: 4644 Loss: 2.6470141410827637  acc_train_error 44.1875%  acc_test_error 50.0%\n",
      "Epoch: 4645 Loss: 2.6458070278167725  acc_train_error 44.1875%  acc_test_error 50.0%\n",
      "Epoch: 4646 Loss: 2.644596576690674  acc_train_error 44.1875%  acc_test_error 50.0%\n",
      "Epoch: 4647 Loss: 2.643386125564575  acc_train_error 44.2%  acc_test_error 50.0%\n",
      "Epoch: 4648 Loss: 2.6421799659729004  acc_train_error 44.2%  acc_test_error 50.0%\n",
      "Epoch: 4649 Loss: 2.6409740447998047  acc_train_error 44.2%  acc_test_error 50.0%\n",
      "Epoch: 4650 Loss: 2.6397619247436523  acc_train_error 44.2%  acc_test_error 50.0%\n",
      "Epoch: 4651 Loss: 2.6385581493377686  acc_train_error 44.2%  acc_test_error 50.0%\n",
      "Epoch: 4652 Loss: 2.637352705001831  acc_train_error 44.2125%  acc_test_error 50.0%\n",
      "Epoch: 4653 Loss: 2.63614559173584  acc_train_error 44.2125%  acc_test_error 50.0%\n",
      "Epoch: 4654 Loss: 2.634942054748535  acc_train_error 44.2125%  acc_test_error 50.0%\n",
      "Epoch: 4655 Loss: 2.633733034133911  acc_train_error 44.2125%  acc_test_error 50.0%\n",
      "Epoch: 4656 Loss: 2.632533073425293  acc_train_error 44.2375%  acc_test_error 50.0%\n",
      "Epoch: 4657 Loss: 2.6313304901123047  acc_train_error 44.25%  acc_test_error 50.0%\n",
      "Epoch: 4658 Loss: 2.630125045776367  acc_train_error 44.25%  acc_test_error 50.0%\n",
      "Epoch: 4659 Loss: 2.62892484664917  acc_train_error 44.2625%  acc_test_error 50.0%\n",
      "Epoch: 4660 Loss: 2.627720832824707  acc_train_error 44.2625%  acc_test_error 50.0%\n",
      "Epoch: 4661 Loss: 2.626519203186035  acc_train_error 44.275%  acc_test_error 50.0%\n",
      "Epoch: 4662 Loss: 2.6253302097320557  acc_train_error 44.275%  acc_test_error 50.0%\n",
      "Epoch: 4663 Loss: 2.6241190433502197  acc_train_error 44.275%  acc_test_error 50.0%\n",
      "Epoch: 4664 Loss: 2.622921943664551  acc_train_error 44.2875%  acc_test_error 50.0%\n",
      "Epoch: 4665 Loss: 2.621725559234619  acc_train_error 44.2875%  acc_test_error 50.0%\n",
      "Epoch: 4666 Loss: 2.62052321434021  acc_train_error 44.2875%  acc_test_error 50.0%\n",
      "Epoch: 4667 Loss: 2.6193273067474365  acc_train_error 44.2875%  acc_test_error 50.0%\n",
      "Epoch: 4668 Loss: 2.618130683898926  acc_train_error 44.3%  acc_test_error 50.0%\n",
      "Epoch: 4669 Loss: 2.616934061050415  acc_train_error 44.3%  acc_test_error 50.0%\n",
      "Epoch: 4670 Loss: 2.6157379150390625  acc_train_error 44.325%  acc_test_error 50.0%\n",
      "Epoch: 4671 Loss: 2.6145405769348145  acc_train_error 44.325%  acc_test_error 50.0%\n",
      "Epoch: 4672 Loss: 2.6133458614349365  acc_train_error 44.3375%  acc_test_error 50.0%\n",
      "Epoch: 4673 Loss: 2.6121535301208496  acc_train_error 44.35%  acc_test_error 50.0%\n",
      "Epoch: 4674 Loss: 2.610960006713867  acc_train_error 44.35%  acc_test_error 50.0%\n",
      "Epoch: 4675 Loss: 2.6097664833068848  acc_train_error 44.3625%  acc_test_error 50.0%\n",
      "Epoch: 4676 Loss: 2.6085727214813232  acc_train_error 44.3625%  acc_test_error 50.0%\n",
      "Epoch: 4677 Loss: 2.6073789596557617  acc_train_error 44.3625%  acc_test_error 50.0%\n",
      "Epoch: 4678 Loss: 2.606189727783203  acc_train_error 44.375%  acc_test_error 50.0%\n",
      "Epoch: 4679 Loss: 2.6049981117248535  acc_train_error 44.375%  acc_test_error 50.0%\n",
      "Epoch: 4680 Loss: 2.603808641433716  acc_train_error 44.375%  acc_test_error 50.0%\n",
      "Epoch: 4681 Loss: 2.6026289463043213  acc_train_error 44.375%  acc_test_error 50.0%\n",
      "Epoch: 4682 Loss: 2.6014304161071777  acc_train_error 44.3875%  acc_test_error 50.0%\n",
      "Epoch: 4683 Loss: 2.600242853164673  acc_train_error 44.4%  acc_test_error 50.0%\n",
      "Epoch: 4684 Loss: 2.599057674407959  acc_train_error 44.4%  acc_test_error 50.0%\n",
      "Epoch: 4685 Loss: 2.5978691577911377  acc_train_error 44.3875%  acc_test_error 50.0%\n",
      "Epoch: 4686 Loss: 2.5966835021972656  acc_train_error 44.3875%  acc_test_error 50.0%\n",
      "Epoch: 4687 Loss: 2.5954995155334473  acc_train_error 44.3875%  acc_test_error 50.0%\n",
      "Epoch: 4688 Loss: 2.5943100452423096  acc_train_error 44.375%  acc_test_error 50.0%\n",
      "Epoch: 4689 Loss: 2.5931308269500732  acc_train_error 44.3875%  acc_test_error 50.0%\n",
      "Epoch: 4690 Loss: 2.5919458866119385  acc_train_error 44.3875%  acc_test_error 50.0%\n",
      "Epoch: 4691 Loss: 2.590764284133911  acc_train_error 44.3875%  acc_test_error 50.0%\n",
      "Epoch: 4692 Loss: 2.589578151702881  acc_train_error 44.375%  acc_test_error 50.0%\n",
      "Epoch: 4693 Loss: 2.588397264480591  acc_train_error 44.3875%  acc_test_error 50.0%\n",
      "Epoch: 4694 Loss: 2.587216377258301  acc_train_error 44.3875%  acc_test_error 50.0%\n",
      "Epoch: 4695 Loss: 2.5860347747802734  acc_train_error 44.375%  acc_test_error 50.0%\n",
      "Epoch: 4696 Loss: 2.584853410720825  acc_train_error 44.375%  acc_test_error 50.0%\n",
      "Epoch: 4697 Loss: 2.5836732387542725  acc_train_error 44.375%  acc_test_error 50.0%\n",
      "Epoch: 4698 Loss: 2.5824954509735107  acc_train_error 44.375%  acc_test_error 50.0%\n",
      "Epoch: 4699 Loss: 2.5813159942626953  acc_train_error 44.3875%  acc_test_error 50.0%\n",
      "Epoch: 4700 Loss: 2.580134391784668  acc_train_error 44.375%  acc_test_error 50.0%\n",
      "Epoch: 4701 Loss: 2.578958511352539  acc_train_error 44.3875%  acc_test_error 50.0%\n",
      "Epoch: 4702 Loss: 2.5777814388275146  acc_train_error 44.375%  acc_test_error 50.0%\n",
      "Epoch: 4703 Loss: 2.5766055583953857  acc_train_error 44.3875%  acc_test_error 50.0%\n",
      "Epoch: 4704 Loss: 2.575425863265991  acc_train_error 44.3875%  acc_test_error 50.0%\n",
      "Epoch: 4705 Loss: 2.5742504596710205  acc_train_error 44.3875%  acc_test_error 50.0%\n",
      "Epoch: 4706 Loss: 2.57307767868042  acc_train_error 44.3875%  acc_test_error 50.0%\n",
      "Epoch: 4707 Loss: 2.571913957595825  acc_train_error 44.3875%  acc_test_error 50.0%\n",
      "Epoch: 4708 Loss: 2.5707268714904785  acc_train_error 44.3875%  acc_test_error 50.0%\n",
      "Epoch: 4709 Loss: 2.5695557594299316  acc_train_error 44.4%  acc_test_error 50.0%\n",
      "Epoch: 4710 Loss: 2.5683820247650146  acc_train_error 44.4%  acc_test_error 50.0%\n",
      "Epoch: 4711 Loss: 2.567211866378784  acc_train_error 44.3875%  acc_test_error 50.0%\n",
      "Epoch: 4712 Loss: 2.566037893295288  acc_train_error 44.3875%  acc_test_error 50.0%\n",
      "Epoch: 4713 Loss: 2.5648670196533203  acc_train_error 44.3875%  acc_test_error 50.0%\n",
      "Epoch: 4714 Loss: 2.563694715499878  acc_train_error 44.3875%  acc_test_error 50.0%\n",
      "Epoch: 4715 Loss: 2.562523365020752  acc_train_error 44.3875%  acc_test_error 50.0%\n",
      "Epoch: 4716 Loss: 2.5613558292388916  acc_train_error 44.4%  acc_test_error 50.0%\n",
      "Epoch: 4717 Loss: 2.5601868629455566  acc_train_error 44.4%  acc_test_error 50.0%\n",
      "Epoch: 4718 Loss: 2.559015989303589  acc_train_error 44.4%  acc_test_error 50.0%\n",
      "Epoch: 4719 Loss: 2.5578482151031494  acc_train_error 44.4%  acc_test_error 50.0%\n",
      "Epoch: 4720 Loss: 2.5566816329956055  acc_train_error 44.4%  acc_test_error 50.0%\n",
      "Epoch: 4721 Loss: 2.5555131435394287  acc_train_error 44.4%  acc_test_error 50.0%\n",
      "Epoch: 4722 Loss: 2.5543463230133057  acc_train_error 44.4%  acc_test_error 50.0%\n",
      "Epoch: 4723 Loss: 2.553182601928711  acc_train_error 44.4%  acc_test_error 50.0%\n",
      "Epoch: 4724 Loss: 2.5520174503326416  acc_train_error 44.4%  acc_test_error 50.0%\n",
      "Epoch: 4725 Loss: 2.5508508682250977  acc_train_error 44.4%  acc_test_error 50.0%\n",
      "Epoch: 4726 Loss: 2.5496878623962402  acc_train_error 44.4%  acc_test_error 50.0%\n",
      "Epoch: 4727 Loss: 2.5485219955444336  acc_train_error 44.4%  acc_test_error 50.0%\n",
      "Epoch: 4728 Loss: 2.547360897064209  acc_train_error 44.4%  acc_test_error 50.0%\n",
      "Epoch: 4729 Loss: 2.5461974143981934  acc_train_error 44.4%  acc_test_error 50.0%\n",
      "Epoch: 4730 Loss: 2.545034646987915  acc_train_error 44.4%  acc_test_error 50.0%\n",
      "Epoch: 4731 Loss: 2.543872594833374  acc_train_error 44.4%  acc_test_error 50.0%\n",
      "Epoch: 4732 Loss: 2.5427122116088867  acc_train_error 44.4%  acc_test_error 50.0%\n",
      "Epoch: 4733 Loss: 2.5415561199188232  acc_train_error 44.425%  acc_test_error 50.0%\n",
      "Epoch: 4734 Loss: 2.540374279022217  acc_train_error 44.4125%  acc_test_error 50.0%\n",
      "Epoch: 4735 Loss: 2.539207696914673  acc_train_error 44.425%  acc_test_error 50.0%\n",
      "Epoch: 4736 Loss: 2.5380563735961914  acc_train_error 44.425%  acc_test_error 50.0%\n",
      "Epoch: 4737 Loss: 2.5368902683258057  acc_train_error 44.425%  acc_test_error 50.0%\n",
      "Epoch: 4738 Loss: 2.535734176635742  acc_train_error 44.425%  acc_test_error 50.0%\n",
      "Epoch: 4739 Loss: 2.534573793411255  acc_train_error 44.425%  acc_test_error 50.0%\n",
      "Epoch: 4740 Loss: 2.5334184169769287  acc_train_error 44.425%  acc_test_error 50.0%\n",
      "Epoch: 4741 Loss: 2.532261610031128  acc_train_error 44.425%  acc_test_error 50.0%\n",
      "Epoch: 4742 Loss: 2.531111001968384  acc_train_error 44.425%  acc_test_error 50.0%\n",
      "Epoch: 4743 Loss: 2.5299527645111084  acc_train_error 44.4375%  acc_test_error 50.0%\n",
      "Epoch: 4744 Loss: 2.5287961959838867  acc_train_error 44.4375%  acc_test_error 50.0%\n",
      "Epoch: 4745 Loss: 2.527639627456665  acc_train_error 44.4375%  acc_test_error 50.0%\n",
      "Epoch: 4746 Loss: 2.526486396789551  acc_train_error 44.4375%  acc_test_error 50.0%\n",
      "Epoch: 4747 Loss: 2.525332450866699  acc_train_error 44.4375%  acc_test_error 50.0%\n",
      "Epoch: 4748 Loss: 2.5241799354553223  acc_train_error 44.4375%  acc_test_error 50.0%\n",
      "Epoch: 4749 Loss: 2.5230250358581543  acc_train_error 44.4375%  acc_test_error 50.0%\n",
      "Epoch: 4750 Loss: 2.5218751430511475  acc_train_error 44.4375%  acc_test_error 50.0%\n",
      "Epoch: 4751 Loss: 2.520723581314087  acc_train_error 44.45%  acc_test_error 50.0%\n",
      "Epoch: 4752 Loss: 2.5195748805999756  acc_train_error 44.4625%  acc_test_error 50.0%\n",
      "Epoch: 4753 Loss: 2.518437147140503  acc_train_error 44.45%  acc_test_error 50.0%\n",
      "Epoch: 4754 Loss: 2.5172770023345947  acc_train_error 44.475%  acc_test_error 50.0%\n",
      "Epoch: 4755 Loss: 2.516131639480591  acc_train_error 44.475%  acc_test_error 50.0%\n",
      "Epoch: 4756 Loss: 2.5149805545806885  acc_train_error 44.475%  acc_test_error 50.0%\n",
      "Epoch: 4757 Loss: 2.513834238052368  acc_train_error 44.475%  acc_test_error 50.0%\n",
      "Epoch: 4758 Loss: 2.5126864910125732  acc_train_error 44.475%  acc_test_error 50.0%\n",
      "Epoch: 4759 Loss: 2.5115396976470947  acc_train_error 44.475%  acc_test_error 50.0%\n",
      "Epoch: 4760 Loss: 2.510392665863037  acc_train_error 44.475%  acc_test_error 50.0%\n",
      "Epoch: 4761 Loss: 2.509246587753296  acc_train_error 44.475%  acc_test_error 50.0%\n",
      "Epoch: 4762 Loss: 2.5081028938293457  acc_train_error 44.475%  acc_test_error 50.0%\n",
      "Epoch: 4763 Loss: 2.5069594383239746  acc_train_error 44.475%  acc_test_error 50.0%\n",
      "Epoch: 4764 Loss: 2.5058159828186035  acc_train_error 44.4875%  acc_test_error 50.0%\n",
      "Epoch: 4765 Loss: 2.504676580429077  acc_train_error 44.4875%  acc_test_error 50.0%\n",
      "Epoch: 4766 Loss: 2.503528118133545  acc_train_error 44.4875%  acc_test_error 50.0%\n",
      "Epoch: 4767 Loss: 2.5023937225341797  acc_train_error 44.4875%  acc_test_error 50.0%\n",
      "Epoch: 4768 Loss: 2.5012478828430176  acc_train_error 44.4875%  acc_test_error 50.0%\n",
      "Epoch: 4769 Loss: 2.5001065731048584  acc_train_error 44.4875%  acc_test_error 50.0%\n",
      "Epoch: 4770 Loss: 2.498966932296753  acc_train_error 44.4875%  acc_test_error 50.0%\n",
      "Epoch: 4771 Loss: 2.4978270530700684  acc_train_error 44.4875%  acc_test_error 50.0%\n",
      "Epoch: 4772 Loss: 2.4966881275177  acc_train_error 44.4875%  acc_test_error 50.0%\n",
      "Epoch: 4773 Loss: 2.4955461025238037  acc_train_error 44.5%  acc_test_error 50.0%\n",
      "Epoch: 4774 Loss: 2.4944097995758057  acc_train_error 44.5%  acc_test_error 50.0%\n",
      "Epoch: 4775 Loss: 2.4932703971862793  acc_train_error 44.5%  acc_test_error 50.0%\n",
      "Epoch: 4776 Loss: 2.4921350479125977  acc_train_error 44.5%  acc_test_error 50.0%\n",
      "Epoch: 4777 Loss: 2.4909965991973877  acc_train_error 44.5%  acc_test_error 50.0%\n",
      "Epoch: 4778 Loss: 2.4898643493652344  acc_train_error 44.5125%  acc_test_error 50.0%\n",
      "Epoch: 4779 Loss: 2.488724708557129  acc_train_error 44.5%  acc_test_error 50.0%\n",
      "Epoch: 4780 Loss: 2.4875924587249756  acc_train_error 44.5125%  acc_test_error 50.0%\n",
      "Epoch: 4781 Loss: 2.486469268798828  acc_train_error 44.5125%  acc_test_error 50.0%\n",
      "Epoch: 4782 Loss: 2.485325813293457  acc_train_error 44.5125%  acc_test_error 50.0%\n",
      "Epoch: 4783 Loss: 2.484194040298462  acc_train_error 44.5125%  acc_test_error 50.0%\n",
      "Epoch: 4784 Loss: 2.483060598373413  acc_train_error 44.5125%  acc_test_error 50.0%\n",
      "Epoch: 4785 Loss: 2.481928586959839  acc_train_error 44.525%  acc_test_error 50.0%\n",
      "Epoch: 4786 Loss: 2.4807941913604736  acc_train_error 44.525%  acc_test_error 50.0%\n",
      "Epoch: 4787 Loss: 2.479663848876953  acc_train_error 44.525%  acc_test_error 50.0%\n",
      "Epoch: 4788 Loss: 2.478530168533325  acc_train_error 44.525%  acc_test_error 50.0%\n",
      "Epoch: 4789 Loss: 2.4774017333984375  acc_train_error 44.525%  acc_test_error 50.0%\n",
      "Epoch: 4790 Loss: 2.4762697219848633  acc_train_error 44.525%  acc_test_error 50.0%\n",
      "Epoch: 4791 Loss: 2.4751462936401367  acc_train_error 44.525%  acc_test_error 50.0%\n",
      "Epoch: 4792 Loss: 2.474013090133667  acc_train_error 44.525%  acc_test_error 50.0%\n",
      "Epoch: 4793 Loss: 2.472886085510254  acc_train_error 44.5375%  acc_test_error 50.0%\n",
      "Epoch: 4794 Loss: 2.471756935119629  acc_train_error 44.5375%  acc_test_error 50.0%\n",
      "Epoch: 4795 Loss: 2.470642328262329  acc_train_error 44.5375%  acc_test_error 50.0%\n",
      "Epoch: 4796 Loss: 2.4695072174072266  acc_train_error 44.5375%  acc_test_error 50.0%\n",
      "Epoch: 4797 Loss: 2.4683799743652344  acc_train_error 44.55%  acc_test_error 50.0%\n",
      "Epoch: 4798 Loss: 2.4672536849975586  acc_train_error 44.55%  acc_test_error 50.0%\n",
      "Epoch: 4799 Loss: 2.4661288261413574  acc_train_error 44.5625%  acc_test_error 50.0%\n",
      "Epoch: 4800 Loss: 2.4650015830993652  acc_train_error 44.5625%  acc_test_error 50.0%\n",
      "Epoch: 4801 Loss: 2.463878631591797  acc_train_error 44.5625%  acc_test_error 50.0%\n",
      "Epoch: 4802 Loss: 2.4627528190612793  acc_train_error 44.575%  acc_test_error 50.0%\n",
      "Epoch: 4803 Loss: 2.461634874343872  acc_train_error 44.575%  acc_test_error 50.0%\n",
      "Epoch: 4804 Loss: 2.460507869720459  acc_train_error 44.575%  acc_test_error 50.0%\n",
      "Epoch: 4805 Loss: 2.4593873023986816  acc_train_error 44.575%  acc_test_error 50.0%\n",
      "Epoch: 4806 Loss: 2.4582643508911133  acc_train_error 44.575%  acc_test_error 50.0%\n",
      "Epoch: 4807 Loss: 2.4571428298950195  acc_train_error 44.575%  acc_test_error 50.0%\n",
      "Epoch: 4808 Loss: 2.456021308898926  acc_train_error 44.5875%  acc_test_error 50.0%\n",
      "Epoch: 4809 Loss: 2.454916000366211  acc_train_error 44.5875%  acc_test_error 50.0%\n",
      "Epoch: 4810 Loss: 2.4537858963012695  acc_train_error 44.5875%  acc_test_error 50.0%\n",
      "Epoch: 4811 Loss: 2.452666759490967  acc_train_error 44.5875%  acc_test_error 50.0%\n",
      "Epoch: 4812 Loss: 2.4515466690063477  acc_train_error 44.5875%  acc_test_error 50.0%\n",
      "Epoch: 4813 Loss: 2.4504284858703613  acc_train_error 44.6%  acc_test_error 50.0%\n",
      "Epoch: 4814 Loss: 2.449317216873169  acc_train_error 44.6375%  acc_test_error 50.0%\n",
      "Epoch: 4815 Loss: 2.4481966495513916  acc_train_error 44.65%  acc_test_error 50.0%\n",
      "Epoch: 4816 Loss: 2.4470789432525635  acc_train_error 44.6625%  acc_test_error 50.0%\n",
      "Epoch: 4817 Loss: 2.44596266746521  acc_train_error 44.675%  acc_test_error 50.0%\n",
      "Epoch: 4818 Loss: 2.444847822189331  acc_train_error 44.6875%  acc_test_error 50.0%\n",
      "Epoch: 4819 Loss: 2.4437320232391357  acc_train_error 44.7%  acc_test_error 50.0%\n",
      "Epoch: 4820 Loss: 2.442617893218994  acc_train_error 44.7125%  acc_test_error 50.0%\n",
      "Epoch: 4821 Loss: 2.4415035247802734  acc_train_error 44.7375%  acc_test_error 50.0%\n",
      "Epoch: 4822 Loss: 2.440390110015869  acc_train_error 44.7375%  acc_test_error 50.0%\n",
      "Epoch: 4823 Loss: 2.439291477203369  acc_train_error 44.7375%  acc_test_error 50.0%\n",
      "Epoch: 4824 Loss: 2.438166618347168  acc_train_error 44.7375%  acc_test_error 50.0%\n",
      "Epoch: 4825 Loss: 2.437061309814453  acc_train_error 44.75%  acc_test_error 50.0%\n",
      "Epoch: 4826 Loss: 2.4359471797943115  acc_train_error 44.75%  acc_test_error 50.0%\n",
      "Epoch: 4827 Loss: 2.43483567237854  acc_train_error 44.75%  acc_test_error 50.0%\n",
      "Epoch: 4828 Loss: 2.4337267875671387  acc_train_error 44.7625%  acc_test_error 50.0%\n",
      "Epoch: 4829 Loss: 2.4326179027557373  acc_train_error 44.7625%  acc_test_error 50.0%\n",
      "Epoch: 4830 Loss: 2.4315078258514404  acc_train_error 44.775%  acc_test_error 50.0%\n",
      "Epoch: 4831 Loss: 2.4304001331329346  acc_train_error 44.775%  acc_test_error 50.0%\n",
      "Epoch: 4832 Loss: 2.4292945861816406  acc_train_error 44.7875%  acc_test_error 50.0%\n",
      "Epoch: 4833 Loss: 2.4281880855560303  acc_train_error 44.7875%  acc_test_error 50.0%\n",
      "Epoch: 4834 Loss: 2.4270801544189453  acc_train_error 44.7875%  acc_test_error 50.0%\n",
      "Epoch: 4835 Loss: 2.4259743690490723  acc_train_error 44.7875%  acc_test_error 50.0%\n",
      "Epoch: 4836 Loss: 2.424872398376465  acc_train_error 44.8%  acc_test_error 50.0%\n",
      "Epoch: 4837 Loss: 2.4237637519836426  acc_train_error 44.8125%  acc_test_error 50.0%\n",
      "Epoch: 4838 Loss: 2.422661304473877  acc_train_error 44.8125%  acc_test_error 50.0%\n",
      "Epoch: 4839 Loss: 2.421557664871216  acc_train_error 44.8125%  acc_test_error 50.0%\n",
      "Epoch: 4840 Loss: 2.4204626083374023  acc_train_error 44.8125%  acc_test_error 50.0%\n",
      "Epoch: 4841 Loss: 2.419351577758789  acc_train_error 44.8125%  acc_test_error 50.0%\n",
      "Epoch: 4842 Loss: 2.4182498455047607  acc_train_error 44.825%  acc_test_error 50.0%\n",
      "Epoch: 4843 Loss: 2.4171459674835205  acc_train_error 44.8375%  acc_test_error 50.0%\n",
      "Epoch: 4844 Loss: 2.416045665740967  acc_train_error 44.85%  acc_test_error 50.0%\n",
      "Epoch: 4845 Loss: 2.4149436950683594  acc_train_error 44.8375%  acc_test_error 50.0%\n",
      "Epoch: 4846 Loss: 2.4138495922088623  acc_train_error 44.85%  acc_test_error 50.0%\n",
      "Epoch: 4847 Loss: 2.4127438068389893  acc_train_error 44.875%  acc_test_error 50.0%\n",
      "Epoch: 4848 Loss: 2.4116456508636475  acc_train_error 44.85%  acc_test_error 50.0%\n",
      "Epoch: 4849 Loss: 2.410547971725464  acc_train_error 44.875%  acc_test_error 50.0%\n",
      "Epoch: 4850 Loss: 2.4094479084014893  acc_train_error 44.875%  acc_test_error 50.0%\n",
      "Epoch: 4851 Loss: 2.408350706100464  acc_train_error 44.9%  acc_test_error 50.0%\n",
      "Epoch: 4852 Loss: 2.407254457473755  acc_train_error 44.9%  acc_test_error 50.0%\n",
      "Epoch: 4853 Loss: 2.406157970428467  acc_train_error 44.8875%  acc_test_error 50.0%\n",
      "Epoch: 4854 Loss: 2.405061960220337  acc_train_error 44.9%  acc_test_error 50.0%\n",
      "Epoch: 4855 Loss: 2.403975248336792  acc_train_error 44.9%  acc_test_error 50.0%\n",
      "Epoch: 4856 Loss: 2.4028701782226562  acc_train_error 44.9%  acc_test_error 50.0%\n",
      "Epoch: 4857 Loss: 2.401779890060425  acc_train_error 44.9375%  acc_test_error 50.0%\n",
      "Epoch: 4858 Loss: 2.400681972503662  acc_train_error 44.9375%  acc_test_error 50.0%\n",
      "Epoch: 4859 Loss: 2.3995895385742188  acc_train_error 44.9375%  acc_test_error 50.0%\n",
      "Epoch: 4860 Loss: 2.3984932899475098  acc_train_error 44.9375%  acc_test_error 50.0%\n",
      "Epoch: 4861 Loss: 2.397402286529541  acc_train_error 44.95%  acc_test_error 50.0%\n",
      "Epoch: 4862 Loss: 2.396310806274414  acc_train_error 44.95%  acc_test_error 50.0%\n",
      "Epoch: 4863 Loss: 2.395216941833496  acc_train_error 44.95%  acc_test_error 50.0%\n",
      "Epoch: 4864 Loss: 2.394125461578369  acc_train_error 44.975%  acc_test_error 50.0%\n",
      "Epoch: 4865 Loss: 2.3930323123931885  acc_train_error 44.975%  acc_test_error 50.0%\n",
      "Epoch: 4866 Loss: 2.391944408416748  acc_train_error 44.9875%  acc_test_error 50.0%\n",
      "Epoch: 4867 Loss: 2.390857458114624  acc_train_error 44.9875%  acc_test_error 50.0%\n",
      "Epoch: 4868 Loss: 2.389782428741455  acc_train_error 44.9875%  acc_test_error 50.0%\n",
      "Epoch: 4869 Loss: 2.3886826038360596  acc_train_error 45.0125%  acc_test_error 50.0%\n",
      "Epoch: 4870 Loss: 2.3875954151153564  acc_train_error 45.0125%  acc_test_error 50.0%\n",
      "Epoch: 4871 Loss: 2.386510133743286  acc_train_error 45.0125%  acc_test_error 50.0%\n",
      "Epoch: 4872 Loss: 2.385422945022583  acc_train_error 45.0125%  acc_test_error 50.0%\n",
      "Epoch: 4873 Loss: 2.3843374252319336  acc_train_error 45.0125%  acc_test_error 50.0%\n",
      "Epoch: 4874 Loss: 2.3832507133483887  acc_train_error 45.0125%  acc_test_error 50.0%\n",
      "Epoch: 4875 Loss: 2.3821678161621094  acc_train_error 45.025%  acc_test_error 50.0%\n",
      "Epoch: 4876 Loss: 2.3810832500457764  acc_train_error 45.025%  acc_test_error 50.0%\n",
      "Epoch: 4877 Loss: 2.380000352859497  acc_train_error 45.025%  acc_test_error 50.0%\n",
      "Epoch: 4878 Loss: 2.378918409347534  acc_train_error 45.0375%  acc_test_error 50.0%\n",
      "Epoch: 4879 Loss: 2.3778350353240967  acc_train_error 45.0375%  acc_test_error 50.0%\n",
      "Epoch: 4880 Loss: 2.376753807067871  acc_train_error 45.0375%  acc_test_error 50.0%\n",
      "Epoch: 4881 Loss: 2.375678062438965  acc_train_error 45.05%  acc_test_error 50.0%\n",
      "Epoch: 4882 Loss: 2.374593734741211  acc_train_error 45.05%  acc_test_error 50.0%\n",
      "Epoch: 4883 Loss: 2.3735129833221436  acc_train_error 45.05%  acc_test_error 50.0%\n",
      "Epoch: 4884 Loss: 2.3724427223205566  acc_train_error 45.0375%  acc_test_error 50.0%\n",
      "Epoch: 4885 Loss: 2.371358633041382  acc_train_error 45.075%  acc_test_error 50.0%\n",
      "Epoch: 4886 Loss: 2.370276927947998  acc_train_error 45.1%  acc_test_error 50.0%\n",
      "Epoch: 4887 Loss: 2.369199275970459  acc_train_error 45.1%  acc_test_error 50.0%\n",
      "Epoch: 4888 Loss: 2.3681201934814453  acc_train_error 45.1125%  acc_test_error 50.0%\n",
      "Epoch: 4889 Loss: 2.367042064666748  acc_train_error 45.1125%  acc_test_error 50.0%\n",
      "Epoch: 4890 Loss: 2.365964651107788  acc_train_error 45.1%  acc_test_error 50.0%\n",
      "Epoch: 4891 Loss: 2.3648879528045654  acc_train_error 45.125%  acc_test_error 50.0%\n",
      "Epoch: 4892 Loss: 2.3638126850128174  acc_train_error 45.125%  acc_test_error 50.0%\n",
      "Epoch: 4893 Loss: 2.362736463546753  acc_train_error 45.15%  acc_test_error 50.0%\n",
      "Epoch: 4894 Loss: 2.361666679382324  acc_train_error 45.1625%  acc_test_error 50.0%\n",
      "Epoch: 4895 Loss: 2.3605892658233643  acc_train_error 45.2%  acc_test_error 50.0%\n",
      "Epoch: 4896 Loss: 2.3595151901245117  acc_train_error 45.1875%  acc_test_error 50.0%\n",
      "Epoch: 4897 Loss: 2.358441114425659  acc_train_error 45.175%  acc_test_error 50.0%\n",
      "Epoch: 4898 Loss: 2.357367753982544  acc_train_error 45.2%  acc_test_error 50.0%\n",
      "Epoch: 4899 Loss: 2.35630202293396  acc_train_error 45.2125%  acc_test_error 50.0%\n",
      "Epoch: 4900 Loss: 2.3552277088165283  acc_train_error 45.225%  acc_test_error 50.0%\n",
      "Epoch: 4901 Loss: 2.3541550636291504  acc_train_error 45.2375%  acc_test_error 50.0%\n",
      "Epoch: 4902 Loss: 2.353083372116089  acc_train_error 45.2375%  acc_test_error 50.0%\n",
      "Epoch: 4903 Loss: 2.352012872695923  acc_train_error 45.25%  acc_test_error 50.0%\n",
      "Epoch: 4904 Loss: 2.350940704345703  acc_train_error 45.25%  acc_test_error 50.0%\n",
      "Epoch: 4905 Loss: 2.34987735748291  acc_train_error 45.275%  acc_test_error 50.0%\n",
      "Epoch: 4906 Loss: 2.348803997039795  acc_train_error 45.275%  acc_test_error 50.0%\n",
      "Epoch: 4907 Loss: 2.3477365970611572  acc_train_error 45.275%  acc_test_error 50.0%\n",
      "Epoch: 4908 Loss: 2.346667528152466  acc_train_error 45.275%  acc_test_error 50.0%\n",
      "Epoch: 4909 Loss: 2.34559965133667  acc_train_error 45.3%  acc_test_error 50.0%\n",
      "Epoch: 4910 Loss: 2.3445327281951904  acc_train_error 45.3125%  acc_test_error 50.0%\n",
      "Epoch: 4911 Loss: 2.343466281890869  acc_train_error 45.3125%  acc_test_error 50.0%\n",
      "Epoch: 4912 Loss: 2.3424010276794434  acc_train_error 45.3125%  acc_test_error 50.0%\n",
      "Epoch: 4913 Loss: 2.341343641281128  acc_train_error 45.3125%  acc_test_error 50.0%\n",
      "Epoch: 4914 Loss: 2.340270519256592  acc_train_error 45.325%  acc_test_error 50.0%\n",
      "Epoch: 4915 Loss: 2.3392045497894287  acc_train_error 45.3375%  acc_test_error 50.0%\n",
      "Epoch: 4916 Loss: 2.338143825531006  acc_train_error 45.35%  acc_test_error 50.0%\n",
      "Epoch: 4917 Loss: 2.33707857131958  acc_train_error 45.35%  acc_test_error 50.0%\n",
      "Epoch: 4918 Loss: 2.3360142707824707  acc_train_error 45.3875%  acc_test_error 50.0%\n",
      "Epoch: 4919 Loss: 2.334951877593994  acc_train_error 45.4%  acc_test_error 50.0%\n",
      "Epoch: 4920 Loss: 2.3338871002197266  acc_train_error 45.4125%  acc_test_error 50.0%\n",
      "Epoch: 4921 Loss: 2.3328254222869873  acc_train_error 45.4125%  acc_test_error 50.0%\n",
      "Epoch: 4922 Loss: 2.3317646980285645  acc_train_error 45.425%  acc_test_error 50.0%\n",
      "Epoch: 4923 Loss: 2.330702304840088  acc_train_error 45.425%  acc_test_error 50.0%\n",
      "Epoch: 4924 Loss: 2.329641580581665  acc_train_error 45.4625%  acc_test_error 50.0%\n",
      "Epoch: 4925 Loss: 2.3285930156707764  acc_train_error 45.475%  acc_test_error 50.0%\n",
      "Epoch: 4926 Loss: 2.3275299072265625  acc_train_error 45.475%  acc_test_error 50.0%\n",
      "Epoch: 4927 Loss: 2.3264687061309814  acc_train_error 45.4875%  acc_test_error 50.0%\n",
      "Epoch: 4928 Loss: 2.325409173965454  acc_train_error 45.5%  acc_test_error 50.0%\n",
      "Epoch: 4929 Loss: 2.324352264404297  acc_train_error 45.5125%  acc_test_error 50.0%\n",
      "Epoch: 4930 Loss: 2.3232953548431396  acc_train_error 45.525%  acc_test_error 50.0%\n",
      "Epoch: 4931 Loss: 2.3222367763519287  acc_train_error 45.5375%  acc_test_error 50.0%\n",
      "Epoch: 4932 Loss: 2.3211820125579834  acc_train_error 45.5375%  acc_test_error 50.0%\n",
      "Epoch: 4933 Loss: 2.32012677192688  acc_train_error 45.5375%  acc_test_error 50.0%\n",
      "Epoch: 4934 Loss: 2.3190722465515137  acc_train_error 45.55%  acc_test_error 50.0%\n",
      "Epoch: 4935 Loss: 2.3180172443389893  acc_train_error 45.55%  acc_test_error 50.0%\n",
      "Epoch: 4936 Loss: 2.3169655799865723  acc_train_error 45.5625%  acc_test_error 50.0%\n",
      "Epoch: 4937 Loss: 2.3159124851226807  acc_train_error 45.5625%  acc_test_error 50.0%\n",
      "Epoch: 4938 Loss: 2.3148622512817383  acc_train_error 45.575%  acc_test_error 50.0%\n",
      "Epoch: 4939 Loss: 2.3138067722320557  acc_train_error 45.5875%  acc_test_error 50.0%\n",
      "Epoch: 4940 Loss: 2.3127567768096924  acc_train_error 45.6%  acc_test_error 50.0%\n",
      "Epoch: 4941 Loss: 2.311704635620117  acc_train_error 45.6%  acc_test_error 50.0%\n",
      "Epoch: 4942 Loss: 2.3106558322906494  acc_train_error 45.6%  acc_test_error 50.0%\n",
      "Epoch: 4943 Loss: 2.3096060752868652  acc_train_error 45.6125%  acc_test_error 50.0%\n",
      "Epoch: 4944 Loss: 2.308560848236084  acc_train_error 45.6125%  acc_test_error 50.0%\n",
      "Epoch: 4945 Loss: 2.3075058460235596  acc_train_error 45.6375%  acc_test_error 50.0%\n",
      "Epoch: 4946 Loss: 2.306457281112671  acc_train_error 45.6375%  acc_test_error 50.0%\n",
      "Epoch: 4947 Loss: 2.305408477783203  acc_train_error 45.6375%  acc_test_error 50.0%\n",
      "Epoch: 4948 Loss: 2.30436110496521  acc_train_error 45.6375%  acc_test_error 50.0%\n",
      "Epoch: 4949 Loss: 2.303313732147217  acc_train_error 45.65%  acc_test_error 50.0%\n",
      "Epoch: 4950 Loss: 2.302269458770752  acc_train_error 45.6625%  acc_test_error 50.0%\n",
      "Epoch: 4951 Loss: 2.301222562789917  acc_train_error 45.675%  acc_test_error 50.0%\n",
      "Epoch: 4952 Loss: 2.3001749515533447  acc_train_error 45.675%  acc_test_error 50.0%\n",
      "Epoch: 4953 Loss: 2.2991302013397217  acc_train_error 45.675%  acc_test_error 50.0%\n",
      "Epoch: 4954 Loss: 2.298085927963257  acc_train_error 45.675%  acc_test_error 50.0%\n",
      "Epoch: 4955 Loss: 2.2970409393310547  acc_train_error 45.675%  acc_test_error 50.0%\n",
      "Epoch: 4956 Loss: 2.29599666595459  acc_train_error 45.675%  acc_test_error 50.0%\n",
      "Epoch: 4957 Loss: 2.2949533462524414  acc_train_error 45.6875%  acc_test_error 50.0%\n",
      "Epoch: 4958 Loss: 2.293910264968872  acc_train_error 45.7125%  acc_test_error 50.0%\n",
      "Epoch: 4959 Loss: 2.2928667068481445  acc_train_error 45.7125%  acc_test_error 50.0%\n",
      "Epoch: 4960 Loss: 2.2918267250061035  acc_train_error 45.725%  acc_test_error 50.0%\n",
      "Epoch: 4961 Loss: 2.290783643722534  acc_train_error 45.7125%  acc_test_error 50.0%\n",
      "Epoch: 4962 Loss: 2.289748430252075  acc_train_error 45.7125%  acc_test_error 50.0%\n",
      "Epoch: 4963 Loss: 2.288710594177246  acc_train_error 45.725%  acc_test_error 50.0%\n",
      "Epoch: 4964 Loss: 2.287667751312256  acc_train_error 45.7375%  acc_test_error 50.0%\n",
      "Epoch: 4965 Loss: 2.286625385284424  acc_train_error 45.7375%  acc_test_error 50.0%\n",
      "Epoch: 4966 Loss: 2.2855873107910156  acc_train_error 45.7625%  acc_test_error 50.0%\n",
      "Epoch: 4967 Loss: 2.2845468521118164  acc_train_error 45.7625%  acc_test_error 50.0%\n",
      "Epoch: 4968 Loss: 2.283510208129883  acc_train_error 45.7875%  acc_test_error 50.0%\n",
      "Epoch: 4969 Loss: 2.282470703125  acc_train_error 45.7625%  acc_test_error 50.0%\n",
      "Epoch: 4970 Loss: 2.2814362049102783  acc_train_error 45.7875%  acc_test_error 50.0%\n",
      "Epoch: 4971 Loss: 2.2803988456726074  acc_train_error 45.7875%  acc_test_error 50.0%\n",
      "Epoch: 4972 Loss: 2.2793617248535156  acc_train_error 45.8125%  acc_test_error 50.0%\n",
      "Epoch: 4973 Loss: 2.278331995010376  acc_train_error 45.8%  acc_test_error 50.0%\n",
      "Epoch: 4974 Loss: 2.277294635772705  acc_train_error 45.825%  acc_test_error 50.0%\n",
      "Epoch: 4975 Loss: 2.2762584686279297  acc_train_error 45.8125%  acc_test_error 50.0%\n",
      "Epoch: 4976 Loss: 2.275223731994629  acc_train_error 45.8375%  acc_test_error 50.0%\n",
      "Epoch: 4977 Loss: 2.274190902709961  acc_train_error 45.85%  acc_test_error 50.0%\n",
      "Epoch: 4978 Loss: 2.2731566429138184  acc_train_error 45.85%  acc_test_error 50.0%\n",
      "Epoch: 4979 Loss: 2.272125005722046  acc_train_error 45.85%  acc_test_error 50.0%\n",
      "Epoch: 4980 Loss: 2.2710912227630615  acc_train_error 45.8625%  acc_test_error 50.0%\n",
      "Epoch: 4981 Loss: 2.2700603008270264  acc_train_error 45.8625%  acc_test_error 50.0%\n",
      "Epoch: 4982 Loss: 2.269028663635254  acc_train_error 45.875%  acc_test_error 50.0%\n",
      "Epoch: 4983 Loss: 2.2680017948150635  acc_train_error 45.8875%  acc_test_error 50.0%\n",
      "Epoch: 4984 Loss: 2.2669715881347656  acc_train_error 45.8875%  acc_test_error 50.0%\n",
      "Epoch: 4985 Loss: 2.265939474105835  acc_train_error 45.8875%  acc_test_error 50.0%\n",
      "Epoch: 4986 Loss: 2.2649123668670654  acc_train_error 45.8875%  acc_test_error 50.0%\n",
      "Epoch: 4987 Loss: 2.263882637023926  acc_train_error 45.9125%  acc_test_error 50.0%\n",
      "Epoch: 4988 Loss: 2.262855291366577  acc_train_error 45.9125%  acc_test_error 50.0%\n",
      "Epoch: 4989 Loss: 2.2618253231048584  acc_train_error 45.925%  acc_test_error 50.0%\n",
      "Epoch: 4990 Loss: 2.2607967853546143  acc_train_error 45.925%  acc_test_error 50.0%\n",
      "Epoch: 4991 Loss: 2.2597694396972656  acc_train_error 45.925%  acc_test_error 50.0%\n",
      "Epoch: 4992 Loss: 2.2587497234344482  acc_train_error 45.9375%  acc_test_error 50.0%\n",
      "Epoch: 4993 Loss: 2.2577152252197266  acc_train_error 45.9625%  acc_test_error 50.0%\n",
      "Epoch: 4994 Loss: 2.2566945552825928  acc_train_error 45.975%  acc_test_error 50.0%\n",
      "Epoch: 4995 Loss: 2.255666494369507  acc_train_error 45.975%  acc_test_error 50.0%\n",
      "Epoch: 4996 Loss: 2.254641532897949  acc_train_error 45.9875%  acc_test_error 50.0%\n",
      "Epoch: 4997 Loss: 2.25361704826355  acc_train_error 46.0%  acc_test_error 50.0%\n",
      "Epoch: 4998 Loss: 2.252591133117676  acc_train_error 46.0%  acc_test_error 50.0%\n",
      "Epoch: 4999 Loss: 2.251568078994751  acc_train_error 46.0125%  acc_test_error 50.0%\n",
      "Epoch: 5000 Loss: 2.2505459785461426  acc_train_error 46.0375%  acc_test_error 50.0%\n",
      "Epoch: 5001 Loss: 2.249521493911743  acc_train_error 46.0375%  acc_test_error 50.0%\n",
      "Epoch: 5002 Loss: 2.248499631881714  acc_train_error 46.05%  acc_test_error 50.0%\n",
      "Epoch: 5003 Loss: 2.2474772930145264  acc_train_error 46.0625%  acc_test_error 50.0%\n",
      "Epoch: 5004 Loss: 2.246461868286133  acc_train_error 46.1%  acc_test_error 50.0%\n",
      "Epoch: 5005 Loss: 2.2454171180725098  acc_train_error 46.125%  acc_test_error 50.0%\n",
      "Epoch: 5006 Loss: 2.244380474090576  acc_train_error 46.125%  acc_test_error 50.0%\n",
      "Epoch: 5007 Loss: 2.243346929550171  acc_train_error 46.1375%  acc_test_error 50.0%\n",
      "Epoch: 5008 Loss: 2.2423126697540283  acc_train_error 46.1375%  acc_test_error 50.0%\n",
      "Epoch: 5009 Loss: 2.241291046142578  acc_train_error 46.1375%  acc_test_error 50.0%\n",
      "Epoch: 5010 Loss: 2.2402546405792236  acc_train_error 46.1375%  acc_test_error 50.0%\n",
      "Epoch: 5011 Loss: 2.2392239570617676  acc_train_error 46.1625%  acc_test_error 50.0%\n",
      "Epoch: 5012 Loss: 2.238194227218628  acc_train_error 46.1625%  acc_test_error 50.0%\n",
      "Epoch: 5013 Loss: 2.237168073654175  acc_train_error 46.1625%  acc_test_error 50.0%\n",
      "Epoch: 5014 Loss: 2.236135244369507  acc_train_error 46.175%  acc_test_error 50.0%\n",
      "Epoch: 5015 Loss: 2.2351133823394775  acc_train_error 46.1875%  acc_test_error 50.0%\n",
      "Epoch: 5016 Loss: 2.234081506729126  acc_train_error 46.2%  acc_test_error 50.0%\n",
      "Epoch: 5017 Loss: 2.2330543994903564  acc_train_error 46.225%  acc_test_error 50.0%\n",
      "Epoch: 5018 Loss: 2.232028007507324  acc_train_error 46.225%  acc_test_error 50.0%\n",
      "Epoch: 5019 Loss: 2.2310025691986084  acc_train_error 46.225%  acc_test_error 50.0%\n",
      "Epoch: 5020 Loss: 2.229980230331421  acc_train_error 46.2375%  acc_test_error 50.0%\n",
      "Epoch: 5021 Loss: 2.228956699371338  acc_train_error 46.2375%  acc_test_error 50.0%\n",
      "Epoch: 5022 Loss: 2.227940797805786  acc_train_error 46.2375%  acc_test_error 50.0%\n",
      "Epoch: 5023 Loss: 2.226911783218384  acc_train_error 46.2625%  acc_test_error 50.0%\n",
      "Epoch: 5024 Loss: 2.225893020629883  acc_train_error 46.275%  acc_test_error 50.0%\n",
      "Epoch: 5025 Loss: 2.224874973297119  acc_train_error 46.275%  acc_test_error 50.0%\n",
      "Epoch: 5026 Loss: 2.2238612174987793  acc_train_error 46.275%  acc_test_error 50.0%\n",
      "Epoch: 5027 Loss: 2.2228424549102783  acc_train_error 46.2875%  acc_test_error 50.0%\n",
      "Epoch: 5028 Loss: 2.221829891204834  acc_train_error 46.3%  acc_test_error 50.0%\n",
      "Epoch: 5029 Loss: 2.2208139896392822  acc_train_error 46.3125%  acc_test_error 50.0%\n",
      "Epoch: 5030 Loss: 2.219803810119629  acc_train_error 46.325%  acc_test_error 50.0%\n",
      "Epoch: 5031 Loss: 2.2187886238098145  acc_train_error 46.325%  acc_test_error 50.0%\n",
      "Epoch: 5032 Loss: 2.21777606010437  acc_train_error 46.325%  acc_test_error 50.0%\n",
      "Epoch: 5033 Loss: 2.2167630195617676  acc_train_error 46.3375%  acc_test_error 50.0%\n",
      "Epoch: 5034 Loss: 2.215747356414795  acc_train_error 46.35%  acc_test_error 50.0%\n",
      "Epoch: 5035 Loss: 2.214733600616455  acc_train_error 46.35%  acc_test_error 50.0%\n",
      "Epoch: 5036 Loss: 2.213721513748169  acc_train_error 46.3625%  acc_test_error 50.0%\n",
      "Epoch: 5037 Loss: 2.2127058506011963  acc_train_error 46.3625%  acc_test_error 50.0%\n",
      "Epoch: 5038 Loss: 2.211690664291382  acc_train_error 46.3625%  acc_test_error 50.0%\n",
      "Epoch: 5039 Loss: 2.210676431655884  acc_train_error 46.3875%  acc_test_error 50.0%\n",
      "Epoch: 5040 Loss: 2.209669351577759  acc_train_error 46.3875%  acc_test_error 50.0%\n",
      "Epoch: 5041 Loss: 2.2086563110351562  acc_train_error 46.4%  acc_test_error 50.0%\n",
      "Epoch: 5042 Loss: 2.2076427936553955  acc_train_error 46.425%  acc_test_error 50.0%\n",
      "Epoch: 5043 Loss: 2.2066330909729004  acc_train_error 46.425%  acc_test_error 50.0%\n",
      "Epoch: 5044 Loss: 2.205620527267456  acc_train_error 46.425%  acc_test_error 50.0%\n",
      "Epoch: 5045 Loss: 2.2046103477478027  acc_train_error 46.45%  acc_test_error 50.0%\n",
      "Epoch: 5046 Loss: 2.2036080360412598  acc_train_error 46.45%  acc_test_error 50.0%\n",
      "Epoch: 5047 Loss: 2.202594041824341  acc_train_error 46.45%  acc_test_error 50.0%\n",
      "Epoch: 5048 Loss: 2.2015910148620605  acc_train_error 46.4625%  acc_test_error 50.0%\n",
      "Epoch: 5049 Loss: 2.200582981109619  acc_train_error 46.475%  acc_test_error 50.0%\n",
      "Epoch: 5050 Loss: 2.1995749473571777  acc_train_error 46.475%  acc_test_error 50.0%\n",
      "Epoch: 5051 Loss: 2.1985695362091064  acc_train_error 46.475%  acc_test_error 50.0%\n",
      "Epoch: 5052 Loss: 2.1975648403167725  acc_train_error 46.4875%  acc_test_error 50.0%\n",
      "Epoch: 5053 Loss: 2.19655704498291  acc_train_error 46.5125%  acc_test_error 50.0%\n",
      "Epoch: 5054 Loss: 2.195549249649048  acc_train_error 46.5125%  acc_test_error 50.0%\n",
      "Epoch: 5055 Loss: 2.1945416927337646  acc_train_error 46.5125%  acc_test_error 50.0%\n",
      "Epoch: 5056 Loss: 2.19354248046875  acc_train_error 46.5375%  acc_test_error 50.0%\n",
      "Epoch: 5057 Loss: 2.192535400390625  acc_train_error 46.5375%  acc_test_error 50.0%\n",
      "Epoch: 5058 Loss: 2.1915297508239746  acc_train_error 46.55%  acc_test_error 50.0%\n",
      "Epoch: 5059 Loss: 2.1905274391174316  acc_train_error 46.55%  acc_test_error 50.0%\n",
      "Epoch: 5060 Loss: 2.189523696899414  acc_train_error 46.5625%  acc_test_error 50.0%\n",
      "Epoch: 5061 Loss: 2.188519239425659  acc_train_error 46.575%  acc_test_error 50.0%\n",
      "Epoch: 5062 Loss: 2.1875154972076416  acc_train_error 46.6%  acc_test_error 50.0%\n",
      "Epoch: 5063 Loss: 2.1865150928497314  acc_train_error 46.6%  acc_test_error 50.0%\n",
      "Epoch: 5064 Loss: 2.185520887374878  acc_train_error 46.6125%  acc_test_error 50.0%\n",
      "Epoch: 5065 Loss: 2.184520721435547  acc_train_error 46.6125%  acc_test_error 50.0%\n",
      "Epoch: 5066 Loss: 2.1835272312164307  acc_train_error 46.6125%  acc_test_error 50.0%\n",
      "Epoch: 5067 Loss: 2.182535409927368  acc_train_error 46.625%  acc_test_error 50.0%\n",
      "Epoch: 5068 Loss: 2.1815428733825684  acc_train_error 46.6375%  acc_test_error 50.0%\n",
      "Epoch: 5069 Loss: 2.1805505752563477  acc_train_error 46.6375%  acc_test_error 50.0%\n",
      "Epoch: 5070 Loss: 2.1795573234558105  acc_train_error 46.6375%  acc_test_error 50.0%\n",
      "Epoch: 5071 Loss: 2.1785666942596436  acc_train_error 46.6625%  acc_test_error 50.0%\n",
      "Epoch: 5072 Loss: 2.177581787109375  acc_train_error 46.675%  acc_test_error 50.0%\n",
      "Epoch: 5073 Loss: 2.176593065261841  acc_train_error 46.675%  acc_test_error 50.0%\n",
      "Epoch: 5074 Loss: 2.17560076713562  acc_train_error 46.7%  acc_test_error 50.0%\n",
      "Epoch: 5075 Loss: 2.1746132373809814  acc_train_error 46.7%  acc_test_error 50.0%\n",
      "Epoch: 5076 Loss: 2.173624277114868  acc_train_error 46.7%  acc_test_error 50.0%\n",
      "Epoch: 5077 Loss: 2.1726348400115967  acc_train_error 46.7125%  acc_test_error 50.0%\n",
      "Epoch: 5078 Loss: 2.171649217605591  acc_train_error 46.7125%  acc_test_error 50.0%\n",
      "Epoch: 5079 Loss: 2.1706604957580566  acc_train_error 46.7125%  acc_test_error 50.0%\n",
      "Epoch: 5080 Loss: 2.169675827026367  acc_train_error 46.7125%  acc_test_error 50.0%\n",
      "Epoch: 5081 Loss: 2.168696880340576  acc_train_error 46.7375%  acc_test_error 50.0%\n",
      "Epoch: 5082 Loss: 2.1677091121673584  acc_train_error 46.7375%  acc_test_error 50.0%\n",
      "Epoch: 5083 Loss: 2.166722297668457  acc_train_error 46.75%  acc_test_error 50.0%\n",
      "Epoch: 5084 Loss: 2.1657378673553467  acc_train_error 46.7625%  acc_test_error 50.0%\n",
      "Epoch: 5085 Loss: 2.1647539138793945  acc_train_error 46.775%  acc_test_error 50.0%\n",
      "Epoch: 5086 Loss: 2.1637699604034424  acc_train_error 46.7875%  acc_test_error 50.0%\n",
      "Epoch: 5087 Loss: 2.1627867221832275  acc_train_error 46.7875%  acc_test_error 50.0%\n",
      "Epoch: 5088 Loss: 2.1618034839630127  acc_train_error 46.7875%  acc_test_error 50.0%\n",
      "Epoch: 5089 Loss: 2.160825252532959  acc_train_error 46.8%  acc_test_error 50.0%\n",
      "Epoch: 5090 Loss: 2.1598458290100098  acc_train_error 46.8%  acc_test_error 50.0%\n",
      "Epoch: 5091 Loss: 2.158860921859741  acc_train_error 46.8%  acc_test_error 50.0%\n",
      "Epoch: 5092 Loss: 2.157881498336792  acc_train_error 46.8375%  acc_test_error 50.0%\n",
      "Epoch: 5093 Loss: 2.156898021697998  acc_train_error 46.8375%  acc_test_error 50.0%\n",
      "Epoch: 5094 Loss: 2.1559197902679443  acc_train_error 46.8375%  acc_test_error 50.0%\n",
      "Epoch: 5095 Loss: 2.154940128326416  acc_train_error 46.8375%  acc_test_error 50.0%\n",
      "Epoch: 5096 Loss: 2.153960943222046  acc_train_error 46.85%  acc_test_error 50.0%\n",
      "Epoch: 5097 Loss: 2.152984142303467  acc_train_error 46.8625%  acc_test_error 50.0%\n",
      "Epoch: 5098 Loss: 2.1520121097564697  acc_train_error 46.8625%  acc_test_error 50.0%\n",
      "Epoch: 5099 Loss: 2.151031017303467  acc_train_error 46.8875%  acc_test_error 50.0%\n",
      "Epoch: 5100 Loss: 2.150052309036255  acc_train_error 46.8875%  acc_test_error 50.0%\n",
      "Epoch: 5101 Loss: 2.1490767002105713  acc_train_error 46.8875%  acc_test_error 50.0%\n",
      "Epoch: 5102 Loss: 2.1480982303619385  acc_train_error 46.9%  acc_test_error 50.0%\n",
      "Epoch: 5103 Loss: 2.147122383117676  acc_train_error 46.9125%  acc_test_error 50.0%\n",
      "Epoch: 5104 Loss: 2.1461470127105713  acc_train_error 46.9125%  acc_test_error 50.0%\n",
      "Epoch: 5105 Loss: 2.145172595977783  acc_train_error 46.925%  acc_test_error 50.0%\n",
      "Epoch: 5106 Loss: 2.14420485496521  acc_train_error 46.9375%  acc_test_error 50.0%\n",
      "Epoch: 5107 Loss: 2.1432278156280518  acc_train_error 46.95%  acc_test_error 50.0%\n",
      "Epoch: 5108 Loss: 2.1422550678253174  acc_train_error 46.95%  acc_test_error 50.0%\n",
      "Epoch: 5109 Loss: 2.141279935836792  acc_train_error 46.95%  acc_test_error 50.0%\n",
      "Epoch: 5110 Loss: 2.1403074264526367  acc_train_error 46.9625%  acc_test_error 50.0%\n",
      "Epoch: 5111 Loss: 2.139336585998535  acc_train_error 46.9625%  acc_test_error 50.0%\n",
      "Epoch: 5112 Loss: 2.138364315032959  acc_train_error 46.975%  acc_test_error 50.0%\n",
      "Epoch: 5113 Loss: 2.1373934745788574  acc_train_error 47.0%  acc_test_error 50.0%\n",
      "Epoch: 5114 Loss: 2.1364188194274902  acc_train_error 47.0%  acc_test_error 50.0%\n",
      "Epoch: 5115 Loss: 2.1354598999023438  acc_train_error 47.0125%  acc_test_error 50.0%\n",
      "Epoch: 5116 Loss: 2.13448429107666  acc_train_error 47.025%  acc_test_error 50.0%\n",
      "Epoch: 5117 Loss: 2.1335132122039795  acc_train_error 47.025%  acc_test_error 50.0%\n",
      "Epoch: 5118 Loss: 2.13254714012146  acc_train_error 47.0375%  acc_test_error 50.0%\n",
      "Epoch: 5119 Loss: 2.131578207015991  acc_train_error 47.0375%  acc_test_error 50.0%\n",
      "Epoch: 5120 Loss: 2.1306090354919434  acc_train_error 47.0375%  acc_test_error 50.0%\n",
      "Epoch: 5121 Loss: 2.129643440246582  acc_train_error 47.05%  acc_test_error 50.0%\n",
      "Epoch: 5122 Loss: 2.1286728382110596  acc_train_error 47.05%  acc_test_error 50.0%\n",
      "Epoch: 5123 Loss: 2.1277103424072266  acc_train_error 47.075%  acc_test_error 50.0%\n",
      "Epoch: 5124 Loss: 2.1267449855804443  acc_train_error 47.075%  acc_test_error 50.0%\n",
      "Epoch: 5125 Loss: 2.1257784366607666  acc_train_error 47.075%  acc_test_error 50.0%\n",
      "Epoch: 5126 Loss: 2.124812364578247  acc_train_error 47.0875%  acc_test_error 50.0%\n",
      "Epoch: 5127 Loss: 2.123847484588623  acc_train_error 47.0875%  acc_test_error 50.0%\n",
      "Epoch: 5128 Loss: 2.122882127761841  acc_train_error 47.1%  acc_test_error 50.0%\n",
      "Epoch: 5129 Loss: 2.1219160556793213  acc_train_error 47.1125%  acc_test_error 50.0%\n",
      "Epoch: 5130 Loss: 2.120952844619751  acc_train_error 47.125%  acc_test_error 50.0%\n",
      "Epoch: 5131 Loss: 2.119990587234497  acc_train_error 47.1375%  acc_test_error 50.0%\n",
      "Epoch: 5132 Loss: 2.1190345287323  acc_train_error 47.1375%  acc_test_error 50.0%\n",
      "Epoch: 5133 Loss: 2.118068218231201  acc_train_error 47.15%  acc_test_error 50.0%\n",
      "Epoch: 5134 Loss: 2.117107391357422  acc_train_error 47.1625%  acc_test_error 50.0%\n",
      "Epoch: 5135 Loss: 2.1161458492279053  acc_train_error 47.1625%  acc_test_error 50.0%\n",
      "Epoch: 5136 Loss: 2.1151840686798096  acc_train_error 47.1625%  acc_test_error 50.0%\n",
      "Epoch: 5137 Loss: 2.114222526550293  acc_train_error 47.175%  acc_test_error 50.0%\n",
      "Epoch: 5138 Loss: 2.1132614612579346  acc_train_error 47.175%  acc_test_error 50.0%\n",
      "Epoch: 5139 Loss: 2.11230206489563  acc_train_error 47.175%  acc_test_error 50.0%\n",
      "Epoch: 5140 Loss: 2.111341714859009  acc_train_error 47.1875%  acc_test_error 50.0%\n",
      "Epoch: 5141 Loss: 2.11039137840271  acc_train_error 47.1875%  acc_test_error 50.0%\n",
      "Epoch: 5142 Loss: 2.1094284057617188  acc_train_error 47.2%  acc_test_error 50.0%\n",
      "Epoch: 5143 Loss: 2.1084704399108887  acc_train_error 47.2%  acc_test_error 50.0%\n",
      "Epoch: 5144 Loss: 2.1075127124786377  acc_train_error 47.225%  acc_test_error 50.0%\n",
      "Epoch: 5145 Loss: 2.1065561771392822  acc_train_error 47.2375%  acc_test_error 50.0%\n",
      "Epoch: 5146 Loss: 2.1055986881256104  acc_train_error 47.25%  acc_test_error 50.0%\n",
      "Epoch: 5147 Loss: 2.104641914367676  acc_train_error 47.2625%  acc_test_error 50.0%\n",
      "Epoch: 5148 Loss: 2.1036853790283203  acc_train_error 47.2625%  acc_test_error 50.0%\n",
      "Epoch: 5149 Loss: 2.1027352809906006  acc_train_error 47.275%  acc_test_error 50.0%\n",
      "Epoch: 5150 Loss: 2.1017813682556152  acc_train_error 47.275%  acc_test_error 50.0%\n",
      "Epoch: 5151 Loss: 2.100832939147949  acc_train_error 47.275%  acc_test_error 50.0%\n",
      "Epoch: 5152 Loss: 2.099869966506958  acc_train_error 47.275%  acc_test_error 50.0%\n",
      "Epoch: 5153 Loss: 2.0989177227020264  acc_train_error 47.2875%  acc_test_error 50.0%\n",
      "Epoch: 5154 Loss: 2.097961902618408  acc_train_error 47.3%  acc_test_error 50.0%\n",
      "Epoch: 5155 Loss: 2.097005605697632  acc_train_error 47.3125%  acc_test_error 50.0%\n",
      "Epoch: 5156 Loss: 2.0960488319396973  acc_train_error 47.3125%  acc_test_error 50.0%\n",
      "Epoch: 5157 Loss: 2.095093250274658  acc_train_error 47.325%  acc_test_error 50.0%\n",
      "Epoch: 5158 Loss: 2.0941474437713623  acc_train_error 47.3375%  acc_test_error 50.0%\n",
      "Epoch: 5159 Loss: 2.093186855316162  acc_train_error 47.35%  acc_test_error 50.0%\n",
      "Epoch: 5160 Loss: 2.0922353267669678  acc_train_error 47.35%  acc_test_error 50.0%\n",
      "Epoch: 5161 Loss: 2.0912814140319824  acc_train_error 47.3625%  acc_test_error 50.0%\n",
      "Epoch: 5162 Loss: 2.090329647064209  acc_train_error 47.3625%  acc_test_error 50.0%\n",
      "Epoch: 5163 Loss: 2.08937668800354  acc_train_error 47.3625%  acc_test_error 50.0%\n",
      "Epoch: 5164 Loss: 2.088423252105713  acc_train_error 47.3875%  acc_test_error 50.0%\n",
      "Epoch: 5165 Loss: 2.087475061416626  acc_train_error 47.4%  acc_test_error 50.0%\n",
      "Epoch: 5166 Loss: 2.0865235328674316  acc_train_error 47.4%  acc_test_error 50.0%\n",
      "Epoch: 5167 Loss: 2.085577964782715  acc_train_error 47.4125%  acc_test_error 50.0%\n",
      "Epoch: 5168 Loss: 2.0846328735351562  acc_train_error 47.4125%  acc_test_error 50.0%\n",
      "Epoch: 5169 Loss: 2.0836827754974365  acc_train_error 47.425%  acc_test_error 50.0%\n",
      "Epoch: 5170 Loss: 2.082732915878296  acc_train_error 47.4375%  acc_test_error 50.0%\n",
      "Epoch: 5171 Loss: 2.081784725189209  acc_train_error 47.4375%  acc_test_error 50.0%\n",
      "Epoch: 5172 Loss: 2.080836057662964  acc_train_error 47.45%  acc_test_error 50.0%\n",
      "Epoch: 5173 Loss: 2.0798895359039307  acc_train_error 47.4625%  acc_test_error 50.0%\n",
      "Epoch: 5174 Loss: 2.078939914703369  acc_train_error 47.4625%  acc_test_error 50.0%\n",
      "Epoch: 5175 Loss: 2.077995777130127  acc_train_error 47.4875%  acc_test_error 50.0%\n",
      "Epoch: 5176 Loss: 2.0770483016967773  acc_train_error 47.4875%  acc_test_error 50.0%\n",
      "Epoch: 5177 Loss: 2.0761115550994873  acc_train_error 47.5%  acc_test_error 50.0%\n",
      "Epoch: 5178 Loss: 2.075164556503296  acc_train_error 47.5125%  acc_test_error 50.0%\n",
      "Epoch: 5179 Loss: 2.0742194652557373  acc_train_error 47.5125%  acc_test_error 50.0%\n",
      "Epoch: 5180 Loss: 2.073275327682495  acc_train_error 47.5375%  acc_test_error 50.0%\n",
      "Epoch: 5181 Loss: 2.0723323822021484  acc_train_error 47.5375%  acc_test_error 50.0%\n",
      "Epoch: 5182 Loss: 2.0713911056518555  acc_train_error 47.5375%  acc_test_error 50.0%\n",
      "Epoch: 5183 Loss: 2.0704472064971924  acc_train_error 47.55%  acc_test_error 50.0%\n",
      "Epoch: 5184 Loss: 2.0695035457611084  acc_train_error 47.55%  acc_test_error 50.0%\n",
      "Epoch: 5185 Loss: 2.0685617923736572  acc_train_error 47.5625%  acc_test_error 50.0%\n",
      "Epoch: 5186 Loss: 2.067620038986206  acc_train_error 47.5625%  acc_test_error 50.0%\n",
      "Epoch: 5187 Loss: 2.0666873455047607  acc_train_error 47.5875%  acc_test_error 50.0%\n",
      "Epoch: 5188 Loss: 2.0657451152801514  acc_train_error 47.5875%  acc_test_error 50.0%\n",
      "Epoch: 5189 Loss: 2.0648038387298584  acc_train_error 47.5875%  acc_test_error 50.0%\n",
      "Epoch: 5190 Loss: 2.0638630390167236  acc_train_error 47.6%  acc_test_error 50.0%\n",
      "Epoch: 5191 Loss: 2.0629241466522217  acc_train_error 47.6%  acc_test_error 50.0%\n",
      "Epoch: 5192 Loss: 2.0619874000549316  acc_train_error 47.6125%  acc_test_error 50.0%\n",
      "Epoch: 5193 Loss: 2.061049222946167  acc_train_error 47.625%  acc_test_error 50.0%\n",
      "Epoch: 5194 Loss: 2.060112953186035  acc_train_error 47.6375%  acc_test_error 50.0%\n",
      "Epoch: 5195 Loss: 2.059178352355957  acc_train_error 47.65%  acc_test_error 50.0%\n",
      "Epoch: 5196 Loss: 2.0582447052001953  acc_train_error 47.6625%  acc_test_error 50.0%\n",
      "Epoch: 5197 Loss: 2.057309150695801  acc_train_error 47.6625%  acc_test_error 50.0%\n",
      "Epoch: 5198 Loss: 2.056375026702881  acc_train_error 47.6625%  acc_test_error 50.0%\n",
      "Epoch: 5199 Loss: 2.0554397106170654  acc_train_error 47.6875%  acc_test_error 50.0%\n",
      "Epoch: 5200 Loss: 2.054503917694092  acc_train_error 47.6875%  acc_test_error 50.0%\n",
      "Epoch: 5201 Loss: 2.0535707473754883  acc_train_error 47.6875%  acc_test_error 50.0%\n",
      "Epoch: 5202 Loss: 2.052635908126831  acc_train_error 47.7%  acc_test_error 50.0%\n",
      "Epoch: 5203 Loss: 2.0517029762268066  acc_train_error 47.7%  acc_test_error 50.0%\n",
      "Epoch: 5204 Loss: 2.050772190093994  acc_train_error 47.7%  acc_test_error 50.0%\n",
      "Epoch: 5205 Loss: 2.0498363971710205  acc_train_error 47.7125%  acc_test_error 50.0%\n",
      "Epoch: 5206 Loss: 2.0489072799682617  acc_train_error 47.725%  acc_test_error 50.0%\n",
      "Epoch: 5207 Loss: 2.047985553741455  acc_train_error 47.7375%  acc_test_error 50.0%\n",
      "Epoch: 5208 Loss: 2.0470502376556396  acc_train_error 47.75%  acc_test_error 50.0%\n",
      "Epoch: 5209 Loss: 2.046119451522827  acc_train_error 47.7625%  acc_test_error 50.0%\n",
      "Epoch: 5210 Loss: 2.0451881885528564  acc_train_error 47.775%  acc_test_error 50.0%\n",
      "Epoch: 5211 Loss: 2.0442593097686768  acc_train_error 47.8%  acc_test_error 50.0%\n",
      "Epoch: 5212 Loss: 2.0433292388916016  acc_train_error 47.825%  acc_test_error 50.0%\n",
      "Epoch: 5213 Loss: 2.042396068572998  acc_train_error 47.8375%  acc_test_error 50.0%\n",
      "Epoch: 5214 Loss: 2.041465997695923  acc_train_error 47.85%  acc_test_error 50.0%\n",
      "Epoch: 5215 Loss: 2.0405361652374268  acc_train_error 47.8625%  acc_test_error 50.0%\n",
      "Epoch: 5216 Loss: 2.039608955383301  acc_train_error 47.8875%  acc_test_error 50.0%\n",
      "Epoch: 5217 Loss: 2.038689613342285  acc_train_error 47.9%  acc_test_error 50.0%\n",
      "Epoch: 5218 Loss: 2.0377585887908936  acc_train_error 47.925%  acc_test_error 50.0%\n",
      "Epoch: 5219 Loss: 2.036832094192505  acc_train_error 47.9375%  acc_test_error 50.0%\n",
      "Epoch: 5220 Loss: 2.035902976989746  acc_train_error 47.95%  acc_test_error 50.0%\n",
      "Epoch: 5221 Loss: 2.0349745750427246  acc_train_error 47.9625%  acc_test_error 50.0%\n",
      "Epoch: 5222 Loss: 2.034048080444336  acc_train_error 47.9625%  acc_test_error 50.0%\n",
      "Epoch: 5223 Loss: 2.0331194400787354  acc_train_error 47.975%  acc_test_error 50.0%\n",
      "Epoch: 5224 Loss: 2.032195568084717  acc_train_error 47.9875%  acc_test_error 50.0%\n",
      "Epoch: 5225 Loss: 2.0312745571136475  acc_train_error 48.025%  acc_test_error 50.0%\n",
      "Epoch: 5226 Loss: 2.0303492546081543  acc_train_error 48.05%  acc_test_error 50.0%\n",
      "Epoch: 5227 Loss: 2.029428243637085  acc_train_error 48.05%  acc_test_error 50.0%\n",
      "Epoch: 5228 Loss: 2.028501033782959  acc_train_error 48.0625%  acc_test_error 50.0%\n",
      "Epoch: 5229 Loss: 2.0275778770446777  acc_train_error 48.075%  acc_test_error 50.0%\n",
      "Epoch: 5230 Loss: 2.0266549587249756  acc_train_error 48.0875%  acc_test_error 50.0%\n",
      "Epoch: 5231 Loss: 2.0257315635681152  acc_train_error 48.1125%  acc_test_error 50.0%\n",
      "Epoch: 5232 Loss: 2.024810552597046  acc_train_error 48.1625%  acc_test_error 50.0%\n",
      "Epoch: 5233 Loss: 2.023886203765869  acc_train_error 48.1875%  acc_test_error 50.0%\n",
      "Epoch: 5234 Loss: 2.0229651927948  acc_train_error 48.2125%  acc_test_error 50.0%\n",
      "Epoch: 5235 Loss: 2.0220534801483154  acc_train_error 48.225%  acc_test_error 50.0%\n",
      "Epoch: 5236 Loss: 2.0211293697357178  acc_train_error 48.25%  acc_test_error 50.0%\n",
      "Epoch: 5237 Loss: 2.0202088356018066  acc_train_error 48.2625%  acc_test_error 50.0%\n",
      "Epoch: 5238 Loss: 2.0192880630493164  acc_train_error 48.275%  acc_test_error 50.0%\n",
      "Epoch: 5239 Loss: 2.0183663368225098  acc_train_error 48.3%  acc_test_error 50.0%\n",
      "Epoch: 5240 Loss: 2.017451524734497  acc_train_error 48.3125%  acc_test_error 50.0%\n",
      "Epoch: 5241 Loss: 2.0165324211120605  acc_train_error 48.3375%  acc_test_error 50.0%\n",
      "Epoch: 5242 Loss: 2.0156118869781494  acc_train_error 48.3875%  acc_test_error 50.0%\n",
      "Epoch: 5243 Loss: 2.014694929122925  acc_train_error 48.4625%  acc_test_error 50.0%\n",
      "Epoch: 5244 Loss: 2.0137784481048584  acc_train_error 48.5125%  acc_test_error 50.0%\n",
      "Epoch: 5245 Loss: 2.0128695964813232  acc_train_error 48.55%  acc_test_error 50.0%\n",
      "Epoch: 5246 Loss: 2.0119545459747314  acc_train_error 48.55%  acc_test_error 50.0%\n",
      "Epoch: 5247 Loss: 2.0110366344451904  acc_train_error 48.55%  acc_test_error 50.0%\n",
      "Epoch: 5248 Loss: 2.0101208686828613  acc_train_error 48.55%  acc_test_error 50.0%\n",
      "Epoch: 5249 Loss: 2.0092034339904785  acc_train_error 48.55%  acc_test_error 50.0%\n",
      "Epoch: 5250 Loss: 2.0082900524139404  acc_train_error 48.55%  acc_test_error 50.0%\n",
      "Epoch: 5251 Loss: 2.0073771476745605  acc_train_error 48.55%  acc_test_error 50.0%\n",
      "Epoch: 5252 Loss: 2.006462335586548  acc_train_error 48.55%  acc_test_error 50.0%\n",
      "Epoch: 5253 Loss: 2.0055458545684814  acc_train_error 48.55%  acc_test_error 50.0%\n",
      "Epoch: 5254 Loss: 2.004636764526367  acc_train_error 48.55%  acc_test_error 50.0%\n",
      "Epoch: 5255 Loss: 2.003727912902832  acc_train_error 48.55%  acc_test_error 50.0%\n",
      "Epoch: 5256 Loss: 2.0028159618377686  acc_train_error 48.55%  acc_test_error 50.0%\n",
      "Epoch: 5257 Loss: 2.0019028186798096  acc_train_error 48.55%  acc_test_error 50.0%\n",
      "Epoch: 5258 Loss: 2.000992774963379  acc_train_error 48.55%  acc_test_error 50.0%\n",
      "Epoch: 5259 Loss: 2.00008225440979  acc_train_error 48.55%  acc_test_error 50.0%\n",
      "Epoch: 5260 Loss: 1.9991700649261475  acc_train_error 48.5625%  acc_test_error 50.0%\n",
      "Epoch: 5261 Loss: 1.9982609748840332  acc_train_error 48.5625%  acc_test_error 50.0%\n",
      "Epoch: 5262 Loss: 1.9973450899124146  acc_train_error 48.5625%  acc_test_error 50.0%\n",
      "Epoch: 5263 Loss: 1.9964325428009033  acc_train_error 48.5625%  acc_test_error 50.0%\n",
      "Epoch: 5264 Loss: 1.9955207109451294  acc_train_error 48.5625%  acc_test_error 50.0%\n",
      "Epoch: 5265 Loss: 1.99461829662323  acc_train_error 48.5625%  acc_test_error 50.0%\n",
      "Epoch: 5266 Loss: 1.9936988353729248  acc_train_error 48.5625%  acc_test_error 50.0%\n",
      "Epoch: 5267 Loss: 1.9927846193313599  acc_train_error 48.5625%  acc_test_error 50.0%\n",
      "Epoch: 5268 Loss: 1.9918732643127441  acc_train_error 48.5625%  acc_test_error 50.0%\n",
      "Epoch: 5269 Loss: 1.9909498691558838  acc_train_error 48.5625%  acc_test_error 50.0%\n",
      "Epoch: 5270 Loss: 1.9900319576263428  acc_train_error 48.5625%  acc_test_error 50.0%\n",
      "Epoch: 5271 Loss: 1.9891200065612793  acc_train_error 48.5625%  acc_test_error 50.0%\n",
      "Epoch: 5272 Loss: 1.9882087707519531  acc_train_error 48.5625%  acc_test_error 50.0%\n",
      "Epoch: 5273 Loss: 1.9872932434082031  acc_train_error 48.5625%  acc_test_error 50.0%\n",
      "Epoch: 5274 Loss: 1.986374855041504  acc_train_error 48.575%  acc_test_error 50.0%\n",
      "Epoch: 5275 Loss: 1.9854545593261719  acc_train_error 48.575%  acc_test_error 50.0%\n",
      "Epoch: 5276 Loss: 1.9845424890518188  acc_train_error 48.575%  acc_test_error 50.0%\n",
      "Epoch: 5277 Loss: 1.9836307764053345  acc_train_error 48.575%  acc_test_error 50.0%\n",
      "Epoch: 5278 Loss: 1.982735276222229  acc_train_error 48.575%  acc_test_error 50.0%\n",
      "Epoch: 5279 Loss: 1.9818311929702759  acc_train_error 48.575%  acc_test_error 50.0%\n",
      "Epoch: 5280 Loss: 1.980928897857666  acc_train_error 48.5625%  acc_test_error 50.0%\n",
      "Epoch: 5281 Loss: 1.980027198791504  acc_train_error 48.5625%  acc_test_error 50.0%\n",
      "Epoch: 5282 Loss: 1.9791287183761597  acc_train_error 48.5625%  acc_test_error 50.0%\n",
      "Epoch: 5283 Loss: 1.9782273769378662  acc_train_error 48.5625%  acc_test_error 50.0%\n",
      "Epoch: 5284 Loss: 1.9773283004760742  acc_train_error 48.5625%  acc_test_error 50.0%\n",
      "Epoch: 5285 Loss: 1.976431965827942  acc_train_error 48.5625%  acc_test_error 50.0%\n",
      "Epoch: 5286 Loss: 1.9755353927612305  acc_train_error 48.5625%  acc_test_error 50.0%\n",
      "Epoch: 5287 Loss: 1.974635362625122  acc_train_error 48.5625%  acc_test_error 50.0%\n",
      "Epoch: 5288 Loss: 1.973736047744751  acc_train_error 48.5625%  acc_test_error 50.0%\n",
      "Epoch: 5289 Loss: 1.97283935546875  acc_train_error 48.5625%  acc_test_error 50.0%\n",
      "Epoch: 5290 Loss: 1.971940040588379  acc_train_error 48.5625%  acc_test_error 50.0%\n",
      "Epoch: 5291 Loss: 1.9710443019866943  acc_train_error 48.5625%  acc_test_error 50.0%\n",
      "Epoch: 5292 Loss: 1.9701470136642456  acc_train_error 48.5625%  acc_test_error 50.0%\n",
      "Epoch: 5293 Loss: 1.969257116317749  acc_train_error 48.5625%  acc_test_error 50.0%\n",
      "Epoch: 5294 Loss: 1.9683603048324585  acc_train_error 48.5625%  acc_test_error 50.0%\n",
      "Epoch: 5295 Loss: 1.9674627780914307  acc_train_error 48.5625%  acc_test_error 50.0%\n",
      "Epoch: 5296 Loss: 1.9665683507919312  acc_train_error 48.5625%  acc_test_error 50.0%\n",
      "Epoch: 5297 Loss: 1.9656730890274048  acc_train_error 48.5625%  acc_test_error 50.0%\n",
      "Epoch: 5298 Loss: 1.9647774696350098  acc_train_error 48.5625%  acc_test_error 50.0%\n",
      "Epoch: 5299 Loss: 1.9638844728469849  acc_train_error 48.5625%  acc_test_error 50.0%\n",
      "Epoch: 5300 Loss: 1.9629943370819092  acc_train_error 48.5625%  acc_test_error 50.0%\n",
      "Epoch: 5301 Loss: 1.9621034860610962  acc_train_error 48.5625%  acc_test_error 50.0%\n",
      "Epoch: 5302 Loss: 1.9612085819244385  acc_train_error 48.5625%  acc_test_error 50.0%\n",
      "Epoch: 5303 Loss: 1.9603158235549927  acc_train_error 48.5625%  acc_test_error 50.0%\n",
      "Epoch: 5304 Loss: 1.9594221115112305  acc_train_error 48.5625%  acc_test_error 50.0%\n",
      "Epoch: 5305 Loss: 1.9585307836532593  acc_train_error 48.5625%  acc_test_error 50.0%\n",
      "Epoch: 5306 Loss: 1.9576389789581299  acc_train_error 48.5625%  acc_test_error 50.0%\n",
      "Epoch: 5307 Loss: 1.956751823425293  acc_train_error 48.5625%  acc_test_error 50.0%\n",
      "Epoch: 5308 Loss: 1.9558653831481934  acc_train_error 48.5625%  acc_test_error 50.0%\n",
      "Epoch: 5309 Loss: 1.9549707174301147  acc_train_error 48.5625%  acc_test_error 50.0%\n",
      "Epoch: 5310 Loss: 1.954076886177063  acc_train_error 48.5625%  acc_test_error 50.0%\n",
      "Epoch: 5311 Loss: 1.9531856775283813  acc_train_error 48.5625%  acc_test_error 50.0%\n",
      "Epoch: 5312 Loss: 1.9522936344146729  acc_train_error 48.5625%  acc_test_error 50.0%\n",
      "Epoch: 5313 Loss: 1.951404333114624  acc_train_error 48.5625%  acc_test_error 50.0%\n",
      "Epoch: 5314 Loss: 1.9505223035812378  acc_train_error 48.5625%  acc_test_error 50.0%\n",
      "Epoch: 5315 Loss: 1.949633002281189  acc_train_error 48.5625%  acc_test_error 50.0%\n",
      "Epoch: 5316 Loss: 1.9487420320510864  acc_train_error 48.5625%  acc_test_error 50.0%\n",
      "Epoch: 5317 Loss: 1.9478527307510376  acc_train_error 48.5625%  acc_test_error 50.0%\n",
      "Epoch: 5318 Loss: 1.9469640254974365  acc_train_error 48.5625%  acc_test_error 50.0%\n",
      "Epoch: 5319 Loss: 1.9460746049880981  acc_train_error 48.5625%  acc_test_error 50.0%\n",
      "Epoch: 5320 Loss: 1.9451942443847656  acc_train_error 48.5625%  acc_test_error 50.0%\n",
      "Epoch: 5321 Loss: 1.9443068504333496  acc_train_error 48.5625%  acc_test_error 50.0%\n",
      "Epoch: 5322 Loss: 1.9434210062026978  acc_train_error 48.5625%  acc_test_error 50.0%\n",
      "Epoch: 5323 Loss: 1.9425280094146729  acc_train_error 48.5625%  acc_test_error 50.0%\n",
      "Epoch: 5324 Loss: 1.9415687322616577  acc_train_error 48.575%  acc_test_error 50.0%\n",
      "Epoch: 5325 Loss: 1.94064462184906  acc_train_error 48.575%  acc_test_error 50.0%\n",
      "Epoch: 5326 Loss: 1.9397037029266357  acc_train_error 48.575%  acc_test_error 50.0%\n",
      "Epoch: 5327 Loss: 1.9387497901916504  acc_train_error 48.5875%  acc_test_error 50.0%\n",
      "Epoch: 5328 Loss: 1.9378021955490112  acc_train_error 48.5875%  acc_test_error 50.0%\n",
      "Epoch: 5329 Loss: 1.9368830919265747  acc_train_error 48.5875%  acc_test_error 50.0%\n",
      "Epoch: 5330 Loss: 1.9359626770019531  acc_train_error 48.5875%  acc_test_error 50.0%\n",
      "Epoch: 5331 Loss: 1.9350268840789795  acc_train_error 48.6%  acc_test_error 50.0%\n",
      "Epoch: 5332 Loss: 1.9341338872909546  acc_train_error 48.6%  acc_test_error 50.0%\n",
      "Epoch: 5333 Loss: 1.9332301616668701  acc_train_error 48.6125%  acc_test_error 50.0%\n",
      "Epoch: 5334 Loss: 1.932349443435669  acc_train_error 48.6125%  acc_test_error 50.0%\n",
      "Epoch: 5335 Loss: 1.9314366579055786  acc_train_error 48.6125%  acc_test_error 50.0%\n",
      "Epoch: 5336 Loss: 1.9305329322814941  acc_train_error 48.6125%  acc_test_error 50.0%\n",
      "Epoch: 5337 Loss: 1.9296300411224365  acc_train_error 48.6125%  acc_test_error 50.0%\n",
      "Epoch: 5338 Loss: 1.9287477731704712  acc_train_error 48.6125%  acc_test_error 50.0%\n",
      "Epoch: 5339 Loss: 1.9278490543365479  acc_train_error 48.6125%  acc_test_error 50.0%\n",
      "Epoch: 5340 Loss: 1.926945686340332  acc_train_error 48.6125%  acc_test_error 50.0%\n",
      "Epoch: 5341 Loss: 1.9260528087615967  acc_train_error 48.6125%  acc_test_error 50.0%\n",
      "Epoch: 5342 Loss: 1.9251681566238403  acc_train_error 48.625%  acc_test_error 50.0%\n",
      "Epoch: 5343 Loss: 1.9242559671401978  acc_train_error 48.625%  acc_test_error 50.0%\n",
      "Epoch: 5344 Loss: 1.9233847856521606  acc_train_error 48.625%  acc_test_error 50.0%\n",
      "Epoch: 5345 Loss: 1.9224886894226074  acc_train_error 48.6375%  acc_test_error 50.0%\n",
      "Epoch: 5346 Loss: 1.9216058254241943  acc_train_error 48.6375%  acc_test_error 50.0%\n",
      "Epoch: 5347 Loss: 1.9207158088684082  acc_train_error 48.6375%  acc_test_error 50.0%\n",
      "Epoch: 5348 Loss: 1.9198259115219116  acc_train_error 48.6375%  acc_test_error 50.0%\n",
      "Epoch: 5349 Loss: 1.918934941291809  acc_train_error 48.6375%  acc_test_error 50.0%\n",
      "Epoch: 5350 Loss: 1.9180558919906616  acc_train_error 48.6375%  acc_test_error 50.0%\n",
      "Epoch: 5351 Loss: 1.9171786308288574  acc_train_error 48.6375%  acc_test_error 50.0%\n",
      "Epoch: 5352 Loss: 1.9162890911102295  acc_train_error 48.65%  acc_test_error 50.0%\n",
      "Epoch: 5353 Loss: 1.9154012203216553  acc_train_error 48.65%  acc_test_error 50.0%\n",
      "Epoch: 5354 Loss: 1.9145162105560303  acc_train_error 48.65%  acc_test_error 50.0%\n",
      "Epoch: 5355 Loss: 1.9136543273925781  acc_train_error 48.65%  acc_test_error 50.0%\n",
      "Epoch: 5356 Loss: 1.9127602577209473  acc_train_error 48.65%  acc_test_error 50.0%\n",
      "Epoch: 5357 Loss: 1.9118784666061401  acc_train_error 48.65%  acc_test_error 50.0%\n",
      "Epoch: 5358 Loss: 1.9109947681427002  acc_train_error 48.65%  acc_test_error 50.0%\n",
      "Epoch: 5359 Loss: 1.9101300239562988  acc_train_error 48.65%  acc_test_error 50.0%\n",
      "Epoch: 5360 Loss: 1.9092211723327637  acc_train_error 48.6625%  acc_test_error 50.0%\n",
      "Epoch: 5361 Loss: 1.9083645343780518  acc_train_error 48.6625%  acc_test_error 50.0%\n",
      "Epoch: 5362 Loss: 1.9074840545654297  acc_train_error 48.6625%  acc_test_error 50.0%\n",
      "Epoch: 5363 Loss: 1.9066146612167358  acc_train_error 48.6625%  acc_test_error 50.0%\n",
      "Epoch: 5364 Loss: 1.905734896659851  acc_train_error 48.6625%  acc_test_error 50.0%\n",
      "Epoch: 5365 Loss: 1.904854655265808  acc_train_error 48.6625%  acc_test_error 50.0%\n",
      "Epoch: 5366 Loss: 1.9039742946624756  acc_train_error 48.6625%  acc_test_error 50.0%\n",
      "Epoch: 5367 Loss: 1.9031038284301758  acc_train_error 48.675%  acc_test_error 50.0%\n",
      "Epoch: 5368 Loss: 1.9022318124771118  acc_train_error 48.675%  acc_test_error 50.0%\n",
      "Epoch: 5369 Loss: 1.9013526439666748  acc_train_error 48.675%  acc_test_error 50.0%\n",
      "Epoch: 5370 Loss: 1.9004530906677246  acc_train_error 48.675%  acc_test_error 50.0%\n",
      "Epoch: 5371 Loss: 1.8996044397354126  acc_train_error 48.675%  acc_test_error 50.0%\n",
      "Epoch: 5372 Loss: 1.8987479209899902  acc_train_error 48.675%  acc_test_error 50.0%\n",
      "Epoch: 5373 Loss: 1.8978627920150757  acc_train_error 48.675%  acc_test_error 50.0%\n",
      "Epoch: 5374 Loss: 1.8969863653182983  acc_train_error 48.675%  acc_test_error 50.0%\n",
      "Epoch: 5375 Loss: 1.8961106538772583  acc_train_error 48.675%  acc_test_error 50.0%\n",
      "Epoch: 5376 Loss: 1.8952511548995972  acc_train_error 48.675%  acc_test_error 50.0%\n",
      "Epoch: 5377 Loss: 1.8943549394607544  acc_train_error 48.675%  acc_test_error 50.0%\n",
      "Epoch: 5378 Loss: 1.8935067653656006  acc_train_error 48.6875%  acc_test_error 50.0%\n",
      "Epoch: 5379 Loss: 1.8926323652267456  acc_train_error 48.6875%  acc_test_error 50.0%\n",
      "Epoch: 5380 Loss: 1.891767978668213  acc_train_error 48.6875%  acc_test_error 50.0%\n",
      "Epoch: 5381 Loss: 1.8909000158309937  acc_train_error 48.6875%  acc_test_error 50.0%\n",
      "Epoch: 5382 Loss: 1.8900246620178223  acc_train_error 48.6875%  acc_test_error 50.0%\n",
      "Epoch: 5383 Loss: 1.889154076576233  acc_train_error 48.7%  acc_test_error 50.0%\n",
      "Epoch: 5384 Loss: 1.888262152671814  acc_train_error 48.7%  acc_test_error 50.0%\n",
      "Epoch: 5385 Loss: 1.887439250946045  acc_train_error 48.7%  acc_test_error 50.0%\n",
      "Epoch: 5386 Loss: 1.8865580558776855  acc_train_error 48.7%  acc_test_error 50.0%\n",
      "Epoch: 5387 Loss: 1.88568913936615  acc_train_error 48.7%  acc_test_error 50.0%\n",
      "Epoch: 5388 Loss: 1.884818196296692  acc_train_error 48.7%  acc_test_error 50.0%\n",
      "Epoch: 5389 Loss: 1.8839620351791382  acc_train_error 48.7%  acc_test_error 50.0%\n",
      "Epoch: 5390 Loss: 1.8830726146697998  acc_train_error 48.7%  acc_test_error 50.0%\n",
      "Epoch: 5391 Loss: 1.8822296857833862  acc_train_error 48.7%  acc_test_error 50.0%\n",
      "Epoch: 5392 Loss: 1.8813592195510864  acc_train_error 48.7%  acc_test_error 50.0%\n",
      "Epoch: 5393 Loss: 1.8804996013641357  acc_train_error 48.7%  acc_test_error 50.0%\n",
      "Epoch: 5394 Loss: 1.8796347379684448  acc_train_error 48.7%  acc_test_error 50.0%\n",
      "Epoch: 5395 Loss: 1.8787702322006226  acc_train_error 48.7%  acc_test_error 50.0%\n",
      "Epoch: 5396 Loss: 1.8778825998306274  acc_train_error 48.7%  acc_test_error 50.0%\n",
      "Epoch: 5397 Loss: 1.8770461082458496  acc_train_error 48.7%  acc_test_error 50.0%\n",
      "Epoch: 5398 Loss: 1.8761906623840332  acc_train_error 48.7%  acc_test_error 50.0%\n",
      "Epoch: 5399 Loss: 1.875330924987793  acc_train_error 48.7125%  acc_test_error 50.0%\n",
      "Epoch: 5400 Loss: 1.874459981918335  acc_train_error 48.7125%  acc_test_error 50.0%\n",
      "Epoch: 5401 Loss: 1.8736116886138916  acc_train_error 48.7125%  acc_test_error 50.0%\n",
      "Epoch: 5402 Loss: 1.8727467060089111  acc_train_error 48.7125%  acc_test_error 50.0%\n",
      "Epoch: 5403 Loss: 1.8718931674957275  acc_train_error 48.7125%  acc_test_error 50.0%\n",
      "Epoch: 5404 Loss: 1.871045470237732  acc_train_error 48.7125%  acc_test_error 50.0%\n",
      "Epoch: 5405 Loss: 1.8702037334442139  acc_train_error 48.7125%  acc_test_error 50.0%\n",
      "Epoch: 5406 Loss: 1.8693301677703857  acc_train_error 48.7125%  acc_test_error 50.0%\n",
      "Epoch: 5407 Loss: 1.8684805631637573  acc_train_error 48.7125%  acc_test_error 50.0%\n",
      "Epoch: 5408 Loss: 1.8676279783248901  acc_train_error 48.7125%  acc_test_error 50.0%\n",
      "Epoch: 5409 Loss: 1.8667715787887573  acc_train_error 48.7125%  acc_test_error 50.0%\n",
      "Epoch: 5410 Loss: 1.8659213781356812  acc_train_error 48.7125%  acc_test_error 50.0%\n",
      "Epoch: 5411 Loss: 1.8650622367858887  acc_train_error 48.7125%  acc_test_error 50.0%\n",
      "Epoch: 5412 Loss: 1.8642237186431885  acc_train_error 48.7125%  acc_test_error 50.0%\n",
      "Epoch: 5413 Loss: 1.8633654117584229  acc_train_error 48.7125%  acc_test_error 50.0%\n",
      "Epoch: 5414 Loss: 1.8625060319900513  acc_train_error 48.7125%  acc_test_error 50.0%\n",
      "Epoch: 5415 Loss: 1.8616653680801392  acc_train_error 48.7125%  acc_test_error 50.0%\n",
      "Epoch: 5416 Loss: 1.8607981204986572  acc_train_error 48.7125%  acc_test_error 50.0%\n",
      "Epoch: 5417 Loss: 1.8599482774734497  acc_train_error 48.7125%  acc_test_error 50.0%\n",
      "Epoch: 5418 Loss: 1.8591022491455078  acc_train_error 48.7125%  acc_test_error 50.0%\n",
      "Epoch: 5419 Loss: 1.8582499027252197  acc_train_error 48.7125%  acc_test_error 50.0%\n",
      "Epoch: 5420 Loss: 1.857405424118042  acc_train_error 48.7125%  acc_test_error 50.0%\n",
      "Epoch: 5421 Loss: 1.8565489053726196  acc_train_error 48.7125%  acc_test_error 50.0%\n",
      "Epoch: 5422 Loss: 1.8557041883468628  acc_train_error 48.7125%  acc_test_error 50.0%\n",
      "Epoch: 5423 Loss: 1.8548420667648315  acc_train_error 48.7125%  acc_test_error 50.0%\n",
      "Epoch: 5424 Loss: 1.8539925813674927  acc_train_error 48.7125%  acc_test_error 50.0%\n",
      "Epoch: 5425 Loss: 1.8531498908996582  acc_train_error 48.7125%  acc_test_error 50.0%\n",
      "Epoch: 5426 Loss: 1.8522999286651611  acc_train_error 48.7125%  acc_test_error 50.0%\n",
      "Epoch: 5427 Loss: 1.8514567613601685  acc_train_error 48.7125%  acc_test_error 50.0%\n",
      "Epoch: 5428 Loss: 1.8506029844284058  acc_train_error 48.7125%  acc_test_error 50.0%\n",
      "Epoch: 5429 Loss: 1.8497596979141235  acc_train_error 48.7125%  acc_test_error 50.0%\n",
      "Epoch: 5430 Loss: 1.8488991260528564  acc_train_error 48.7125%  acc_test_error 50.0%\n",
      "Epoch: 5431 Loss: 1.848046898841858  acc_train_error 48.7125%  acc_test_error 50.0%\n",
      "Epoch: 5432 Loss: 1.8472119569778442  acc_train_error 48.7125%  acc_test_error 50.0%\n",
      "Epoch: 5433 Loss: 1.8463600873947144  acc_train_error 48.7125%  acc_test_error 50.0%\n",
      "Epoch: 5434 Loss: 1.8455185890197754  acc_train_error 48.725%  acc_test_error 50.0%\n",
      "Epoch: 5435 Loss: 1.8446663618087769  acc_train_error 48.7125%  acc_test_error 50.0%\n",
      "Epoch: 5436 Loss: 1.8438260555267334  acc_train_error 48.7125%  acc_test_error 50.0%\n",
      "Epoch: 5437 Loss: 1.8429665565490723  acc_train_error 48.725%  acc_test_error 50.0%\n",
      "Epoch: 5438 Loss: 1.8421199321746826  acc_train_error 48.725%  acc_test_error 50.0%\n",
      "Epoch: 5439 Loss: 1.8412853479385376  acc_train_error 48.725%  acc_test_error 50.0%\n",
      "Epoch: 5440 Loss: 1.8404337167739868  acc_train_error 48.725%  acc_test_error 50.0%\n",
      "Epoch: 5441 Loss: 1.839606523513794  acc_train_error 48.725%  acc_test_error 50.0%\n",
      "Epoch: 5442 Loss: 1.8387346267700195  acc_train_error 48.725%  acc_test_error 50.0%\n",
      "Epoch: 5443 Loss: 1.8378952741622925  acc_train_error 48.725%  acc_test_error 50.0%\n",
      "Epoch: 5444 Loss: 1.8370490074157715  acc_train_error 48.725%  acc_test_error 50.0%\n",
      "Epoch: 5445 Loss: 1.8362011909484863  acc_train_error 48.725%  acc_test_error 50.0%\n",
      "Epoch: 5446 Loss: 1.83537757396698  acc_train_error 48.725%  acc_test_error 50.0%\n",
      "Epoch: 5447 Loss: 1.8344833850860596  acc_train_error 48.725%  acc_test_error 50.0%\n",
      "Epoch: 5448 Loss: 1.8336466550827026  acc_train_error 48.725%  acc_test_error 50.0%\n",
      "Epoch: 5449 Loss: 1.8327667713165283  acc_train_error 48.7375%  acc_test_error 50.0%\n",
      "Epoch: 5450 Loss: 1.8319141864776611  acc_train_error 48.725%  acc_test_error 50.0%\n",
      "Epoch: 5451 Loss: 1.8310580253601074  acc_train_error 48.7375%  acc_test_error 50.0%\n",
      "Epoch: 5452 Loss: 1.830203652381897  acc_train_error 48.7375%  acc_test_error 50.0%\n",
      "Epoch: 5453 Loss: 1.8293583393096924  acc_train_error 48.7375%  acc_test_error 50.0%\n",
      "Epoch: 5454 Loss: 1.8284986019134521  acc_train_error 48.7375%  acc_test_error 50.0%\n",
      "Epoch: 5455 Loss: 1.8276536464691162  acc_train_error 48.7375%  acc_test_error 50.0%\n",
      "Epoch: 5456 Loss: 1.8267847299575806  acc_train_error 48.7375%  acc_test_error 50.0%\n",
      "Epoch: 5457 Loss: 1.825934648513794  acc_train_error 48.7375%  acc_test_error 50.0%\n",
      "Epoch: 5458 Loss: 1.8250871896743774  acc_train_error 48.7375%  acc_test_error 50.0%\n",
      "Epoch: 5459 Loss: 1.8242435455322266  acc_train_error 48.7375%  acc_test_error 50.0%\n",
      "Epoch: 5460 Loss: 1.8234186172485352  acc_train_error 48.7375%  acc_test_error 50.0%\n",
      "Epoch: 5461 Loss: 1.8225605487823486  acc_train_error 48.75%  acc_test_error 50.0%\n",
      "Epoch: 5462 Loss: 1.8217253684997559  acc_train_error 48.75%  acc_test_error 50.0%\n",
      "Epoch: 5463 Loss: 1.8208861351013184  acc_train_error 48.75%  acc_test_error 50.0%\n",
      "Epoch: 5464 Loss: 1.8200438022613525  acc_train_error 48.75%  acc_test_error 50.0%\n",
      "Epoch: 5465 Loss: 1.8192142248153687  acc_train_error 48.75%  acc_test_error 50.0%\n",
      "Epoch: 5466 Loss: 1.8183743953704834  acc_train_error 48.75%  acc_test_error 50.0%\n",
      "Epoch: 5467 Loss: 1.8175303936004639  acc_train_error 48.75%  acc_test_error 50.0%\n",
      "Epoch: 5468 Loss: 1.8167027235031128  acc_train_error 48.75%  acc_test_error 50.0%\n",
      "Epoch: 5469 Loss: 1.8158543109893799  acc_train_error 48.75%  acc_test_error 50.0%\n",
      "Epoch: 5470 Loss: 1.815014123916626  acc_train_error 48.75%  acc_test_error 50.0%\n",
      "Epoch: 5471 Loss: 1.8141975402832031  acc_train_error 48.75%  acc_test_error 50.0%\n",
      "Epoch: 5472 Loss: 1.8133492469787598  acc_train_error 48.75%  acc_test_error 50.0%\n",
      "Epoch: 5473 Loss: 1.8125108480453491  acc_train_error 48.75%  acc_test_error 50.0%\n",
      "Epoch: 5474 Loss: 1.8116775751113892  acc_train_error 48.75%  acc_test_error 50.0%\n",
      "Epoch: 5475 Loss: 1.8108375072479248  acc_train_error 48.75%  acc_test_error 50.0%\n",
      "Epoch: 5476 Loss: 1.8099967241287231  acc_train_error 48.75%  acc_test_error 50.0%\n",
      "Epoch: 5477 Loss: 1.8091760873794556  acc_train_error 48.75%  acc_test_error 50.0%\n",
      "Epoch: 5478 Loss: 1.8083330392837524  acc_train_error 48.75%  acc_test_error 50.0%\n",
      "Epoch: 5479 Loss: 1.8075103759765625  acc_train_error 48.75%  acc_test_error 50.0%\n",
      "Epoch: 5480 Loss: 1.8066619634628296  acc_train_error 48.75%  acc_test_error 50.0%\n",
      "Epoch: 5481 Loss: 1.8058217763900757  acc_train_error 48.75%  acc_test_error 50.0%\n",
      "Epoch: 5482 Loss: 1.8049920797348022  acc_train_error 48.75%  acc_test_error 50.0%\n",
      "Epoch: 5483 Loss: 1.8041657209396362  acc_train_error 48.75%  acc_test_error 50.0%\n",
      "Epoch: 5484 Loss: 1.8033138513565063  acc_train_error 48.75%  acc_test_error 50.0%\n",
      "Epoch: 5485 Loss: 1.8024933338165283  acc_train_error 48.75%  acc_test_error 50.0%\n",
      "Epoch: 5486 Loss: 1.801661729812622  acc_train_error 48.75%  acc_test_error 50.0%\n",
      "Epoch: 5487 Loss: 1.8008249998092651  acc_train_error 48.75%  acc_test_error 50.0%\n",
      "Epoch: 5488 Loss: 1.7999955415725708  acc_train_error 48.75%  acc_test_error 50.0%\n",
      "Epoch: 5489 Loss: 1.79917311668396  acc_train_error 48.7625%  acc_test_error 50.0%\n",
      "Epoch: 5490 Loss: 1.7983424663543701  acc_train_error 48.7625%  acc_test_error 50.0%\n",
      "Epoch: 5491 Loss: 1.797508716583252  acc_train_error 48.7625%  acc_test_error 50.0%\n",
      "Epoch: 5492 Loss: 1.79667067527771  acc_train_error 48.7625%  acc_test_error 50.0%\n",
      "Epoch: 5493 Loss: 1.7958550453186035  acc_train_error 48.7625%  acc_test_error 50.0%\n",
      "Epoch: 5494 Loss: 1.7950224876403809  acc_train_error 48.7625%  acc_test_error 50.0%\n",
      "Epoch: 5495 Loss: 1.7942008972167969  acc_train_error 48.7625%  acc_test_error 50.0%\n",
      "Epoch: 5496 Loss: 1.7933510541915894  acc_train_error 48.7625%  acc_test_error 50.0%\n",
      "Epoch: 5497 Loss: 1.7925151586532593  acc_train_error 48.7625%  acc_test_error 50.0%\n",
      "Epoch: 5498 Loss: 1.791717767715454  acc_train_error 48.7625%  acc_test_error 50.0%\n",
      "Epoch: 5499 Loss: 1.790879726409912  acc_train_error 48.7625%  acc_test_error 50.0%\n",
      "Epoch: 5500 Loss: 1.790061593055725  acc_train_error 48.7625%  acc_test_error 50.0%\n",
      "Epoch: 5501 Loss: 1.7892379760742188  acc_train_error 48.7625%  acc_test_error 50.0%\n",
      "Epoch: 5502 Loss: 1.788417935371399  acc_train_error 48.7625%  acc_test_error 50.0%\n",
      "Epoch: 5503 Loss: 1.787591814994812  acc_train_error 48.7625%  acc_test_error 50.0%\n",
      "Epoch: 5504 Loss: 1.78678560256958  acc_train_error 48.7625%  acc_test_error 50.0%\n",
      "Epoch: 5505 Loss: 1.7859623432159424  acc_train_error 48.7625%  acc_test_error 50.0%\n",
      "Epoch: 5506 Loss: 1.7851319313049316  acc_train_error 48.7625%  acc_test_error 50.0%\n",
      "Epoch: 5507 Loss: 1.784304141998291  acc_train_error 48.7625%  acc_test_error 50.0%\n",
      "Epoch: 5508 Loss: 1.7834758758544922  acc_train_error 48.7625%  acc_test_error 50.0%\n",
      "Epoch: 5509 Loss: 1.7826652526855469  acc_train_error 48.7625%  acc_test_error 50.0%\n",
      "Epoch: 5510 Loss: 1.7818350791931152  acc_train_error 48.7625%  acc_test_error 50.0%\n",
      "Epoch: 5511 Loss: 1.7810132503509521  acc_train_error 48.7625%  acc_test_error 50.0%\n",
      "Epoch: 5512 Loss: 1.7801833152770996  acc_train_error 48.7625%  acc_test_error 50.0%\n",
      "Epoch: 5513 Loss: 1.7793587446212769  acc_train_error 48.7625%  acc_test_error 50.0%\n",
      "Epoch: 5514 Loss: 1.7785298824310303  acc_train_error 48.7625%  acc_test_error 50.0%\n",
      "Epoch: 5515 Loss: 1.7776966094970703  acc_train_error 48.7625%  acc_test_error 50.0%\n",
      "Epoch: 5516 Loss: 1.7768698930740356  acc_train_error 48.775%  acc_test_error 50.0%\n",
      "Epoch: 5517 Loss: 1.7760335206985474  acc_train_error 48.775%  acc_test_error 50.0%\n",
      "Epoch: 5518 Loss: 1.77522611618042  acc_train_error 48.775%  acc_test_error 50.0%\n",
      "Epoch: 5519 Loss: 1.7743897438049316  acc_train_error 48.775%  acc_test_error 50.0%\n",
      "Epoch: 5520 Loss: 1.773573398590088  acc_train_error 48.775%  acc_test_error 50.0%\n",
      "Epoch: 5521 Loss: 1.7727429866790771  acc_train_error 48.775%  acc_test_error 50.0%\n",
      "Epoch: 5522 Loss: 1.7719331979751587  acc_train_error 48.775%  acc_test_error 50.0%\n",
      "Epoch: 5523 Loss: 1.771105170249939  acc_train_error 48.775%  acc_test_error 50.0%\n",
      "Epoch: 5524 Loss: 1.7702600955963135  acc_train_error 48.775%  acc_test_error 50.0%\n",
      "Epoch: 5525 Loss: 1.7694505453109741  acc_train_error 48.775%  acc_test_error 50.0%\n",
      "Epoch: 5526 Loss: 1.7686406373977661  acc_train_error 48.775%  acc_test_error 50.0%\n",
      "Epoch: 5527 Loss: 1.767811894416809  acc_train_error 48.775%  acc_test_error 50.0%\n",
      "Epoch: 5528 Loss: 1.7669851779937744  acc_train_error 48.775%  acc_test_error 50.0%\n",
      "Epoch: 5529 Loss: 1.7661715745925903  acc_train_error 48.775%  acc_test_error 50.0%\n",
      "Epoch: 5530 Loss: 1.7653347253799438  acc_train_error 48.775%  acc_test_error 50.0%\n",
      "Epoch: 5531 Loss: 1.7645015716552734  acc_train_error 48.775%  acc_test_error 50.0%\n",
      "Epoch: 5532 Loss: 1.7636950016021729  acc_train_error 48.775%  acc_test_error 50.0%\n",
      "Epoch: 5533 Loss: 1.7628681659698486  acc_train_error 48.775%  acc_test_error 50.0%\n",
      "Epoch: 5534 Loss: 1.7620313167572021  acc_train_error 48.775%  acc_test_error 50.0%\n",
      "Epoch: 5535 Loss: 1.761224627494812  acc_train_error 48.775%  acc_test_error 50.0%\n",
      "Epoch: 5536 Loss: 1.7604093551635742  acc_train_error 48.775%  acc_test_error 50.0%\n",
      "Epoch: 5537 Loss: 1.7595725059509277  acc_train_error 48.7875%  acc_test_error 50.0%\n",
      "Epoch: 5538 Loss: 1.7587428092956543  acc_train_error 48.7875%  acc_test_error 50.0%\n",
      "Epoch: 5539 Loss: 1.7579267024993896  acc_train_error 48.7875%  acc_test_error 50.0%\n",
      "Epoch: 5540 Loss: 1.7571130990982056  acc_train_error 48.7875%  acc_test_error 50.0%\n",
      "Epoch: 5541 Loss: 1.7562873363494873  acc_train_error 48.7875%  acc_test_error 50.0%\n",
      "Epoch: 5542 Loss: 1.7554510831832886  acc_train_error 48.7875%  acc_test_error 50.0%\n",
      "Epoch: 5543 Loss: 1.7546387910842896  acc_train_error 48.8%  acc_test_error 50.0%\n",
      "Epoch: 5544 Loss: 1.7538156509399414  acc_train_error 48.8%  acc_test_error 50.0%\n",
      "Epoch: 5545 Loss: 1.7529685497283936  acc_train_error 48.8%  acc_test_error 50.0%\n",
      "Epoch: 5546 Loss: 1.7521626949310303  acc_train_error 48.8%  acc_test_error 50.0%\n",
      "Epoch: 5547 Loss: 1.7513337135314941  acc_train_error 48.8%  acc_test_error 50.0%\n",
      "Epoch: 5548 Loss: 1.750501036643982  acc_train_error 48.8%  acc_test_error 50.0%\n",
      "Epoch: 5549 Loss: 1.749681830406189  acc_train_error 48.8%  acc_test_error 50.0%\n",
      "Epoch: 5550 Loss: 1.7488524913787842  acc_train_error 48.8%  acc_test_error 50.0%\n",
      "Epoch: 5551 Loss: 1.7480264902114868  acc_train_error 48.8%  acc_test_error 50.0%\n",
      "Epoch: 5552 Loss: 1.747198224067688  acc_train_error 48.8%  acc_test_error 50.0%\n",
      "Epoch: 5553 Loss: 1.7463746070861816  acc_train_error 48.8%  acc_test_error 50.0%\n",
      "Epoch: 5554 Loss: 1.7455523014068604  acc_train_error 48.8%  acc_test_error 50.0%\n",
      "Epoch: 5555 Loss: 1.7447203397750854  acc_train_error 48.8%  acc_test_error 50.0%\n",
      "Epoch: 5556 Loss: 1.7438973188400269  acc_train_error 48.8%  acc_test_error 50.0%\n",
      "Epoch: 5557 Loss: 1.7430833578109741  acc_train_error 48.8%  acc_test_error 50.0%\n",
      "Epoch: 5558 Loss: 1.7422429323196411  acc_train_error 48.8%  acc_test_error 50.0%\n",
      "Epoch: 5559 Loss: 1.7414536476135254  acc_train_error 48.8125%  acc_test_error 50.0%\n",
      "Epoch: 5560 Loss: 1.7406190633773804  acc_train_error 48.8125%  acc_test_error 50.0%\n",
      "Epoch: 5561 Loss: 1.7397958040237427  acc_train_error 48.8125%  acc_test_error 50.0%\n",
      "Epoch: 5562 Loss: 1.7390015125274658  acc_train_error 48.8125%  acc_test_error 50.0%\n",
      "Epoch: 5563 Loss: 1.7381722927093506  acc_train_error 48.8125%  acc_test_error 50.0%\n",
      "Epoch: 5564 Loss: 1.7373476028442383  acc_train_error 48.8125%  acc_test_error 50.0%\n",
      "Epoch: 5565 Loss: 1.736538290977478  acc_train_error 48.8125%  acc_test_error 50.0%\n",
      "Epoch: 5566 Loss: 1.7357313632965088  acc_train_error 48.8125%  acc_test_error 50.0%\n",
      "Epoch: 5567 Loss: 1.7348947525024414  acc_train_error 48.8125%  acc_test_error 50.0%\n",
      "Epoch: 5568 Loss: 1.7340935468673706  acc_train_error 48.8125%  acc_test_error 50.0%\n",
      "Epoch: 5569 Loss: 1.7332737445831299  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5570 Loss: 1.732469081878662  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5571 Loss: 1.731631875038147  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5572 Loss: 1.7308460474014282  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5573 Loss: 1.7299972772598267  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5574 Loss: 1.7291758060455322  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5575 Loss: 1.7283469438552856  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5576 Loss: 1.7275420427322388  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5577 Loss: 1.7267143726348877  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5578 Loss: 1.7258870601654053  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5579 Loss: 1.7250635623931885  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5580 Loss: 1.7242428064346313  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5581 Loss: 1.7234269380569458  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5582 Loss: 1.7225918769836426  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5583 Loss: 1.72174870967865  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5584 Loss: 1.720901608467102  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5585 Loss: 1.720069169998169  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5586 Loss: 1.7193686962127686  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5587 Loss: 1.7185155153274536  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5588 Loss: 1.7177547216415405  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5589 Loss: 1.7169630527496338  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5590 Loss: 1.7161482572555542  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5591 Loss: 1.7154076099395752  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5592 Loss: 1.7145475149154663  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5593 Loss: 1.713852047920227  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5594 Loss: 1.7129545211791992  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5595 Loss: 1.7122979164123535  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5596 Loss: 1.711431860923767  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5597 Loss: 1.7106770277023315  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5598 Loss: 1.7098876237869263  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5599 Loss: 1.7090860605239868  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5600 Loss: 1.7083375453948975  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5601 Loss: 1.7075127363204956  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5602 Loss: 1.7067373991012573  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5603 Loss: 1.7059937715530396  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5604 Loss: 1.7052001953125  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5605 Loss: 1.7044153213500977  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5606 Loss: 1.7036488056182861  acc_train_error 48.8375%  acc_test_error 50.0%\n",
      "Epoch: 5607 Loss: 1.7028502225875854  acc_train_error 48.8375%  acc_test_error 50.0%\n",
      "Epoch: 5608 Loss: 1.7020076513290405  acc_train_error 48.8375%  acc_test_error 50.0%\n",
      "Epoch: 5609 Loss: 1.7013894319534302  acc_train_error 48.8375%  acc_test_error 50.0%\n",
      "Epoch: 5610 Loss: 1.700512409210205  acc_train_error 48.8375%  acc_test_error 50.0%\n",
      "Epoch: 5611 Loss: 1.6997922658920288  acc_train_error 48.8375%  acc_test_error 50.0%\n",
      "Epoch: 5612 Loss: 1.6989713907241821  acc_train_error 48.8375%  acc_test_error 50.0%\n",
      "Epoch: 5613 Loss: 1.6982314586639404  acc_train_error 48.8375%  acc_test_error 50.0%\n",
      "Epoch: 5614 Loss: 1.6974232196807861  acc_train_error 48.8375%  acc_test_error 50.0%\n",
      "Epoch: 5615 Loss: 1.6966919898986816  acc_train_error 48.8375%  acc_test_error 50.0%\n",
      "Epoch: 5616 Loss: 1.6958458423614502  acc_train_error 48.8375%  acc_test_error 50.0%\n",
      "Epoch: 5617 Loss: 1.6951829195022583  acc_train_error 48.8375%  acc_test_error 50.0%\n",
      "Epoch: 5618 Loss: 1.6943117380142212  acc_train_error 48.8375%  acc_test_error 50.0%\n",
      "Epoch: 5619 Loss: 1.6935877799987793  acc_train_error 48.8375%  acc_test_error 50.0%\n",
      "Epoch: 5620 Loss: 1.6928112506866455  acc_train_error 48.8375%  acc_test_error 50.0%\n",
      "Epoch: 5621 Loss: 1.6920586824417114  acc_train_error 48.8375%  acc_test_error 50.0%\n",
      "Epoch: 5622 Loss: 1.691263198852539  acc_train_error 48.8375%  acc_test_error 50.0%\n",
      "Epoch: 5623 Loss: 1.6905176639556885  acc_train_error 48.8375%  acc_test_error 50.0%\n",
      "Epoch: 5624 Loss: 1.689719796180725  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5625 Loss: 1.6889753341674805  acc_train_error 48.8375%  acc_test_error 50.0%\n",
      "Epoch: 5626 Loss: 1.6881941556930542  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5627 Loss: 1.6873464584350586  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5628 Loss: 1.6867330074310303  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5629 Loss: 1.6858301162719727  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5630 Loss: 1.6851319074630737  acc_train_error 48.8375%  acc_test_error 50.0%\n",
      "Epoch: 5631 Loss: 1.6843551397323608  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5632 Loss: 1.6836018562316895  acc_train_error 48.8375%  acc_test_error 50.0%\n",
      "Epoch: 5633 Loss: 1.682820439338684  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5634 Loss: 1.6820626258850098  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5635 Loss: 1.6812852621078491  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5636 Loss: 1.6805226802825928  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5637 Loss: 1.6797564029693604  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5638 Loss: 1.6789848804473877  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5639 Loss: 1.6782341003417969  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5640 Loss: 1.6774101257324219  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5641 Loss: 1.6767425537109375  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5642 Loss: 1.675899624824524  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5643 Loss: 1.6752041578292847  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5644 Loss: 1.6743810176849365  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5645 Loss: 1.6736639738082886  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5646 Loss: 1.672873854637146  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5647 Loss: 1.6720486879348755  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5648 Loss: 1.6714280843734741  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5649 Loss: 1.670547604560852  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5650 Loss: 1.6698874235153198  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5651 Loss: 1.6690373420715332  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5652 Loss: 1.6683496236801147  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5653 Loss: 1.667534589767456  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5654 Loss: 1.6667184829711914  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5655 Loss: 1.6661157608032227  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5656 Loss: 1.6652251482009888  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5657 Loss: 1.664579153060913  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5658 Loss: 1.663719892501831  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5659 Loss: 1.66304349899292  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5660 Loss: 1.6622189283370972  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5661 Loss: 1.661495566368103  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5662 Loss: 1.6607226133346558  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5663 Loss: 1.6599128246307373  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5664 Loss: 1.6592965126037598  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5665 Loss: 1.6584136486053467  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5666 Loss: 1.6577577590942383  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5667 Loss: 1.6569207906723022  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5668 Loss: 1.6562250852584839  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5669 Loss: 1.6554330587387085  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5670 Loss: 1.6546239852905273  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5671 Loss: 1.6540111303329468  acc_train_error 48.8375%  acc_test_error 50.0%\n",
      "Epoch: 5672 Loss: 1.6531476974487305  acc_train_error 48.8375%  acc_test_error 50.0%\n",
      "Epoch: 5673 Loss: 1.6524747610092163  acc_train_error 48.8375%  acc_test_error 50.0%\n",
      "Epoch: 5674 Loss: 1.651660442352295  acc_train_error 48.8375%  acc_test_error 50.0%\n",
      "Epoch: 5675 Loss: 1.6509428024291992  acc_train_error 48.8375%  acc_test_error 50.0%\n",
      "Epoch: 5676 Loss: 1.6501740217208862  acc_train_error 48.8375%  acc_test_error 50.0%\n",
      "Epoch: 5677 Loss: 1.6494139432907104  acc_train_error 48.8375%  acc_test_error 50.0%\n",
      "Epoch: 5678 Loss: 1.6486884355545044  acc_train_error 48.8375%  acc_test_error 50.0%\n",
      "Epoch: 5679 Loss: 1.647888422012329  acc_train_error 48.8375%  acc_test_error 50.0%\n",
      "Epoch: 5680 Loss: 1.6472035646438599  acc_train_error 48.8375%  acc_test_error 50.0%\n",
      "Epoch: 5681 Loss: 1.6464204788208008  acc_train_error 48.8375%  acc_test_error 50.0%\n",
      "Epoch: 5682 Loss: 1.6456761360168457  acc_train_error 48.8375%  acc_test_error 50.0%\n",
      "Epoch: 5683 Loss: 1.6449425220489502  acc_train_error 48.8375%  acc_test_error 50.0%\n",
      "Epoch: 5684 Loss: 1.6441287994384766  acc_train_error 48.8375%  acc_test_error 50.0%\n",
      "Epoch: 5685 Loss: 1.6434468030929565  acc_train_error 48.8375%  acc_test_error 50.0%\n",
      "Epoch: 5686 Loss: 1.6426663398742676  acc_train_error 48.8375%  acc_test_error 50.0%\n",
      "Epoch: 5687 Loss: 1.6419559717178345  acc_train_error 48.8375%  acc_test_error 50.0%\n",
      "Epoch: 5688 Loss: 1.6411950588226318  acc_train_error 48.8375%  acc_test_error 50.0%\n",
      "Epoch: 5689 Loss: 1.6404335498809814  acc_train_error 48.8375%  acc_test_error 50.0%\n",
      "Epoch: 5690 Loss: 1.6397221088409424  acc_train_error 48.8375%  acc_test_error 50.0%\n",
      "Epoch: 5691 Loss: 1.638897180557251  acc_train_error 48.8375%  acc_test_error 50.0%\n",
      "Epoch: 5692 Loss: 1.6382173299789429  acc_train_error 48.85%  acc_test_error 50.0%\n",
      "Epoch: 5693 Loss: 1.6374731063842773  acc_train_error 48.8375%  acc_test_error 50.0%\n",
      "Epoch: 5694 Loss: 1.6367031335830688  acc_train_error 48.85%  acc_test_error 50.0%\n",
      "Epoch: 5695 Loss: 1.6360065937042236  acc_train_error 48.8375%  acc_test_error 50.0%\n",
      "Epoch: 5696 Loss: 1.6351631879806519  acc_train_error 48.8375%  acc_test_error 50.0%\n",
      "Epoch: 5697 Loss: 1.6345642805099487  acc_train_error 48.8375%  acc_test_error 50.0%\n",
      "Epoch: 5698 Loss: 1.6337032318115234  acc_train_error 48.8375%  acc_test_error 50.0%\n",
      "Epoch: 5699 Loss: 1.6330406665802002  acc_train_error 48.8375%  acc_test_error 50.0%\n",
      "Epoch: 5700 Loss: 1.6322424411773682  acc_train_error 48.8375%  acc_test_error 50.0%\n",
      "Epoch: 5701 Loss: 1.6315193176269531  acc_train_error 48.8375%  acc_test_error 50.0%\n",
      "Epoch: 5702 Loss: 1.6307852268218994  acc_train_error 48.8375%  acc_test_error 50.0%\n",
      "Epoch: 5703 Loss: 1.629999041557312  acc_train_error 48.8375%  acc_test_error 50.0%\n",
      "Epoch: 5704 Loss: 1.6293283700942993  acc_train_error 48.8375%  acc_test_error 50.0%\n",
      "Epoch: 5705 Loss: 1.6285468339920044  acc_train_error 48.8375%  acc_test_error 50.0%\n",
      "Epoch: 5706 Loss: 1.6277880668640137  acc_train_error 48.85%  acc_test_error 50.0%\n",
      "Epoch: 5707 Loss: 1.627099633216858  acc_train_error 48.8375%  acc_test_error 50.0%\n",
      "Epoch: 5708 Loss: 1.6262787580490112  acc_train_error 48.8375%  acc_test_error 50.0%\n",
      "Epoch: 5709 Loss: 1.6255886554718018  acc_train_error 48.85%  acc_test_error 50.0%\n",
      "Epoch: 5710 Loss: 1.624875545501709  acc_train_error 48.85%  acc_test_error 50.0%\n",
      "Epoch: 5711 Loss: 1.6240403652191162  acc_train_error 48.8375%  acc_test_error 50.0%\n",
      "Epoch: 5712 Loss: 1.6234675645828247  acc_train_error 48.85%  acc_test_error 50.0%\n",
      "Epoch: 5713 Loss: 1.6225954294204712  acc_train_error 48.85%  acc_test_error 50.0%\n",
      "Epoch: 5714 Loss: 1.6219478845596313  acc_train_error 48.85%  acc_test_error 50.0%\n",
      "Epoch: 5715 Loss: 1.6211488246917725  acc_train_error 48.85%  acc_test_error 50.0%\n",
      "Epoch: 5716 Loss: 1.6204293966293335  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5717 Loss: 1.6197059154510498  acc_train_error 48.85%  acc_test_error 50.0%\n",
      "Epoch: 5718 Loss: 1.6189178228378296  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5719 Loss: 1.6182587146759033  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5720 Loss: 1.617458701133728  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5721 Loss: 1.6167216300964355  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5722 Loss: 1.6160504817962646  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5723 Loss: 1.6152225732803345  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5724 Loss: 1.6146069765090942  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5725 Loss: 1.613787293434143  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5726 Loss: 1.6130918264389038  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5727 Loss: 1.6123534440994263  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5728 Loss: 1.6115785837173462  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5729 Loss: 1.6109226942062378  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5730 Loss: 1.6101213693618774  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5731 Loss: 1.6093878746032715  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5732 Loss: 1.6087292432785034  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5733 Loss: 1.6079049110412598  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5734 Loss: 1.607282042503357  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5735 Loss: 1.6064796447753906  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5736 Loss: 1.605769395828247  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5737 Loss: 1.6050562858581543  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5738 Loss: 1.6042876243591309  acc_train_error 48.85%  acc_test_error 50.0%\n",
      "Epoch: 5739 Loss: 1.6036297082901  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5740 Loss: 1.6028379201889038  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5741 Loss: 1.6021219491958618  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5742 Loss: 1.601415991783142  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5743 Loss: 1.600633978843689  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5744 Loss: 1.59999418258667  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5745 Loss: 1.5991936922073364  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5746 Loss: 1.5985089540481567  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5747 Loss: 1.597776174545288  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5748 Loss: 1.5970072746276855  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5749 Loss: 1.5963612794876099  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5750 Loss: 1.5955486297607422  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5751 Loss: 1.594910740852356  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5752 Loss: 1.5941390991210938  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5753 Loss: 1.5934019088745117  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5754 Loss: 1.5927313566207886  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5755 Loss: 1.5919533967971802  acc_train_error 48.85%  acc_test_error 50.0%\n",
      "Epoch: 5756 Loss: 1.5912723541259766  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5757 Loss: 1.5905338525772095  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5758 Loss: 1.5897737741470337  acc_train_error 48.875%  acc_test_error 50.0%\n",
      "Epoch: 5759 Loss: 1.5891289710998535  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5760 Loss: 1.5883325338363647  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5761 Loss: 1.5876491069793701  acc_train_error 48.875%  acc_test_error 50.0%\n",
      "Epoch: 5762 Loss: 1.5869418382644653  acc_train_error 48.875%  acc_test_error 50.0%\n",
      "Epoch: 5763 Loss: 1.586132287979126  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5764 Loss: 1.5855696201324463  acc_train_error 48.875%  acc_test_error 50.0%\n",
      "Epoch: 5765 Loss: 1.5847636461257935  acc_train_error 48.875%  acc_test_error 50.0%\n",
      "Epoch: 5766 Loss: 1.5840646028518677  acc_train_error 48.875%  acc_test_error 50.0%\n",
      "Epoch: 5767 Loss: 1.5832878351211548  acc_train_error 48.875%  acc_test_error 50.0%\n",
      "Epoch: 5768 Loss: 1.5826343297958374  acc_train_error 48.875%  acc_test_error 50.0%\n",
      "Epoch: 5769 Loss: 1.5818899869918823  acc_train_error 48.875%  acc_test_error 50.0%\n",
      "Epoch: 5770 Loss: 1.5811421871185303  acc_train_error 48.875%  acc_test_error 50.0%\n",
      "Epoch: 5771 Loss: 1.5804961919784546  acc_train_error 48.875%  acc_test_error 50.0%\n",
      "Epoch: 5772 Loss: 1.5796939134597778  acc_train_error 48.875%  acc_test_error 50.0%\n",
      "Epoch: 5773 Loss: 1.57902991771698  acc_train_error 48.875%  acc_test_error 50.0%\n",
      "Epoch: 5774 Loss: 1.5783230066299438  acc_train_error 48.875%  acc_test_error 50.0%\n",
      "Epoch: 5775 Loss: 1.5775084495544434  acc_train_error 48.875%  acc_test_error 50.0%\n",
      "Epoch: 5776 Loss: 1.5769129991531372  acc_train_error 48.875%  acc_test_error 50.0%\n",
      "Epoch: 5777 Loss: 1.5761586427688599  acc_train_error 48.875%  acc_test_error 50.0%\n",
      "Epoch: 5778 Loss: 1.5754233598709106  acc_train_error 48.875%  acc_test_error 50.0%\n",
      "Epoch: 5779 Loss: 1.5747692584991455  acc_train_error 48.875%  acc_test_error 50.0%\n",
      "Epoch: 5780 Loss: 1.573961615562439  acc_train_error 48.875%  acc_test_error 50.0%\n",
      "Epoch: 5781 Loss: 1.5733628273010254  acc_train_error 48.875%  acc_test_error 50.0%\n",
      "Epoch: 5782 Loss: 1.572515845298767  acc_train_error 48.875%  acc_test_error 50.0%\n",
      "Epoch: 5783 Loss: 1.5719175338745117  acc_train_error 48.875%  acc_test_error 50.0%\n",
      "Epoch: 5784 Loss: 1.5711005926132202  acc_train_error 48.875%  acc_test_error 50.0%\n",
      "Epoch: 5785 Loss: 1.570449709892273  acc_train_error 48.875%  acc_test_error 50.0%\n",
      "Epoch: 5786 Loss: 1.569713830947876  acc_train_error 48.875%  acc_test_error 50.0%\n",
      "Epoch: 5787 Loss: 1.569029450416565  acc_train_error 48.875%  acc_test_error 50.0%\n",
      "Epoch: 5788 Loss: 1.5682820081710815  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5789 Loss: 1.5675649642944336  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5790 Loss: 1.5668597221374512  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5791 Loss: 1.5661457777023315  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5792 Loss: 1.5654479265213013  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5793 Loss: 1.5647538900375366  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5794 Loss: 1.5640414953231812  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5795 Loss: 1.5632635354995728  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5796 Loss: 1.5626581907272339  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5797 Loss: 1.5618784427642822  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5798 Loss: 1.5612032413482666  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5799 Loss: 1.5604681968688965  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5800 Loss: 1.5597840547561646  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5801 Loss: 1.5590740442276  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5802 Loss: 1.5583974123001099  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5803 Loss: 1.5576727390289307  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5804 Loss: 1.5568991899490356  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5805 Loss: 1.5563020706176758  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5806 Loss: 1.55552339553833  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5807 Loss: 1.5548813343048096  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5808 Loss: 1.554123878479004  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5809 Loss: 1.5534439086914062  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5810 Loss: 1.552727460861206  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5811 Loss: 1.5520154237747192  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5812 Loss: 1.5513367652893066  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5813 Loss: 1.5506223440170288  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5814 Loss: 1.54993736743927  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5815 Loss: 1.5491704940795898  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5816 Loss: 1.5485624074935913  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5817 Loss: 1.5477983951568604  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5818 Loss: 1.5471197366714478  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5819 Loss: 1.5464143753051758  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5820 Loss: 1.545735478401184  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5821 Loss: 1.5450122356414795  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5822 Loss: 1.5443023443222046  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5823 Loss: 1.5436254739761353  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5824 Loss: 1.542863368988037  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5825 Loss: 1.542243480682373  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5826 Loss: 1.5415079593658447  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5827 Loss: 1.5408488512039185  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5828 Loss: 1.5400937795639038  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5829 Loss: 1.5394463539123535  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5830 Loss: 1.5387150049209595  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5831 Loss: 1.5380547046661377  acc_train_error 48.8625%  acc_test_error 50.0%\n",
      "Epoch: 5832 Loss: 1.5373317003250122  acc_train_error 48.85%  acc_test_error 50.0%\n",
      "Epoch: 5833 Loss: 1.5366225242614746  acc_train_error 48.85%  acc_test_error 50.0%\n",
      "Epoch: 5834 Loss: 1.535943627357483  acc_train_error 48.85%  acc_test_error 50.0%\n",
      "Epoch: 5835 Loss: 1.5352340936660767  acc_train_error 48.85%  acc_test_error 50.0%\n",
      "Epoch: 5836 Loss: 1.5345618724822998  acc_train_error 48.85%  acc_test_error 50.0%\n",
      "Epoch: 5837 Loss: 1.5338340997695923  acc_train_error 48.85%  acc_test_error 50.0%\n",
      "Epoch: 5838 Loss: 1.5331809520721436  acc_train_error 48.85%  acc_test_error 50.0%\n",
      "Epoch: 5839 Loss: 1.5324242115020752  acc_train_error 48.85%  acc_test_error 50.0%\n",
      "Epoch: 5840 Loss: 1.5317963361740112  acc_train_error 48.85%  acc_test_error 50.0%\n",
      "Epoch: 5841 Loss: 1.5310786962509155  acc_train_error 48.85%  acc_test_error 50.0%\n",
      "Epoch: 5842 Loss: 1.5304033756256104  acc_train_error 48.85%  acc_test_error 50.0%\n",
      "Epoch: 5843 Loss: 1.5296930074691772  acc_train_error 48.85%  acc_test_error 50.0%\n",
      "Epoch: 5844 Loss: 1.528939962387085  acc_train_error 48.8375%  acc_test_error 50.0%\n",
      "Epoch: 5845 Loss: 1.5283466577529907  acc_train_error 48.85%  acc_test_error 50.0%\n",
      "Epoch: 5846 Loss: 1.5275975465774536  acc_train_error 48.8375%  acc_test_error 50.0%\n",
      "Epoch: 5847 Loss: 1.526949405670166  acc_train_error 48.8375%  acc_test_error 50.0%\n",
      "Epoch: 5848 Loss: 1.5262335538864136  acc_train_error 48.8375%  acc_test_error 50.0%\n",
      "Epoch: 5849 Loss: 1.5255571603775024  acc_train_error 48.8375%  acc_test_error 50.0%\n",
      "Epoch: 5850 Loss: 1.5248665809631348  acc_train_error 48.8375%  acc_test_error 50.0%\n",
      "Epoch: 5851 Loss: 1.5241796970367432  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5852 Loss: 1.523486852645874  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5853 Loss: 1.5227257013320923  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5854 Loss: 1.5221364498138428  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5855 Loss: 1.521385908126831  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5856 Loss: 1.5207587480545044  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5857 Loss: 1.5200088024139404  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5858 Loss: 1.5193333625793457  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5859 Loss: 1.5186619758605957  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5860 Loss: 1.5179786682128906  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5861 Loss: 1.517283320426941  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5862 Loss: 1.5165400505065918  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5863 Loss: 1.5159399509429932  acc_train_error 48.825%  acc_test_error 50.0%\n",
      "Epoch: 5864 Loss: 1.5152173042297363  acc_train_error 48.8%  acc_test_error 50.0%\n",
      "Epoch: 5865 Loss: 1.514566421508789  acc_train_error 48.8%  acc_test_error 50.0%\n",
      "Epoch: 5866 Loss: 1.5138418674468994  acc_train_error 48.8%  acc_test_error 50.0%\n",
      "Epoch: 5867 Loss: 1.5131030082702637  acc_train_error 48.8%  acc_test_error 50.0%\n",
      "Epoch: 5868 Loss: 1.5125203132629395  acc_train_error 48.8%  acc_test_error 50.0%\n",
      "Epoch: 5869 Loss: 1.5117831230163574  acc_train_error 48.8%  acc_test_error 50.0%\n",
      "Epoch: 5870 Loss: 1.511155128479004  acc_train_error 48.8%  acc_test_error 50.0%\n",
      "Epoch: 5871 Loss: 1.5104142427444458  acc_train_error 48.8%  acc_test_error 50.0%\n",
      "Epoch: 5872 Loss: 1.5097473859786987  acc_train_error 48.8%  acc_test_error 50.0%\n",
      "Epoch: 5873 Loss: 1.5090850591659546  acc_train_error 48.8%  acc_test_error 50.0%\n",
      "Epoch: 5874 Loss: 1.508385181427002  acc_train_error 48.8%  acc_test_error 50.0%\n",
      "Epoch: 5875 Loss: 1.5077210664749146  acc_train_error 48.8%  acc_test_error 50.0%\n",
      "Epoch: 5876 Loss: 1.5069749355316162  acc_train_error 48.8%  acc_test_error 50.0%\n",
      "Epoch: 5877 Loss: 1.5063525438308716  acc_train_error 48.8%  acc_test_error 50.0%\n",
      "Epoch: 5878 Loss: 1.5056723356246948  acc_train_error 48.7875%  acc_test_error 50.0%\n",
      "Epoch: 5879 Loss: 1.5049834251403809  acc_train_error 48.7875%  acc_test_error 50.0%\n",
      "Epoch: 5880 Loss: 1.5043127536773682  acc_train_error 48.7875%  acc_test_error 50.0%\n",
      "Epoch: 5881 Loss: 1.503558874130249  acc_train_error 48.7875%  acc_test_error 50.0%\n",
      "Epoch: 5882 Loss: 1.5029830932617188  acc_train_error 48.7875%  acc_test_error 50.0%\n",
      "Epoch: 5883 Loss: 1.5022510290145874  acc_train_error 48.7875%  acc_test_error 50.0%\n",
      "Epoch: 5884 Loss: 1.5016212463378906  acc_train_error 48.7875%  acc_test_error 50.0%\n",
      "Epoch: 5885 Loss: 1.5009005069732666  acc_train_error 48.775%  acc_test_error 50.0%\n",
      "Epoch: 5886 Loss: 1.5001674890518188  acc_train_error 48.775%  acc_test_error 50.0%\n",
      "Epoch: 5887 Loss: 1.4995856285095215  acc_train_error 48.775%  acc_test_error 50.0%\n",
      "Epoch: 5888 Loss: 1.4988688230514526  acc_train_error 48.775%  acc_test_error 50.0%\n",
      "Epoch: 5889 Loss: 1.4982213973999023  acc_train_error 48.775%  acc_test_error 50.0%\n",
      "Epoch: 5890 Loss: 1.4975132942199707  acc_train_error 48.7625%  acc_test_error 50.0%\n",
      "Epoch: 5891 Loss: 1.49678635597229  acc_train_error 48.7625%  acc_test_error 50.0%\n",
      "Epoch: 5892 Loss: 1.4962480068206787  acc_train_error 48.7625%  acc_test_error 50.0%\n",
      "Epoch: 5893 Loss: 1.4954594373703003  acc_train_error 48.7625%  acc_test_error 50.0%\n",
      "Epoch: 5894 Loss: 1.4948360919952393  acc_train_error 48.7625%  acc_test_error 50.0%\n",
      "Epoch: 5895 Loss: 1.494154691696167  acc_train_error 48.7625%  acc_test_error 50.0%\n",
      "Epoch: 5896 Loss: 1.4934810400009155  acc_train_error 48.7625%  acc_test_error 50.0%\n",
      "Epoch: 5897 Loss: 1.4928021430969238  acc_train_error 48.7625%  acc_test_error 50.0%\n",
      "Epoch: 5898 Loss: 1.4920638799667358  acc_train_error 48.7625%  acc_test_error 50.0%\n",
      "Epoch: 5899 Loss: 1.491501808166504  acc_train_error 48.7625%  acc_test_error 50.0%\n",
      "Epoch: 5900 Loss: 1.4907419681549072  acc_train_error 48.7625%  acc_test_error 50.0%\n",
      "Epoch: 5901 Loss: 1.4901059865951538  acc_train_error 48.7625%  acc_test_error 50.0%\n",
      "Epoch: 5902 Loss: 1.4894225597381592  acc_train_error 48.7375%  acc_test_error 50.0%\n",
      "Epoch: 5903 Loss: 1.488747239112854  acc_train_error 48.7375%  acc_test_error 50.0%\n",
      "Epoch: 5904 Loss: 1.4880863428115845  acc_train_error 48.7375%  acc_test_error 50.0%\n",
      "Epoch: 5905 Loss: 1.4873592853546143  acc_train_error 48.7375%  acc_test_error 50.0%\n",
      "Epoch: 5906 Loss: 1.4867315292358398  acc_train_error 48.7375%  acc_test_error 50.0%\n",
      "Epoch: 5907 Loss: 1.4860717058181763  acc_train_error 48.7375%  acc_test_error 50.0%\n",
      "Epoch: 5908 Loss: 1.4853838682174683  acc_train_error 48.7375%  acc_test_error 50.0%\n",
      "Epoch: 5909 Loss: 1.4847201108932495  acc_train_error 48.7375%  acc_test_error 50.0%\n",
      "Epoch: 5910 Loss: 1.4839988946914673  acc_train_error 48.725%  acc_test_error 50.0%\n",
      "Epoch: 5911 Loss: 1.4833871126174927  acc_train_error 48.7375%  acc_test_error 50.0%\n",
      "Epoch: 5912 Loss: 1.4827369451522827  acc_train_error 48.725%  acc_test_error 50.0%\n",
      "Epoch: 5913 Loss: 1.4820324182510376  acc_train_error 48.725%  acc_test_error 50.0%\n",
      "Epoch: 5914 Loss: 1.4813894033432007  acc_train_error 48.725%  acc_test_error 50.0%\n",
      "Epoch: 5915 Loss: 1.4806581735610962  acc_train_error 48.725%  acc_test_error 50.0%\n",
      "Epoch: 5916 Loss: 1.4800738096237183  acc_train_error 48.725%  acc_test_error 50.0%\n",
      "Epoch: 5917 Loss: 1.479353904724121  acc_train_error 48.725%  acc_test_error 50.0%\n",
      "Epoch: 5918 Loss: 1.4786821603775024  acc_train_error 48.725%  acc_test_error 50.0%\n",
      "Epoch: 5919 Loss: 1.4780393838882446  acc_train_error 48.7125%  acc_test_error 50.0%\n",
      "Epoch: 5920 Loss: 1.4773502349853516  acc_train_error 48.7125%  acc_test_error 50.0%\n",
      "Epoch: 5921 Loss: 1.4767154455184937  acc_train_error 48.7%  acc_test_error 50.0%\n",
      "Epoch: 5922 Loss: 1.4759912490844727  acc_train_error 48.7%  acc_test_error 50.0%\n",
      "Epoch: 5923 Loss: 1.475365161895752  acc_train_error 48.7%  acc_test_error 50.0%\n",
      "Epoch: 5924 Loss: 1.4747244119644165  acc_train_error 48.7%  acc_test_error 50.0%\n",
      "Epoch: 5925 Loss: 1.4740285873413086  acc_train_error 48.7%  acc_test_error 50.0%\n",
      "Epoch: 5926 Loss: 1.4733917713165283  acc_train_error 48.7%  acc_test_error 50.0%\n",
      "Epoch: 5927 Loss: 1.4726643562316895  acc_train_error 48.7%  acc_test_error 50.0%\n",
      "Epoch: 5928 Loss: 1.4720854759216309  acc_train_error 48.7%  acc_test_error 50.0%\n",
      "Epoch: 5929 Loss: 1.4713687896728516  acc_train_error 48.7%  acc_test_error 50.0%\n",
      "Epoch: 5930 Loss: 1.4707287549972534  acc_train_error 48.7%  acc_test_error 50.0%\n",
      "Epoch: 5931 Loss: 1.4700703620910645  acc_train_error 48.7%  acc_test_error 50.0%\n",
      "Epoch: 5932 Loss: 1.469396710395813  acc_train_error 48.7%  acc_test_error 50.0%\n",
      "Epoch: 5933 Loss: 1.4687641859054565  acc_train_error 48.7%  acc_test_error 50.0%\n",
      "Epoch: 5934 Loss: 1.46803617477417  acc_train_error 48.675%  acc_test_error 50.0%\n",
      "Epoch: 5935 Loss: 1.4674203395843506  acc_train_error 48.675%  acc_test_error 50.0%\n",
      "Epoch: 5936 Loss: 1.4667738676071167  acc_train_error 48.675%  acc_test_error 50.0%\n",
      "Epoch: 5937 Loss: 1.466081976890564  acc_train_error 48.675%  acc_test_error 50.0%\n",
      "Epoch: 5938 Loss: 1.4654475450515747  acc_train_error 48.675%  acc_test_error 50.0%\n",
      "Epoch: 5939 Loss: 1.4647339582443237  acc_train_error 48.675%  acc_test_error 50.0%\n",
      "Epoch: 5940 Loss: 1.464196801185608  acc_train_error 48.675%  acc_test_error 50.0%\n",
      "Epoch: 5941 Loss: 1.463439702987671  acc_train_error 48.675%  acc_test_error 50.0%\n",
      "Epoch: 5942 Loss: 1.4627480506896973  acc_train_error 48.675%  acc_test_error 50.0%\n",
      "Epoch: 5943 Loss: 1.4621734619140625  acc_train_error 48.675%  acc_test_error 50.0%\n",
      "Epoch: 5944 Loss: 1.4614932537078857  acc_train_error 48.675%  acc_test_error 50.0%\n",
      "Epoch: 5945 Loss: 1.460823893547058  acc_train_error 48.6625%  acc_test_error 50.0%\n",
      "Epoch: 5946 Loss: 1.460195541381836  acc_train_error 48.6625%  acc_test_error 50.0%\n",
      "Epoch: 5947 Loss: 1.4594694375991821  acc_train_error 48.6625%  acc_test_error 50.0%\n",
      "Epoch: 5948 Loss: 1.458876371383667  acc_train_error 48.6625%  acc_test_error 50.0%\n",
      "Epoch: 5949 Loss: 1.458196759223938  acc_train_error 48.6625%  acc_test_error 50.0%\n",
      "Epoch: 5950 Loss: 1.4575756788253784  acc_train_error 48.6625%  acc_test_error 50.0%\n",
      "Epoch: 5951 Loss: 1.4568898677825928  acc_train_error 48.65%  acc_test_error 50.0%\n",
      "Epoch: 5952 Loss: 1.4561793804168701  acc_train_error 48.65%  acc_test_error 50.0%\n",
      "Epoch: 5953 Loss: 1.4556022882461548  acc_train_error 48.65%  acc_test_error 50.0%\n",
      "Epoch: 5954 Loss: 1.4549394845962524  acc_train_error 48.65%  acc_test_error 50.0%\n",
      "Epoch: 5955 Loss: 1.4542832374572754  acc_train_error 48.65%  acc_test_error 50.0%\n",
      "Epoch: 5956 Loss: 1.4536254405975342  acc_train_error 48.65%  acc_test_error 50.0%\n",
      "Epoch: 5957 Loss: 1.4529505968093872  acc_train_error 48.65%  acc_test_error 50.0%\n",
      "Epoch: 5958 Loss: 1.4523322582244873  acc_train_error 48.65%  acc_test_error 50.0%\n",
      "Epoch: 5959 Loss: 1.4516150951385498  acc_train_error 48.65%  acc_test_error 50.0%\n",
      "Epoch: 5960 Loss: 1.4510406255722046  acc_train_error 48.65%  acc_test_error 50.0%\n",
      "Epoch: 5961 Loss: 1.4503594636917114  acc_train_error 48.65%  acc_test_error 50.0%\n",
      "Epoch: 5962 Loss: 1.4497100114822388  acc_train_error 48.65%  acc_test_error 50.0%\n",
      "Epoch: 5963 Loss: 1.44906485080719  acc_train_error 48.6375%  acc_test_error 50.0%\n",
      "Epoch: 5964 Loss: 1.4483535289764404  acc_train_error 48.6375%  acc_test_error 50.0%\n",
      "Epoch: 5965 Loss: 1.4477949142456055  acc_train_error 48.6375%  acc_test_error 50.0%\n",
      "Epoch: 5966 Loss: 1.4470970630645752  acc_train_error 48.6375%  acc_test_error 50.0%\n",
      "Epoch: 5967 Loss: 1.4464287757873535  acc_train_error 48.6375%  acc_test_error 50.0%\n",
      "Epoch: 5968 Loss: 1.4458308219909668  acc_train_error 48.6375%  acc_test_error 50.0%\n",
      "Epoch: 5969 Loss: 1.4451433420181274  acc_train_error 48.6375%  acc_test_error 50.0%\n",
      "Epoch: 5970 Loss: 1.444535493850708  acc_train_error 48.6375%  acc_test_error 50.0%\n",
      "Epoch: 5971 Loss: 1.4438186883926392  acc_train_error 48.6375%  acc_test_error 50.0%\n",
      "Epoch: 5972 Loss: 1.4432430267333984  acc_train_error 48.6375%  acc_test_error 50.0%\n",
      "Epoch: 5973 Loss: 1.4425504207611084  acc_train_error 48.625%  acc_test_error 50.0%\n",
      "Epoch: 5974 Loss: 1.4418498277664185  acc_train_error 48.625%  acc_test_error 50.0%\n",
      "Epoch: 5975 Loss: 1.4412823915481567  acc_train_error 48.625%  acc_test_error 50.0%\n",
      "Epoch: 5976 Loss: 1.4406301975250244  acc_train_error 48.625%  acc_test_error 50.0%\n",
      "Epoch: 5977 Loss: 1.4399659633636475  acc_train_error 48.6125%  acc_test_error 50.0%\n",
      "Epoch: 5978 Loss: 1.4393377304077148  acc_train_error 48.6125%  acc_test_error 50.0%\n",
      "Epoch: 5979 Loss: 1.4386399984359741  acc_train_error 48.6125%  acc_test_error 50.0%\n",
      "Epoch: 5980 Loss: 1.4380574226379395  acc_train_error 48.6125%  acc_test_error 50.0%\n",
      "Epoch: 5981 Loss: 1.4373409748077393  acc_train_error 48.6125%  acc_test_error 50.0%\n",
      "Epoch: 5982 Loss: 1.4367496967315674  acc_train_error 48.6125%  acc_test_error 50.0%\n",
      "Epoch: 5983 Loss: 1.4361110925674438  acc_train_error 48.6125%  acc_test_error 50.0%\n",
      "Epoch: 5984 Loss: 1.435431957244873  acc_train_error 48.6125%  acc_test_error 50.0%\n",
      "Epoch: 5985 Loss: 1.434828519821167  acc_train_error 48.6125%  acc_test_error 50.0%\n",
      "Epoch: 5986 Loss: 1.4341278076171875  acc_train_error 48.6125%  acc_test_error 50.0%\n",
      "Epoch: 5987 Loss: 1.433531403541565  acc_train_error 48.6125%  acc_test_error 50.0%\n",
      "Epoch: 5988 Loss: 1.4328755140304565  acc_train_error 48.6125%  acc_test_error 50.0%\n",
      "Epoch: 5989 Loss: 1.4322153329849243  acc_train_error 48.6125%  acc_test_error 50.0%\n",
      "Epoch: 5990 Loss: 1.4316041469573975  acc_train_error 48.6125%  acc_test_error 50.0%\n",
      "Epoch: 5991 Loss: 1.4309052228927612  acc_train_error 48.6125%  acc_test_error 50.0%\n",
      "Epoch: 5992 Loss: 1.430335283279419  acc_train_error 48.6125%  acc_test_error 50.0%\n",
      "Epoch: 5993 Loss: 1.4296443462371826  acc_train_error 48.6%  acc_test_error 50.0%\n",
      "Epoch: 5994 Loss: 1.4289617538452148  acc_train_error 48.6%  acc_test_error 50.0%\n",
      "Epoch: 5995 Loss: 1.428375482559204  acc_train_error 48.6%  acc_test_error 50.0%\n",
      "Epoch: 5996 Loss: 1.4277431964874268  acc_train_error 48.6%  acc_test_error 50.0%\n",
      "Epoch: 5997 Loss: 1.4270720481872559  acc_train_error 48.6%  acc_test_error 50.0%\n",
      "Epoch: 5998 Loss: 1.4264557361602783  acc_train_error 48.6%  acc_test_error 50.0%\n",
      "Epoch: 5999 Loss: 1.425760269165039  acc_train_error 48.5875%  acc_test_error 50.0%\n"
     ]
    }
   ],
   "source": [
    "# Train the network #\n",
    "\n",
    "nb_of_epochs=6000\n",
    "\n",
    "batch_size=100\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for t in range(nb_of_epochs):\n",
    "    sum_loss=0\n",
    "    for b in range(0,x_variable.size(0),batch_size):\n",
    "        out = net(x_variable.narrow(0,b,batch_size))                 # input x and predict based on x\n",
    "        loss = loss_func(out, y_variable.narrow(0,b,batch_size))     # must be (1. nn output, 2. target), the target label is NOT one-hotted\n",
    "        \n",
    "        sum_loss+=loss\n",
    "        optimizer.zero_grad()   # clear gradients for next train\n",
    "        loss.backward()         # backpropagation, compute gradients\n",
    "        #print(t,loss.data[0])\n",
    "        optimizer.step()        # apply gradients\n",
    "    #print(\"Epoch:\",t,\"Loss:\",sum_loss.data[0])\n",
    "    net.eval()\n",
    "    nb_train_errors=0\n",
    "    out = net(x_variable)\n",
    "    values, indices = torch.max(out.data, 1)\n",
    "    \n",
    "    for j in range(2*nb_of_samples):\n",
    "        if indices[j]is not y_variable[j].data[0]:\n",
    "            nb_train_errors+=1\n",
    "    nb_test_errors=0\n",
    "    out_test = net(x_test_variable)\n",
    "    values_test, indices_test = torch.max(out_test.data, 1)\n",
    "    for j in range(2*nb_of_test_samples):\n",
    "        if indices_test[j]is not y_test_variable[j].data[0]:\n",
    "            nb_test_errors+=1\n",
    "            \n",
    "    net.train()\n",
    "    print(\"Epoch:\",t,\"Loss:\",sum_loss.data[0],' acc_train_error {}%'.format((100 * nb_train_errors) / (2*nb_of_samples)),\n",
    "         ' acc_test_error {}%'.format((100 * nb_test_errors) / (2*nb_of_test_samples)))\n",
    "    \n",
    "#for t in range(nb_of_epochs):\n",
    "#    \n",
    "#    out = net(x_variable)                 # input x and predict based on x\n",
    "#    loss = loss_func(out, y_variable)     # must be (1. nn output, 2. target), the target label is NOT one-hotted\n",
    "#        \n",
    "#       \n",
    "#    optimizer.zero_grad()   # clear gradients for next train\n",
    "#    loss.backward()         # backpropagation, compute gradients\n",
    "#    #print(t,loss.data[0])\n",
    "#    optimizer.step()        # apply gradients\n",
    "#    print(\"Epoch:\",t,\"Loss:\",loss.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
